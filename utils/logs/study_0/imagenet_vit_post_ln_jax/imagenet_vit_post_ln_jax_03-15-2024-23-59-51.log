python3 submission_runner.py --framework=jax --workload=imagenet_vit_post_ln --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=3173852236 --max_global_steps=186666 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_vit_post_ln/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/imagenet_vit_post_ln_jax_03-15-2024-23-59-51.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0316 00:00:11.566439 140033285822272 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax.
I0316 00:00:12.563362 140033285822272 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0316 00:00:12.564169 140033285822272 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0316 00:00:12.564315 140033285822272 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0316 00:00:12.569919 140033285822272 submission_runner.py:554] Using RNG seed 3173852236
I0316 00:00:13.659821 140033285822272 submission_runner.py:563] --- Tuning run 1/1 ---
I0316 00:00:13.660044 140033285822272 submission_runner.py:568] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1.
I0316 00:00:13.660221 140033285822272 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1/hparams.json.
I0316 00:00:13.839598 140033285822272 submission_runner.py:209] Initializing dataset.
I0316 00:00:13.855502 140033285822272 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:00:13.865468 140033285822272 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0316 00:00:14.247655 140033285822272 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:00:22.466131 140033285822272 submission_runner.py:220] Initializing model.
I0316 00:00:31.458210 140033285822272 submission_runner.py:262] Initializing optimizer.
I0316 00:00:32.420233 140033285822272 submission_runner.py:269] Initializing metrics bundle.
I0316 00:00:32.420427 140033285822272 submission_runner.py:287] Initializing checkpoint and logger.
I0316 00:00:32.421577 140033285822272 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1 with prefix checkpoint_
I0316 00:00:32.421716 140033285822272 submission_runner.py:307] Saving meta data to /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0316 00:00:32.756739 140033285822272 logger_utils.py:220] Unable to record git information. Continuing without it.
I0316 00:00:33.064836 140033285822272 submission_runner.py:311] Saving flags to /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1/flags_0.json.
I0316 00:00:33.075245 140033285822272 submission_runner.py:321] Starting training loop.
I0316 00:01:14.138068 139869720401664 logging_writer.py:48] [0] global_step=0, grad_norm=0.3938342034816742, loss=6.9077558517456055
I0316 00:01:14.155561 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:01:14.163531 140033285822272 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:01:14.172635 140033285822272 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0316 00:01:14.254874 140033285822272 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:01:31.504192 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:01:31.512259 140033285822272 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:01:31.528261 140033285822272 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0316 00:01:31.593162 140033285822272 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0316 00:01:48.860535 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:01:48.867143 140033285822272 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0316 00:01:48.874033 140033285822272 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0316 00:01:48.928765 140033285822272 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0316 00:01:54.239927 140033285822272 submission_runner.py:420] Time since start: 81.16s, 	Step: 1, 	{'train/accuracy': 0.0007617187220603228, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 41.08020734786987, 'total_duration': 81.16462087631226, 'accumulated_submission_time': 41.08020734786987, 'accumulated_eval_time': 40.084317207336426, 'accumulated_logging_time': 0}
I0316 00:01:54.256282 139836400850688 logging_writer.py:48] [1] accumulated_eval_time=40.084317, accumulated_logging_time=0, accumulated_submission_time=41.080207, global_step=1, preemption_count=0, score=41.080207, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=81.164621, train/accuracy=0.000762, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0316 00:02:16.276137 139870466991872 logging_writer.py:48] [1] global_step=1, grad_norm=0.3756982386112213, loss=6.9077558517456055
I0316 00:02:16.661754 139870475384576 logging_writer.py:48] [2] global_step=2, grad_norm=0.3727283775806427, loss=6.9077558517456055
I0316 00:02:17.056505 139870466991872 logging_writer.py:48] [3] global_step=3, grad_norm=0.3983844518661499, loss=6.907755374908447
I0316 00:02:17.451198 139870475384576 logging_writer.py:48] [4] global_step=4, grad_norm=0.38651415705680847, loss=6.907754421234131
I0316 00:02:17.847070 139870466991872 logging_writer.py:48] [5] global_step=5, grad_norm=0.3883418142795563, loss=6.907754898071289
I0316 00:02:18.248831 139870475384576 logging_writer.py:48] [6] global_step=6, grad_norm=0.3876117765903473, loss=6.907753944396973
I0316 00:02:18.646788 139870466991872 logging_writer.py:48] [7] global_step=7, grad_norm=0.3863912522792816, loss=6.907754421234131
I0316 00:02:19.039775 139870475384576 logging_writer.py:48] [8] global_step=8, grad_norm=0.381976455450058, loss=6.907753944396973
I0316 00:02:19.439713 139870466991872 logging_writer.py:48] [9] global_step=9, grad_norm=0.39094141125679016, loss=6.90775203704834
I0316 00:02:19.837753 139870475384576 logging_writer.py:48] [10] global_step=10, grad_norm=0.38759270310401917, loss=6.907751083374023
I0316 00:02:20.245109 139870466991872 logging_writer.py:48] [11] global_step=11, grad_norm=0.392534464597702, loss=6.9077558517456055
I0316 00:02:20.644135 139870475384576 logging_writer.py:48] [12] global_step=12, grad_norm=0.3960970640182495, loss=6.9077534675598145
I0316 00:02:21.043689 139870466991872 logging_writer.py:48] [13] global_step=13, grad_norm=0.38809719681739807, loss=6.907748222351074
I0316 00:02:21.447440 139870475384576 logging_writer.py:48] [14] global_step=14, grad_norm=0.374808132648468, loss=6.90775203704834
I0316 00:02:21.914649 139870466991872 logging_writer.py:48] [15] global_step=15, grad_norm=0.3880757689476013, loss=6.907755374908447
I0316 00:02:22.317076 139870475384576 logging_writer.py:48] [16] global_step=16, grad_norm=0.3722555935382843, loss=6.907750129699707
I0316 00:02:22.717270 139870466991872 logging_writer.py:48] [17] global_step=17, grad_norm=0.36764946579933167, loss=6.907749652862549
I0316 00:02:23.117752 139870475384576 logging_writer.py:48] [18] global_step=18, grad_norm=0.3859368562698364, loss=6.907754421234131
I0316 00:02:23.515083 139870466991872 logging_writer.py:48] [19] global_step=19, grad_norm=0.3734357953071594, loss=6.907746315002441
I0316 00:02:23.918158 139870475384576 logging_writer.py:48] [20] global_step=20, grad_norm=0.38179147243499756, loss=6.907746315002441
I0316 00:02:24.322252 139870466991872 logging_writer.py:48] [21] global_step=21, grad_norm=0.3887183368206024, loss=6.90773868560791
I0316 00:02:24.725409 139870475384576 logging_writer.py:48] [22] global_step=22, grad_norm=0.3929829001426697, loss=6.907731056213379
I0316 00:02:25.127587 139870466991872 logging_writer.py:48] [23] global_step=23, grad_norm=0.40158843994140625, loss=6.907745361328125
I0316 00:02:25.536915 139870475384576 logging_writer.py:48] [24] global_step=24, grad_norm=0.3835151493549347, loss=6.9077348709106445
I0316 00:02:25.939705 139870466991872 logging_writer.py:48] [25] global_step=25, grad_norm=0.38055744767189026, loss=6.907729625701904
I0316 00:02:26.342969 139870475384576 logging_writer.py:48] [26] global_step=26, grad_norm=0.388971209526062, loss=6.907727241516113
I0316 00:02:26.743848 139870466991872 logging_writer.py:48] [27] global_step=27, grad_norm=0.3871460556983948, loss=6.9077324867248535
I0316 00:02:27.143694 139870475384576 logging_writer.py:48] [28] global_step=28, grad_norm=0.39195382595062256, loss=6.9077372550964355
I0316 00:02:27.542354 139870466991872 logging_writer.py:48] [29] global_step=29, grad_norm=0.38741835951805115, loss=6.907736778259277
I0316 00:02:27.940728 139870475384576 logging_writer.py:48] [30] global_step=30, grad_norm=0.36873483657836914, loss=6.907726764678955
I0316 00:02:28.344924 139870466991872 logging_writer.py:48] [31] global_step=31, grad_norm=0.37401294708251953, loss=6.907739639282227
I0316 00:02:28.742841 139870475384576 logging_writer.py:48] [32] global_step=32, grad_norm=0.3872448205947876, loss=6.907716751098633
I0316 00:02:29.146697 139870466991872 logging_writer.py:48] [33] global_step=33, grad_norm=0.4009174108505249, loss=6.907731056213379
I0316 00:02:29.552837 139870475384576 logging_writer.py:48] [34] global_step=34, grad_norm=0.400471568107605, loss=6.907718181610107
I0316 00:02:29.956585 139870466991872 logging_writer.py:48] [35] global_step=35, grad_norm=0.38762012124061584, loss=6.907716751098633
I0316 00:02:30.357203 139870475384576 logging_writer.py:48] [36] global_step=36, grad_norm=0.3907240927219391, loss=6.907711505889893
I0316 00:02:30.757600 139870466991872 logging_writer.py:48] [37] global_step=37, grad_norm=0.3834764063358307, loss=6.907725811004639
I0316 00:02:31.157552 139870475384576 logging_writer.py:48] [38] global_step=38, grad_norm=0.39075538516044617, loss=6.907743453979492
I0316 00:02:31.559998 139870466991872 logging_writer.py:48] [39] global_step=39, grad_norm=0.3595119118690491, loss=6.90773868560791
I0316 00:02:31.968888 139870475384576 logging_writer.py:48] [40] global_step=40, grad_norm=0.3969852328300476, loss=6.9077043533325195
I0316 00:02:32.366866 139870466991872 logging_writer.py:48] [41] global_step=41, grad_norm=0.3811723291873932, loss=6.907686710357666
I0316 00:02:32.780363 139870475384576 logging_writer.py:48] [42] global_step=42, grad_norm=0.38330987095832825, loss=6.90768575668335
I0316 00:02:33.184152 139870466991872 logging_writer.py:48] [43] global_step=43, grad_norm=0.37313687801361084, loss=6.907722473144531
I0316 00:02:33.594841 139870475384576 logging_writer.py:48] [44] global_step=44, grad_norm=0.3610216975212097, loss=6.907707214355469
I0316 00:02:34.000790 139870466991872 logging_writer.py:48] [45] global_step=45, grad_norm=0.3700004816055298, loss=6.907674789428711
I0316 00:02:34.401733 139870475384576 logging_writer.py:48] [46] global_step=46, grad_norm=0.3751589357852936, loss=6.9076972007751465
I0316 00:02:34.798743 139870466991872 logging_writer.py:48] [47] global_step=47, grad_norm=0.38514575362205505, loss=6.907703399658203
I0316 00:02:35.203786 139870475384576 logging_writer.py:48] [48] global_step=48, grad_norm=0.3755865693092346, loss=6.9077229499816895
I0316 00:02:35.606493 139870466991872 logging_writer.py:48] [49] global_step=49, grad_norm=0.3890818655490875, loss=6.907654285430908
I0316 00:02:36.009911 139870475384576 logging_writer.py:48] [50] global_step=50, grad_norm=0.3641391098499298, loss=6.907707214355469
I0316 00:02:36.417762 139870466991872 logging_writer.py:48] [51] global_step=51, grad_norm=0.37825286388397217, loss=6.907679080963135
I0316 00:02:36.814741 139870475384576 logging_writer.py:48] [52] global_step=52, grad_norm=0.3994346261024475, loss=6.9076642990112305
I0316 00:02:37.213932 139870466991872 logging_writer.py:48] [53] global_step=53, grad_norm=0.3940330147743225, loss=6.90762996673584
I0316 00:02:37.617130 139870475384576 logging_writer.py:48] [54] global_step=54, grad_norm=0.36783677339553833, loss=6.907686233520508
I0316 00:02:38.019535 139870466991872 logging_writer.py:48] [55] global_step=55, grad_norm=0.3597096800804138, loss=6.9077067375183105
I0316 00:02:38.422367 139870475384576 logging_writer.py:48] [56] global_step=56, grad_norm=0.38616427779197693, loss=6.907678127288818
I0316 00:02:38.823628 139870466991872 logging_writer.py:48] [57] global_step=57, grad_norm=0.3645528554916382, loss=6.9076738357543945
I0316 00:02:39.222534 139870475384576 logging_writer.py:48] [58] global_step=58, grad_norm=0.40399906039237976, loss=6.907609939575195
I0316 00:02:39.628535 139870466991872 logging_writer.py:48] [59] global_step=59, grad_norm=0.38753125071525574, loss=6.907637119293213
I0316 00:02:40.033708 139870475384576 logging_writer.py:48] [60] global_step=60, grad_norm=0.3954210579395294, loss=6.907646656036377
I0316 00:02:40.430833 139870466991872 logging_writer.py:48] [61] global_step=61, grad_norm=0.40130117535591125, loss=6.9075727462768555
I0316 00:02:40.838682 139870475384576 logging_writer.py:48] [62] global_step=62, grad_norm=0.3826932907104492, loss=6.907632827758789
I0316 00:02:41.243902 139870466991872 logging_writer.py:48] [63] global_step=63, grad_norm=0.3523252606391907, loss=6.907651901245117
I0316 00:02:41.645392 139870475384576 logging_writer.py:48] [64] global_step=64, grad_norm=0.3976028263568878, loss=6.907646179199219
I0316 00:02:42.050686 139870466991872 logging_writer.py:48] [65] global_step=65, grad_norm=0.3846225440502167, loss=6.907635688781738
I0316 00:02:42.455766 139870475384576 logging_writer.py:48] [66] global_step=66, grad_norm=0.358576238155365, loss=6.907681941986084
I0316 00:02:42.858140 139870466991872 logging_writer.py:48] [67] global_step=67, grad_norm=0.39309802651405334, loss=6.907655715942383
I0316 00:02:43.272307 139870475384576 logging_writer.py:48] [68] global_step=68, grad_norm=0.3952833414077759, loss=6.9075469970703125
I0316 00:02:43.677933 139870466991872 logging_writer.py:48] [69] global_step=69, grad_norm=0.3775479793548584, loss=6.9075727462768555
I0316 00:02:44.077314 139870475384576 logging_writer.py:48] [70] global_step=70, grad_norm=0.37853148579597473, loss=6.907590866088867
I0316 00:02:44.478043 139870466991872 logging_writer.py:48] [71] global_step=71, grad_norm=0.3910606801509857, loss=6.907551288604736
I0316 00:02:44.875658 139870475384576 logging_writer.py:48] [72] global_step=72, grad_norm=0.38537517189979553, loss=6.9075775146484375
I0316 00:02:45.285796 139870466991872 logging_writer.py:48] [73] global_step=73, grad_norm=0.3603183925151825, loss=6.907563209533691
I0316 00:02:45.687719 139870475384576 logging_writer.py:48] [74] global_step=74, grad_norm=0.3872446119785309, loss=6.9075541496276855
I0316 00:02:46.095379 139870466991872 logging_writer.py:48] [75] global_step=75, grad_norm=0.3711696267127991, loss=6.9076337814331055
I0316 00:02:46.503122 139870475384576 logging_writer.py:48] [76] global_step=76, grad_norm=0.39352166652679443, loss=6.907537937164307
I0316 00:02:46.910634 139870466991872 logging_writer.py:48] [77] global_step=77, grad_norm=0.37241482734680176, loss=6.907571792602539
I0316 00:02:47.320080 139870475384576 logging_writer.py:48] [78] global_step=78, grad_norm=0.39632466435432434, loss=6.907477378845215
I0316 00:02:47.725515 139870466991872 logging_writer.py:48] [79] global_step=79, grad_norm=0.36467212438583374, loss=6.907602310180664
I0316 00:02:48.127052 139870475384576 logging_writer.py:48] [80] global_step=80, grad_norm=0.39542290568351746, loss=6.907540798187256
I0316 00:02:48.531691 139870466991872 logging_writer.py:48] [81] global_step=81, grad_norm=0.3710428476333618, loss=6.907440662384033
I0316 00:02:48.933456 139870475384576 logging_writer.py:48] [82] global_step=82, grad_norm=0.37729504704475403, loss=6.907524108886719
I0316 00:02:49.339848 139870466991872 logging_writer.py:48] [83] global_step=83, grad_norm=0.3981883227825165, loss=6.907421112060547
I0316 00:02:49.752156 139870475384576 logging_writer.py:48] [84] global_step=84, grad_norm=0.39913302659988403, loss=6.907473087310791
I0316 00:02:50.158516 139870466991872 logging_writer.py:48] [85] global_step=85, grad_norm=0.4009978473186493, loss=6.9074249267578125
I0316 00:02:50.557017 139870475384576 logging_writer.py:48] [86] global_step=86, grad_norm=0.3658345341682434, loss=6.907509803771973
I0316 00:02:50.957000 139870466991872 logging_writer.py:48] [87] global_step=87, grad_norm=0.37548014521598816, loss=6.907475471496582
I0316 00:02:51.363280 139870475384576 logging_writer.py:48] [88] global_step=88, grad_norm=0.3715553283691406, loss=6.907506942749023
I0316 00:02:51.763214 139870466991872 logging_writer.py:48] [89] global_step=89, grad_norm=0.39217332005500793, loss=6.907364845275879
I0316 00:02:52.170582 139870475384576 logging_writer.py:48] [90] global_step=90, grad_norm=0.3951757550239563, loss=6.907480716705322
I0316 00:02:52.574336 139870466991872 logging_writer.py:48] [91] global_step=91, grad_norm=0.3605244755744934, loss=6.9074482917785645
I0316 00:02:52.980626 139870475384576 logging_writer.py:48] [92] global_step=92, grad_norm=0.3535877466201782, loss=6.907451629638672
I0316 00:02:53.380526 139870466991872 logging_writer.py:48] [93] global_step=93, grad_norm=0.404690146446228, loss=6.907233238220215
I0316 00:02:53.780294 139870475384576 logging_writer.py:48] [94] global_step=94, grad_norm=0.40517139434814453, loss=6.9072442054748535
I0316 00:02:54.188600 139870466991872 logging_writer.py:48] [95] global_step=95, grad_norm=0.348324716091156, loss=6.907526969909668
I0316 00:02:54.591829 139870475384576 logging_writer.py:48] [96] global_step=96, grad_norm=0.3589041531085968, loss=6.907482624053955
I0316 00:02:55.005522 139870466991872 logging_writer.py:48] [97] global_step=97, grad_norm=0.4015863239765167, loss=6.907263278961182
I0316 00:02:55.413764 139870475384576 logging_writer.py:48] [98] global_step=98, grad_norm=0.36165595054626465, loss=6.907513618469238
I0316 00:02:55.813298 139870466991872 logging_writer.py:48] [99] global_step=99, grad_norm=0.41321390867233276, loss=6.9072747230529785
I0316 00:02:56.225621 139870475384576 logging_writer.py:48] [100] global_step=100, grad_norm=0.40392428636550903, loss=6.907224178314209
I0316 00:05:48.198702 139870466991872 logging_writer.py:48] [500] global_step=500, grad_norm=0.663736879825592, loss=6.8600616455078125
I0316 00:08:54.258125 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:09:05.875423 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:09:13.934720 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:09:15.753179 140033285822272 submission_runner.py:420] Time since start: 522.68s, 	Step: 926, 	{'train/accuracy': 0.006582031026482582, 'train/loss': 6.714056968688965, 'validation/accuracy': 0.006300000008195639, 'validation/loss': 6.719353675842285, 'validation/num_examples': 50000, 'test/accuracy': 0.004600000102072954, 'test/loss': 6.733641147613525, 'test/num_examples': 10000, 'score': 461.0231363773346, 'total_duration': 522.6778628826141, 'accumulated_submission_time': 461.0231363773346, 'accumulated_eval_time': 61.57937526702881, 'accumulated_logging_time': 0.02532482147216797}
I0316 00:09:15.772152 139836409243392 logging_writer.py:48] [926] accumulated_eval_time=61.579375, accumulated_logging_time=0.025325, accumulated_submission_time=461.023136, global_step=926, preemption_count=0, score=461.023136, test/accuracy=0.004600, test/loss=6.733641, test/num_examples=10000, total_duration=522.677863, train/accuracy=0.006582, train/loss=6.714057, validation/accuracy=0.006300, validation/loss=6.719354, validation/num_examples=50000
I0316 00:09:44.999123 139836417636096 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.3733290433883667, loss=6.808742523193359
I0316 00:13:21.530723 139836409243392 logging_writer.py:48] [1500] global_step=1500, grad_norm=2.105346918106079, loss=6.595977306365967
I0316 00:16:15.953275 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:16:27.592169 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:16:35.584512 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:16:37.250607 140033285822272 submission_runner.py:420] Time since start: 964.18s, 	Step: 1901, 	{'train/accuracy': 0.016679687425494194, 'train/loss': 6.3422441482543945, 'validation/accuracy': 0.01565999910235405, 'validation/loss': 6.359914302825928, 'validation/num_examples': 50000, 'test/accuracy': 0.012800000607967377, 'test/loss': 6.409088134765625, 'test/num_examples': 10000, 'score': 881.1417100429535, 'total_duration': 964.175261259079, 'accumulated_submission_time': 881.1417100429535, 'accumulated_eval_time': 82.8766758441925, 'accumulated_logging_time': 0.0546259880065918}
I0316 00:16:37.268356 139836417636096 logging_writer.py:48] [1901] accumulated_eval_time=82.876676, accumulated_logging_time=0.054626, accumulated_submission_time=881.141710, global_step=1901, preemption_count=0, score=881.141710, test/accuracy=0.012800, test/loss=6.409088, test/num_examples=10000, total_duration=964.175261, train/accuracy=0.016680, train/loss=6.342244, validation/accuracy=0.015660, validation/loss=6.359914, validation/num_examples=50000
I0316 00:17:16.309884 139836409243392 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.8527872562408447, loss=6.572420120239258
I0316 00:20:53.839626 139836417636096 logging_writer.py:48] [2500] global_step=2500, grad_norm=2.9981958866119385, loss=6.289988040924072
I0316 00:23:37.695665 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:23:49.830704 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:23:57.965974 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:23:59.637390 140033285822272 submission_runner.py:420] Time since start: 1406.56s, 	Step: 2877, 	{'train/accuracy': 0.03150390461087227, 'train/loss': 5.981964111328125, 'validation/accuracy': 0.029159998521208763, 'validation/loss': 6.014761924743652, 'validation/num_examples': 50000, 'test/accuracy': 0.02410000190138817, 'test/loss': 6.1073899269104, 'test/num_examples': 10000, 'score': 1301.505422115326, 'total_duration': 1406.5620710849762, 'accumulated_submission_time': 1301.505422115326, 'accumulated_eval_time': 104.81840634346008, 'accumulated_logging_time': 0.08502578735351562}
I0316 00:23:59.655832 139836409243392 logging_writer.py:48] [2877] accumulated_eval_time=104.818406, accumulated_logging_time=0.085026, accumulated_submission_time=1301.505422, global_step=2877, preemption_count=0, score=1301.505422, test/accuracy=0.024100, test/loss=6.107390, test/num_examples=10000, total_duration=1406.562071, train/accuracy=0.031504, train/loss=5.981964, validation/accuracy=0.029160, validation/loss=6.014762, validation/num_examples=50000
I0316 00:24:48.225124 139836417636096 logging_writer.py:48] [3000] global_step=3000, grad_norm=2.385685682296753, loss=6.676101207733154
I0316 00:28:26.200214 139836409243392 logging_writer.py:48] [3500] global_step=3500, grad_norm=3.6762969493865967, loss=6.627563953399658
I0316 00:30:59.711719 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:31:11.922576 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:31:20.026575 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:31:21.696637 140033285822272 submission_runner.py:420] Time since start: 1848.62s, 	Step: 3855, 	{'train/accuracy': 0.04957031086087227, 'train/loss': 5.680673122406006, 'validation/accuracy': 0.04731999710202217, 'validation/loss': 5.7118449211120605, 'validation/num_examples': 50000, 'test/accuracy': 0.03920000046491623, 'test/loss': 5.855755805969238, 'test/num_examples': 10000, 'score': 1721.4997999668121, 'total_duration': 1848.6213216781616, 'accumulated_submission_time': 1721.4997999668121, 'accumulated_eval_time': 126.8033504486084, 'accumulated_logging_time': 0.11359977722167969}
I0316 00:31:21.715250 139836417636096 logging_writer.py:48] [3855] accumulated_eval_time=126.803350, accumulated_logging_time=0.113600, accumulated_submission_time=1721.499800, global_step=3855, preemption_count=0, score=1721.499800, test/accuracy=0.039200, test/loss=5.855756, test/num_examples=10000, total_duration=1848.621322, train/accuracy=0.049570, train/loss=5.680673, validation/accuracy=0.047320, validation/loss=5.711845, validation/num_examples=50000
I0316 00:32:21.826791 139836409243392 logging_writer.py:48] [4000] global_step=4000, grad_norm=3.877549171447754, loss=5.921272277832031
I0316 00:36:00.819413 139836417636096 logging_writer.py:48] [4500] global_step=4500, grad_norm=3.5056729316711426, loss=6.5387773513793945
I0316 00:38:21.792718 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:38:33.815444 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:38:41.936545 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:38:43.599800 140033285822272 submission_runner.py:420] Time since start: 2290.52s, 	Step: 4824, 	{'train/accuracy': 0.06197265535593033, 'train/loss': 5.449063777923584, 'validation/accuracy': 0.06045999750494957, 'validation/loss': 5.482926845550537, 'validation/num_examples': 50000, 'test/accuracy': 0.04780000075697899, 'test/loss': 5.6592698097229, 'test/num_examples': 10000, 'score': 2141.5182423591614, 'total_duration': 2290.524486064911, 'accumulated_submission_time': 2141.5182423591614, 'accumulated_eval_time': 148.610445022583, 'accumulated_logging_time': 0.1418454647064209}
I0316 00:38:43.621641 139836409243392 logging_writer.py:48] [4824] accumulated_eval_time=148.610445, accumulated_logging_time=0.141845, accumulated_submission_time=2141.518242, global_step=4824, preemption_count=0, score=2141.518242, test/accuracy=0.047800, test/loss=5.659270, test/num_examples=10000, total_duration=2290.524486, train/accuracy=0.061973, train/loss=5.449064, validation/accuracy=0.060460, validation/loss=5.482927, validation/num_examples=50000
I0316 00:39:56.104463 139836417636096 logging_writer.py:48] [5000] global_step=5000, grad_norm=2.4057490825653076, loss=6.511286735534668
I0316 00:43:37.388892 139836409243392 logging_writer.py:48] [5500] global_step=5500, grad_norm=2.684587240219116, loss=5.762458801269531
I0316 00:45:43.640608 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:45:55.855650 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:46:03.945611 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:46:05.609762 140033285822272 submission_runner.py:420] Time since start: 2732.53s, 	Step: 5789, 	{'train/accuracy': 0.08013671636581421, 'train/loss': 5.217288494110107, 'validation/accuracy': 0.07655999809503555, 'validation/loss': 5.264044284820557, 'validation/num_examples': 50000, 'test/accuracy': 0.05620000138878822, 'test/loss': 5.48585319519043, 'test/num_examples': 10000, 'score': 2561.473810195923, 'total_duration': 2732.53444647789, 'accumulated_submission_time': 2561.473810195923, 'accumulated_eval_time': 170.5796058177948, 'accumulated_logging_time': 0.17626452445983887}
I0316 00:46:05.628213 139836417636096 logging_writer.py:48] [5789] accumulated_eval_time=170.579606, accumulated_logging_time=0.176265, accumulated_submission_time=2561.473810, global_step=5789, preemption_count=0, score=2561.473810, test/accuracy=0.056200, test/loss=5.485853, test/num_examples=10000, total_duration=2732.534446, train/accuracy=0.080137, train/loss=5.217288, validation/accuracy=0.076560, validation/loss=5.264044, validation/num_examples=50000
I0316 00:47:33.389941 139836409243392 logging_writer.py:48] [6000] global_step=6000, grad_norm=2.7999861240386963, loss=5.764077186584473
I0316 00:51:12.797288 139836417636096 logging_writer.py:48] [6500] global_step=6500, grad_norm=2.392307996749878, loss=5.517270088195801
I0316 00:53:05.743373 140033285822272 spec.py:321] Evaluating on the training split.
I0316 00:53:17.786026 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 00:53:25.816338 140033285822272 spec.py:349] Evaluating on the test split.
I0316 00:53:27.489469 140033285822272 submission_runner.py:420] Time since start: 3174.41s, 	Step: 6759, 	{'train/accuracy': 0.1013476550579071, 'train/loss': 4.993688106536865, 'validation/accuracy': 0.09341999888420105, 'validation/loss': 5.065521240234375, 'validation/num_examples': 50000, 'test/accuracy': 0.06980000436306, 'test/loss': 5.323365211486816, 'test/num_examples': 10000, 'score': 2981.527709722519, 'total_duration': 3174.414154291153, 'accumulated_submission_time': 2981.527709722519, 'accumulated_eval_time': 192.32569646835327, 'accumulated_logging_time': 0.20553112030029297}
I0316 00:53:27.508949 139836409243392 logging_writer.py:48] [6759] accumulated_eval_time=192.325696, accumulated_logging_time=0.205531, accumulated_submission_time=2981.527710, global_step=6759, preemption_count=0, score=2981.527710, test/accuracy=0.069800, test/loss=5.323365, test/num_examples=10000, total_duration=3174.414154, train/accuracy=0.101348, train/loss=4.993688, validation/accuracy=0.093420, validation/loss=5.065521, validation/num_examples=50000
I0316 00:55:08.368804 139836417636096 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.8995023965835571, loss=5.953338623046875
I0316 00:58:47.442536 139836409243392 logging_writer.py:48] [7500] global_step=7500, grad_norm=2.3726680278778076, loss=5.385939121246338
I0316 01:00:27.786553 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:00:39.845598 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:00:47.957743 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:00:49.628428 140033285822272 submission_runner.py:420] Time since start: 3616.55s, 	Step: 7728, 	{'train/accuracy': 0.11998046934604645, 'train/loss': 4.808412551879883, 'validation/accuracy': 0.11267999559640884, 'validation/loss': 4.850436687469482, 'validation/num_examples': 50000, 'test/accuracy': 0.08540000766515732, 'test/loss': 5.1297783851623535, 'test/num_examples': 10000, 'score': 3401.743551969528, 'total_duration': 3616.5531113147736, 'accumulated_submission_time': 3401.743551969528, 'accumulated_eval_time': 214.16758465766907, 'accumulated_logging_time': 0.23641633987426758}
I0316 01:00:49.647923 139836417636096 logging_writer.py:48] [7728] accumulated_eval_time=214.167585, accumulated_logging_time=0.236416, accumulated_submission_time=3401.743552, global_step=7728, preemption_count=0, score=3401.743552, test/accuracy=0.085400, test/loss=5.129778, test/num_examples=10000, total_duration=3616.553111, train/accuracy=0.119980, train/loss=4.808413, validation/accuracy=0.112680, validation/loss=4.850437, validation/num_examples=50000
I0316 01:02:44.076588 139836409243392 logging_writer.py:48] [8000] global_step=8000, grad_norm=2.4321954250335693, loss=5.259451866149902
I0316 01:06:22.913592 139836417636096 logging_writer.py:48] [8500] global_step=8500, grad_norm=2.7267894744873047, loss=5.11539888381958
I0316 01:07:49.950989 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:08:02.106780 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:08:15.202741 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:08:16.872568 140033285822272 submission_runner.py:420] Time since start: 4063.80s, 	Step: 8699, 	{'train/accuracy': 0.14232420921325684, 'train/loss': 4.569924354553223, 'validation/accuracy': 0.13220000267028809, 'validation/loss': 4.647293567657471, 'validation/num_examples': 50000, 'test/accuracy': 0.10190000385046005, 'test/loss': 4.963707447052002, 'test/num_examples': 10000, 'score': 3821.985910177231, 'total_duration': 4063.7972338199615, 'accumulated_submission_time': 3821.985910177231, 'accumulated_eval_time': 241.08913397789001, 'accumulated_logging_time': 0.26611995697021484}
I0316 01:08:16.894884 139836409243392 logging_writer.py:48] [8699] accumulated_eval_time=241.089134, accumulated_logging_time=0.266120, accumulated_submission_time=3821.985910, global_step=8699, preemption_count=0, score=3821.985910, test/accuracy=0.101900, test/loss=4.963707, test/num_examples=10000, total_duration=4063.797234, train/accuracy=0.142324, train/loss=4.569924, validation/accuracy=0.132200, validation/loss=4.647294, validation/num_examples=50000
I0316 01:10:24.229824 139836417636096 logging_writer.py:48] [9000] global_step=9000, grad_norm=2.6268692016601562, loss=5.083146572113037
I0316 01:14:04.901102 139836409243392 logging_writer.py:48] [9500] global_step=9500, grad_norm=2.0920021533966064, loss=5.5659637451171875
I0316 01:15:16.890302 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:15:28.932950 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:15:38.142295 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:15:39.813854 140033285822272 submission_runner.py:420] Time since start: 4506.74s, 	Step: 9666, 	{'train/accuracy': 0.16783203184604645, 'train/loss': 4.347902297973633, 'validation/accuracy': 0.15410000085830688, 'validation/loss': 4.429182529449463, 'validation/num_examples': 50000, 'test/accuracy': 0.11750000715255737, 'test/loss': 4.765655040740967, 'test/num_examples': 10000, 'score': 4241.9191472530365, 'total_duration': 4506.738534450531, 'accumulated_submission_time': 4241.9191472530365, 'accumulated_eval_time': 264.0126805305481, 'accumulated_logging_time': 0.30106043815612793}
I0316 01:15:39.836527 139836417636096 logging_writer.py:48] [9666] accumulated_eval_time=264.012681, accumulated_logging_time=0.301060, accumulated_submission_time=4241.919147, global_step=9666, preemption_count=0, score=4241.919147, test/accuracy=0.117500, test/loss=4.765655, test/num_examples=10000, total_duration=4506.738534, train/accuracy=0.167832, train/loss=4.347902, validation/accuracy=0.154100, validation/loss=4.429183, validation/num_examples=50000
I0316 01:18:02.064039 139836409243392 logging_writer.py:48] [10000] global_step=10000, grad_norm=2.3676891326904297, loss=5.079387664794922
I0316 01:21:41.412999 139836417636096 logging_writer.py:48] [10500] global_step=10500, grad_norm=2.8513402938842773, loss=5.1435723304748535
I0316 01:22:39.958813 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:22:52.044312 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:23:02.578686 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:23:04.237395 140033285822272 submission_runner.py:420] Time since start: 4951.16s, 	Step: 10636, 	{'train/accuracy': 0.19873046875, 'train/loss': 4.126186370849609, 'validation/accuracy': 0.1750599890947342, 'validation/loss': 4.249802589416504, 'validation/num_examples': 50000, 'test/accuracy': 0.1315000057220459, 'test/loss': 4.625553131103516, 'test/num_examples': 10000, 'score': 4661.980578184128, 'total_duration': 4951.162081241608, 'accumulated_submission_time': 4661.980578184128, 'accumulated_eval_time': 288.2912566661835, 'accumulated_logging_time': 0.3340919017791748}
I0316 01:23:04.256389 139836409243392 logging_writer.py:48] [10636] accumulated_eval_time=288.291257, accumulated_logging_time=0.334092, accumulated_submission_time=4661.980578, global_step=10636, preemption_count=0, score=4661.980578, test/accuracy=0.131500, test/loss=4.625553, test/num_examples=10000, total_duration=4951.162081, train/accuracy=0.198730, train/loss=4.126186, validation/accuracy=0.175060, validation/loss=4.249803, validation/num_examples=50000
I0316 01:25:40.018753 139836417636096 logging_writer.py:48] [11000] global_step=11000, grad_norm=2.37420654296875, loss=5.783533096313477
I0316 01:29:20.239945 139836409243392 logging_writer.py:48] [11500] global_step=11500, grad_norm=2.9659290313720703, loss=4.879312992095947
I0316 01:30:04.369719 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:30:16.568273 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:30:29.378816 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:30:31.044678 140033285822272 submission_runner.py:420] Time since start: 5397.97s, 	Step: 11602, 	{'train/accuracy': 0.22062499821186066, 'train/loss': 3.9403603076934814, 'validation/accuracy': 0.20306000113487244, 'validation/loss': 4.047501564025879, 'validation/num_examples': 50000, 'test/accuracy': 0.15280000865459442, 'test/loss': 4.449875354766846, 'test/num_examples': 10000, 'score': 5082.0325129032135, 'total_duration': 5397.969358682632, 'accumulated_submission_time': 5082.0325129032135, 'accumulated_eval_time': 314.96621322631836, 'accumulated_logging_time': 0.36377620697021484}
I0316 01:30:31.064167 139836417636096 logging_writer.py:48] [11602] accumulated_eval_time=314.966213, accumulated_logging_time=0.363776, accumulated_submission_time=5082.032513, global_step=11602, preemption_count=0, score=5082.032513, test/accuracy=0.152800, test/loss=4.449875, test/num_examples=10000, total_duration=5397.969359, train/accuracy=0.220625, train/loss=3.940360, validation/accuracy=0.203060, validation/loss=4.047502, validation/num_examples=50000
I0316 01:33:20.902376 139836409243392 logging_writer.py:48] [12000] global_step=12000, grad_norm=2.6697497367858887, loss=4.509191513061523
I0316 01:37:02.701857 139836417636096 logging_writer.py:48] [12500] global_step=12500, grad_norm=2.283820867538452, loss=5.351311206817627
I0316 01:37:31.203890 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:37:43.579053 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:37:54.547649 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:37:56.246025 140033285822272 submission_runner.py:420] Time since start: 5843.17s, 	Step: 12566, 	{'train/accuracy': 0.2492968738079071, 'train/loss': 3.7531585693359375, 'validation/accuracy': 0.2243800014257431, 'validation/loss': 3.883746385574341, 'validation/num_examples': 50000, 'test/accuracy': 0.170400008559227, 'test/loss': 4.311071395874023, 'test/num_examples': 10000, 'score': 5502.110665559769, 'total_duration': 5843.170692920685, 'accumulated_submission_time': 5502.110665559769, 'accumulated_eval_time': 340.00833344459534, 'accumulated_logging_time': 0.3936030864715576}
I0316 01:37:56.278365 139836409243392 logging_writer.py:48] [12566] accumulated_eval_time=340.008333, accumulated_logging_time=0.393603, accumulated_submission_time=5502.110666, global_step=12566, preemption_count=0, score=5502.110666, test/accuracy=0.170400, test/loss=4.311071, test/num_examples=10000, total_duration=5843.170693, train/accuracy=0.249297, train/loss=3.753159, validation/accuracy=0.224380, validation/loss=3.883746, validation/num_examples=50000
I0316 01:41:04.215811 139836417636096 logging_writer.py:48] [13000] global_step=13000, grad_norm=2.5142998695373535, loss=4.467177867889404
I0316 01:44:45.108213 139836409243392 logging_writer.py:48] [13500] global_step=13500, grad_norm=2.6672472953796387, loss=4.406020164489746
I0316 01:44:56.662820 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:45:09.266491 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:45:24.002130 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:45:25.652848 140033285822272 submission_runner.py:420] Time since start: 6292.58s, 	Step: 13528, 	{'train/accuracy': 0.27210935950279236, 'train/loss': 3.5523247718811035, 'validation/accuracy': 0.2468400001525879, 'validation/loss': 3.6852965354919434, 'validation/num_examples': 50000, 'test/accuracy': 0.18460001051425934, 'test/loss': 4.1573100090026855, 'test/num_examples': 10000, 'score': 5922.427560567856, 'total_duration': 6292.57753610611, 'accumulated_submission_time': 5922.427560567856, 'accumulated_eval_time': 368.9983401298523, 'accumulated_logging_time': 0.4434661865234375}
I0316 01:45:25.674712 139836417636096 logging_writer.py:48] [13528] accumulated_eval_time=368.998340, accumulated_logging_time=0.443466, accumulated_submission_time=5922.427561, global_step=13528, preemption_count=0, score=5922.427561, test/accuracy=0.184600, test/loss=4.157310, test/num_examples=10000, total_duration=6292.577536, train/accuracy=0.272109, train/loss=3.552325, validation/accuracy=0.246840, validation/loss=3.685297, validation/num_examples=50000
I0316 01:48:52.270058 139836409243392 logging_writer.py:48] [14000] global_step=14000, grad_norm=2.5004820823669434, loss=4.241806983947754
I0316 01:52:26.072044 140033285822272 spec.py:321] Evaluating on the training split.
I0316 01:52:39.498989 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 01:52:56.503895 140033285822272 spec.py:349] Evaluating on the test split.
I0316 01:52:58.189764 140033285822272 submission_runner.py:420] Time since start: 6745.11s, 	Step: 14478, 	{'train/accuracy': 0.2886328101158142, 'train/loss': 3.419095039367676, 'validation/accuracy': 0.2662599980831146, 'validation/loss': 3.558997392654419, 'validation/num_examples': 50000, 'test/accuracy': 0.1997000128030777, 'test/loss': 4.048617839813232, 'test/num_examples': 10000, 'score': 6342.762490987778, 'total_duration': 6745.11438536644, 'accumulated_submission_time': 6342.762490987778, 'accumulated_eval_time': 401.11600852012634, 'accumulated_logging_time': 0.47854089736938477}
I0316 01:52:58.218903 139836417636096 logging_writer.py:48] [14478] accumulated_eval_time=401.116009, accumulated_logging_time=0.478541, accumulated_submission_time=6342.762491, global_step=14478, preemption_count=0, score=6342.762491, test/accuracy=0.199700, test/loss=4.048618, test/num_examples=10000, total_duration=6745.114385, train/accuracy=0.288633, train/loss=3.419095, validation/accuracy=0.266260, validation/loss=3.558997, validation/num_examples=50000
I0316 01:53:07.230112 139836409243392 logging_writer.py:48] [14500] global_step=14500, grad_norm=2.650756359100342, loss=4.276134490966797
I0316 01:56:43.811527 139836417636096 logging_writer.py:48] [15000] global_step=15000, grad_norm=2.923889636993408, loss=4.2390055656433105
I0316 01:59:59.019975 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:00:12.329347 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:00:30.354830 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:00:32.012499 140033285822272 submission_runner.py:420] Time since start: 7198.94s, 	Step: 15440, 	{'train/accuracy': 0.31990233063697815, 'train/loss': 3.2628514766693115, 'validation/accuracy': 0.2917400002479553, 'validation/loss': 3.4116780757904053, 'validation/num_examples': 50000, 'test/accuracy': 0.22120000422000885, 'test/loss': 3.929030656814575, 'test/num_examples': 10000, 'score': 6763.496320009232, 'total_duration': 7198.937178134918, 'accumulated_submission_time': 6763.496320009232, 'accumulated_eval_time': 434.10852456092834, 'accumulated_logging_time': 0.5244593620300293}
I0316 02:00:32.033220 139836409243392 logging_writer.py:48] [15440] accumulated_eval_time=434.108525, accumulated_logging_time=0.524459, accumulated_submission_time=6763.496320, global_step=15440, preemption_count=0, score=6763.496320, test/accuracy=0.221200, test/loss=3.929031, test/num_examples=10000, total_duration=7198.937178, train/accuracy=0.319902, train/loss=3.262851, validation/accuracy=0.291740, validation/loss=3.411678, validation/num_examples=50000
I0316 02:00:55.856010 139836417636096 logging_writer.py:48] [15500] global_step=15500, grad_norm=2.3620405197143555, loss=4.395965576171875
I0316 02:04:33.947204 139836409243392 logging_writer.py:48] [16000] global_step=16000, grad_norm=2.404599189758301, loss=4.384859085083008
I0316 02:07:32.308421 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:07:46.656122 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:08:04.276907 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:08:05.933039 140033285822272 submission_runner.py:420] Time since start: 7652.86s, 	Step: 16403, 	{'train/accuracy': 0.33998045325279236, 'train/loss': 3.1379647254943848, 'validation/accuracy': 0.3125, 'validation/loss': 3.283846139907837, 'validation/num_examples': 50000, 'test/accuracy': 0.2395000159740448, 'test/loss': 3.829561948776245, 'test/num_examples': 10000, 'score': 7183.709098100662, 'total_duration': 7652.857706308365, 'accumulated_submission_time': 7183.709098100662, 'accumulated_eval_time': 467.7331323623657, 'accumulated_logging_time': 0.5573093891143799}
I0316 02:08:05.957861 139836417636096 logging_writer.py:48] [16403] accumulated_eval_time=467.733132, accumulated_logging_time=0.557309, accumulated_submission_time=7183.709098, global_step=16403, preemption_count=0, score=7183.709098, test/accuracy=0.239500, test/loss=3.829562, test/num_examples=10000, total_duration=7652.857706, train/accuracy=0.339980, train/loss=3.137965, validation/accuracy=0.312500, validation/loss=3.283846, validation/num_examples=50000
I0316 02:08:45.242818 139836409243392 logging_writer.py:48] [16500] global_step=16500, grad_norm=2.7538528442382812, loss=4.14132022857666
I0316 02:12:27.542339 139836417636096 logging_writer.py:48] [17000] global_step=17000, grad_norm=2.8053340911865234, loss=3.9863710403442383
I0316 02:15:06.022714 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:15:20.617527 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:15:36.731950 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:15:38.388734 140033285822272 submission_runner.py:420] Time since start: 8105.31s, 	Step: 17359, 	{'train/accuracy': 0.36570310592651367, 'train/loss': 2.9488189220428467, 'validation/accuracy': 0.3349599838256836, 'validation/loss': 3.1350302696228027, 'validation/num_examples': 50000, 'test/accuracy': 0.25550001859664917, 'test/loss': 3.685300588607788, 'test/num_examples': 10000, 'score': 7603.709952116013, 'total_duration': 8105.313410997391, 'accumulated_submission_time': 7603.709952116013, 'accumulated_eval_time': 500.099139213562, 'accumulated_logging_time': 0.5962083339691162}
I0316 02:15:38.411573 139836409243392 logging_writer.py:48] [17359] accumulated_eval_time=500.099139, accumulated_logging_time=0.596208, accumulated_submission_time=7603.709952, global_step=17359, preemption_count=0, score=7603.709952, test/accuracy=0.255500, test/loss=3.685301, test/num_examples=10000, total_duration=8105.313411, train/accuracy=0.365703, train/loss=2.948819, validation/accuracy=0.334960, validation/loss=3.135030, validation/num_examples=50000
I0316 02:16:37.987507 139836417636096 logging_writer.py:48] [17500] global_step=17500, grad_norm=2.6293017864227295, loss=3.980131149291992
I0316 02:20:20.089283 139836409243392 logging_writer.py:48] [18000] global_step=18000, grad_norm=2.850609302520752, loss=3.8735756874084473
I0316 02:22:38.616988 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:22:53.394989 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:23:16.183955 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:23:17.846345 140033285822272 submission_runner.py:420] Time since start: 8564.77s, 	Step: 18314, 	{'train/accuracy': 0.38001951575279236, 'train/loss': 2.8648183345794678, 'validation/accuracy': 0.3544600009918213, 'validation/loss': 3.0171849727630615, 'validation/num_examples': 50000, 'test/accuracy': 0.2752000093460083, 'test/loss': 3.5676486492156982, 'test/num_examples': 10000, 'score': 8023.856166362762, 'total_duration': 8564.771030426025, 'accumulated_submission_time': 8023.856166362762, 'accumulated_eval_time': 539.3285284042358, 'accumulated_logging_time': 0.6289534568786621}
I0316 02:23:17.867282 139836417636096 logging_writer.py:48] [18314] accumulated_eval_time=539.328528, accumulated_logging_time=0.628953, accumulated_submission_time=8023.856166, global_step=18314, preemption_count=0, score=8023.856166, test/accuracy=0.275200, test/loss=3.567649, test/num_examples=10000, total_duration=8564.771030, train/accuracy=0.380020, train/loss=2.864818, validation/accuracy=0.354460, validation/loss=3.017185, validation/num_examples=50000
I0316 02:24:34.990710 139836409243392 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.9432684183120728, loss=5.053536415100098
I0316 02:28:16.943389 139836417636096 logging_writer.py:48] [19000] global_step=19000, grad_norm=2.7596797943115234, loss=3.8240184783935547
I0316 02:30:18.143021 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:30:32.123874 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:31:02.941466 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:31:04.586007 140033285822272 submission_runner.py:420] Time since start: 9031.51s, 	Step: 19275, 	{'train/accuracy': 0.3986523449420929, 'train/loss': 2.756155014038086, 'validation/accuracy': 0.3685799837112427, 'validation/loss': 2.9221696853637695, 'validation/num_examples': 50000, 'test/accuracy': 0.2873000204563141, 'test/loss': 3.4840786457061768, 'test/num_examples': 10000, 'score': 8444.070172548294, 'total_duration': 9031.510703086853, 'accumulated_submission_time': 8444.070172548294, 'accumulated_eval_time': 585.7715458869934, 'accumulated_logging_time': 0.6613638401031494}
I0316 02:31:04.606077 139836409243392 logging_writer.py:48] [19275] accumulated_eval_time=585.771546, accumulated_logging_time=0.661364, accumulated_submission_time=8444.070173, global_step=19275, preemption_count=0, score=8444.070173, test/accuracy=0.287300, test/loss=3.484079, test/num_examples=10000, total_duration=9031.510703, train/accuracy=0.398652, train/loss=2.756155, validation/accuracy=0.368580, validation/loss=2.922170, validation/num_examples=50000
I0316 02:32:38.484169 139836417636096 logging_writer.py:48] [19500] global_step=19500, grad_norm=2.5204954147338867, loss=3.6288483142852783
I0316 02:36:18.753994 139836409243392 logging_writer.py:48] [20000] global_step=20000, grad_norm=2.74558424949646, loss=3.724900484085083
I0316 02:38:05.011740 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:38:19.445472 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:38:41.531491 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:38:43.196011 140033285822272 submission_runner.py:420] Time since start: 9490.12s, 	Step: 20240, 	{'train/accuracy': 0.41951170563697815, 'train/loss': 2.647538423538208, 'validation/accuracy': 0.3833400011062622, 'validation/loss': 2.8261804580688477, 'validation/num_examples': 50000, 'test/accuracy': 0.2948000133037567, 'test/loss': 3.4086766242980957, 'test/num_examples': 10000, 'score': 8864.412791013718, 'total_duration': 9490.120684146881, 'accumulated_submission_time': 8864.412791013718, 'accumulated_eval_time': 623.9557950496674, 'accumulated_logging_time': 0.6943995952606201}
I0316 02:38:43.223377 139836417636096 logging_writer.py:48] [20240] accumulated_eval_time=623.955795, accumulated_logging_time=0.694400, accumulated_submission_time=8864.412791, global_step=20240, preemption_count=0, score=8864.412791, test/accuracy=0.294800, test/loss=3.408677, test/num_examples=10000, total_duration=9490.120684, train/accuracy=0.419512, train/loss=2.647538, validation/accuracy=0.383340, validation/loss=2.826180, validation/num_examples=50000
I0316 02:40:33.372742 139836409243392 logging_writer.py:48] [20500] global_step=20500, grad_norm=2.5233607292175293, loss=3.5197548866271973
I0316 02:44:15.617658 139836417636096 logging_writer.py:48] [21000] global_step=21000, grad_norm=2.070809841156006, loss=4.444790840148926
I0316 02:45:43.556735 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:45:58.757478 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:46:19.915119 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:46:21.580290 140033285822272 submission_runner.py:420] Time since start: 9948.50s, 	Step: 21198, 	{'train/accuracy': 0.45726561546325684, 'train/loss': 2.4732565879821777, 'validation/accuracy': 0.40535998344421387, 'validation/loss': 2.72802472114563, 'validation/num_examples': 50000, 'test/accuracy': 0.3059000074863434, 'test/loss': 3.3493459224700928, 'test/num_examples': 10000, 'score': 9284.682085990906, 'total_duration': 9948.50497341156, 'accumulated_submission_time': 9284.682085990906, 'accumulated_eval_time': 661.9793405532837, 'accumulated_logging_time': 0.7352142333984375}
I0316 02:46:21.602397 139836409243392 logging_writer.py:48] [21198] accumulated_eval_time=661.979341, accumulated_logging_time=0.735214, accumulated_submission_time=9284.682086, global_step=21198, preemption_count=0, score=9284.682086, test/accuracy=0.305900, test/loss=3.349346, test/num_examples=10000, total_duration=9948.504973, train/accuracy=0.457266, train/loss=2.473257, validation/accuracy=0.405360, validation/loss=2.728025, validation/num_examples=50000
I0316 02:48:32.402996 139836417636096 logging_writer.py:48] [21500] global_step=21500, grad_norm=2.1810193061828613, loss=4.586575508117676
I0316 02:52:15.951390 139836409243392 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.83543860912323, loss=5.913525104522705
I0316 02:53:21.769940 140033285822272 spec.py:321] Evaluating on the training split.
I0316 02:53:36.594847 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 02:54:04.275037 140033285822272 spec.py:349] Evaluating on the test split.
I0316 02:54:05.965445 140033285822272 submission_runner.py:420] Time since start: 10412.89s, 	Step: 22149, 	{'train/accuracy': 0.4543749988079071, 'train/loss': 2.465040922164917, 'validation/accuracy': 0.41731998324394226, 'validation/loss': 2.6536571979522705, 'validation/num_examples': 50000, 'test/accuracy': 0.320900022983551, 'test/loss': 3.2446231842041016, 'test/num_examples': 10000, 'score': 9704.787395954132, 'total_duration': 10412.890138149261, 'accumulated_submission_time': 9704.787395954132, 'accumulated_eval_time': 706.1748690605164, 'accumulated_logging_time': 0.7688145637512207}
I0316 02:54:05.988477 139836417636096 logging_writer.py:48] [22149] accumulated_eval_time=706.174869, accumulated_logging_time=0.768815, accumulated_submission_time=9704.787396, global_step=22149, preemption_count=0, score=9704.787396, test/accuracy=0.320900, test/loss=3.244623, test/num_examples=10000, total_duration=10412.890138, train/accuracy=0.454375, train/loss=2.465041, validation/accuracy=0.417320, validation/loss=2.653657, validation/num_examples=50000
I0316 02:56:36.750821 139836409243392 logging_writer.py:48] [22500] global_step=22500, grad_norm=2.9624102115631104, loss=3.554938316345215
I0316 03:00:20.421520 139836417636096 logging_writer.py:48] [23000] global_step=23000, grad_norm=2.7307326793670654, loss=3.4113025665283203
I0316 03:01:06.365920 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:01:17.310005 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:01:39.954782 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:01:41.620903 140033285822272 submission_runner.py:420] Time since start: 10868.55s, 	Step: 23105, 	{'train/accuracy': 0.46406248211860657, 'train/loss': 2.4436635971069336, 'validation/accuracy': 0.428879976272583, 'validation/loss': 2.617060661315918, 'validation/num_examples': 50000, 'test/accuracy': 0.329800009727478, 'test/loss': 3.222968578338623, 'test/num_examples': 10000, 'score': 10125.104326963425, 'total_duration': 10868.545593976974, 'accumulated_submission_time': 10125.104326963425, 'accumulated_eval_time': 741.4298379421234, 'accumulated_logging_time': 0.8018918037414551}
I0316 03:01:41.641439 139836409243392 logging_writer.py:48] [23105] accumulated_eval_time=741.429838, accumulated_logging_time=0.801892, accumulated_submission_time=10125.104327, global_step=23105, preemption_count=0, score=10125.104327, test/accuracy=0.329800, test/loss=3.222969, test/num_examples=10000, total_duration=10868.545594, train/accuracy=0.464062, train/loss=2.443664, validation/accuracy=0.428880, validation/loss=2.617061, validation/num_examples=50000
I0316 03:04:31.507153 139836417636096 logging_writer.py:48] [23500] global_step=23500, grad_norm=2.667119026184082, loss=3.278367042541504
I0316 03:08:14.025318 139836409243392 logging_writer.py:48] [24000] global_step=24000, grad_norm=2.632585048675537, loss=3.574272394180298
I0316 03:08:41.819400 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:08:52.273385 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:09:17.258172 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:09:18.907429 140033285822272 submission_runner.py:420] Time since start: 11325.83s, 	Step: 24064, 	{'train/accuracy': 0.48402342200279236, 'train/loss': 2.274030923843384, 'validation/accuracy': 0.44132000207901, 'validation/loss': 2.5044198036193848, 'validation/num_examples': 50000, 'test/accuracy': 0.33740001916885376, 'test/loss': 3.1391141414642334, 'test/num_examples': 10000, 'score': 10545.221867799759, 'total_duration': 11325.832127809525, 'accumulated_submission_time': 10545.221867799759, 'accumulated_eval_time': 778.5178802013397, 'accumulated_logging_time': 0.832313060760498}
I0316 03:09:18.925849 139836417636096 logging_writer.py:48] [24064] accumulated_eval_time=778.517880, accumulated_logging_time=0.832313, accumulated_submission_time=10545.221868, global_step=24064, preemption_count=0, score=10545.221868, test/accuracy=0.337400, test/loss=3.139114, test/num_examples=10000, total_duration=11325.832128, train/accuracy=0.484023, train/loss=2.274031, validation/accuracy=0.441320, validation/loss=2.504420, validation/num_examples=50000
I0316 03:12:27.584688 139836409243392 logging_writer.py:48] [24500] global_step=24500, grad_norm=2.596018075942993, loss=3.3658363819122314
I0316 03:16:09.580264 139836417636096 logging_writer.py:48] [25000] global_step=25000, grad_norm=2.2382562160491943, loss=4.340507984161377
I0316 03:16:18.925285 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:16:29.490616 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:16:50.751222 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:16:52.422826 140033285822272 submission_runner.py:420] Time since start: 11779.35s, 	Step: 25022, 	{'train/accuracy': 0.4825390577316284, 'train/loss': 2.341752767562866, 'validation/accuracy': 0.44105997681617737, 'validation/loss': 2.5438315868377686, 'validation/num_examples': 50000, 'test/accuracy': 0.3443000018596649, 'test/loss': 3.128399610519409, 'test/num_examples': 10000, 'score': 10965.162417888641, 'total_duration': 11779.347505807877, 'accumulated_submission_time': 10965.162417888641, 'accumulated_eval_time': 812.0153987407684, 'accumulated_logging_time': 0.8595268726348877}
I0316 03:16:52.443141 139836409243392 logging_writer.py:48] [25022] accumulated_eval_time=812.015399, accumulated_logging_time=0.859527, accumulated_submission_time=10965.162418, global_step=25022, preemption_count=0, score=10965.162418, test/accuracy=0.344300, test/loss=3.128400, test/num_examples=10000, total_duration=11779.347506, train/accuracy=0.482539, train/loss=2.341753, validation/accuracy=0.441060, validation/loss=2.543832, validation/num_examples=50000
I0316 03:20:21.443858 139836417636096 logging_writer.py:48] [25500] global_step=25500, grad_norm=2.7080836296081543, loss=3.217766761779785
I0316 03:23:52.487184 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:24:02.602524 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:24:27.101460 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:24:28.773294 140033285822272 submission_runner.py:420] Time since start: 12235.70s, 	Step: 25975, 	{'train/accuracy': 0.5054687261581421, 'train/loss': 2.183162212371826, 'validation/accuracy': 0.4658399820327759, 'validation/loss': 2.391172170639038, 'validation/num_examples': 50000, 'test/accuracy': 0.35450002551078796, 'test/loss': 3.0186808109283447, 'test/num_examples': 10000, 'score': 11385.145975112915, 'total_duration': 12235.697974681854, 'accumulated_submission_time': 11385.145975112915, 'accumulated_eval_time': 848.301506280899, 'accumulated_logging_time': 0.8902637958526611}
I0316 03:24:28.799665 139836409243392 logging_writer.py:48] [25975] accumulated_eval_time=848.301506, accumulated_logging_time=0.890264, accumulated_submission_time=11385.145975, global_step=25975, preemption_count=0, score=11385.145975, test/accuracy=0.354500, test/loss=3.018681, test/num_examples=10000, total_duration=12235.697975, train/accuracy=0.505469, train/loss=2.183162, validation/accuracy=0.465840, validation/loss=2.391172, validation/num_examples=50000
I0316 03:24:38.991900 139836417636096 logging_writer.py:48] [26000] global_step=26000, grad_norm=2.9221060276031494, loss=3.1476075649261475
I0316 03:28:18.296045 139836409243392 logging_writer.py:48] [26500] global_step=26500, grad_norm=2.016218900680542, loss=4.808743000030518
I0316 03:31:29.057533 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:31:39.164899 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:32:00.149138 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:32:01.826951 140033285822272 submission_runner.py:420] Time since start: 12688.75s, 	Step: 26931, 	{'train/accuracy': 0.5189648270606995, 'train/loss': 2.1033716201782227, 'validation/accuracy': 0.47925999760627747, 'validation/loss': 2.310682535171509, 'validation/num_examples': 50000, 'test/accuracy': 0.3725000321865082, 'test/loss': 2.9614574909210205, 'test/num_examples': 10000, 'score': 11805.339718580246, 'total_duration': 12688.75161910057, 'accumulated_submission_time': 11805.339718580246, 'accumulated_eval_time': 881.0709578990936, 'accumulated_logging_time': 0.9305129051208496}
I0316 03:32:01.845618 139836417636096 logging_writer.py:48] [26931] accumulated_eval_time=881.070958, accumulated_logging_time=0.930513, accumulated_submission_time=11805.339719, global_step=26931, preemption_count=0, score=11805.339719, test/accuracy=0.372500, test/loss=2.961457, test/num_examples=10000, total_duration=12688.751619, train/accuracy=0.518965, train/loss=2.103372, validation/accuracy=0.479260, validation/loss=2.310683, validation/num_examples=50000
I0316 03:32:29.195953 139836409243392 logging_writer.py:48] [27000] global_step=27000, grad_norm=2.8748981952667236, loss=3.260317802429199
I0316 03:36:10.928827 139836417636096 logging_writer.py:48] [27500] global_step=27500, grad_norm=2.8385562896728516, loss=3.2167809009552
I0316 03:39:02.161404 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:39:12.342726 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:39:34.232119 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:39:35.890337 140033285822272 submission_runner.py:420] Time since start: 13142.82s, 	Step: 27885, 	{'train/accuracy': 0.5319726467132568, 'train/loss': 2.045513153076172, 'validation/accuracy': 0.48413997888565063, 'validation/loss': 2.290728807449341, 'validation/num_examples': 50000, 'test/accuracy': 0.3693000078201294, 'test/loss': 2.930393695831299, 'test/num_examples': 10000, 'score': 12225.59505367279, 'total_duration': 13142.815021753311, 'accumulated_submission_time': 12225.59505367279, 'accumulated_eval_time': 914.799902677536, 'accumulated_logging_time': 0.9597744941711426}
I0316 03:39:35.914879 139836409243392 logging_writer.py:48] [27885] accumulated_eval_time=914.799903, accumulated_logging_time=0.959774, accumulated_submission_time=12225.595054, global_step=27885, preemption_count=0, score=12225.595054, test/accuracy=0.369300, test/loss=2.930394, test/num_examples=10000, total_duration=13142.815022, train/accuracy=0.531973, train/loss=2.045513, validation/accuracy=0.484140, validation/loss=2.290729, validation/num_examples=50000
I0316 03:40:23.130404 139836417636096 logging_writer.py:48] [28000] global_step=28000, grad_norm=2.81489634513855, loss=3.1648738384246826
I0316 03:44:05.003830 139836409243392 logging_writer.py:48] [28500] global_step=28500, grad_norm=2.8517305850982666, loss=3.1106491088867188
I0316 03:46:36.323355 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:46:46.591497 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:47:13.471189 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:47:15.134363 140033285822272 submission_runner.py:420] Time since start: 13602.06s, 	Step: 28842, 	{'train/accuracy': 0.5350195169448853, 'train/loss': 2.024923324584961, 'validation/accuracy': 0.49699997901916504, 'validation/loss': 2.221653461456299, 'validation/num_examples': 50000, 'test/accuracy': 0.38350000977516174, 'test/loss': 2.8705570697784424, 'test/num_examples': 10000, 'score': 12645.94331908226, 'total_duration': 13602.059030294418, 'accumulated_submission_time': 12645.94331908226, 'accumulated_eval_time': 953.6108977794647, 'accumulated_logging_time': 0.9948720932006836}
I0316 03:47:15.162421 139836417636096 logging_writer.py:48] [28842] accumulated_eval_time=953.610898, accumulated_logging_time=0.994872, accumulated_submission_time=12645.943319, global_step=28842, preemption_count=0, score=12645.943319, test/accuracy=0.383500, test/loss=2.870557, test/num_examples=10000, total_duration=13602.059030, train/accuracy=0.535020, train/loss=2.024923, validation/accuracy=0.497000, validation/loss=2.221653, validation/num_examples=50000
I0316 03:48:20.840943 139836409243392 logging_writer.py:48] [29000] global_step=29000, grad_norm=2.3006739616394043, loss=3.827944278717041
I0316 03:52:03.015427 139836417636096 logging_writer.py:48] [29500] global_step=29500, grad_norm=2.0499796867370605, loss=4.3163042068481445
I0316 03:54:15.187834 140033285822272 spec.py:321] Evaluating on the training split.
I0316 03:54:25.389174 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 03:54:57.488142 140033285822272 spec.py:349] Evaluating on the test split.
I0316 03:54:59.153584 140033285822272 submission_runner.py:420] Time since start: 14066.08s, 	Step: 29799, 	{'train/accuracy': 0.5426366925239563, 'train/loss': 1.9930421113967896, 'validation/accuracy': 0.49629998207092285, 'validation/loss': 2.222616195678711, 'validation/num_examples': 50000, 'test/accuracy': 0.3903000056743622, 'test/loss': 2.845533609390259, 'test/num_examples': 10000, 'score': 13065.907601118088, 'total_duration': 14066.07828116417, 'accumulated_submission_time': 13065.907601118088, 'accumulated_eval_time': 997.5766913890839, 'accumulated_logging_time': 1.0336031913757324}
I0316 03:54:59.176794 139836409243392 logging_writer.py:48] [29799] accumulated_eval_time=997.576691, accumulated_logging_time=1.033603, accumulated_submission_time=13065.907601, global_step=29799, preemption_count=0, score=13065.907601, test/accuracy=0.390300, test/loss=2.845534, test/num_examples=10000, total_duration=14066.078281, train/accuracy=0.542637, train/loss=1.993042, validation/accuracy=0.496300, validation/loss=2.222616, validation/num_examples=50000
I0316 03:56:23.028352 139836417636096 logging_writer.py:48] [30000] global_step=30000, grad_norm=2.6746976375579834, loss=2.8300464153289795
I0316 04:00:05.419738 139836409243392 logging_writer.py:48] [30500] global_step=30500, grad_norm=2.1654348373413086, loss=5.157331466674805
I0316 04:01:59.500447 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:02:09.562055 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:02:35.981393 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:02:37.633887 140033285822272 submission_runner.py:420] Time since start: 14524.56s, 	Step: 30759, 	{'train/accuracy': 0.5582226514816284, 'train/loss': 1.8914048671722412, 'validation/accuracy': 0.5114200115203857, 'validation/loss': 2.1356563568115234, 'validation/num_examples': 50000, 'test/accuracy': 0.4012000262737274, 'test/loss': 2.780033826828003, 'test/num_examples': 10000, 'score': 13486.169509887695, 'total_duration': 14524.558580875397, 'accumulated_submission_time': 13486.169509887695, 'accumulated_eval_time': 1035.710154056549, 'accumulated_logging_time': 1.068241834640503}
I0316 04:02:37.654755 139836417636096 logging_writer.py:48] [30759] accumulated_eval_time=1035.710154, accumulated_logging_time=1.068242, accumulated_submission_time=13486.169510, global_step=30759, preemption_count=0, score=13486.169510, test/accuracy=0.401200, test/loss=2.780034, test/num_examples=10000, total_duration=14524.558581, train/accuracy=0.558223, train/loss=1.891405, validation/accuracy=0.511420, validation/loss=2.135656, validation/num_examples=50000
I0316 04:04:19.381973 139836409243392 logging_writer.py:48] [31000] global_step=31000, grad_norm=2.6848244667053223, loss=2.9538137912750244
I0316 04:08:02.614642 139836417636096 logging_writer.py:48] [31500] global_step=31500, grad_norm=2.7287650108337402, loss=2.9595468044281006
I0316 04:09:37.968484 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:09:48.224248 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:10:12.122335 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:10:13.773209 140033285822272 submission_runner.py:420] Time since start: 14980.70s, 	Step: 31716, 	{'train/accuracy': 0.5696093440055847, 'train/loss': 1.8607499599456787, 'validation/accuracy': 0.5142399668693542, 'validation/loss': 2.12805438041687, 'validation/num_examples': 50000, 'test/accuracy': 0.403300017118454, 'test/loss': 2.7867681980133057, 'test/num_examples': 10000, 'score': 13906.422610759735, 'total_duration': 14980.697907924652, 'accumulated_submission_time': 13906.422610759735, 'accumulated_eval_time': 1071.5148980617523, 'accumulated_logging_time': 1.098806619644165}
I0316 04:10:13.791108 139836409243392 logging_writer.py:48] [31716] accumulated_eval_time=1071.514898, accumulated_logging_time=1.098807, accumulated_submission_time=13906.422611, global_step=31716, preemption_count=0, score=13906.422611, test/accuracy=0.403300, test/loss=2.786768, test/num_examples=10000, total_duration=14980.697908, train/accuracy=0.569609, train/loss=1.860750, validation/accuracy=0.514240, validation/loss=2.128054, validation/num_examples=50000
I0316 04:12:15.154949 139836417636096 logging_writer.py:48] [32000] global_step=32000, grad_norm=2.50052547454834, loss=3.4466593265533447
I0316 04:15:57.552209 139836409243392 logging_writer.py:48] [32500] global_step=32500, grad_norm=2.1916558742523193, loss=3.912466287612915
I0316 04:17:13.820808 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:17:24.138337 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:17:45.707653 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:17:47.366831 140033285822272 submission_runner.py:420] Time since start: 15434.29s, 	Step: 32672, 	{'train/accuracy': 0.5730664134025574, 'train/loss': 1.8205695152282715, 'validation/accuracy': 0.5302799940109253, 'validation/loss': 2.033155679702759, 'validation/num_examples': 50000, 'test/accuracy': 0.4157000184059143, 'test/loss': 2.687333822250366, 'test/num_examples': 10000, 'score': 14326.388909578323, 'total_duration': 15434.29147529602, 'accumulated_submission_time': 14326.388909578323, 'accumulated_eval_time': 1105.0609011650085, 'accumulated_logging_time': 1.130598783493042}
I0316 04:17:47.392136 139836417636096 logging_writer.py:48] [32672] accumulated_eval_time=1105.060901, accumulated_logging_time=1.130599, accumulated_submission_time=14326.388910, global_step=32672, preemption_count=0, score=14326.388910, test/accuracy=0.415700, test/loss=2.687334, test/num_examples=10000, total_duration=15434.291475, train/accuracy=0.573066, train/loss=1.820570, validation/accuracy=0.530280, validation/loss=2.033156, validation/num_examples=50000
I0316 04:20:10.266656 139836409243392 logging_writer.py:48] [33000] global_step=33000, grad_norm=2.7187345027923584, loss=3.096006393432617
I0316 04:23:54.063540 139836417636096 logging_writer.py:48] [33500] global_step=33500, grad_norm=2.656147003173828, loss=2.749148368835449
I0316 04:24:47.762891 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:24:58.194185 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:25:24.833356 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:25:26.497233 140033285822272 submission_runner.py:420] Time since start: 15893.42s, 	Step: 33621, 	{'train/accuracy': 0.5838671922683716, 'train/loss': 1.7662866115570068, 'validation/accuracy': 0.535860002040863, 'validation/loss': 2.0103554725646973, 'validation/num_examples': 50000, 'test/accuracy': 0.417900025844574, 'test/loss': 2.676462411880493, 'test/num_examples': 10000, 'score': 14746.696274280548, 'total_duration': 15893.421913385391, 'accumulated_submission_time': 14746.696274280548, 'accumulated_eval_time': 1143.7952399253845, 'accumulated_logging_time': 1.1695642471313477}
I0316 04:25:26.517223 139836409243392 logging_writer.py:48] [33621] accumulated_eval_time=1143.795240, accumulated_logging_time=1.169564, accumulated_submission_time=14746.696274, global_step=33621, preemption_count=0, score=14746.696274, test/accuracy=0.417900, test/loss=2.676462, test/num_examples=10000, total_duration=15893.421913, train/accuracy=0.583867, train/loss=1.766287, validation/accuracy=0.535860, validation/loss=2.010355, validation/num_examples=50000
I0316 04:28:11.471978 139836417636096 logging_writer.py:48] [34000] global_step=34000, grad_norm=2.8040125370025635, loss=2.7871429920196533
I0316 04:31:55.079813 139836409243392 logging_writer.py:48] [34500] global_step=34500, grad_norm=2.366945743560791, loss=3.4269073009490967
I0316 04:32:26.756127 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:32:36.927253 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:33:05.129456 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:33:06.796743 140033285822272 submission_runner.py:420] Time since start: 16353.72s, 	Step: 34573, 	{'train/accuracy': 0.6007617115974426, 'train/loss': 1.6721882820129395, 'validation/accuracy': 0.5429800152778625, 'validation/loss': 1.9515763521194458, 'validation/num_examples': 50000, 'test/accuracy': 0.42660000920295715, 'test/loss': 2.6220309734344482, 'test/num_examples': 10000, 'score': 15166.874994754791, 'total_duration': 16353.72144317627, 'accumulated_submission_time': 15166.874994754791, 'accumulated_eval_time': 1183.8358619213104, 'accumulated_logging_time': 1.1999287605285645}
I0316 04:33:06.817561 139836417636096 logging_writer.py:48] [34573] accumulated_eval_time=1183.835862, accumulated_logging_time=1.199929, accumulated_submission_time=15166.874995, global_step=34573, preemption_count=0, score=15166.874995, test/accuracy=0.426600, test/loss=2.622031, test/num_examples=10000, total_duration=16353.721443, train/accuracy=0.600762, train/loss=1.672188, validation/accuracy=0.542980, validation/loss=1.951576, validation/num_examples=50000
I0316 04:36:12.013588 139836409243392 logging_writer.py:48] [35000] global_step=35000, grad_norm=2.5159523487091064, loss=2.9946107864379883
I0316 04:39:54.207649 139836417636096 logging_writer.py:48] [35500] global_step=35500, grad_norm=2.2524242401123047, loss=4.104681015014648
I0316 04:40:06.891238 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:40:17.192560 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:40:38.978080 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:40:40.638400 140033285822272 submission_runner.py:420] Time since start: 16807.56s, 	Step: 35530, 	{'train/accuracy': 0.5900585651397705, 'train/loss': 1.7342700958251953, 'validation/accuracy': 0.5461599826812744, 'validation/loss': 1.9654384851455688, 'validation/num_examples': 50000, 'test/accuracy': 0.42750000953674316, 'test/loss': 2.632882833480835, 'test/num_examples': 10000, 'score': 15586.89006471634, 'total_duration': 16807.56308698654, 'accumulated_submission_time': 15586.89006471634, 'accumulated_eval_time': 1217.5830099582672, 'accumulated_logging_time': 1.2297043800354004}
I0316 04:40:40.663017 139836409243392 logging_writer.py:48] [35530] accumulated_eval_time=1217.583010, accumulated_logging_time=1.229704, accumulated_submission_time=15586.890065, global_step=35530, preemption_count=0, score=15586.890065, test/accuracy=0.427500, test/loss=2.632883, test/num_examples=10000, total_duration=16807.563087, train/accuracy=0.590059, train/loss=1.734270, validation/accuracy=0.546160, validation/loss=1.965438, validation/num_examples=50000
I0316 04:44:06.014454 139836417636096 logging_writer.py:48] [36000] global_step=36000, grad_norm=2.700439691543579, loss=2.638561248779297
I0316 04:47:40.766815 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:47:50.942333 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:48:15.122238 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:48:16.782699 140033285822272 submission_runner.py:420] Time since start: 17263.71s, 	Step: 36484, 	{'train/accuracy': 0.6089453101158142, 'train/loss': 1.6495379209518433, 'validation/accuracy': 0.5564799904823303, 'validation/loss': 1.8977562189102173, 'validation/num_examples': 50000, 'test/accuracy': 0.43380001187324524, 'test/loss': 2.585392475128174, 'test/num_examples': 10000, 'score': 16006.934529304504, 'total_duration': 17263.707371473312, 'accumulated_submission_time': 16006.934529304504, 'accumulated_eval_time': 1253.5988926887512, 'accumulated_logging_time': 1.2636237144470215}
I0316 04:48:16.806679 139836409243392 logging_writer.py:48] [36484] accumulated_eval_time=1253.598893, accumulated_logging_time=1.263624, accumulated_submission_time=16006.934529, global_step=36484, preemption_count=0, score=16006.934529, test/accuracy=0.433800, test/loss=2.585392, test/num_examples=10000, total_duration=17263.707371, train/accuracy=0.608945, train/loss=1.649538, validation/accuracy=0.556480, validation/loss=1.897756, validation/num_examples=50000
I0316 04:48:23.453245 139836417636096 logging_writer.py:48] [36500] global_step=36500, grad_norm=2.636396884918213, loss=2.9069738388061523
I0316 04:52:02.221858 139836409243392 logging_writer.py:48] [37000] global_step=37000, grad_norm=2.67897891998291, loss=2.754563570022583
I0316 04:55:17.127343 140033285822272 spec.py:321] Evaluating on the training split.
I0316 04:55:27.295171 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 04:56:00.674752 140033285822272 spec.py:349] Evaluating on the test split.
I0316 04:56:02.359045 140033285822272 submission_runner.py:420] Time since start: 17729.28s, 	Step: 37440, 	{'train/accuracy': 0.6157616972923279, 'train/loss': 1.5937190055847168, 'validation/accuracy': 0.563759982585907, 'validation/loss': 1.8479629755020142, 'validation/num_examples': 50000, 'test/accuracy': 0.4449000358581543, 'test/loss': 2.5360238552093506, 'test/num_examples': 10000, 'score': 16427.194246530533, 'total_duration': 17729.283722162247, 'accumulated_submission_time': 16427.194246530533, 'accumulated_eval_time': 1298.8306069374084, 'accumulated_logging_time': 1.2985265254974365}
I0316 04:56:02.382680 139836417636096 logging_writer.py:48] [37440] accumulated_eval_time=1298.830607, accumulated_logging_time=1.298527, accumulated_submission_time=16427.194247, global_step=37440, preemption_count=0, score=16427.194247, test/accuracy=0.444900, test/loss=2.536024, test/num_examples=10000, total_duration=17729.283722, train/accuracy=0.615762, train/loss=1.593719, validation/accuracy=0.563760, validation/loss=1.847963, validation/num_examples=50000
I0316 04:56:26.216980 139836409243392 logging_writer.py:48] [37500] global_step=37500, grad_norm=2.697115898132324, loss=2.603325605392456
I0316 05:00:05.504371 139836417636096 logging_writer.py:48] [38000] global_step=38000, grad_norm=2.5018560886383057, loss=2.4754233360290527
I0316 05:03:02.713099 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:03:12.797379 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:03:38.104236 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:03:39.762904 140033285822272 submission_runner.py:420] Time since start: 18186.69s, 	Step: 38400, 	{'train/accuracy': 0.6366210579872131, 'train/loss': 1.5172066688537598, 'validation/accuracy': 0.5677399635314941, 'validation/loss': 1.8366968631744385, 'validation/num_examples': 50000, 'test/accuracy': 0.44780001044273376, 'test/loss': 2.5162038803100586, 'test/num_examples': 10000, 'score': 16847.46401500702, 'total_duration': 18186.687578439713, 'accumulated_submission_time': 16847.46401500702, 'accumulated_eval_time': 1335.8804173469543, 'accumulated_logging_time': 1.3324460983276367}
I0316 05:03:39.783530 139836409243392 logging_writer.py:48] [38400] accumulated_eval_time=1335.880417, accumulated_logging_time=1.332446, accumulated_submission_time=16847.464015, global_step=38400, preemption_count=0, score=16847.464015, test/accuracy=0.447800, test/loss=2.516204, test/num_examples=10000, total_duration=18186.687578, train/accuracy=0.636621, train/loss=1.517207, validation/accuracy=0.567740, validation/loss=1.836697, validation/num_examples=50000
I0316 05:04:19.240444 139836417636096 logging_writer.py:48] [38500] global_step=38500, grad_norm=2.1033239364624023, loss=5.216627597808838
I0316 05:08:00.535735 139836409243392 logging_writer.py:48] [39000] global_step=39000, grad_norm=2.8479127883911133, loss=2.648557662963867
I0316 05:10:39.895202 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:10:50.130546 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:11:15.584633 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:11:17.244672 140033285822272 submission_runner.py:420] Time since start: 18644.17s, 	Step: 39361, 	{'train/accuracy': 0.6253125071525574, 'train/loss': 1.5803190469741821, 'validation/accuracy': 0.5726799964904785, 'validation/loss': 1.8311997652053833, 'validation/num_examples': 50000, 'test/accuracy': 0.4498000144958496, 'test/loss': 2.4852004051208496, 'test/num_examples': 10000, 'score': 17267.515798330307, 'total_duration': 18644.169363975525, 'accumulated_submission_time': 17267.515798330307, 'accumulated_eval_time': 1373.2299056053162, 'accumulated_logging_time': 1.3624634742736816}
I0316 05:11:17.264232 139836417636096 logging_writer.py:48] [39361] accumulated_eval_time=1373.229906, accumulated_logging_time=1.362463, accumulated_submission_time=17267.515798, global_step=39361, preemption_count=0, score=17267.515798, test/accuracy=0.449800, test/loss=2.485200, test/num_examples=10000, total_duration=18644.169364, train/accuracy=0.625313, train/loss=1.580319, validation/accuracy=0.572680, validation/loss=1.831200, validation/num_examples=50000
I0316 05:12:14.488823 139836409243392 logging_writer.py:48] [39500] global_step=39500, grad_norm=2.508164405822754, loss=2.467517614364624
I0316 05:15:57.149644 139836417636096 logging_writer.py:48] [40000] global_step=40000, grad_norm=2.0180275440216064, loss=4.438875198364258
I0316 05:18:17.643783 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:18:28.313836 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:18:54.482040 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:18:56.132481 140033285822272 submission_runner.py:420] Time since start: 19103.06s, 	Step: 40318, 	{'train/accuracy': 0.636523425579071, 'train/loss': 1.5090090036392212, 'validation/accuracy': 0.5835199952125549, 'validation/loss': 1.7715173959732056, 'validation/num_examples': 50000, 'test/accuracy': 0.46490001678466797, 'test/loss': 2.445481777191162, 'test/num_examples': 10000, 'score': 17687.836143493652, 'total_duration': 19103.057171821594, 'accumulated_submission_time': 17687.836143493652, 'accumulated_eval_time': 1411.718628168106, 'accumulated_logging_time': 1.3917474746704102}
I0316 05:18:56.152811 139836409243392 logging_writer.py:48] [40318] accumulated_eval_time=1411.718628, accumulated_logging_time=1.391747, accumulated_submission_time=17687.836143, global_step=40318, preemption_count=0, score=17687.836143, test/accuracy=0.464900, test/loss=2.445482, test/num_examples=10000, total_duration=19103.057172, train/accuracy=0.636523, train/loss=1.509009, validation/accuracy=0.583520, validation/loss=1.771517, validation/num_examples=50000
I0316 05:20:12.392139 139836417636096 logging_writer.py:48] [40500] global_step=40500, grad_norm=2.1633388996124268, loss=4.643570423126221
I0316 05:23:58.543447 139836409243392 logging_writer.py:48] [41000] global_step=41000, grad_norm=2.305402994155884, loss=3.4150052070617676
I0316 05:25:56.170266 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:26:06.467511 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:26:28.649926 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:26:30.321625 140033285822272 submission_runner.py:420] Time since start: 19557.25s, 	Step: 41265, 	{'train/accuracy': 0.6448046565055847, 'train/loss': 1.478863000869751, 'validation/accuracy': 0.5865399837493896, 'validation/loss': 1.761332631111145, 'validation/num_examples': 50000, 'test/accuracy': 0.4617000222206116, 'test/loss': 2.4383459091186523, 'test/num_examples': 10000, 'score': 18107.49636220932, 'total_duration': 19557.246302843094, 'accumulated_submission_time': 18107.49636220932, 'accumulated_eval_time': 1445.8699808120728, 'accumulated_logging_time': 1.7200422286987305}
I0316 05:26:30.348282 139836417636096 logging_writer.py:48] [41265] accumulated_eval_time=1445.869981, accumulated_logging_time=1.720042, accumulated_submission_time=18107.496362, global_step=41265, preemption_count=0, score=18107.496362, test/accuracy=0.461700, test/loss=2.438346, test/num_examples=10000, total_duration=19557.246303, train/accuracy=0.644805, train/loss=1.478863, validation/accuracy=0.586540, validation/loss=1.761333, validation/num_examples=50000
I0316 05:28:11.071745 139836409243392 logging_writer.py:48] [41500] global_step=41500, grad_norm=2.2680532932281494, loss=3.9092936515808105
I0316 05:31:54.277123 139836417636096 logging_writer.py:48] [42000] global_step=42000, grad_norm=2.6658644676208496, loss=2.4524905681610107
I0316 05:33:30.365268 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:33:40.662777 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:34:12.939717 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:34:14.601106 140033285822272 submission_runner.py:420] Time since start: 20021.53s, 	Step: 42218, 	{'train/accuracy': 0.6465820074081421, 'train/loss': 1.4708688259124756, 'validation/accuracy': 0.5926600098609924, 'validation/loss': 1.7223899364471436, 'validation/num_examples': 50000, 'test/accuracy': 0.46700000762939453, 'test/loss': 2.410362958908081, 'test/num_examples': 10000, 'score': 18527.45361971855, 'total_duration': 20021.525790691376, 'accumulated_submission_time': 18527.45361971855, 'accumulated_eval_time': 1490.1058139801025, 'accumulated_logging_time': 1.7573609352111816}
I0316 05:34:14.626797 139836409243392 logging_writer.py:48] [42218] accumulated_eval_time=1490.105814, accumulated_logging_time=1.757361, accumulated_submission_time=18527.453620, global_step=42218, preemption_count=0, score=18527.453620, test/accuracy=0.467000, test/loss=2.410363, test/num_examples=10000, total_duration=20021.525791, train/accuracy=0.646582, train/loss=1.470869, validation/accuracy=0.592660, validation/loss=1.722390, validation/num_examples=50000
I0316 05:36:14.939346 139836417636096 logging_writer.py:48] [42500] global_step=42500, grad_norm=2.766432523727417, loss=2.5975513458251953
I0316 05:39:58.443803 139836409243392 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.958356499671936, loss=5.072012424468994
I0316 05:41:14.950824 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:41:25.580492 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:41:48.508342 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:41:50.170222 140033285822272 submission_runner.py:420] Time since start: 20477.09s, 	Step: 43173, 	{'train/accuracy': 0.6506640315055847, 'train/loss': 1.450050950050354, 'validation/accuracy': 0.5936200022697449, 'validation/loss': 1.710167407989502, 'validation/num_examples': 50000, 'test/accuracy': 0.4692000150680542, 'test/loss': 2.394214391708374, 'test/num_examples': 10000, 'score': 18947.717879533768, 'total_duration': 20477.094908475876, 'accumulated_submission_time': 18947.717879533768, 'accumulated_eval_time': 1525.3252108097076, 'accumulated_logging_time': 1.7933471202850342}
I0316 05:41:50.195595 139836417636096 logging_writer.py:48] [43173] accumulated_eval_time=1525.325211, accumulated_logging_time=1.793347, accumulated_submission_time=18947.717880, global_step=43173, preemption_count=0, score=18947.717880, test/accuracy=0.469200, test/loss=2.394214, test/num_examples=10000, total_duration=20477.094908, train/accuracy=0.650664, train/loss=1.450051, validation/accuracy=0.593620, validation/loss=1.710167, validation/num_examples=50000
I0316 05:44:11.734923 139836409243392 logging_writer.py:48] [43500] global_step=43500, grad_norm=2.817286252975464, loss=2.3854031562805176
I0316 05:47:55.565770 139836417636096 logging_writer.py:48] [44000] global_step=44000, grad_norm=2.756742238998413, loss=2.4187798500061035
I0316 05:48:50.263180 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:49:00.382231 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:49:25.989841 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:49:27.634135 140033285822272 submission_runner.py:420] Time since start: 20934.56s, 	Step: 44124, 	{'train/accuracy': 0.6599413752555847, 'train/loss': 1.3911164999008179, 'validation/accuracy': 0.6062799692153931, 'validation/loss': 1.662405252456665, 'validation/num_examples': 50000, 'test/accuracy': 0.48280003666877747, 'test/loss': 2.3503904342651367, 'test/num_examples': 10000, 'score': 19367.72512102127, 'total_duration': 20934.558821439743, 'accumulated_submission_time': 19367.72512102127, 'accumulated_eval_time': 1562.6961524486542, 'accumulated_logging_time': 1.830763339996338}
I0316 05:49:27.656436 139836409243392 logging_writer.py:48] [44124] accumulated_eval_time=1562.696152, accumulated_logging_time=1.830763, accumulated_submission_time=19367.725121, global_step=44124, preemption_count=0, score=19367.725121, test/accuracy=0.482800, test/loss=2.350390, test/num_examples=10000, total_duration=20934.558821, train/accuracy=0.659941, train/loss=1.391116, validation/accuracy=0.606280, validation/loss=1.662405, validation/num_examples=50000
I0316 05:52:10.138609 139836417636096 logging_writer.py:48] [44500] global_step=44500, grad_norm=2.452613353729248, loss=3.128434181213379
I0316 05:55:53.399226 139836409243392 logging_writer.py:48] [45000] global_step=45000, grad_norm=2.5702481269836426, loss=2.5828685760498047
I0316 05:56:27.913221 140033285822272 spec.py:321] Evaluating on the training split.
I0316 05:56:38.023661 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 05:57:00.947923 140033285822272 spec.py:349] Evaluating on the test split.
I0316 05:57:02.623274 140033285822272 submission_runner.py:420] Time since start: 21389.55s, 	Step: 45079, 	{'train/accuracy': 0.6740429401397705, 'train/loss': 1.329019546508789, 'validation/accuracy': 0.6092399954795837, 'validation/loss': 1.6442941427230835, 'validation/num_examples': 50000, 'test/accuracy': 0.4886000156402588, 'test/loss': 2.3218066692352295, 'test/num_examples': 10000, 'score': 19787.92154598236, 'total_duration': 21389.5479490757, 'accumulated_submission_time': 19787.92154598236, 'accumulated_eval_time': 1597.4061863422394, 'accumulated_logging_time': 1.8645439147949219}
I0316 05:57:02.648104 139836417636096 logging_writer.py:48] [45079] accumulated_eval_time=1597.406186, accumulated_logging_time=1.864544, accumulated_submission_time=19787.921546, global_step=45079, preemption_count=0, score=19787.921546, test/accuracy=0.488600, test/loss=2.321807, test/num_examples=10000, total_duration=21389.547949, train/accuracy=0.674043, train/loss=1.329020, validation/accuracy=0.609240, validation/loss=1.644294, validation/num_examples=50000
I0316 06:00:04.898192 139836409243392 logging_writer.py:48] [45500] global_step=45500, grad_norm=2.129852771759033, loss=4.422615051269531
I0316 06:03:46.881206 139836417636096 logging_writer.py:48] [46000] global_step=46000, grad_norm=2.1292037963867188, loss=3.707855224609375
I0316 06:04:02.672436 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:04:12.953696 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:04:35.082123 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:04:36.743083 140033285822272 submission_runner.py:420] Time since start: 21843.67s, 	Step: 46037, 	{'train/accuracy': 0.6686718463897705, 'train/loss': 1.3530316352844238, 'validation/accuracy': 0.6150599718093872, 'validation/loss': 1.6116976737976074, 'validation/num_examples': 50000, 'test/accuracy': 0.4865000247955322, 'test/loss': 2.3106882572174072, 'test/num_examples': 10000, 'score': 20207.886675834656, 'total_duration': 21843.66777586937, 'accumulated_submission_time': 20207.886675834656, 'accumulated_eval_time': 1631.4768223762512, 'accumulated_logging_time': 1.8995838165283203}
I0316 06:04:36.765342 139836409243392 logging_writer.py:48] [46037] accumulated_eval_time=1631.476822, accumulated_logging_time=1.899584, accumulated_submission_time=20207.886676, global_step=46037, preemption_count=0, score=20207.886676, test/accuracy=0.486500, test/loss=2.310688, test/num_examples=10000, total_duration=21843.667776, train/accuracy=0.668672, train/loss=1.353032, validation/accuracy=0.615060, validation/loss=1.611698, validation/num_examples=50000
I0316 06:07:59.592825 139836417636096 logging_writer.py:48] [46500] global_step=46500, grad_norm=2.6299917697906494, loss=2.5682716369628906
I0316 06:11:37.202372 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:11:47.653161 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:12:12.638244 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:12:14.303762 140033285822272 submission_runner.py:420] Time since start: 22301.23s, 	Step: 46990, 	{'train/accuracy': 0.6719921827316284, 'train/loss': 1.3276513814926147, 'validation/accuracy': 0.6168199777603149, 'validation/loss': 1.6015956401824951, 'validation/num_examples': 50000, 'test/accuracy': 0.4887000322341919, 'test/loss': 2.290903329849243, 'test/num_examples': 10000, 'score': 20628.261212348938, 'total_duration': 22301.228451251984, 'accumulated_submission_time': 20628.261212348938, 'accumulated_eval_time': 1668.5782387256622, 'accumulated_logging_time': 1.9347178936004639}
I0316 06:12:14.327687 139836409243392 logging_writer.py:48] [46990] accumulated_eval_time=1668.578239, accumulated_logging_time=1.934718, accumulated_submission_time=20628.261212, global_step=46990, preemption_count=0, score=20628.261212, test/accuracy=0.488700, test/loss=2.290903, test/num_examples=10000, total_duration=22301.228451, train/accuracy=0.671992, train/loss=1.327651, validation/accuracy=0.616820, validation/loss=1.601596, validation/num_examples=50000
I0316 06:12:18.647122 139836417636096 logging_writer.py:48] [47000] global_step=47000, grad_norm=2.415811538696289, loss=3.159397602081299
I0316 06:15:56.954867 139836409243392 logging_writer.py:48] [47500] global_step=47500, grad_norm=2.6721715927124023, loss=2.352062463760376
I0316 06:19:14.576315 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:19:24.938028 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:19:49.184131 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:19:50.845930 140033285822272 submission_runner.py:420] Time since start: 22757.77s, 	Step: 47944, 	{'train/accuracy': 0.6779491901397705, 'train/loss': 1.3019496202468872, 'validation/accuracy': 0.6201399564743042, 'validation/loss': 1.5818183422088623, 'validation/num_examples': 50000, 'test/accuracy': 0.4913000166416168, 'test/loss': 2.2568938732147217, 'test/num_examples': 10000, 'score': 21048.45112323761, 'total_duration': 22757.770616292953, 'accumulated_submission_time': 21048.45112323761, 'accumulated_eval_time': 1704.8478543758392, 'accumulated_logging_time': 1.968759298324585}
I0316 06:19:50.870048 139836417636096 logging_writer.py:48] [47944] accumulated_eval_time=1704.847854, accumulated_logging_time=1.968759, accumulated_submission_time=21048.451123, global_step=47944, preemption_count=0, score=21048.451123, test/accuracy=0.491300, test/loss=2.256894, test/num_examples=10000, total_duration=22757.770616, train/accuracy=0.677949, train/loss=1.301950, validation/accuracy=0.620140, validation/loss=1.581818, validation/num_examples=50000
I0316 06:20:13.146946 139836409243392 logging_writer.py:48] [48000] global_step=48000, grad_norm=2.5841379165649414, loss=2.5334904193878174
I0316 06:23:54.401608 139836417636096 logging_writer.py:48] [48500] global_step=48500, grad_norm=2.627070426940918, loss=2.329768419265747
I0316 06:26:50.914628 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:27:00.955193 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:27:33.027925 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:27:34.690221 140033285822272 submission_runner.py:420] Time since start: 23221.61s, 	Step: 48897, 	{'train/accuracy': 0.6955468654632568, 'train/loss': 1.2310354709625244, 'validation/accuracy': 0.6251199841499329, 'validation/loss': 1.557105302810669, 'validation/num_examples': 50000, 'test/accuracy': 0.49870002269744873, 'test/loss': 2.2372066974639893, 'test/num_examples': 10000, 'score': 21468.4367480278, 'total_duration': 23221.61490869522, 'accumulated_submission_time': 21468.4367480278, 'accumulated_eval_time': 1748.6234555244446, 'accumulated_logging_time': 2.0034050941467285}
I0316 06:27:34.721861 139836409243392 logging_writer.py:48] [48897] accumulated_eval_time=1748.623456, accumulated_logging_time=2.003405, accumulated_submission_time=21468.436748, global_step=48897, preemption_count=0, score=21468.436748, test/accuracy=0.498700, test/loss=2.237207, test/num_examples=10000, total_duration=23221.614909, train/accuracy=0.695547, train/loss=1.231035, validation/accuracy=0.625120, validation/loss=1.557105, validation/num_examples=50000
I0316 06:28:15.449253 139836417636096 logging_writer.py:48] [49000] global_step=49000, grad_norm=2.5883796215057373, loss=2.6831018924713135
I0316 06:31:57.564223 139836409243392 logging_writer.py:48] [49500] global_step=49500, grad_norm=2.3054754734039307, loss=3.387315273284912
I0316 06:34:35.144487 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:34:45.087185 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:35:11.101960 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:35:12.751913 140033285822272 submission_runner.py:420] Time since start: 23679.68s, 	Step: 49857, 	{'train/accuracy': 0.6855273246765137, 'train/loss': 1.2761197090148926, 'validation/accuracy': 0.6314600110054016, 'validation/loss': 1.5329201221466064, 'validation/num_examples': 50000, 'test/accuracy': 0.5034000277519226, 'test/loss': 2.21596097946167, 'test/num_examples': 10000, 'score': 21888.799356222153, 'total_duration': 23679.67661356926, 'accumulated_submission_time': 21888.799356222153, 'accumulated_eval_time': 1786.2309200763702, 'accumulated_logging_time': 2.0461082458496094}
I0316 06:35:12.774267 139836417636096 logging_writer.py:48] [49857] accumulated_eval_time=1786.230920, accumulated_logging_time=2.046108, accumulated_submission_time=21888.799356, global_step=49857, preemption_count=0, score=21888.799356, test/accuracy=0.503400, test/loss=2.215961, test/num_examples=10000, total_duration=23679.676614, train/accuracy=0.685527, train/loss=1.276120, validation/accuracy=0.631460, validation/loss=1.532920, validation/num_examples=50000
I0316 06:36:10.794691 139836409243392 logging_writer.py:48] [50000] global_step=50000, grad_norm=2.7114062309265137, loss=2.3041443824768066
I0316 06:39:53.243422 139836417636096 logging_writer.py:48] [50500] global_step=50500, grad_norm=2.133310556411743, loss=4.901406288146973
I0316 06:42:13.144683 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:42:23.364683 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:42:45.724661 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:42:47.383212 140033285822272 submission_runner.py:420] Time since start: 24134.31s, 	Step: 50816, 	{'train/accuracy': 0.6879491806030273, 'train/loss': 1.267967700958252, 'validation/accuracy': 0.6278199553489685, 'validation/loss': 1.5532413721084595, 'validation/num_examples': 50000, 'test/accuracy': 0.5005000233650208, 'test/loss': 2.232085704803467, 'test/num_examples': 10000, 'score': 22309.111480474472, 'total_duration': 24134.307889938354, 'accumulated_submission_time': 22309.111480474472, 'accumulated_eval_time': 1820.4694256782532, 'accumulated_logging_time': 2.0777573585510254}
I0316 06:42:47.412474 139836409243392 logging_writer.py:48] [50816] accumulated_eval_time=1820.469426, accumulated_logging_time=2.077757, accumulated_submission_time=22309.111480, global_step=50816, preemption_count=0, score=22309.111480, test/accuracy=0.500500, test/loss=2.232086, test/num_examples=10000, total_duration=24134.307890, train/accuracy=0.687949, train/loss=1.267968, validation/accuracy=0.627820, validation/loss=1.553241, validation/num_examples=50000
I0316 06:44:04.943898 139836417636096 logging_writer.py:48] [51000] global_step=51000, grad_norm=2.124274730682373, loss=4.958351135253906
I0316 06:47:48.562164 139836409243392 logging_writer.py:48] [51500] global_step=51500, grad_norm=2.688319683074951, loss=2.2435302734375
I0316 06:49:47.694189 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:49:58.056460 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:50:21.370392 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:50:23.035807 140033285822272 submission_runner.py:420] Time since start: 24589.96s, 	Step: 51769, 	{'train/accuracy': 0.6981835961341858, 'train/loss': 1.232142686843872, 'validation/accuracy': 0.6326000094413757, 'validation/loss': 1.5290515422821045, 'validation/num_examples': 50000, 'test/accuracy': 0.5062000155448914, 'test/loss': 2.203350782394409, 'test/num_examples': 10000, 'score': 22729.33373618126, 'total_duration': 24589.960483789444, 'accumulated_submission_time': 22729.33373618126, 'accumulated_eval_time': 1855.8110496997833, 'accumulated_logging_time': 2.117459535598755}
I0316 06:50:23.061490 139836417636096 logging_writer.py:48] [51769] accumulated_eval_time=1855.811050, accumulated_logging_time=2.117460, accumulated_submission_time=22729.333736, global_step=51769, preemption_count=0, score=22729.333736, test/accuracy=0.506200, test/loss=2.203351, test/num_examples=10000, total_duration=24589.960484, train/accuracy=0.698184, train/loss=1.232143, validation/accuracy=0.632600, validation/loss=1.529052, validation/num_examples=50000
I0316 06:52:01.717773 139836409243392 logging_writer.py:48] [52000] global_step=52000, grad_norm=2.3572802543640137, loss=3.257303237915039
I0316 06:55:45.018868 139836417636096 logging_writer.py:48] [52500] global_step=52500, grad_norm=2.0898702144622803, loss=4.33168888092041
I0316 06:57:23.113667 140033285822272 spec.py:321] Evaluating on the training split.
I0316 06:57:33.175259 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 06:58:12.772451 140033285822272 spec.py:349] Evaluating on the test split.
I0316 06:58:14.426597 140033285822272 submission_runner.py:420] Time since start: 25061.35s, 	Step: 52722, 	{'train/accuracy': 0.6948632597923279, 'train/loss': 1.2600173950195312, 'validation/accuracy': 0.6378200054168701, 'validation/loss': 1.5118967294692993, 'validation/num_examples': 50000, 'test/accuracy': 0.5085000395774841, 'test/loss': 2.1973907947540283, 'test/num_examples': 10000, 'score': 23149.325989961624, 'total_duration': 25061.351286172867, 'accumulated_submission_time': 23149.325989961624, 'accumulated_eval_time': 1907.1239984035492, 'accumulated_logging_time': 2.1540443897247314}
I0316 06:58:14.446732 139836409243392 logging_writer.py:48] [52722] accumulated_eval_time=1907.123998, accumulated_logging_time=2.154044, accumulated_submission_time=23149.325990, global_step=52722, preemption_count=0, score=23149.325990, test/accuracy=0.508500, test/loss=2.197391, test/num_examples=10000, total_duration=25061.351286, train/accuracy=0.694863, train/loss=1.260017, validation/accuracy=0.637820, validation/loss=1.511897, validation/num_examples=50000
I0316 07:00:13.356679 139836417636096 logging_writer.py:48] [53000] global_step=53000, grad_norm=2.238292694091797, loss=3.2576005458831787
I0316 07:03:55.790436 139836409243392 logging_writer.py:48] [53500] global_step=53500, grad_norm=2.263458251953125, loss=3.032101631164551
I0316 07:05:14.606280 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:05:24.796345 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:05:45.659207 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:05:47.323577 140033285822272 submission_runner.py:420] Time since start: 25514.25s, 	Step: 53679, 	{'train/accuracy': 0.70277339220047, 'train/loss': 1.1971427202224731, 'validation/accuracy': 0.6426599621772766, 'validation/loss': 1.477855920791626, 'validation/num_examples': 50000, 'test/accuracy': 0.5153000354766846, 'test/loss': 2.1577723026275635, 'test/num_examples': 10000, 'score': 23569.422335863113, 'total_duration': 25514.248254537582, 'accumulated_submission_time': 23569.422335863113, 'accumulated_eval_time': 1939.8412914276123, 'accumulated_logging_time': 2.187542200088501}
I0316 07:05:47.347283 139836417636096 logging_writer.py:48] [53679] accumulated_eval_time=1939.841291, accumulated_logging_time=2.187542, accumulated_submission_time=23569.422336, global_step=53679, preemption_count=0, score=23569.422336, test/accuracy=0.515300, test/loss=2.157772, test/num_examples=10000, total_duration=25514.248255, train/accuracy=0.702773, train/loss=1.197143, validation/accuracy=0.642660, validation/loss=1.477856, validation/num_examples=50000
I0316 07:08:07.019805 139836409243392 logging_writer.py:48] [54000] global_step=54000, grad_norm=2.6315383911132812, loss=2.319610118865967
I0316 07:11:50.194976 139836417636096 logging_writer.py:48] [54500] global_step=54500, grad_norm=2.4498836994171143, loss=4.845390319824219
I0316 07:12:47.511637 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:12:57.915439 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:13:20.149522 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:13:21.811037 140033285822272 submission_runner.py:420] Time since start: 25968.74s, 	Step: 54630, 	{'train/accuracy': 0.7091405987739563, 'train/loss': 1.1641696691513062, 'validation/accuracy': 0.6421799659729004, 'validation/loss': 1.470869541168213, 'validation/num_examples': 50000, 'test/accuracy': 0.5128999948501587, 'test/loss': 2.161769151687622, 'test/num_examples': 10000, 'score': 23989.525492668152, 'total_duration': 25968.735725164413, 'accumulated_submission_time': 23989.525492668152, 'accumulated_eval_time': 1974.1406950950623, 'accumulated_logging_time': 2.2235701084136963}
I0316 07:13:21.835960 139836409243392 logging_writer.py:48] [54630] accumulated_eval_time=1974.140695, accumulated_logging_time=2.223570, accumulated_submission_time=23989.525493, global_step=54630, preemption_count=0, score=23989.525493, test/accuracy=0.512900, test/loss=2.161769, test/num_examples=10000, total_duration=25968.735725, train/accuracy=0.709141, train/loss=1.164170, validation/accuracy=0.642180, validation/loss=1.470870, validation/num_examples=50000
I0316 07:16:02.316074 139836417636096 logging_writer.py:48] [55000] global_step=55000, grad_norm=2.548057794570923, loss=2.181560516357422
I0316 07:19:45.456454 139836409243392 logging_writer.py:48] [55500] global_step=55500, grad_norm=2.531585931777954, loss=2.096174955368042
I0316 07:20:21.931433 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:20:32.164021 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:21:04.662138 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:21:06.329956 140033285822272 submission_runner.py:420] Time since start: 26433.25s, 	Step: 55583, 	{'train/accuracy': 0.72181636095047, 'train/loss': 1.1253297328948975, 'validation/accuracy': 0.6502199769020081, 'validation/loss': 1.4542932510375977, 'validation/num_examples': 50000, 'test/accuracy': 0.5207000374794006, 'test/loss': 2.1293928623199463, 'test/num_examples': 10000, 'score': 24409.56231069565, 'total_duration': 26433.254653453827, 'accumulated_submission_time': 24409.56231069565, 'accumulated_eval_time': 2018.5392236709595, 'accumulated_logging_time': 2.2584595680236816}
I0316 07:21:06.350968 139836417636096 logging_writer.py:48] [55583] accumulated_eval_time=2018.539224, accumulated_logging_time=2.258460, accumulated_submission_time=24409.562311, global_step=55583, preemption_count=0, score=24409.562311, test/accuracy=0.520700, test/loss=2.129393, test/num_examples=10000, total_duration=26433.254653, train/accuracy=0.721816, train/loss=1.125330, validation/accuracy=0.650220, validation/loss=1.454293, validation/num_examples=50000
I0316 07:24:06.681847 139836409243392 logging_writer.py:48] [56000] global_step=56000, grad_norm=2.5578112602233887, loss=2.352947235107422
I0316 07:27:49.370932 139836417636096 logging_writer.py:48] [56500] global_step=56500, grad_norm=2.222806215286255, loss=4.228137969970703
I0316 07:28:06.836410 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:28:17.142923 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:28:41.988148 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:28:43.637736 140033285822272 submission_runner.py:420] Time since start: 26890.56s, 	Step: 56541, 	{'train/accuracy': 0.7114452719688416, 'train/loss': 1.1574795246124268, 'validation/accuracy': 0.6506999731063843, 'validation/loss': 1.4476364850997925, 'validation/num_examples': 50000, 'test/accuracy': 0.5216000080108643, 'test/loss': 2.1287922859191895, 'test/num_examples': 10000, 'score': 24829.98928809166, 'total_duration': 26890.562438964844, 'accumulated_submission_time': 24829.98928809166, 'accumulated_eval_time': 2055.3405468463898, 'accumulated_logging_time': 2.2891829013824463}
I0316 07:28:43.657042 139836409243392 logging_writer.py:48] [56541] accumulated_eval_time=2055.340547, accumulated_logging_time=2.289183, accumulated_submission_time=24829.989288, global_step=56541, preemption_count=0, score=24829.989288, test/accuracy=0.521600, test/loss=2.128792, test/num_examples=10000, total_duration=26890.562439, train/accuracy=0.711445, train/loss=1.157480, validation/accuracy=0.650700, validation/loss=1.447636, validation/num_examples=50000
I0316 07:32:02.521517 139836417636096 logging_writer.py:48] [57000] global_step=57000, grad_norm=2.3750429153442383, loss=3.072129487991333
I0316 07:35:43.803086 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:35:54.106393 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:36:15.658079 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:36:17.317909 140033285822272 submission_runner.py:420] Time since start: 27344.24s, 	Step: 57500, 	{'train/accuracy': 0.7221288681030273, 'train/loss': 1.1055638790130615, 'validation/accuracy': 0.6574400067329407, 'validation/loss': 1.402391791343689, 'validation/num_examples': 50000, 'test/accuracy': 0.5339000225067139, 'test/loss': 2.0681939125061035, 'test/num_examples': 10000, 'score': 25250.077412605286, 'total_duration': 27344.242587804794, 'accumulated_submission_time': 25250.077412605286, 'accumulated_eval_time': 2088.8553755283356, 'accumulated_logging_time': 2.3174197673797607}
I0316 07:36:17.342334 139836409243392 logging_writer.py:48] [57500] accumulated_eval_time=2088.855376, accumulated_logging_time=2.317420, accumulated_submission_time=25250.077413, global_step=57500, preemption_count=0, score=25250.077413, test/accuracy=0.533900, test/loss=2.068194, test/num_examples=10000, total_duration=27344.242588, train/accuracy=0.722129, train/loss=1.105564, validation/accuracy=0.657440, validation/loss=1.402392, validation/num_examples=50000
I0316 07:36:17.757443 139836417636096 logging_writer.py:48] [57500] global_step=57500, grad_norm=2.661158323287964, loss=2.1612355709075928
I0316 07:39:56.186295 139836409243392 logging_writer.py:48] [58000] global_step=58000, grad_norm=2.5963213443756104, loss=1.9053680896759033
I0316 07:43:17.556073 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:43:28.239437 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:43:50.015315 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:43:51.684919 140033285822272 submission_runner.py:420] Time since start: 27798.61s, 	Step: 58454, 	{'train/accuracy': 0.7285351157188416, 'train/loss': 1.0815355777740479, 'validation/accuracy': 0.6565399765968323, 'validation/loss': 1.405508041381836, 'validation/num_examples': 50000, 'test/accuracy': 0.5283000469207764, 'test/loss': 2.0920517444610596, 'test/num_examples': 10000, 'score': 25670.230689525604, 'total_duration': 27798.60959649086, 'accumulated_submission_time': 25670.230689525604, 'accumulated_eval_time': 2122.9842004776, 'accumulated_logging_time': 2.3531556129455566}
I0316 07:43:51.713630 139836417636096 logging_writer.py:48] [58454] accumulated_eval_time=2122.984200, accumulated_logging_time=2.353156, accumulated_submission_time=25670.230690, global_step=58454, preemption_count=0, score=25670.230690, test/accuracy=0.528300, test/loss=2.092052, test/num_examples=10000, total_duration=27798.609596, train/accuracy=0.728535, train/loss=1.081536, validation/accuracy=0.656540, validation/loss=1.405508, validation/num_examples=50000
I0316 07:44:10.102317 139836409243392 logging_writer.py:48] [58500] global_step=58500, grad_norm=2.7902448177337646, loss=2.0910277366638184
I0316 07:47:52.529618 139836417636096 logging_writer.py:48] [59000] global_step=59000, grad_norm=2.5684595108032227, loss=2.0087878704071045
I0316 07:50:51.877069 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:51:01.935945 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:51:26.948269 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:51:28.614037 140033285822272 submission_runner.py:420] Time since start: 28255.54s, 	Step: 59402, 	{'train/accuracy': 0.7279687523841858, 'train/loss': 1.1011300086975098, 'validation/accuracy': 0.6636599898338318, 'validation/loss': 1.3928900957107544, 'validation/num_examples': 50000, 'test/accuracy': 0.5357000231742859, 'test/loss': 2.075573205947876, 'test/num_examples': 10000, 'score': 26090.332412958145, 'total_duration': 28255.53872179985, 'accumulated_submission_time': 26090.332412958145, 'accumulated_eval_time': 2159.7212035655975, 'accumulated_logging_time': 2.39406418800354}
I0316 07:51:28.647257 139836409243392 logging_writer.py:48] [59402] accumulated_eval_time=2159.721204, accumulated_logging_time=2.394064, accumulated_submission_time=26090.332413, global_step=59402, preemption_count=0, score=26090.332413, test/accuracy=0.535700, test/loss=2.075573, test/num_examples=10000, total_duration=28255.538722, train/accuracy=0.727969, train/loss=1.101130, validation/accuracy=0.663660, validation/loss=1.392890, validation/num_examples=50000
I0316 07:52:07.964739 139836417636096 logging_writer.py:48] [59500] global_step=59500, grad_norm=2.3627147674560547, loss=2.369331121444702
I0316 07:55:50.426789 139836409243392 logging_writer.py:48] [60000] global_step=60000, grad_norm=2.57243013381958, loss=2.124089479446411
I0316 07:58:29.019197 140033285822272 spec.py:321] Evaluating on the training split.
I0316 07:58:39.034435 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 07:59:06.436739 140033285822272 spec.py:349] Evaluating on the test split.
I0316 07:59:08.097667 140033285822272 submission_runner.py:420] Time since start: 28715.02s, 	Step: 60358, 	{'train/accuracy': 0.7314453125, 'train/loss': 1.0799096822738647, 'validation/accuracy': 0.6635199785232544, 'validation/loss': 1.3858510255813599, 'validation/num_examples': 50000, 'test/accuracy': 0.5383000373840332, 'test/loss': 2.071120262145996, 'test/num_examples': 10000, 'score': 26510.644585371017, 'total_duration': 28715.022350788116, 'accumulated_submission_time': 26510.644585371017, 'accumulated_eval_time': 2198.7996776103973, 'accumulated_logging_time': 2.4381754398345947}
I0316 07:59:08.123518 139836417636096 logging_writer.py:48] [60358] accumulated_eval_time=2198.799678, accumulated_logging_time=2.438175, accumulated_submission_time=26510.644585, global_step=60358, preemption_count=0, score=26510.644585, test/accuracy=0.538300, test/loss=2.071120, test/num_examples=10000, total_duration=28715.022351, train/accuracy=0.731445, train/loss=1.079910, validation/accuracy=0.663520, validation/loss=1.385851, validation/num_examples=50000
I0316 08:00:06.919008 139836409243392 logging_writer.py:48] [60500] global_step=60500, grad_norm=2.509765625, loss=2.134484052658081
I0316 08:03:49.218513 139836417636096 logging_writer.py:48] [61000] global_step=61000, grad_norm=2.318216323852539, loss=3.991266965866089
I0316 08:06:08.259074 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:06:18.545563 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:06:47.477496 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:06:49.131385 140033285822272 submission_runner.py:420] Time since start: 29176.06s, 	Step: 61314, 	{'train/accuracy': 0.7382616996765137, 'train/loss': 1.0544168949127197, 'validation/accuracy': 0.6686800122261047, 'validation/loss': 1.3709102869033813, 'validation/num_examples': 50000, 'test/accuracy': 0.5408000349998474, 'test/loss': 2.0456087589263916, 'test/num_examples': 10000, 'score': 26930.717651605606, 'total_duration': 29176.056070804596, 'accumulated_submission_time': 26930.717651605606, 'accumulated_eval_time': 2239.6720128059387, 'accumulated_logging_time': 2.4774415493011475}
I0316 08:06:49.152593 139836409243392 logging_writer.py:48] [61314] accumulated_eval_time=2239.672013, accumulated_logging_time=2.477442, accumulated_submission_time=26930.717652, global_step=61314, preemption_count=0, score=26930.717652, test/accuracy=0.540800, test/loss=2.045609, test/num_examples=10000, total_duration=29176.056071, train/accuracy=0.738262, train/loss=1.054417, validation/accuracy=0.668680, validation/loss=1.370910, validation/num_examples=50000
I0316 08:08:06.331770 139836417636096 logging_writer.py:48] [61500] global_step=61500, grad_norm=2.582327365875244, loss=2.393664598464966
I0316 08:11:49.412810 139836409243392 logging_writer.py:48] [62000] global_step=62000, grad_norm=2.58172607421875, loss=2.180511713027954
I0316 08:13:49.207242 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:13:59.165765 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:14:25.600584 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:14:27.250265 140033285822272 submission_runner.py:420] Time since start: 29634.17s, 	Step: 62270, 	{'train/accuracy': 0.7459570169448853, 'train/loss': 1.0130585432052612, 'validation/accuracy': 0.6721400022506714, 'validation/loss': 1.3495044708251953, 'validation/num_examples': 50000, 'test/accuracy': 0.5412000417709351, 'test/loss': 2.0216023921966553, 'test/num_examples': 10000, 'score': 27350.71274805069, 'total_duration': 29634.174962759018, 'accumulated_submission_time': 27350.71274805069, 'accumulated_eval_time': 2277.7150735855103, 'accumulated_logging_time': 2.5092341899871826}
I0316 08:14:27.273401 139836417636096 logging_writer.py:48] [62270] accumulated_eval_time=2277.715074, accumulated_logging_time=2.509234, accumulated_submission_time=27350.712748, global_step=62270, preemption_count=0, score=27350.712748, test/accuracy=0.541200, test/loss=2.021602, test/num_examples=10000, total_duration=29634.174963, train/accuracy=0.745957, train/loss=1.013059, validation/accuracy=0.672140, validation/loss=1.349504, validation/num_examples=50000
I0316 08:16:04.323145 139836409243392 logging_writer.py:48] [62500] global_step=62500, grad_norm=2.5825421810150146, loss=2.1139042377471924
I0316 08:19:48.299046 139836417636096 logging_writer.py:48] [63000] global_step=63000, grad_norm=2.795565366744995, loss=2.2242767810821533
I0316 08:21:27.328375 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:21:37.760660 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:21:58.230105 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:21:59.904102 140033285822272 submission_runner.py:420] Time since start: 30086.83s, 	Step: 63224, 	{'train/accuracy': 0.734667956829071, 'train/loss': 1.0518362522125244, 'validation/accuracy': 0.6714800000190735, 'validation/loss': 1.3484188318252563, 'validation/num_examples': 50000, 'test/accuracy': 0.5412999987602234, 'test/loss': 2.035330295562744, 'test/num_examples': 10000, 'score': 27770.708323955536, 'total_duration': 30086.828785657883, 'accumulated_submission_time': 27770.708323955536, 'accumulated_eval_time': 2310.290809392929, 'accumulated_logging_time': 2.54256534576416}
I0316 08:21:59.925897 139836409243392 logging_writer.py:48] [63224] accumulated_eval_time=2310.290809, accumulated_logging_time=2.542565, accumulated_submission_time=27770.708324, global_step=63224, preemption_count=0, score=27770.708324, test/accuracy=0.541300, test/loss=2.035330, test/num_examples=10000, total_duration=30086.828786, train/accuracy=0.734668, train/loss=1.051836, validation/accuracy=0.671480, validation/loss=1.348419, validation/num_examples=50000
I0316 08:23:58.556921 139836417636096 logging_writer.py:48] [63500] global_step=63500, grad_norm=2.6353507041931152, loss=2.0770528316497803
I0316 08:27:41.988473 139836409243392 logging_writer.py:48] [64000] global_step=64000, grad_norm=2.327089548110962, loss=2.99025297164917
I0316 08:29:00.244924 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:29:10.588686 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:29:36.453672 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:29:38.098743 140033285822272 submission_runner.py:420] Time since start: 30545.02s, 	Step: 64177, 	{'train/accuracy': 0.7443554401397705, 'train/loss': 1.0113919973373413, 'validation/accuracy': 0.675879955291748, 'validation/loss': 1.3233118057250977, 'validation/num_examples': 50000, 'test/accuracy': 0.5424000024795532, 'test/loss': 1.9937825202941895, 'test/num_examples': 10000, 'score': 28190.968728780746, 'total_duration': 30545.023442029953, 'accumulated_submission_time': 28190.968728780746, 'accumulated_eval_time': 2348.144644498825, 'accumulated_logging_time': 2.5741465091705322}
I0316 08:29:38.121648 139836417636096 logging_writer.py:48] [64177] accumulated_eval_time=2348.144644, accumulated_logging_time=2.574147, accumulated_submission_time=28190.968729, global_step=64177, preemption_count=0, score=28190.968729, test/accuracy=0.542400, test/loss=1.993783, test/num_examples=10000, total_duration=30545.023442, train/accuracy=0.744355, train/loss=1.011392, validation/accuracy=0.675880, validation/loss=1.323312, validation/num_examples=50000
I0316 08:31:57.406434 139836409243392 logging_writer.py:48] [64500] global_step=64500, grad_norm=2.6185145378112793, loss=1.8863697052001953
I0316 08:35:39.496567 139836417636096 logging_writer.py:48] [65000] global_step=65000, grad_norm=2.2319281101226807, loss=3.291764497756958
I0316 08:36:38.297073 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:36:48.674591 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:37:13.076461 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:37:14.732563 140033285822272 submission_runner.py:420] Time since start: 31001.66s, 	Step: 65134, 	{'train/accuracy': 0.7463085651397705, 'train/loss': 1.0072282552719116, 'validation/accuracy': 0.6761400103569031, 'validation/loss': 1.3315125703811646, 'validation/num_examples': 50000, 'test/accuracy': 0.5491000413894653, 'test/loss': 2.013658285140991, 'test/num_examples': 10000, 'score': 28611.084764242172, 'total_duration': 31001.657252073288, 'accumulated_submission_time': 28611.084764242172, 'accumulated_eval_time': 2384.58016872406, 'accumulated_logging_time': 2.606630325317383}
I0316 08:37:14.757200 139836409243392 logging_writer.py:48] [65134] accumulated_eval_time=2384.580169, accumulated_logging_time=2.606630, accumulated_submission_time=28611.084764, global_step=65134, preemption_count=0, score=28611.084764, test/accuracy=0.549100, test/loss=2.013658, test/num_examples=10000, total_duration=31001.657252, train/accuracy=0.746309, train/loss=1.007228, validation/accuracy=0.676140, validation/loss=1.331513, validation/num_examples=50000
I0316 08:39:54.250867 139836417636096 logging_writer.py:48] [65500] global_step=65500, grad_norm=2.3216769695281982, loss=4.405705451965332
I0316 08:43:37.272107 139836409243392 logging_writer.py:48] [66000] global_step=66000, grad_norm=2.335193157196045, loss=2.780233144760132
I0316 08:44:14.981360 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:44:25.274050 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:44:47.505753 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:44:49.166955 140033285822272 submission_runner.py:420] Time since start: 31456.09s, 	Step: 66086, 	{'train/accuracy': 0.7609570026397705, 'train/loss': 0.9604236483573914, 'validation/accuracy': 0.6792399883270264, 'validation/loss': 1.3203444480895996, 'validation/num_examples': 50000, 'test/accuracy': 0.5486000180244446, 'test/loss': 2.0006017684936523, 'test/num_examples': 10000, 'score': 29031.25010251999, 'total_duration': 31456.091632843018, 'accumulated_submission_time': 29031.25010251999, 'accumulated_eval_time': 2418.765745639801, 'accumulated_logging_time': 2.6409361362457275}
I0316 08:44:49.193400 139836417636096 logging_writer.py:48] [66086] accumulated_eval_time=2418.765746, accumulated_logging_time=2.640936, accumulated_submission_time=29031.250103, global_step=66086, preemption_count=0, score=29031.250103, test/accuracy=0.548600, test/loss=2.000602, test/num_examples=10000, total_duration=31456.091633, train/accuracy=0.760957, train/loss=0.960424, validation/accuracy=0.679240, validation/loss=1.320344, validation/num_examples=50000
I0316 08:47:50.888200 139836409243392 logging_writer.py:48] [66500] global_step=66500, grad_norm=2.5490174293518066, loss=4.378511428833008
I0316 08:51:33.247369 139836417636096 logging_writer.py:48] [67000] global_step=67000, grad_norm=2.2864832878112793, loss=2.823235034942627
I0316 08:51:49.260145 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:51:59.381263 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 08:52:27.721822 140033285822272 spec.py:349] Evaluating on the test split.
I0316 08:52:29.382961 140033285822272 submission_runner.py:420] Time since start: 31916.31s, 	Step: 67038, 	{'train/accuracy': 0.754101574420929, 'train/loss': 0.9889141917228699, 'validation/accuracy': 0.6852200031280518, 'validation/loss': 1.2971361875534058, 'validation/num_examples': 50000, 'test/accuracy': 0.5558000206947327, 'test/loss': 1.9769766330718994, 'test/num_examples': 10000, 'score': 29451.256382465363, 'total_duration': 31916.307639837265, 'accumulated_submission_time': 29451.256382465363, 'accumulated_eval_time': 2458.888530254364, 'accumulated_logging_time': 2.6780052185058594}
I0316 08:52:29.408849 139836409243392 logging_writer.py:48] [67038] accumulated_eval_time=2458.888530, accumulated_logging_time=2.678005, accumulated_submission_time=29451.256382, global_step=67038, preemption_count=0, score=29451.256382, test/accuracy=0.555800, test/loss=1.976977, test/num_examples=10000, total_duration=31916.307640, train/accuracy=0.754102, train/loss=0.988914, validation/accuracy=0.685220, validation/loss=1.297136, validation/num_examples=50000
I0316 08:55:49.902035 139836417636096 logging_writer.py:48] [67500] global_step=67500, grad_norm=2.419743299484253, loss=2.2628402709960938
I0316 08:59:29.415336 140033285822272 spec.py:321] Evaluating on the training split.
I0316 08:59:39.731744 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:00:04.100217 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:00:05.748351 140033285822272 submission_runner.py:420] Time since start: 32372.67s, 	Step: 67993, 	{'train/accuracy': 0.7536523342132568, 'train/loss': 0.9675090312957764, 'validation/accuracy': 0.6839599609375, 'validation/loss': 1.2840176820755005, 'validation/num_examples': 50000, 'test/accuracy': 0.5560000538825989, 'test/loss': 1.9566236734390259, 'test/num_examples': 10000, 'score': 29871.203752994537, 'total_duration': 32372.67304301262, 'accumulated_submission_time': 29871.203752994537, 'accumulated_eval_time': 2495.221568584442, 'accumulated_logging_time': 2.713636875152588}
I0316 09:00:05.769639 139836409243392 logging_writer.py:48] [67993] accumulated_eval_time=2495.221569, accumulated_logging_time=2.713637, accumulated_submission_time=29871.203753, global_step=67993, preemption_count=0, score=29871.203753, test/accuracy=0.556000, test/loss=1.956624, test/num_examples=10000, total_duration=32372.673043, train/accuracy=0.753652, train/loss=0.967509, validation/accuracy=0.683960, validation/loss=1.284018, validation/num_examples=50000
I0316 09:00:08.893975 139836417636096 logging_writer.py:48] [68000] global_step=68000, grad_norm=2.30612850189209, loss=3.003006935119629
I0316 09:03:46.336825 139836409243392 logging_writer.py:48] [68500] global_step=68500, grad_norm=2.2754294872283936, loss=3.001147747039795
I0316 09:07:06.206143 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:07:16.303647 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:07:41.853413 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:07:43.503319 140033285822272 submission_runner.py:420] Time since start: 32830.43s, 	Step: 68950, 	{'train/accuracy': 0.7650195360183716, 'train/loss': 0.9357429146766663, 'validation/accuracy': 0.6906399726867676, 'validation/loss': 1.2731653451919556, 'validation/num_examples': 50000, 'test/accuracy': 0.5631000399589539, 'test/loss': 1.9448235034942627, 'test/num_examples': 10000, 'score': 30291.581280708313, 'total_duration': 32830.42801618576, 'accumulated_submission_time': 30291.581280708313, 'accumulated_eval_time': 2532.51881480217, 'accumulated_logging_time': 2.7444560527801514}
I0316 09:07:43.524934 139836417636096 logging_writer.py:48] [68950] accumulated_eval_time=2532.518815, accumulated_logging_time=2.744456, accumulated_submission_time=30291.581281, global_step=68950, preemption_count=0, score=30291.581281, test/accuracy=0.563100, test/loss=1.944824, test/num_examples=10000, total_duration=32830.428016, train/accuracy=0.765020, train/loss=0.935743, validation/accuracy=0.690640, validation/loss=1.273165, validation/num_examples=50000
I0316 09:08:03.458802 139836409243392 logging_writer.py:48] [69000] global_step=69000, grad_norm=2.5008068084716797, loss=2.3670194149017334
I0316 09:11:43.701296 139836417636096 logging_writer.py:48] [69500] global_step=69500, grad_norm=2.304971694946289, loss=4.170026779174805
I0316 09:14:43.694984 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:14:54.176354 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:15:18.166166 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:15:19.830000 140033285822272 submission_runner.py:420] Time since start: 33286.75s, 	Step: 69906, 	{'train/accuracy': 0.7634375095367432, 'train/loss': 0.9249235987663269, 'validation/accuracy': 0.6910200119018555, 'validation/loss': 1.255893349647522, 'validation/num_examples': 50000, 'test/accuracy': 0.5622000098228455, 'test/loss': 1.9211840629577637, 'test/num_examples': 10000, 'score': 30711.692078113556, 'total_duration': 33286.7546775341, 'accumulated_submission_time': 30711.692078113556, 'accumulated_eval_time': 2568.6538326740265, 'accumulated_logging_time': 2.7768213748931885}
I0316 09:15:19.866539 139836409243392 logging_writer.py:48] [69906] accumulated_eval_time=2568.653833, accumulated_logging_time=2.776821, accumulated_submission_time=30711.692078, global_step=69906, preemption_count=0, score=30711.692078, test/accuracy=0.562200, test/loss=1.921184, test/num_examples=10000, total_duration=33286.754678, train/accuracy=0.763438, train/loss=0.924924, validation/accuracy=0.691020, validation/loss=1.255893, validation/num_examples=50000
I0316 09:15:57.214430 139836417636096 logging_writer.py:48] [70000] global_step=70000, grad_norm=2.550527334213257, loss=1.8480616807937622
I0316 09:19:40.720623 139836409243392 logging_writer.py:48] [70500] global_step=70500, grad_norm=2.4355075359344482, loss=4.309565544128418
I0316 09:22:20.214092 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:22:30.674357 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:22:53.998589 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:22:55.675120 140033285822272 submission_runner.py:420] Time since start: 33742.60s, 	Step: 70860, 	{'train/accuracy': 0.7605859041213989, 'train/loss': 0.9275447726249695, 'validation/accuracy': 0.6900399923324585, 'validation/loss': 1.2489606142044067, 'validation/num_examples': 50000, 'test/accuracy': 0.5592000484466553, 'test/loss': 1.929077386856079, 'test/num_examples': 10000, 'score': 31131.98057603836, 'total_duration': 33742.599757909775, 'accumulated_submission_time': 31131.98057603836, 'accumulated_eval_time': 2604.1148250102997, 'accumulated_logging_time': 2.8237569332122803}
I0316 09:22:55.712313 139836417636096 logging_writer.py:48] [70860] accumulated_eval_time=2604.114825, accumulated_logging_time=2.823757, accumulated_submission_time=31131.980576, global_step=70860, preemption_count=0, score=31131.980576, test/accuracy=0.559200, test/loss=1.929077, test/num_examples=10000, total_duration=33742.599758, train/accuracy=0.760586, train/loss=0.927545, validation/accuracy=0.690040, validation/loss=1.248961, validation/num_examples=50000
I0316 09:23:53.533845 139836409243392 logging_writer.py:48] [71000] global_step=71000, grad_norm=2.4031143188476562, loss=3.066153049468994
I0316 09:27:36.550472 139836417636096 logging_writer.py:48] [71500] global_step=71500, grad_norm=2.7939839363098145, loss=2.029052495956421
I0316 09:29:55.963978 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:30:06.401642 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:30:32.411874 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:30:34.059516 140033285822272 submission_runner.py:420] Time since start: 34200.98s, 	Step: 71814, 	{'train/accuracy': 0.7680273056030273, 'train/loss': 0.9155058264732361, 'validation/accuracy': 0.6950799822807312, 'validation/loss': 1.2489674091339111, 'validation/num_examples': 50000, 'test/accuracy': 0.563800036907196, 'test/loss': 1.9288992881774902, 'test/num_examples': 10000, 'score': 31552.173714637756, 'total_duration': 34200.98422002792, 'accumulated_submission_time': 31552.173714637756, 'accumulated_eval_time': 2642.210392475128, 'accumulated_logging_time': 2.870387315750122}
I0316 09:30:34.085095 139836409243392 logging_writer.py:48] [71814] accumulated_eval_time=2642.210392, accumulated_logging_time=2.870387, accumulated_submission_time=31552.173715, global_step=71814, preemption_count=0, score=31552.173715, test/accuracy=0.563800, test/loss=1.928899, test/num_examples=10000, total_duration=34200.984220, train/accuracy=0.768027, train/loss=0.915506, validation/accuracy=0.695080, validation/loss=1.248967, validation/num_examples=50000
I0316 09:31:51.675598 139836417636096 logging_writer.py:48] [72000] global_step=72000, grad_norm=2.7431468963623047, loss=1.987815499305725
I0316 09:35:34.662562 139836409243392 logging_writer.py:48] [72500] global_step=72500, grad_norm=2.637228488922119, loss=1.838953971862793
I0316 09:37:34.169754 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:37:44.566785 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:38:08.128428 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:38:09.790133 140033285822272 submission_runner.py:420] Time since start: 34656.71s, 	Step: 72769, 	{'train/accuracy': 0.7766796946525574, 'train/loss': 0.8705880045890808, 'validation/accuracy': 0.6983000040054321, 'validation/loss': 1.2320274114608765, 'validation/num_examples': 50000, 'test/accuracy': 0.5623000264167786, 'test/loss': 1.9119281768798828, 'test/num_examples': 10000, 'score': 31972.198963165283, 'total_duration': 34656.71481728554, 'accumulated_submission_time': 31972.198963165283, 'accumulated_eval_time': 2677.8308210372925, 'accumulated_logging_time': 2.9055275917053223}
I0316 09:38:09.826723 139836417636096 logging_writer.py:48] [72769] accumulated_eval_time=2677.830821, accumulated_logging_time=2.905528, accumulated_submission_time=31972.198963, global_step=72769, preemption_count=0, score=31972.198963, test/accuracy=0.562300, test/loss=1.911928, test/num_examples=10000, total_duration=34656.714817, train/accuracy=0.776680, train/loss=0.870588, validation/accuracy=0.698300, validation/loss=1.232027, validation/num_examples=50000
I0316 09:39:47.920433 139836409243392 logging_writer.py:48] [73000] global_step=73000, grad_norm=2.429161310195923, loss=2.5183517932891846
I0316 09:43:31.681107 139836417636096 logging_writer.py:48] [73500] global_step=73500, grad_norm=2.496331214904785, loss=1.746049165725708
I0316 09:45:09.880638 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:45:20.372616 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:45:43.480854 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:45:45.137780 140033285822272 submission_runner.py:420] Time since start: 35112.06s, 	Step: 73722, 	{'train/accuracy': 0.7681054472923279, 'train/loss': 0.910663366317749, 'validation/accuracy': 0.6999599933624268, 'validation/loss': 1.216040015220642, 'validation/num_examples': 50000, 'test/accuracy': 0.5683000087738037, 'test/loss': 1.8952546119689941, 'test/num_examples': 10000, 'score': 32392.19476556778, 'total_duration': 35112.06246328354, 'accumulated_submission_time': 32392.19476556778, 'accumulated_eval_time': 2713.08797287941, 'accumulated_logging_time': 2.951908588409424}
I0316 09:45:45.168594 139836409243392 logging_writer.py:48] [73722] accumulated_eval_time=2713.087973, accumulated_logging_time=2.951909, accumulated_submission_time=32392.194766, global_step=73722, preemption_count=0, score=32392.194766, test/accuracy=0.568300, test/loss=1.895255, test/num_examples=10000, total_duration=35112.062463, train/accuracy=0.768105, train/loss=0.910663, validation/accuracy=0.699960, validation/loss=1.216040, validation/num_examples=50000
I0316 09:47:45.088344 139836417636096 logging_writer.py:48] [74000] global_step=74000, grad_norm=2.4547536373138428, loss=2.2269327640533447
I0316 09:51:27.847509 139836409243392 logging_writer.py:48] [74500] global_step=74500, grad_norm=2.49753737449646, loss=1.982722282409668
I0316 09:52:45.291991 140033285822272 spec.py:321] Evaluating on the training split.
I0316 09:52:55.689422 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 09:53:22.758096 140033285822272 spec.py:349] Evaluating on the test split.
I0316 09:53:24.413556 140033285822272 submission_runner.py:420] Time since start: 35571.34s, 	Step: 74675, 	{'train/accuracy': 0.7721874713897705, 'train/loss': 0.8845731019973755, 'validation/accuracy': 0.6978200078010559, 'validation/loss': 1.2194421291351318, 'validation/num_examples': 50000, 'test/accuracy': 0.5712000131607056, 'test/loss': 1.881524920463562, 'test/num_examples': 10000, 'score': 32812.25599312782, 'total_duration': 35571.33825588226, 'accumulated_submission_time': 32812.25599312782, 'accumulated_eval_time': 2752.2095618247986, 'accumulated_logging_time': 2.9954280853271484}
I0316 09:53:24.437940 139836417636096 logging_writer.py:48] [74675] accumulated_eval_time=2752.209562, accumulated_logging_time=2.995428, accumulated_submission_time=32812.255993, global_step=74675, preemption_count=0, score=32812.255993, test/accuracy=0.571200, test/loss=1.881525, test/num_examples=10000, total_duration=35571.338256, train/accuracy=0.772187, train/loss=0.884573, validation/accuracy=0.697820, validation/loss=1.219442, validation/num_examples=50000
I0316 09:55:43.679072 139836409243392 logging_writer.py:48] [75000] global_step=75000, grad_norm=2.5411458015441895, loss=1.794055461883545
I0316 09:59:26.755406 139836417636096 logging_writer.py:48] [75500] global_step=75500, grad_norm=2.616194486618042, loss=1.8611171245574951
I0316 10:00:24.739593 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:00:35.134630 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:00:56.520688 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:00:58.213830 140033285822272 submission_runner.py:420] Time since start: 36025.14s, 	Step: 75632, 	{'train/accuracy': 0.774707019329071, 'train/loss': 0.8985239863395691, 'validation/accuracy': 0.7001999616622925, 'validation/loss': 1.2316291332244873, 'validation/num_examples': 50000, 'test/accuracy': 0.5731000304222107, 'test/loss': 1.8957104682922363, 'test/num_examples': 10000, 'score': 33232.49916625023, 'total_duration': 36025.13847947121, 'accumulated_submission_time': 33232.49916625023, 'accumulated_eval_time': 2785.6837685108185, 'accumulated_logging_time': 3.029832601547241}
I0316 10:00:58.253846 139836409243392 logging_writer.py:48] [75632] accumulated_eval_time=2785.683769, accumulated_logging_time=3.029833, accumulated_submission_time=33232.499166, global_step=75632, preemption_count=0, score=33232.499166, test/accuracy=0.573100, test/loss=1.895710, test/num_examples=10000, total_duration=36025.138479, train/accuracy=0.774707, train/loss=0.898524, validation/accuracy=0.700200, validation/loss=1.231629, validation/num_examples=50000
I0316 10:03:37.203743 139836417636096 logging_writer.py:48] [76000] global_step=76000, grad_norm=2.3670711517333984, loss=4.255685329437256
I0316 10:07:19.866406 139836409243392 logging_writer.py:48] [76500] global_step=76500, grad_norm=2.5310604572296143, loss=2.5054612159729004
I0316 10:07:58.323848 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:08:08.971758 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:08:31.171494 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:08:32.835631 140033285822272 submission_runner.py:420] Time since start: 36479.76s, 	Step: 76588, 	{'train/accuracy': 0.7801171541213989, 'train/loss': 0.83815598487854, 'validation/accuracy': 0.7055400013923645, 'validation/loss': 1.188283920288086, 'validation/num_examples': 50000, 'test/accuracy': 0.578000009059906, 'test/loss': 1.8477613925933838, 'test/num_examples': 10000, 'score': 33652.50452065468, 'total_duration': 36479.760321855545, 'accumulated_submission_time': 33652.50452065468, 'accumulated_eval_time': 2820.195548772812, 'accumulated_logging_time': 3.084975004196167}
I0316 10:08:32.861991 139836417636096 logging_writer.py:48] [76588] accumulated_eval_time=2820.195549, accumulated_logging_time=3.084975, accumulated_submission_time=33652.504521, global_step=76588, preemption_count=0, score=33652.504521, test/accuracy=0.578000, test/loss=1.847761, test/num_examples=10000, total_duration=36479.760322, train/accuracy=0.780117, train/loss=0.838156, validation/accuracy=0.705540, validation/loss=1.188284, validation/num_examples=50000
I0316 10:11:32.672854 139836409243392 logging_writer.py:48] [77000] global_step=77000, grad_norm=2.287102699279785, loss=4.073019504547119
I0316 10:15:15.803082 139836417636096 logging_writer.py:48] [77500] global_step=77500, grad_norm=2.4855775833129883, loss=1.9511194229125977
I0316 10:15:32.888517 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:15:43.675946 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:16:10.819565 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:16:12.484349 140033285822272 submission_runner.py:420] Time since start: 36939.41s, 	Step: 77540, 	{'train/accuracy': 0.7811328172683716, 'train/loss': 0.8406301736831665, 'validation/accuracy': 0.7036399841308594, 'validation/loss': 1.1923822164535522, 'validation/num_examples': 50000, 'test/accuracy': 0.5746999979019165, 'test/loss': 1.8451563119888306, 'test/num_examples': 10000, 'score': 34072.47146344185, 'total_duration': 36939.40902590752, 'accumulated_submission_time': 34072.47146344185, 'accumulated_eval_time': 2859.7913534641266, 'accumulated_logging_time': 3.1218364238739014}
I0316 10:16:12.514363 139836409243392 logging_writer.py:48] [77540] accumulated_eval_time=2859.791353, accumulated_logging_time=3.121836, accumulated_submission_time=34072.471463, global_step=77540, preemption_count=0, score=34072.471463, test/accuracy=0.574700, test/loss=1.845156, test/num_examples=10000, total_duration=36939.409026, train/accuracy=0.781133, train/loss=0.840630, validation/accuracy=0.703640, validation/loss=1.192382, validation/num_examples=50000
I0316 10:19:34.074523 139836417636096 logging_writer.py:48] [78000] global_step=78000, grad_norm=2.3000850677490234, loss=3.6129837036132812
I0316 10:23:12.798855 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:23:23.264034 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:23:53.294738 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:23:54.964592 140033285822272 submission_runner.py:420] Time since start: 37401.89s, 	Step: 78493, 	{'train/accuracy': 0.7834570407867432, 'train/loss': 0.8356504440307617, 'validation/accuracy': 0.7069599628448486, 'validation/loss': 1.18317449092865, 'validation/num_examples': 50000, 'test/accuracy': 0.5753000378608704, 'test/loss': 1.847076416015625, 'test/num_examples': 10000, 'score': 34492.69671034813, 'total_duration': 37401.889246463776, 'accumulated_submission_time': 34492.69671034813, 'accumulated_eval_time': 2901.95707654953, 'accumulated_logging_time': 3.1622819900512695}
I0316 10:23:55.010078 139836409243392 logging_writer.py:48] [78493] accumulated_eval_time=2901.957077, accumulated_logging_time=3.162282, accumulated_submission_time=34492.696710, global_step=78493, preemption_count=0, score=34492.696710, test/accuracy=0.575300, test/loss=1.847076, test/num_examples=10000, total_duration=37401.889246, train/accuracy=0.783457, train/loss=0.835650, validation/accuracy=0.706960, validation/loss=1.183174, validation/num_examples=50000
I0316 10:23:58.159894 139836417636096 logging_writer.py:48] [78500] global_step=78500, grad_norm=2.382666826248169, loss=3.6576738357543945
I0316 10:27:35.796378 139836409243392 logging_writer.py:48] [79000] global_step=79000, grad_norm=2.5877809524536133, loss=1.8804423809051514
I0316 10:30:55.197210 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:31:05.706283 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:31:27.132117 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:31:28.796188 140033285822272 submission_runner.py:420] Time since start: 37855.72s, 	Step: 79450, 	{'train/accuracy': 0.7914257645606995, 'train/loss': 0.8288572430610657, 'validation/accuracy': 0.709559977054596, 'validation/loss': 1.1907429695129395, 'validation/num_examples': 50000, 'test/accuracy': 0.5766000151634216, 'test/loss': 1.8492708206176758, 'test/num_examples': 10000, 'score': 34912.819937705994, 'total_duration': 37855.720873594284, 'accumulated_submission_time': 34912.819937705994, 'accumulated_eval_time': 2935.5560653209686, 'accumulated_logging_time': 3.2225122451782227}
I0316 10:31:28.824946 139836417636096 logging_writer.py:48] [79450] accumulated_eval_time=2935.556065, accumulated_logging_time=3.222512, accumulated_submission_time=34912.819938, global_step=79450, preemption_count=0, score=34912.819938, test/accuracy=0.576600, test/loss=1.849271, test/num_examples=10000, total_duration=37855.720874, train/accuracy=0.791426, train/loss=0.828857, validation/accuracy=0.709560, validation/loss=1.190743, validation/num_examples=50000
I0316 10:31:48.770882 139836409243392 logging_writer.py:48] [79500] global_step=79500, grad_norm=2.5429954528808594, loss=2.170088529586792
I0316 10:35:29.824518 139836417636096 logging_writer.py:48] [80000] global_step=80000, grad_norm=2.636596202850342, loss=1.9279003143310547
I0316 10:38:29.155547 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:38:39.253314 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:39:05.313895 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:39:06.966242 140033285822272 submission_runner.py:420] Time since start: 38313.89s, 	Step: 80403, 	{'train/accuracy': 0.7861523032188416, 'train/loss': 0.8298468589782715, 'validation/accuracy': 0.7110199928283691, 'validation/loss': 1.1689532995224, 'validation/num_examples': 50000, 'test/accuracy': 0.5800999999046326, 'test/loss': 1.8308848142623901, 'test/num_examples': 10000, 'score': 35333.09168720245, 'total_duration': 38313.8909406662, 'accumulated_submission_time': 35333.09168720245, 'accumulated_eval_time': 2973.366780757904, 'accumulated_logging_time': 3.261307954788208}
I0316 10:39:06.988843 139836409243392 logging_writer.py:48] [80403] accumulated_eval_time=2973.366781, accumulated_logging_time=3.261308, accumulated_submission_time=35333.091687, global_step=80403, preemption_count=0, score=35333.091687, test/accuracy=0.580100, test/loss=1.830885, test/num_examples=10000, total_duration=38313.890941, train/accuracy=0.786152, train/loss=0.829847, validation/accuracy=0.711020, validation/loss=1.168953, validation/num_examples=50000
I0316 10:39:45.310604 139836417636096 logging_writer.py:48] [80500] global_step=80500, grad_norm=2.387887477874756, loss=1.9428638219833374
I0316 10:43:27.895653 139836409243392 logging_writer.py:48] [81000] global_step=81000, grad_norm=2.474916934967041, loss=1.704567551612854
I0316 10:46:07.333607 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:46:17.392697 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:46:41.822839 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:46:43.485853 140033285822272 submission_runner.py:420] Time since start: 38770.41s, 	Step: 81360, 	{'train/accuracy': 0.7941992282867432, 'train/loss': 0.796230137348175, 'validation/accuracy': 0.7138999700546265, 'validation/loss': 1.156989574432373, 'validation/num_examples': 50000, 'test/accuracy': 0.5859000086784363, 'test/loss': 1.8184973001480103, 'test/num_examples': 10000, 'score': 35753.37743425369, 'total_duration': 38770.41054081917, 'accumulated_submission_time': 35753.37743425369, 'accumulated_eval_time': 3009.5190649032593, 'accumulated_logging_time': 3.293361186981201}
I0316 10:46:43.517992 139836417636096 logging_writer.py:48] [81360] accumulated_eval_time=3009.519065, accumulated_logging_time=3.293361, accumulated_submission_time=35753.377434, global_step=81360, preemption_count=0, score=35753.377434, test/accuracy=0.585900, test/loss=1.818497, test/num_examples=10000, total_duration=38770.410541, train/accuracy=0.794199, train/loss=0.796230, validation/accuracy=0.713900, validation/loss=1.156990, validation/num_examples=50000
I0316 10:47:40.996590 139836409243392 logging_writer.py:48] [81500] global_step=81500, grad_norm=2.6595470905303955, loss=1.5989629030227661
I0316 10:51:23.693572 139836417636096 logging_writer.py:48] [82000] global_step=82000, grad_norm=2.5657718181610107, loss=1.9891501665115356
I0316 10:53:43.574266 140033285822272 spec.py:321] Evaluating on the training split.
I0316 10:53:53.729619 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 10:54:18.941001 140033285822272 spec.py:349] Evaluating on the test split.
I0316 10:54:20.605323 140033285822272 submission_runner.py:420] Time since start: 39227.53s, 	Step: 82315, 	{'train/accuracy': 0.7957226634025574, 'train/loss': 0.7792394161224365, 'validation/accuracy': 0.7140600085258484, 'validation/loss': 1.1447581052780151, 'validation/num_examples': 50000, 'test/accuracy': 0.58160001039505, 'test/loss': 1.8061102628707886, 'test/num_examples': 10000, 'score': 36173.37316656113, 'total_duration': 39227.530015707016, 'accumulated_submission_time': 36173.37316656113, 'accumulated_eval_time': 3046.5501339435577, 'accumulated_logging_time': 3.3365039825439453}
I0316 10:54:20.631793 139836409243392 logging_writer.py:48] [82315] accumulated_eval_time=3046.550134, accumulated_logging_time=3.336504, accumulated_submission_time=36173.373167, global_step=82315, preemption_count=0, score=36173.373167, test/accuracy=0.581600, test/loss=1.806110, test/num_examples=10000, total_duration=39227.530016, train/accuracy=0.795723, train/loss=0.779239, validation/accuracy=0.714060, validation/loss=1.144758, validation/num_examples=50000
I0316 10:55:37.927791 139836417636096 logging_writer.py:48] [82500] global_step=82500, grad_norm=2.656087875366211, loss=1.7587403059005737
I0316 10:59:20.708555 139836409243392 logging_writer.py:48] [83000] global_step=83000, grad_norm=2.4872312545776367, loss=1.9404802322387695
I0316 11:01:20.656338 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:01:31.233639 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:01:52.709206 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:01:54.372705 140033285822272 submission_runner.py:420] Time since start: 39681.30s, 	Step: 83271, 	{'train/accuracy': 0.8056054711341858, 'train/loss': 0.7583882212638855, 'validation/accuracy': 0.7160199880599976, 'validation/loss': 1.150341272354126, 'validation/num_examples': 50000, 'test/accuracy': 0.5869000554084778, 'test/loss': 1.7996519804000854, 'test/num_examples': 10000, 'score': 36593.338634729385, 'total_duration': 39681.297360658646, 'accumulated_submission_time': 36593.338634729385, 'accumulated_eval_time': 3080.266455888748, 'accumulated_logging_time': 3.372302532196045}
I0316 11:01:54.414874 139836417636096 logging_writer.py:48] [83271] accumulated_eval_time=3080.266456, accumulated_logging_time=3.372303, accumulated_submission_time=36593.338635, global_step=83271, preemption_count=0, score=36593.338635, test/accuracy=0.586900, test/loss=1.799652, test/num_examples=10000, total_duration=39681.297361, train/accuracy=0.805605, train/loss=0.758388, validation/accuracy=0.716020, validation/loss=1.150341, validation/num_examples=50000
I0316 11:03:32.297683 139836409243392 logging_writer.py:48] [83500] global_step=83500, grad_norm=2.3206534385681152, loss=2.820326566696167
I0316 11:07:15.113523 139836417636096 logging_writer.py:48] [84000] global_step=84000, grad_norm=2.4895310401916504, loss=2.0680627822875977
I0316 11:08:54.495513 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:09:04.899820 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:09:27.339639 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:09:29.004708 140033285822272 submission_runner.py:420] Time since start: 40135.93s, 	Step: 84224, 	{'train/accuracy': 0.79554682970047, 'train/loss': 0.7888644933700562, 'validation/accuracy': 0.716159999370575, 'validation/loss': 1.1426273584365845, 'validation/num_examples': 50000, 'test/accuracy': 0.5919000506401062, 'test/loss': 1.7864233255386353, 'test/num_examples': 10000, 'score': 37013.359367609024, 'total_duration': 40135.92939543724, 'accumulated_submission_time': 37013.359367609024, 'accumulated_eval_time': 3114.775664329529, 'accumulated_logging_time': 3.425116539001465}
I0316 11:09:29.030973 139836409243392 logging_writer.py:48] [84224] accumulated_eval_time=3114.775664, accumulated_logging_time=3.425117, accumulated_submission_time=37013.359368, global_step=84224, preemption_count=0, score=37013.359368, test/accuracy=0.591900, test/loss=1.786423, test/num_examples=10000, total_duration=40135.929395, train/accuracy=0.795547, train/loss=0.788864, validation/accuracy=0.716160, validation/loss=1.142627, validation/num_examples=50000
I0316 11:11:28.381951 139836417636096 logging_writer.py:48] [84500] global_step=84500, grad_norm=2.4451282024383545, loss=2.9290385246276855
I0316 11:15:11.137084 139836409243392 logging_writer.py:48] [85000] global_step=85000, grad_norm=2.439157485961914, loss=1.8899446725845337
I0316 11:16:29.276575 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:16:39.285471 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:17:16.922978 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:17:18.568625 140033285822272 submission_runner.py:420] Time since start: 40605.49s, 	Step: 85177, 	{'train/accuracy': 0.7994726300239563, 'train/loss': 0.7706484794616699, 'validation/accuracy': 0.7192999720573425, 'validation/loss': 1.1310958862304688, 'validation/num_examples': 50000, 'test/accuracy': 0.589900016784668, 'test/loss': 1.7978416681289673, 'test/num_examples': 10000, 'score': 37433.54198694229, 'total_duration': 40605.49332666397, 'accumulated_submission_time': 37433.54198694229, 'accumulated_eval_time': 3164.0677342414856, 'accumulated_logging_time': 3.4646859169006348}
I0316 11:17:18.590858 139836417636096 logging_writer.py:48] [85177] accumulated_eval_time=3164.067734, accumulated_logging_time=3.464686, accumulated_submission_time=37433.541987, global_step=85177, preemption_count=0, score=37433.541987, test/accuracy=0.589900, test/loss=1.797842, test/num_examples=10000, total_duration=40605.493327, train/accuracy=0.799473, train/loss=0.770648, validation/accuracy=0.719300, validation/loss=1.131096, validation/num_examples=50000
I0316 11:19:37.451598 139836409243392 logging_writer.py:48] [85500] global_step=85500, grad_norm=2.7117927074432373, loss=1.6176525354385376
I0316 11:23:20.475095 139836417636096 logging_writer.py:48] [86000] global_step=86000, grad_norm=2.487229347229004, loss=3.983527183532715
I0316 11:24:18.657175 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:24:28.969089 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:24:52.855067 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:24:54.509578 140033285822272 submission_runner.py:420] Time since start: 41061.43s, 	Step: 86133, 	{'train/accuracy': 0.8046875, 'train/loss': 0.7627406120300293, 'validation/accuracy': 0.7196800112724304, 'validation/loss': 1.136682391166687, 'validation/num_examples': 50000, 'test/accuracy': 0.5866000056266785, 'test/loss': 1.7942957878112793, 'test/num_examples': 10000, 'score': 37853.546439647675, 'total_duration': 41061.43424797058, 'accumulated_submission_time': 37853.546439647675, 'accumulated_eval_time': 3199.920131921768, 'accumulated_logging_time': 3.4973526000976562}
I0316 11:24:54.539227 139836409243392 logging_writer.py:48] [86133] accumulated_eval_time=3199.920132, accumulated_logging_time=3.497353, accumulated_submission_time=37853.546440, global_step=86133, preemption_count=0, score=37853.546440, test/accuracy=0.586600, test/loss=1.794296, test/num_examples=10000, total_duration=41061.434248, train/accuracy=0.804688, train/loss=0.762741, validation/accuracy=0.719680, validation/loss=1.136682, validation/num_examples=50000
I0316 11:27:32.697571 139836417636096 logging_writer.py:48] [86500] global_step=86500, grad_norm=2.4950528144836426, loss=2.0162510871887207
I0316 11:31:15.018882 139836409243392 logging_writer.py:48] [87000] global_step=87000, grad_norm=2.5695199966430664, loss=1.6001477241516113
I0316 11:31:54.633592 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:32:04.838624 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:32:26.792526 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:32:28.447160 140033285822272 submission_runner.py:420] Time since start: 41515.37s, 	Step: 87091, 	{'train/accuracy': 0.8030663728713989, 'train/loss': 0.7647061944007874, 'validation/accuracy': 0.7223799824714661, 'validation/loss': 1.1233367919921875, 'validation/num_examples': 50000, 'test/accuracy': 0.589400053024292, 'test/loss': 1.7823338508605957, 'test/num_examples': 10000, 'score': 38273.58218240738, 'total_duration': 41515.371849775314, 'accumulated_submission_time': 38273.58218240738, 'accumulated_eval_time': 3233.733690261841, 'accumulated_logging_time': 3.536593437194824}
I0316 11:32:28.473136 139836417636096 logging_writer.py:48] [87091] accumulated_eval_time=3233.733690, accumulated_logging_time=3.536593, accumulated_submission_time=38273.582182, global_step=87091, preemption_count=0, score=38273.582182, test/accuracy=0.589400, test/loss=1.782334, test/num_examples=10000, total_duration=41515.371850, train/accuracy=0.803066, train/loss=0.764706, validation/accuracy=0.722380, validation/loss=1.123337, validation/num_examples=50000
I0316 11:35:26.446306 139836409243392 logging_writer.py:48] [87500] global_step=87500, grad_norm=2.3958747386932373, loss=3.341872215270996
I0316 11:39:10.127057 139836417636096 logging_writer.py:48] [88000] global_step=88000, grad_norm=2.5511045455932617, loss=1.655758261680603
I0316 11:39:28.876517 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:39:39.300273 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:40:03.934189 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:40:05.584246 140033285822272 submission_runner.py:420] Time since start: 41972.51s, 	Step: 88044, 	{'train/accuracy': 0.8049218654632568, 'train/loss': 0.75309157371521, 'validation/accuracy': 0.7244399785995483, 'validation/loss': 1.1125150918960571, 'validation/num_examples': 50000, 'test/accuracy': 0.5962000489234924, 'test/loss': 1.762255311012268, 'test/num_examples': 10000, 'score': 38693.926919698715, 'total_duration': 41972.508944272995, 'accumulated_submission_time': 38693.926919698715, 'accumulated_eval_time': 3270.441417694092, 'accumulated_logging_time': 3.5724127292633057}
I0316 11:40:05.608627 139836409243392 logging_writer.py:48] [88044] accumulated_eval_time=3270.441418, accumulated_logging_time=3.572413, accumulated_submission_time=38693.926920, global_step=88044, preemption_count=0, score=38693.926920, test/accuracy=0.596200, test/loss=1.762255, test/num_examples=10000, total_duration=41972.508944, train/accuracy=0.804922, train/loss=0.753092, validation/accuracy=0.724440, validation/loss=1.112515, validation/num_examples=50000
I0316 11:43:24.011233 139836417636096 logging_writer.py:48] [88500] global_step=88500, grad_norm=2.6346664428710938, loss=1.677438735961914
I0316 11:47:05.844650 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:47:16.327934 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:47:44.662734 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:47:46.325640 140033285822272 submission_runner.py:420] Time since start: 42433.25s, 	Step: 88999, 	{'train/accuracy': 0.8087109327316284, 'train/loss': 0.7536008954048157, 'validation/accuracy': 0.7234599590301514, 'validation/loss': 1.1227951049804688, 'validation/num_examples': 50000, 'test/accuracy': 0.5915000438690186, 'test/loss': 1.7753443717956543, 'test/num_examples': 10000, 'score': 39114.10504937172, 'total_duration': 42433.25032758713, 'accumulated_submission_time': 39114.10504937172, 'accumulated_eval_time': 3310.922417640686, 'accumulated_logging_time': 3.605489492416382}
I0316 11:47:46.358815 139836409243392 logging_writer.py:48] [88999] accumulated_eval_time=3310.922418, accumulated_logging_time=3.605489, accumulated_submission_time=39114.105049, global_step=88999, preemption_count=0, score=39114.105049, test/accuracy=0.591500, test/loss=1.775344, test/num_examples=10000, total_duration=42433.250328, train/accuracy=0.808711, train/loss=0.753601, validation/accuracy=0.723460, validation/loss=1.122795, validation/num_examples=50000
I0316 11:47:47.143289 139836417636096 logging_writer.py:48] [89000] global_step=89000, grad_norm=2.612848997116089, loss=1.6868088245391846
I0316 11:51:24.842882 139836409243392 logging_writer.py:48] [89500] global_step=89500, grad_norm=2.5180954933166504, loss=2.0734541416168213
I0316 11:54:46.577082 140033285822272 spec.py:321] Evaluating on the training split.
I0316 11:54:57.091855 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 11:55:18.777283 140033285822272 spec.py:349] Evaluating on the test split.
I0316 11:55:20.439066 140033285822272 submission_runner.py:420] Time since start: 42887.36s, 	Step: 89953, 	{'train/accuracy': 0.8142773509025574, 'train/loss': 0.7051602005958557, 'validation/accuracy': 0.7251999974250793, 'validation/loss': 1.1013540029525757, 'validation/num_examples': 50000, 'test/accuracy': 0.5942000150680542, 'test/loss': 1.7679145336151123, 'test/num_examples': 10000, 'score': 39534.26315021515, 'total_duration': 42887.363741636276, 'accumulated_submission_time': 39534.26315021515, 'accumulated_eval_time': 3344.784425020218, 'accumulated_logging_time': 3.6490068435668945}
I0316 11:55:20.468122 139836417636096 logging_writer.py:48] [89953] accumulated_eval_time=3344.784425, accumulated_logging_time=3.649007, accumulated_submission_time=39534.263150, global_step=89953, preemption_count=0, score=39534.263150, test/accuracy=0.594200, test/loss=1.767915, test/num_examples=10000, total_duration=42887.363742, train/accuracy=0.814277, train/loss=0.705160, validation/accuracy=0.725200, validation/loss=1.101354, validation/num_examples=50000
I0316 11:55:39.244716 139836409243392 logging_writer.py:48] [90000] global_step=90000, grad_norm=2.631746768951416, loss=3.997901201248169
I0316 11:59:21.348815 139836417636096 logging_writer.py:48] [90500] global_step=90500, grad_norm=2.6290555000305176, loss=1.9586575031280518
I0316 12:02:20.751129 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:02:30.958782 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:02:58.418609 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:03:00.079144 140033285822272 submission_runner.py:420] Time since start: 43347.00s, 	Step: 90904, 	{'train/accuracy': 0.8132421970367432, 'train/loss': 0.7265541553497314, 'validation/accuracy': 0.7272399663925171, 'validation/loss': 1.094468593597412, 'validation/num_examples': 50000, 'test/accuracy': 0.6000000238418579, 'test/loss': 1.7423524856567383, 'test/num_examples': 10000, 'score': 39954.48708152771, 'total_duration': 43347.0038394928, 'accumulated_submission_time': 39954.48708152771, 'accumulated_eval_time': 3384.112462282181, 'accumulated_logging_time': 3.688556671142578}
I0316 12:03:00.102259 139836409243392 logging_writer.py:48] [90904] accumulated_eval_time=3384.112462, accumulated_logging_time=3.688557, accumulated_submission_time=39954.487082, global_step=90904, preemption_count=0, score=39954.487082, test/accuracy=0.600000, test/loss=1.742352, test/num_examples=10000, total_duration=43347.003839, train/accuracy=0.813242, train/loss=0.726554, validation/accuracy=0.727240, validation/loss=1.094469, validation/num_examples=50000
I0316 12:03:38.005747 139836417636096 logging_writer.py:48] [91000] global_step=91000, grad_norm=2.7334725856781006, loss=1.7141578197479248
I0316 12:07:20.142504 139836409243392 logging_writer.py:48] [91500] global_step=91500, grad_norm=2.686403274536133, loss=1.6283985376358032
I0316 12:10:00.342201 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:10:10.552081 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:10:35.326696 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:10:37.000885 140033285822272 submission_runner.py:420] Time since start: 43803.93s, 	Step: 91861, 	{'train/accuracy': 0.8134374618530273, 'train/loss': 0.7182683348655701, 'validation/accuracy': 0.7279999852180481, 'validation/loss': 1.0831648111343384, 'validation/num_examples': 50000, 'test/accuracy': 0.597000002861023, 'test/loss': 1.7358157634735107, 'test/num_examples': 10000, 'score': 40374.66855120659, 'total_duration': 43803.92558503151, 'accumulated_submission_time': 40374.66855120659, 'accumulated_eval_time': 3420.7711465358734, 'accumulated_logging_time': 3.7210538387298584}
I0316 12:10:37.023631 139836417636096 logging_writer.py:48] [91861] accumulated_eval_time=3420.771147, accumulated_logging_time=3.721054, accumulated_submission_time=40374.668551, global_step=91861, preemption_count=0, score=40374.668551, test/accuracy=0.597000, test/loss=1.735816, test/num_examples=10000, total_duration=43803.925585, train/accuracy=0.813437, train/loss=0.718268, validation/accuracy=0.728000, validation/loss=1.083165, validation/num_examples=50000
I0316 12:11:33.803638 139836409243392 logging_writer.py:48] [92000] global_step=92000, grad_norm=2.345113515853882, loss=2.244441032409668
I0316 12:15:16.302419 139836417636096 logging_writer.py:48] [92500] global_step=92500, grad_norm=2.635315179824829, loss=1.6630642414093018
I0316 12:17:37.241481 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:17:47.370486 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:18:13.448257 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:18:15.104247 140033285822272 submission_runner.py:420] Time since start: 44262.03s, 	Step: 92817, 	{'train/accuracy': 0.8158593773841858, 'train/loss': 0.7073391675949097, 'validation/accuracy': 0.7292199730873108, 'validation/loss': 1.0921497344970703, 'validation/num_examples': 50000, 'test/accuracy': 0.5982000231742859, 'test/loss': 1.736130952835083, 'test/num_examples': 10000, 'score': 40794.82723855972, 'total_duration': 44262.02894735336, 'accumulated_submission_time': 40794.82723855972, 'accumulated_eval_time': 3458.633937358856, 'accumulated_logging_time': 3.7532637119293213}
I0316 12:18:15.129211 139836409243392 logging_writer.py:48] [92817] accumulated_eval_time=3458.633937, accumulated_logging_time=3.753264, accumulated_submission_time=40794.827239, global_step=92817, preemption_count=0, score=40794.827239, test/accuracy=0.598200, test/loss=1.736131, test/num_examples=10000, total_duration=44262.028947, train/accuracy=0.815859, train/loss=0.707339, validation/accuracy=0.729220, validation/loss=1.092150, validation/num_examples=50000
I0316 12:19:31.509698 139836417636096 logging_writer.py:48] [93000] global_step=93000, grad_norm=2.3497207164764404, loss=2.9751737117767334
I0316 12:23:14.199386 139836409243392 logging_writer.py:48] [93500] global_step=93500, grad_norm=2.621474266052246, loss=1.4692426919937134
I0316 12:25:15.113533 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:25:25.176453 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:25:50.269540 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:25:51.937524 140033285822272 submission_runner.py:420] Time since start: 44718.86s, 	Step: 93773, 	{'train/accuracy': 0.8169726133346558, 'train/loss': 0.7112701535224915, 'validation/accuracy': 0.7305999994277954, 'validation/loss': 1.0926241874694824, 'validation/num_examples': 50000, 'test/accuracy': 0.6011000275611877, 'test/loss': 1.745832920074463, 'test/num_examples': 10000, 'score': 41214.750838279724, 'total_duration': 44718.862205028534, 'accumulated_submission_time': 41214.750838279724, 'accumulated_eval_time': 3495.4579453468323, 'accumulated_logging_time': 3.7890377044677734}
I0316 12:25:51.970730 139836417636096 logging_writer.py:48] [93773] accumulated_eval_time=3495.457945, accumulated_logging_time=3.789038, accumulated_submission_time=41214.750838, global_step=93773, preemption_count=0, score=41214.750838, test/accuracy=0.601100, test/loss=1.745833, test/num_examples=10000, total_duration=44718.862205, train/accuracy=0.816973, train/loss=0.711270, validation/accuracy=0.730600, validation/loss=1.092624, validation/num_examples=50000
I0316 12:27:28.486720 139836409243392 logging_writer.py:48] [94000] global_step=94000, grad_norm=2.3827056884765625, loss=2.902273416519165
I0316 12:31:12.101745 139836417636096 logging_writer.py:48] [94500] global_step=94500, grad_norm=2.555779218673706, loss=1.5256731510162354
I0316 12:32:52.126350 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:33:02.453732 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:33:26.706696 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:33:28.374397 140033285822272 submission_runner.py:420] Time since start: 45175.30s, 	Step: 94726, 	{'train/accuracy': 0.8153710961341858, 'train/loss': 0.7110303044319153, 'validation/accuracy': 0.7318999767303467, 'validation/loss': 1.0777409076690674, 'validation/num_examples': 50000, 'test/accuracy': 0.6021000146865845, 'test/loss': 1.7228293418884277, 'test/num_examples': 10000, 'score': 41634.846336603165, 'total_duration': 45175.29908680916, 'accumulated_submission_time': 41634.846336603165, 'accumulated_eval_time': 3531.705990552902, 'accumulated_logging_time': 3.833230972290039}
I0316 12:33:28.398466 139836409243392 logging_writer.py:48] [94726] accumulated_eval_time=3531.705991, accumulated_logging_time=3.833231, accumulated_submission_time=41634.846337, global_step=94726, preemption_count=0, score=41634.846337, test/accuracy=0.602100, test/loss=1.722829, test/num_examples=10000, total_duration=45175.299087, train/accuracy=0.815371, train/loss=0.711030, validation/accuracy=0.731900, validation/loss=1.077741, validation/num_examples=50000
I0316 12:35:25.397019 139836417636096 logging_writer.py:48] [95000] global_step=95000, grad_norm=2.188722610473633, loss=2.679337739944458
I0316 12:39:09.060047 139836409243392 logging_writer.py:48] [95500] global_step=95500, grad_norm=2.383735418319702, loss=3.2651257514953613
I0316 12:40:28.604875 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:40:39.007215 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:41:04.826289 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:41:06.476218 140033285822272 submission_runner.py:420] Time since start: 45633.40s, 	Step: 95680, 	{'train/accuracy': 0.8202343583106995, 'train/loss': 0.6909275054931641, 'validation/accuracy': 0.7317599654197693, 'validation/loss': 1.0739268064498901, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.729892611503601, 'test/num_examples': 10000, 'score': 42054.991592645645, 'total_duration': 45633.40091395378, 'accumulated_submission_time': 42054.991592645645, 'accumulated_eval_time': 3569.577343225479, 'accumulated_logging_time': 3.8686208724975586}
I0316 12:41:06.505479 139836417636096 logging_writer.py:48] [95680] accumulated_eval_time=3569.577343, accumulated_logging_time=3.868621, accumulated_submission_time=42054.991593, global_step=95680, preemption_count=0, score=42054.991593, test/accuracy=0.604600, test/loss=1.729893, test/num_examples=10000, total_duration=45633.400914, train/accuracy=0.820234, train/loss=0.690928, validation/accuracy=0.731760, validation/loss=1.073927, validation/num_examples=50000
I0316 12:43:24.190093 139836409243392 logging_writer.py:48] [96000] global_step=96000, grad_norm=2.3818306922912598, loss=3.073287010192871
I0316 12:47:06.990484 139836417636096 logging_writer.py:48] [96500] global_step=96500, grad_norm=2.4831836223602295, loss=1.8238716125488281
I0316 12:48:06.636139 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:48:17.101588 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:48:38.901483 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:48:40.568170 140033285822272 submission_runner.py:420] Time since start: 46087.49s, 	Step: 96636, 	{'train/accuracy': 0.8260937333106995, 'train/loss': 0.6657110452651978, 'validation/accuracy': 0.7340799570083618, 'validation/loss': 1.0653157234191895, 'validation/num_examples': 50000, 'test/accuracy': 0.6053000092506409, 'test/loss': 1.71260404586792, 'test/num_examples': 10000, 'score': 42475.061789512634, 'total_duration': 46087.49285745621, 'accumulated_submission_time': 42475.061789512634, 'accumulated_eval_time': 3603.5093677043915, 'accumulated_logging_time': 3.909106731414795}
I0316 12:48:40.595090 139836409243392 logging_writer.py:48] [96636] accumulated_eval_time=3603.509368, accumulated_logging_time=3.909107, accumulated_submission_time=42475.061790, global_step=96636, preemption_count=0, score=42475.061790, test/accuracy=0.605300, test/loss=1.712604, test/num_examples=10000, total_duration=46087.492857, train/accuracy=0.826094, train/loss=0.665711, validation/accuracy=0.734080, validation/loss=1.065316, validation/num_examples=50000
I0316 12:51:19.292131 139836417636096 logging_writer.py:48] [97000] global_step=97000, grad_norm=2.4496569633483887, loss=1.7397633790969849
I0316 12:55:01.835621 139836409243392 logging_writer.py:48] [97500] global_step=97500, grad_norm=2.660623788833618, loss=1.506858229637146
I0316 12:55:40.978627 140033285822272 spec.py:321] Evaluating on the training split.
I0316 12:55:51.442699 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 12:56:19.424662 140033285822272 spec.py:349] Evaluating on the test split.
I0316 12:56:21.085309 140033285822272 submission_runner.py:420] Time since start: 46548.01s, 	Step: 97589, 	{'train/accuracy': 0.8200585842132568, 'train/loss': 0.6868795156478882, 'validation/accuracy': 0.7324999570846558, 'validation/loss': 1.0643037557601929, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.7156270742416382, 'test/num_examples': 10000, 'score': 42895.38532233238, 'total_duration': 46548.00999832153, 'accumulated_submission_time': 42895.38532233238, 'accumulated_eval_time': 3643.6160628795624, 'accumulated_logging_time': 3.947016477584839}
I0316 12:56:21.111754 139836417636096 logging_writer.py:48] [97589] accumulated_eval_time=3643.616063, accumulated_logging_time=3.947016, accumulated_submission_time=42895.385322, global_step=97589, preemption_count=0, score=42895.385322, test/accuracy=0.604600, test/loss=1.715627, test/num_examples=10000, total_duration=46548.009998, train/accuracy=0.820059, train/loss=0.686880, validation/accuracy=0.732500, validation/loss=1.064304, validation/num_examples=50000
I0316 12:59:20.206162 139836409243392 logging_writer.py:48] [98000] global_step=98000, grad_norm=2.6890928745269775, loss=1.5091545581817627
I0316 13:03:03.067336 139836417636096 logging_writer.py:48] [98500] global_step=98500, grad_norm=2.570253610610962, loss=1.5570862293243408
I0316 13:03:21.523002 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:03:31.881473 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:04:00.670394 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:04:02.323317 140033285822272 submission_runner.py:420] Time since start: 47009.25s, 	Step: 98543, 	{'train/accuracy': 0.8204101324081421, 'train/loss': 0.6935621500015259, 'validation/accuracy': 0.73499995470047, 'validation/loss': 1.0708833932876587, 'validation/num_examples': 50000, 'test/accuracy': 0.6127000451087952, 'test/loss': 1.7051517963409424, 'test/num_examples': 10000, 'score': 43315.73797702789, 'total_duration': 47009.2480134964, 'accumulated_submission_time': 43315.73797702789, 'accumulated_eval_time': 3684.4163761138916, 'accumulated_logging_time': 3.9828202724456787}
I0316 13:04:02.350836 139836409243392 logging_writer.py:48] [98543] accumulated_eval_time=3684.416376, accumulated_logging_time=3.982820, accumulated_submission_time=43315.737977, global_step=98543, preemption_count=0, score=43315.737977, test/accuracy=0.612700, test/loss=1.705152, test/num_examples=10000, total_duration=47009.248013, train/accuracy=0.820410, train/loss=0.693562, validation/accuracy=0.735000, validation/loss=1.070883, validation/num_examples=50000
I0316 13:07:20.660779 139836417636096 logging_writer.py:48] [99000] global_step=99000, grad_norm=2.6221470832824707, loss=1.6016424894332886
I0316 13:11:02.692789 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:11:12.883609 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:11:35.252201 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:11:36.911723 140033285822272 submission_runner.py:420] Time since start: 47463.84s, 	Step: 99500, 	{'train/accuracy': 0.8253710865974426, 'train/loss': 0.6545591354370117, 'validation/accuracy': 0.738379955291748, 'validation/loss': 1.0376094579696655, 'validation/num_examples': 50000, 'test/accuracy': 0.6126000285148621, 'test/loss': 1.693750262260437, 'test/num_examples': 10000, 'score': 43736.02278661728, 'total_duration': 47463.83640551567, 'accumulated_submission_time': 43736.02278661728, 'accumulated_eval_time': 3718.6353046894073, 'accumulated_logging_time': 4.018874168395996}
I0316 13:11:36.942588 139836409243392 logging_writer.py:48] [99500] accumulated_eval_time=3718.635305, accumulated_logging_time=4.018874, accumulated_submission_time=43736.022787, global_step=99500, preemption_count=0, score=43736.022787, test/accuracy=0.612600, test/loss=1.693750, test/num_examples=10000, total_duration=47463.836406, train/accuracy=0.825371, train/loss=0.654559, validation/accuracy=0.738380, validation/loss=1.037609, validation/num_examples=50000
I0316 13:11:37.359789 139836417636096 logging_writer.py:48] [99500] global_step=99500, grad_norm=2.5609068870544434, loss=3.5433664321899414
I0316 13:15:15.992787 139836409243392 logging_writer.py:48] [100000] global_step=100000, grad_norm=2.8179612159729004, loss=1.6304733753204346
I0316 13:18:36.996515 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:18:47.421203 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:19:15.325062 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:19:16.975359 140033285822272 submission_runner.py:420] Time since start: 47923.90s, 	Step: 100453, 	{'train/accuracy': 0.8338866829872131, 'train/loss': 0.6379420161247253, 'validation/accuracy': 0.738860011100769, 'validation/loss': 1.0469478368759155, 'validation/num_examples': 50000, 'test/accuracy': 0.6131000518798828, 'test/loss': 1.6931209564208984, 'test/num_examples': 10000, 'score': 44156.01625561714, 'total_duration': 47923.90005874634, 'accumulated_submission_time': 44156.01625561714, 'accumulated_eval_time': 3758.6141781806946, 'accumulated_logging_time': 4.060467004776001}
I0316 13:19:17.000576 139836417636096 logging_writer.py:48] [100453] accumulated_eval_time=3758.614178, accumulated_logging_time=4.060467, accumulated_submission_time=44156.016256, global_step=100453, preemption_count=0, score=44156.016256, test/accuracy=0.613100, test/loss=1.693121, test/num_examples=10000, total_duration=47923.900059, train/accuracy=0.833887, train/loss=0.637942, validation/accuracy=0.738860, validation/loss=1.046948, validation/num_examples=50000
I0316 13:19:35.813943 139836409243392 logging_writer.py:48] [100500] global_step=100500, grad_norm=2.5333073139190674, loss=3.7388477325439453
I0316 13:23:15.523983 139836417636096 logging_writer.py:48] [101000] global_step=101000, grad_norm=2.8164236545562744, loss=1.4566984176635742
I0316 13:26:17.259632 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:26:27.247717 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:26:50.483178 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:26:52.158047 140033285822272 submission_runner.py:420] Time since start: 48379.08s, 	Step: 101411, 	{'train/accuracy': 0.8299999833106995, 'train/loss': 0.6550570726394653, 'validation/accuracy': 0.7392399907112122, 'validation/loss': 1.0426398515701294, 'validation/num_examples': 50000, 'test/accuracy': 0.6136000156402588, 'test/loss': 1.6880282163619995, 'test/num_examples': 10000, 'score': 44576.21703314781, 'total_duration': 48379.08273267746, 'accumulated_submission_time': 44576.21703314781, 'accumulated_eval_time': 3793.5126116275787, 'accumulated_logging_time': 4.094937324523926}
I0316 13:26:52.186511 139836409243392 logging_writer.py:48] [101411] accumulated_eval_time=3793.512612, accumulated_logging_time=4.094937, accumulated_submission_time=44576.217033, global_step=101411, preemption_count=0, score=44576.217033, test/accuracy=0.613600, test/loss=1.688028, test/num_examples=10000, total_duration=48379.082733, train/accuracy=0.830000, train/loss=0.655057, validation/accuracy=0.739240, validation/loss=1.042640, validation/num_examples=50000
I0316 13:27:27.380378 139836417636096 logging_writer.py:48] [101500] global_step=101500, grad_norm=2.4330568313598633, loss=1.5414793491363525
I0316 13:31:09.625344 139836409243392 logging_writer.py:48] [102000] global_step=102000, grad_norm=2.6203863620758057, loss=1.3856165409088135
I0316 13:33:52.225725 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:34:02.813659 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:34:26.051797 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:34:27.712010 140033285822272 submission_runner.py:420] Time since start: 48834.64s, 	Step: 102368, 	{'train/accuracy': 0.830859363079071, 'train/loss': 0.6350476145744324, 'validation/accuracy': 0.7415199875831604, 'validation/loss': 1.0304890871047974, 'validation/num_examples': 50000, 'test/accuracy': 0.6151000261306763, 'test/loss': 1.665448546409607, 'test/num_examples': 10000, 'score': 44996.19522190094, 'total_duration': 48834.636696100235, 'accumulated_submission_time': 44996.19522190094, 'accumulated_eval_time': 3828.9989156723022, 'accumulated_logging_time': 4.135974168777466}
I0316 13:34:27.742275 139836417636096 logging_writer.py:48] [102368] accumulated_eval_time=3828.998916, accumulated_logging_time=4.135974, accumulated_submission_time=44996.195222, global_step=102368, preemption_count=0, score=44996.195222, test/accuracy=0.615100, test/loss=1.665449, test/num_examples=10000, total_duration=48834.636696, train/accuracy=0.830859, train/loss=0.635048, validation/accuracy=0.741520, validation/loss=1.030489, validation/num_examples=50000
I0316 13:35:22.109065 139836409243392 logging_writer.py:48] [102500] global_step=102500, grad_norm=2.771764039993286, loss=1.3936023712158203
I0316 13:39:04.975776 139836417636096 logging_writer.py:48] [103000] global_step=103000, grad_norm=2.4825873374938965, loss=1.707476019859314
I0316 13:41:27.749738 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:41:37.943441 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:42:05.493748 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:42:07.167398 140033285822272 submission_runner.py:420] Time since start: 49294.09s, 	Step: 103323, 	{'train/accuracy': 0.8330858945846558, 'train/loss': 0.6300832033157349, 'validation/accuracy': 0.7407199740409851, 'validation/loss': 1.0317474603652954, 'validation/num_examples': 50000, 'test/accuracy': 0.6196000576019287, 'test/loss': 1.660083293914795, 'test/num_examples': 10000, 'score': 45416.143211364746, 'total_duration': 49294.09208750725, 'accumulated_submission_time': 45416.143211364746, 'accumulated_eval_time': 3868.4166038036346, 'accumulated_logging_time': 4.176782608032227}
I0316 13:42:07.193487 139836409243392 logging_writer.py:48] [103323] accumulated_eval_time=3868.416604, accumulated_logging_time=4.176783, accumulated_submission_time=45416.143211, global_step=103323, preemption_count=0, score=45416.143211, test/accuracy=0.619600, test/loss=1.660083, test/num_examples=10000, total_duration=49294.092088, train/accuracy=0.833086, train/loss=0.630083, validation/accuracy=0.740720, validation/loss=1.031747, validation/num_examples=50000
I0316 13:43:20.837747 139836417636096 logging_writer.py:48] [103500] global_step=103500, grad_norm=2.497481346130371, loss=3.3117871284484863
I0316 13:47:03.461530 139836409243392 logging_writer.py:48] [104000] global_step=104000, grad_norm=2.9453392028808594, loss=1.5736455917358398
I0316 13:49:07.182924 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:49:17.258105 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:49:39.347234 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:49:41.006839 140033285822272 submission_runner.py:420] Time since start: 49747.93s, 	Step: 104279, 	{'train/accuracy': 0.8360155820846558, 'train/loss': 0.6268386840820312, 'validation/accuracy': 0.74263995885849, 'validation/loss': 1.0254026651382446, 'validation/num_examples': 50000, 'test/accuracy': 0.6196000576019287, 'test/loss': 1.662506103515625, 'test/num_examples': 10000, 'score': 45836.07455945015, 'total_duration': 49747.9315226078, 'accumulated_submission_time': 45836.07455945015, 'accumulated_eval_time': 3902.240537881851, 'accumulated_logging_time': 4.212025880813599}
I0316 13:49:41.038635 139836417636096 logging_writer.py:48] [104279] accumulated_eval_time=3902.240538, accumulated_logging_time=4.212026, accumulated_submission_time=45836.074559, global_step=104279, preemption_count=0, score=45836.074559, test/accuracy=0.619600, test/loss=1.662506, test/num_examples=10000, total_duration=49747.931523, train/accuracy=0.836016, train/loss=0.626839, validation/accuracy=0.742640, validation/loss=1.025403, validation/num_examples=50000
I0316 13:51:15.663894 139836409243392 logging_writer.py:48] [104500] global_step=104500, grad_norm=2.497600793838501, loss=3.056989908218384
I0316 13:54:58.735836 139836417636096 logging_writer.py:48] [105000] global_step=105000, grad_norm=2.5851352214813232, loss=3.8053483963012695
I0316 13:56:41.015041 140033285822272 spec.py:321] Evaluating on the training split.
I0316 13:56:51.301648 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 13:57:17.804860 140033285822272 spec.py:349] Evaluating on the test split.
I0316 13:57:19.460232 140033285822272 submission_runner.py:420] Time since start: 50206.38s, 	Step: 105231, 	{'train/accuracy': 0.8339452743530273, 'train/loss': 0.6383870244026184, 'validation/accuracy': 0.7439999580383301, 'validation/loss': 1.0282624959945679, 'validation/num_examples': 50000, 'test/accuracy': 0.6152000427246094, 'test/loss': 1.6659941673278809, 'test/num_examples': 10000, 'score': 46255.99170088768, 'total_duration': 50206.38493061066, 'accumulated_submission_time': 46255.99170088768, 'accumulated_eval_time': 3940.6857392787933, 'accumulated_logging_time': 4.254321336746216}
I0316 13:57:19.486298 139836409243392 logging_writer.py:48] [105231] accumulated_eval_time=3940.685739, accumulated_logging_time=4.254321, accumulated_submission_time=46255.991701, global_step=105231, preemption_count=0, score=46255.991701, test/accuracy=0.615200, test/loss=1.665994, test/num_examples=10000, total_duration=50206.384931, train/accuracy=0.833945, train/loss=0.638387, validation/accuracy=0.744000, validation/loss=1.028262, validation/num_examples=50000
I0316 13:59:14.293342 139836417636096 logging_writer.py:48] [105500] global_step=105500, grad_norm=2.6031265258789062, loss=1.7410203218460083
I0316 14:02:56.660218 139836409243392 logging_writer.py:48] [106000] global_step=106000, grad_norm=2.78847599029541, loss=1.4363133907318115
I0316 14:04:19.530543 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:04:29.714855 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:04:51.282280 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:04:52.944774 140033285822272 submission_runner.py:420] Time since start: 50659.87s, 	Step: 106188, 	{'train/accuracy': 0.8370898365974426, 'train/loss': 0.6287381052970886, 'validation/accuracy': 0.7427799701690674, 'validation/loss': 1.0315252542495728, 'validation/num_examples': 50000, 'test/accuracy': 0.615600049495697, 'test/loss': 1.6683176755905151, 'test/num_examples': 10000, 'score': 46675.97735834122, 'total_duration': 50659.869463443756, 'accumulated_submission_time': 46675.97735834122, 'accumulated_eval_time': 3974.10001039505, 'accumulated_logging_time': 4.2895667552948}
I0316 14:04:52.973162 139836417636096 logging_writer.py:48] [106188] accumulated_eval_time=3974.100010, accumulated_logging_time=4.289567, accumulated_submission_time=46675.977358, global_step=106188, preemption_count=0, score=46675.977358, test/accuracy=0.615600, test/loss=1.668318, test/num_examples=10000, total_duration=50659.869463, train/accuracy=0.837090, train/loss=0.628738, validation/accuracy=0.742780, validation/loss=1.031525, validation/num_examples=50000
I0316 14:07:08.413130 139836409243392 logging_writer.py:48] [106500] global_step=106500, grad_norm=2.8664586544036865, loss=3.922396421432495
I0316 14:10:51.050455 139836417636096 logging_writer.py:48] [107000] global_step=107000, grad_norm=2.8547732830047607, loss=1.4128448963165283
I0316 14:11:53.114749 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:12:03.452649 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:12:32.783812 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:12:34.445048 140033285822272 submission_runner.py:420] Time since start: 51121.37s, 	Step: 107141, 	{'train/accuracy': 0.8447070121765137, 'train/loss': 0.5922766327857971, 'validation/accuracy': 0.7450599670410156, 'validation/loss': 1.0159118175506592, 'validation/num_examples': 50000, 'test/accuracy': 0.6181000471115112, 'test/loss': 1.6559442281723022, 'test/num_examples': 10000, 'score': 47096.05894970894, 'total_duration': 51121.369712114334, 'accumulated_submission_time': 47096.05894970894, 'accumulated_eval_time': 4015.430284500122, 'accumulated_logging_time': 4.329180955886841}
I0316 14:12:34.472807 139836409243392 logging_writer.py:48] [107141] accumulated_eval_time=4015.430285, accumulated_logging_time=4.329181, accumulated_submission_time=47096.058950, global_step=107141, preemption_count=0, score=47096.058950, test/accuracy=0.618100, test/loss=1.655944, test/num_examples=10000, total_duration=51121.369712, train/accuracy=0.844707, train/loss=0.592277, validation/accuracy=0.745060, validation/loss=1.015912, validation/num_examples=50000
I0316 14:15:10.662613 139836417636096 logging_writer.py:48] [107500] global_step=107500, grad_norm=2.488563060760498, loss=3.046308994293213
I0316 14:18:54.413820 139836409243392 logging_writer.py:48] [108000] global_step=108000, grad_norm=2.5479793548583984, loss=1.9790666103363037
I0316 14:19:34.613778 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:19:44.548315 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:20:12.599105 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:20:14.258255 140033285822272 submission_runner.py:420] Time since start: 51581.18s, 	Step: 108092, 	{'train/accuracy': 0.8363671898841858, 'train/loss': 0.6227496862411499, 'validation/accuracy': 0.74617999792099, 'validation/loss': 1.0163707733154297, 'validation/num_examples': 50000, 'test/accuracy': 0.6180000305175781, 'test/loss': 1.650549292564392, 'test/num_examples': 10000, 'score': 47516.14053821564, 'total_duration': 51581.18294215202, 'accumulated_submission_time': 47516.14053821564, 'accumulated_eval_time': 4055.074747800827, 'accumulated_logging_time': 4.367753982543945}
I0316 14:20:14.285707 139836417636096 logging_writer.py:48] [108092] accumulated_eval_time=4055.074748, accumulated_logging_time=4.367754, accumulated_submission_time=47516.140538, global_step=108092, preemption_count=0, score=47516.140538, test/accuracy=0.618000, test/loss=1.650549, test/num_examples=10000, total_duration=51581.182942, train/accuracy=0.836367, train/loss=0.622750, validation/accuracy=0.746180, validation/loss=1.016371, validation/num_examples=50000
I0316 14:23:12.279374 139836409243392 logging_writer.py:48] [108500] global_step=108500, grad_norm=2.6128461360931396, loss=2.162569999694824
I0316 14:26:55.182492 139836417636096 logging_writer.py:48] [109000] global_step=109000, grad_norm=2.61177659034729, loss=1.390035629272461
I0316 14:27:14.564319 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:27:24.519491 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:27:53.810135 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:27:55.462163 140033285822272 submission_runner.py:420] Time since start: 52042.39s, 	Step: 109045, 	{'train/accuracy': 0.8378320336341858, 'train/loss': 0.6192162036895752, 'validation/accuracy': 0.7454800009727478, 'validation/loss': 1.0157496929168701, 'validation/num_examples': 50000, 'test/accuracy': 0.619700014591217, 'test/loss': 1.6563630104064941, 'test/num_examples': 10000, 'score': 47936.36020040512, 'total_duration': 52042.38684606552, 'accumulated_submission_time': 47936.36020040512, 'accumulated_eval_time': 4095.97256565094, 'accumulated_logging_time': 4.40497350692749}
I0316 14:27:55.487893 139836409243392 logging_writer.py:48] [109045] accumulated_eval_time=4095.972566, accumulated_logging_time=4.404974, accumulated_submission_time=47936.360200, global_step=109045, preemption_count=0, score=47936.360200, test/accuracy=0.619700, test/loss=1.656363, test/num_examples=10000, total_duration=52042.386846, train/accuracy=0.837832, train/loss=0.619216, validation/accuracy=0.745480, validation/loss=1.015750, validation/num_examples=50000
I0316 14:31:12.864711 139836417636096 logging_writer.py:48] [109500] global_step=109500, grad_norm=2.857593059539795, loss=3.738266944885254
I0316 14:34:54.906553 139836409243392 logging_writer.py:48] [110000] global_step=110000, grad_norm=2.5699479579925537, loss=1.8095107078552246
I0316 14:34:55.551467 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:35:05.985112 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:35:27.916501 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:35:29.576635 140033285822272 submission_runner.py:420] Time since start: 52496.50s, 	Step: 110003, 	{'train/accuracy': 0.8412694931030273, 'train/loss': 0.6067090630531311, 'validation/accuracy': 0.7469399571418762, 'validation/loss': 1.0047023296356201, 'validation/num_examples': 50000, 'test/accuracy': 0.6170000433921814, 'test/loss': 1.6504782438278198, 'test/num_examples': 10000, 'score': 48356.365557193756, 'total_duration': 52496.501323223114, 'accumulated_submission_time': 48356.365557193756, 'accumulated_eval_time': 4129.997729063034, 'accumulated_logging_time': 4.440007448196411}
I0316 14:35:29.605355 139836417636096 logging_writer.py:48] [110003] accumulated_eval_time=4129.997729, accumulated_logging_time=4.440007, accumulated_submission_time=48356.365557, global_step=110003, preemption_count=0, score=48356.365557, test/accuracy=0.617000, test/loss=1.650478, test/num_examples=10000, total_duration=52496.501323, train/accuracy=0.841269, train/loss=0.606709, validation/accuracy=0.746940, validation/loss=1.004702, validation/num_examples=50000
I0316 14:39:06.728421 139836409243392 logging_writer.py:48] [110500] global_step=110500, grad_norm=2.6382689476013184, loss=2.2019386291503906
I0316 14:42:29.988420 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:42:40.478371 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:43:04.852884 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:43:06.502099 140033285822272 submission_runner.py:420] Time since start: 52953.43s, 	Step: 110958, 	{'train/accuracy': 0.8490819931030273, 'train/loss': 0.5812028646469116, 'validation/accuracy': 0.7455199956893921, 'validation/loss': 1.0081909894943237, 'validation/num_examples': 50000, 'test/accuracy': 0.6190000176429749, 'test/loss': 1.6425085067749023, 'test/num_examples': 10000, 'score': 48776.686744213104, 'total_duration': 52953.426795721054, 'accumulated_submission_time': 48776.686744213104, 'accumulated_eval_time': 4166.511432647705, 'accumulated_logging_time': 4.481417894363403}
I0316 14:43:06.527902 139836417636096 logging_writer.py:48] [110958] accumulated_eval_time=4166.511433, accumulated_logging_time=4.481418, accumulated_submission_time=48776.686744, global_step=110958, preemption_count=0, score=48776.686744, test/accuracy=0.619000, test/loss=1.642509, test/num_examples=10000, total_duration=52953.426796, train/accuracy=0.849082, train/loss=0.581203, validation/accuracy=0.745520, validation/loss=1.008191, validation/num_examples=50000
I0316 14:43:23.333355 139836409243392 logging_writer.py:48] [111000] global_step=111000, grad_norm=2.618905544281006, loss=3.1694722175598145
I0316 14:47:03.067662 139836417636096 logging_writer.py:48] [111500] global_step=111500, grad_norm=2.493710994720459, loss=2.4668502807617188
I0316 14:50:06.735165 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:50:16.939903 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:50:41.754081 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:50:43.417824 140033285822272 submission_runner.py:420] Time since start: 53410.34s, 	Step: 111914, 	{'train/accuracy': 0.8423241972923279, 'train/loss': 0.5987648367881775, 'validation/accuracy': 0.7480199933052063, 'validation/loss': 0.9991421103477478, 'validation/num_examples': 50000, 'test/accuracy': 0.6178000569343567, 'test/loss': 1.642221212387085, 'test/num_examples': 10000, 'score': 49196.83443522453, 'total_duration': 53410.34250831604, 'accumulated_submission_time': 49196.83443522453, 'accumulated_eval_time': 4203.194106340408, 'accumulated_logging_time': 4.517452716827393}
I0316 14:50:43.451645 139836409243392 logging_writer.py:48] [111914] accumulated_eval_time=4203.194106, accumulated_logging_time=4.517453, accumulated_submission_time=49196.834435, global_step=111914, preemption_count=0, score=49196.834435, test/accuracy=0.617800, test/loss=1.642221, test/num_examples=10000, total_duration=53410.342508, train/accuracy=0.842324, train/loss=0.598765, validation/accuracy=0.748020, validation/loss=0.999142, validation/num_examples=50000
I0316 14:51:17.601466 139836417636096 logging_writer.py:48] [112000] global_step=112000, grad_norm=2.761420488357544, loss=3.7416625022888184
I0316 14:55:00.223637 139836409243392 logging_writer.py:48] [112500] global_step=112500, grad_norm=2.7716352939605713, loss=3.7218713760375977
I0316 14:57:43.591314 140033285822272 spec.py:321] Evaluating on the training split.
I0316 14:57:54.238238 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 14:58:16.175796 140033285822272 spec.py:349] Evaluating on the test split.
I0316 14:58:17.836998 140033285822272 submission_runner.py:420] Time since start: 53864.76s, 	Step: 112866, 	{'train/accuracy': 0.84486323595047, 'train/loss': 0.590288519859314, 'validation/accuracy': 0.7480799555778503, 'validation/loss': 1.0019407272338867, 'validation/num_examples': 50000, 'test/accuracy': 0.6195000410079956, 'test/loss': 1.6393332481384277, 'test/num_examples': 10000, 'score': 49616.911490917206, 'total_duration': 53864.761655807495, 'accumulated_submission_time': 49616.911490917206, 'accumulated_eval_time': 4237.439774990082, 'accumulated_logging_time': 4.564082384109497}
I0316 14:58:17.868743 139836417636096 logging_writer.py:48] [112866] accumulated_eval_time=4237.439775, accumulated_logging_time=4.564082, accumulated_submission_time=49616.911491, global_step=112866, preemption_count=0, score=49616.911491, test/accuracy=0.619500, test/loss=1.639333, test/num_examples=10000, total_duration=53864.761656, train/accuracy=0.844863, train/loss=0.590289, validation/accuracy=0.748080, validation/loss=1.001941, validation/num_examples=50000
I0316 14:59:13.754963 139836409243392 logging_writer.py:48] [113000] global_step=113000, grad_norm=2.812783718109131, loss=1.4881266355514526
I0316 15:02:56.609249 139836417636096 logging_writer.py:48] [113500] global_step=113500, grad_norm=2.60040545463562, loss=1.394440770149231
I0316 15:05:17.921431 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:05:28.143109 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:05:58.888981 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:06:00.560121 140033285822272 submission_runner.py:420] Time since start: 54327.48s, 	Step: 113818, 	{'train/accuracy': 0.8456445336341858, 'train/loss': 0.5927426815032959, 'validation/accuracy': 0.7485799789428711, 'validation/loss': 1.003954291343689, 'validation/num_examples': 50000, 'test/accuracy': 0.6198000311851501, 'test/loss': 1.6341878175735474, 'test/num_examples': 10000, 'score': 50036.90283083916, 'total_duration': 54327.484815359116, 'accumulated_submission_time': 50036.90283083916, 'accumulated_eval_time': 4280.078495264053, 'accumulated_logging_time': 4.607403755187988}
I0316 15:06:00.588934 139836409243392 logging_writer.py:48] [113818] accumulated_eval_time=4280.078495, accumulated_logging_time=4.607404, accumulated_submission_time=50036.902831, global_step=113818, preemption_count=0, score=50036.902831, test/accuracy=0.619800, test/loss=1.634188, test/num_examples=10000, total_duration=54327.484815, train/accuracy=0.845645, train/loss=0.592743, validation/accuracy=0.748580, validation/loss=1.003954, validation/num_examples=50000
I0316 15:07:16.004728 139836417636096 logging_writer.py:48] [114000] global_step=114000, grad_norm=2.5159995555877686, loss=2.048860788345337
I0316 15:10:59.312140 139836409243392 logging_writer.py:48] [114500] global_step=114500, grad_norm=2.72920298576355, loss=1.730337381362915
I0316 15:13:00.883386 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:13:11.276435 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:13:34.187452 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:13:35.854674 140033285822272 submission_runner.py:420] Time since start: 54782.78s, 	Step: 114775, 	{'train/accuracy': 0.8468554615974426, 'train/loss': 0.5843576788902283, 'validation/accuracy': 0.7496199607849121, 'validation/loss': 0.9976999759674072, 'validation/num_examples': 50000, 'test/accuracy': 0.6207000017166138, 'test/loss': 1.6386059522628784, 'test/num_examples': 10000, 'score': 50457.13864898682, 'total_duration': 54782.779359579086, 'accumulated_submission_time': 50457.13864898682, 'accumulated_eval_time': 4315.04980134964, 'accumulated_logging_time': 4.645892381668091}
I0316 15:13:35.883900 139836417636096 logging_writer.py:48] [114775] accumulated_eval_time=4315.049801, accumulated_logging_time=4.645892, accumulated_submission_time=50457.138649, global_step=114775, preemption_count=0, score=50457.138649, test/accuracy=0.620700, test/loss=1.638606, test/num_examples=10000, total_duration=54782.779360, train/accuracy=0.846855, train/loss=0.584358, validation/accuracy=0.749620, validation/loss=0.997700, validation/num_examples=50000
I0316 15:15:10.877641 139836409243392 logging_writer.py:48] [115000] global_step=115000, grad_norm=2.7419273853302, loss=1.857874870300293
I0316 15:18:54.245790 139836417636096 logging_writer.py:48] [115500] global_step=115500, grad_norm=2.879556179046631, loss=1.4349052906036377
I0316 15:20:35.918647 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:20:46.529594 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:21:08.851790 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:21:10.518406 140033285822272 submission_runner.py:420] Time since start: 55237.44s, 	Step: 115730, 	{'train/accuracy': 0.8459765315055847, 'train/loss': 0.5903598070144653, 'validation/accuracy': 0.750059962272644, 'validation/loss': 0.9998406171798706, 'validation/num_examples': 50000, 'test/accuracy': 0.6201000213623047, 'test/loss': 1.6393582820892334, 'test/num_examples': 10000, 'score': 50877.113295555115, 'total_duration': 55237.44309091568, 'accumulated_submission_time': 50877.113295555115, 'accumulated_eval_time': 4349.649586200714, 'accumulated_logging_time': 4.686129331588745}
I0316 15:21:10.547602 139836409243392 logging_writer.py:48] [115730] accumulated_eval_time=4349.649586, accumulated_logging_time=4.686129, accumulated_submission_time=50877.113296, global_step=115730, preemption_count=0, score=50877.113296, test/accuracy=0.620100, test/loss=1.639358, test/num_examples=10000, total_duration=55237.443091, train/accuracy=0.845977, train/loss=0.590360, validation/accuracy=0.750060, validation/loss=0.999841, validation/num_examples=50000
I0316 15:23:06.821580 139836417636096 logging_writer.py:48] [116000] global_step=116000, grad_norm=2.7155377864837646, loss=1.5553290843963623
I0316 15:26:50.236997 139836409243392 logging_writer.py:48] [116500] global_step=116500, grad_norm=2.6289970874786377, loss=3.3276212215423584
I0316 15:28:10.786060 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:28:21.024239 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:28:48.802759 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:28:50.466792 140033285822272 submission_runner.py:420] Time since start: 55697.39s, 	Step: 116683, 	{'train/accuracy': 0.8506445288658142, 'train/loss': 0.5619098544120789, 'validation/accuracy': 0.749779999256134, 'validation/loss': 0.9848576188087463, 'validation/num_examples': 50000, 'test/accuracy': 0.6219000220298767, 'test/loss': 1.6262645721435547, 'test/num_examples': 10000, 'score': 51297.29220557213, 'total_duration': 55697.39147853851, 'accumulated_submission_time': 51297.29220557213, 'accumulated_eval_time': 4389.330322742462, 'accumulated_logging_time': 4.725714683532715}
I0316 15:28:50.500905 139836417636096 logging_writer.py:48] [116683] accumulated_eval_time=4389.330323, accumulated_logging_time=4.725715, accumulated_submission_time=51297.292206, global_step=116683, preemption_count=0, score=51297.292206, test/accuracy=0.621900, test/loss=1.626265, test/num_examples=10000, total_duration=55697.391479, train/accuracy=0.850645, train/loss=0.561910, validation/accuracy=0.749780, validation/loss=0.984858, validation/num_examples=50000
I0316 15:31:07.388300 139836409243392 logging_writer.py:48] [117000] global_step=117000, grad_norm=2.7903575897216797, loss=3.8008534908294678
I0316 15:34:51.280270 139836417636096 logging_writer.py:48] [117500] global_step=117500, grad_norm=2.980363607406616, loss=1.4859163761138916
I0316 15:35:50.703075 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:36:01.092912 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:36:25.119300 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:36:26.777970 140033285822272 submission_runner.py:420] Time since start: 56153.70s, 	Step: 117635, 	{'train/accuracy': 0.85218745470047, 'train/loss': 0.5644310712814331, 'validation/accuracy': 0.7512800097465515, 'validation/loss': 0.9909461736679077, 'validation/num_examples': 50000, 'test/accuracy': 0.6231000423431396, 'test/loss': 1.6262131929397583, 'test/num_examples': 10000, 'score': 51717.43297958374, 'total_duration': 56153.70263981819, 'accumulated_submission_time': 51717.43297958374, 'accumulated_eval_time': 4425.405205488205, 'accumulated_logging_time': 4.772045850753784}
I0316 15:36:26.806188 139836409243392 logging_writer.py:48] [117635] accumulated_eval_time=4425.405205, accumulated_logging_time=4.772046, accumulated_submission_time=51717.432980, global_step=117635, preemption_count=0, score=51717.432980, test/accuracy=0.623100, test/loss=1.626213, test/num_examples=10000, total_duration=56153.702640, train/accuracy=0.852187, train/loss=0.564431, validation/accuracy=0.751280, validation/loss=0.990946, validation/num_examples=50000
I0316 15:39:05.031394 139836417636096 logging_writer.py:48] [118000] global_step=118000, grad_norm=2.671696186065674, loss=1.7622793912887573
I0316 15:42:47.647067 139836409243392 logging_writer.py:48] [118500] global_step=118500, grad_norm=2.733752489089966, loss=1.4186807870864868
I0316 15:43:27.238933 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:43:38.028055 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:44:00.164183 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:44:01.832309 140033285822272 submission_runner.py:420] Time since start: 56608.76s, 	Step: 118590, 	{'train/accuracy': 0.8519335985183716, 'train/loss': 0.5597919821739197, 'validation/accuracy': 0.7525599598884583, 'validation/loss': 0.9866520762443542, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.6207976341247559, 'test/num_examples': 10000, 'score': 52137.802012205124, 'total_duration': 56608.75700259209, 'accumulated_submission_time': 52137.802012205124, 'accumulated_eval_time': 4459.998586654663, 'accumulated_logging_time': 4.8138206005096436}
I0316 15:44:01.857162 139836417636096 logging_writer.py:48] [118590] accumulated_eval_time=4459.998587, accumulated_logging_time=4.813821, accumulated_submission_time=52137.802012, global_step=118590, preemption_count=0, score=52137.802012, test/accuracy=0.626700, test/loss=1.620798, test/num_examples=10000, total_duration=56608.757003, train/accuracy=0.851934, train/loss=0.559792, validation/accuracy=0.752560, validation/loss=0.986652, validation/num_examples=50000
I0316 15:47:00.067219 139836409243392 logging_writer.py:48] [119000] global_step=119000, grad_norm=2.822307825088501, loss=1.785922646522522
I0316 15:50:43.205837 139836417636096 logging_writer.py:48] [119500] global_step=119500, grad_norm=2.573101758956909, loss=3.366636037826538
I0316 15:51:01.899830 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:51:12.411833 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:51:37.398745 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:51:39.048473 140033285822272 submission_runner.py:420] Time since start: 57065.97s, 	Step: 119544, 	{'train/accuracy': 0.8473632335662842, 'train/loss': 0.5713116526603699, 'validation/accuracy': 0.7536199688911438, 'validation/loss': 0.9778622984886169, 'validation/num_examples': 50000, 'test/accuracy': 0.6262000203132629, 'test/loss': 1.6168922185897827, 'test/num_examples': 10000, 'score': 52557.78605103493, 'total_duration': 57065.97317624092, 'accumulated_submission_time': 52557.78605103493, 'accumulated_eval_time': 4497.1472289562225, 'accumulated_logging_time': 4.847980976104736}
I0316 15:51:39.073946 139836409243392 logging_writer.py:48] [119544] accumulated_eval_time=4497.147229, accumulated_logging_time=4.847981, accumulated_submission_time=52557.786051, global_step=119544, preemption_count=0, score=52557.786051, test/accuracy=0.626200, test/loss=1.616892, test/num_examples=10000, total_duration=57065.973176, train/accuracy=0.847363, train/loss=0.571312, validation/accuracy=0.753620, validation/loss=0.977862, validation/num_examples=50000
I0316 15:54:57.326788 139836417636096 logging_writer.py:48] [120000] global_step=120000, grad_norm=2.7615277767181396, loss=2.5081727504730225
I0316 15:58:39.295870 140033285822272 spec.py:321] Evaluating on the training split.
I0316 15:58:49.543519 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 15:59:14.061012 140033285822272 spec.py:349] Evaluating on the test split.
I0316 15:59:15.715582 140033285822272 submission_runner.py:420] Time since start: 57522.64s, 	Step: 120499, 	{'train/accuracy': 0.8544335961341858, 'train/loss': 0.5522642135620117, 'validation/accuracy': 0.7531799674034119, 'validation/loss': 0.9789881110191345, 'validation/num_examples': 50000, 'test/accuracy': 0.6262000203132629, 'test/loss': 1.6122066974639893, 'test/num_examples': 10000, 'score': 52977.94923663139, 'total_duration': 57522.64027953148, 'accumulated_submission_time': 52977.94923663139, 'accumulated_eval_time': 4533.566967010498, 'accumulated_logging_time': 4.882195711135864}
I0316 15:59:15.741162 139836409243392 logging_writer.py:48] [120499] accumulated_eval_time=4533.566967, accumulated_logging_time=4.882196, accumulated_submission_time=52977.949237, global_step=120499, preemption_count=0, score=52977.949237, test/accuracy=0.626200, test/loss=1.612207, test/num_examples=10000, total_duration=57522.640280, train/accuracy=0.854434, train/loss=0.552264, validation/accuracy=0.753180, validation/loss=0.978988, validation/num_examples=50000
I0316 15:59:16.528250 139836417636096 logging_writer.py:48] [120500] global_step=120500, grad_norm=2.4892375469207764, loss=2.424450397491455
I0316 16:02:54.144076 139836409243392 logging_writer.py:48] [121000] global_step=121000, grad_norm=2.761993646621704, loss=1.2789356708526611
I0316 16:06:16.090990 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:06:26.677448 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:06:49.586547 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:06:51.251810 140033285822272 submission_runner.py:420] Time since start: 57978.18s, 	Step: 121454, 	{'train/accuracy': 0.8498241901397705, 'train/loss': 0.5694214701652527, 'validation/accuracy': 0.7528199553489685, 'validation/loss': 0.9818065166473389, 'validation/num_examples': 50000, 'test/accuracy': 0.6256000399589539, 'test/loss': 1.615452766418457, 'test/num_examples': 10000, 'score': 53398.238001823425, 'total_duration': 57978.176491975784, 'accumulated_submission_time': 53398.238001823425, 'accumulated_eval_time': 4568.727827787399, 'accumulated_logging_time': 4.91951847076416}
I0316 16:06:51.282175 139836417636096 logging_writer.py:48] [121454] accumulated_eval_time=4568.727828, accumulated_logging_time=4.919518, accumulated_submission_time=53398.238002, global_step=121454, preemption_count=0, score=53398.238002, test/accuracy=0.625600, test/loss=1.615453, test/num_examples=10000, total_duration=57978.176492, train/accuracy=0.849824, train/loss=0.569421, validation/accuracy=0.752820, validation/loss=0.981807, validation/num_examples=50000
I0316 16:07:09.661806 139836409243392 logging_writer.py:48] [121500] global_step=121500, grad_norm=2.8079307079315186, loss=1.3981389999389648
I0316 16:10:51.062003 139836417636096 logging_writer.py:48] [122000] global_step=122000, grad_norm=2.5496578216552734, loss=1.9748940467834473
I0316 16:13:51.679003 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:14:02.212908 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:14:29.549708 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:14:31.197777 140033285822272 submission_runner.py:420] Time since start: 58438.12s, 	Step: 122407, 	{'train/accuracy': 0.8509570360183716, 'train/loss': 0.5583187341690063, 'validation/accuracy': 0.7542600035667419, 'validation/loss': 0.9754990339279175, 'validation/num_examples': 50000, 'test/accuracy': 0.6246000528335571, 'test/loss': 1.6070241928100586, 'test/num_examples': 10000, 'score': 53818.574295282364, 'total_duration': 58438.1224565506, 'accumulated_submission_time': 53818.574295282364, 'accumulated_eval_time': 4608.24661231041, 'accumulated_logging_time': 4.96071720123291}
I0316 16:14:31.229265 139836409243392 logging_writer.py:48] [122407] accumulated_eval_time=4608.246612, accumulated_logging_time=4.960717, accumulated_submission_time=53818.574295, global_step=122407, preemption_count=0, score=53818.574295, test/accuracy=0.624600, test/loss=1.607024, test/num_examples=10000, total_duration=58438.122457, train/accuracy=0.850957, train/loss=0.558319, validation/accuracy=0.754260, validation/loss=0.975499, validation/num_examples=50000
I0316 16:15:07.947618 139836417636096 logging_writer.py:48] [122500] global_step=122500, grad_norm=2.582069158554077, loss=1.810657024383545
I0316 16:18:51.298544 139836409243392 logging_writer.py:48] [123000] global_step=123000, grad_norm=2.975858688354492, loss=1.3594043254852295
I0316 16:21:31.419917 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:21:41.560677 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:22:06.173759 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:22:07.830832 140033285822272 submission_runner.py:420] Time since start: 58894.76s, 	Step: 123362, 	{'train/accuracy': 0.8512694835662842, 'train/loss': 0.5596078634262085, 'validation/accuracy': 0.7537999749183655, 'validation/loss': 0.9762325286865234, 'validation/num_examples': 50000, 'test/accuracy': 0.625, 'test/loss': 1.6111570596694946, 'test/num_examples': 10000, 'score': 54238.704822063446, 'total_duration': 58894.75551557541, 'accumulated_submission_time': 54238.704822063446, 'accumulated_eval_time': 4644.657539606094, 'accumulated_logging_time': 5.002605438232422}
I0316 16:22:07.863130 139836417636096 logging_writer.py:48] [123362] accumulated_eval_time=4644.657540, accumulated_logging_time=5.002605, accumulated_submission_time=54238.704822, global_step=123362, preemption_count=0, score=54238.704822, test/accuracy=0.625000, test/loss=1.611157, test/num_examples=10000, total_duration=58894.755516, train/accuracy=0.851269, train/loss=0.559608, validation/accuracy=0.753800, validation/loss=0.976233, validation/num_examples=50000
I0316 16:23:04.698097 139836409243392 logging_writer.py:48] [123500] global_step=123500, grad_norm=2.98730731010437, loss=3.8082895278930664
I0316 16:26:47.953714 139836417636096 logging_writer.py:48] [124000] global_step=124000, grad_norm=2.8174679279327393, loss=1.3400955200195312
I0316 16:29:08.296038 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:29:18.749949 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:29:40.499580 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:29:42.165259 140033285822272 submission_runner.py:420] Time since start: 59349.09s, 	Step: 124316, 	{'train/accuracy': 0.8517382740974426, 'train/loss': 0.559052050113678, 'validation/accuracy': 0.7544599771499634, 'validation/loss': 0.9752328395843506, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.606034278869629, 'test/num_examples': 10000, 'score': 54659.079010009766, 'total_duration': 59349.08994650841, 'accumulated_submission_time': 54659.079010009766, 'accumulated_eval_time': 4678.526756763458, 'accumulated_logging_time': 5.044040679931641}
I0316 16:29:42.201344 139836409243392 logging_writer.py:48] [124316] accumulated_eval_time=4678.526757, accumulated_logging_time=5.044041, accumulated_submission_time=54659.079010, global_step=124316, preemption_count=0, score=54659.079010, test/accuracy=0.626700, test/loss=1.606034, test/num_examples=10000, total_duration=59349.089947, train/accuracy=0.851738, train/loss=0.559052, validation/accuracy=0.754460, validation/loss=0.975233, validation/num_examples=50000
I0316 16:31:00.275428 139836417636096 logging_writer.py:48] [124500] global_step=124500, grad_norm=2.6674795150756836, loss=2.6568350791931152
I0316 16:34:43.262738 139836409243392 logging_writer.py:48] [125000] global_step=125000, grad_norm=2.735722303390503, loss=1.3411622047424316
I0316 16:36:42.627169 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:36:53.090474 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:37:23.975173 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:37:25.633797 140033285822272 submission_runner.py:420] Time since start: 59812.56s, 	Step: 125269, 	{'train/accuracy': 0.8548241853713989, 'train/loss': 0.5492197871208191, 'validation/accuracy': 0.7552599906921387, 'validation/loss': 0.9727584719657898, 'validation/num_examples': 50000, 'test/accuracy': 0.6283000111579895, 'test/loss': 1.6030774116516113, 'test/num_examples': 10000, 'score': 55079.44510221481, 'total_duration': 59812.55849838257, 'accumulated_submission_time': 55079.44510221481, 'accumulated_eval_time': 4721.533430814743, 'accumulated_logging_time': 5.090787410736084}
I0316 16:37:25.658964 139836417636096 logging_writer.py:48] [125269] accumulated_eval_time=4721.533431, accumulated_logging_time=5.090787, accumulated_submission_time=55079.445102, global_step=125269, preemption_count=0, score=55079.445102, test/accuracy=0.628300, test/loss=1.603077, test/num_examples=10000, total_duration=59812.558498, train/accuracy=0.854824, train/loss=0.549220, validation/accuracy=0.755260, validation/loss=0.972758, validation/num_examples=50000
I0316 16:39:03.520023 139836409243392 logging_writer.py:48] [125500] global_step=125500, grad_norm=2.656106948852539, loss=3.050891876220703
I0316 16:42:46.205754 139836417636096 logging_writer.py:48] [126000] global_step=126000, grad_norm=2.878282070159912, loss=1.3344112634658813
I0316 16:44:25.825814 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:44:36.113399 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:45:02.498209 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:45:04.144922 140033285822272 submission_runner.py:420] Time since start: 60271.07s, 	Step: 126226, 	{'train/accuracy': 0.85462886095047, 'train/loss': 0.5483165979385376, 'validation/accuracy': 0.7567200064659119, 'validation/loss': 0.9677868485450745, 'validation/num_examples': 50000, 'test/accuracy': 0.6284000277519226, 'test/loss': 1.5996743440628052, 'test/num_examples': 10000, 'score': 55499.55207681656, 'total_duration': 60271.06962299347, 'accumulated_submission_time': 55499.55207681656, 'accumulated_eval_time': 4759.852556467056, 'accumulated_logging_time': 5.126350402832031}
I0316 16:45:04.169844 139836409243392 logging_writer.py:48] [126226] accumulated_eval_time=4759.852556, accumulated_logging_time=5.126350, accumulated_submission_time=55499.552077, global_step=126226, preemption_count=0, score=55499.552077, test/accuracy=0.628400, test/loss=1.599674, test/num_examples=10000, total_duration=60271.069623, train/accuracy=0.854629, train/loss=0.548317, validation/accuracy=0.756720, validation/loss=0.967787, validation/num_examples=50000
I0316 16:47:01.426827 139836417636096 logging_writer.py:48] [126500] global_step=126500, grad_norm=2.7243967056274414, loss=1.459614872932434
I0316 16:50:43.643666 139836409243392 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.696437120437622, loss=2.143028497695923
I0316 16:52:04.533690 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:52:14.956702 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 16:52:38.957004 140033285822272 spec.py:349] Evaluating on the test split.
I0316 16:52:40.619162 140033285822272 submission_runner.py:420] Time since start: 60727.54s, 	Step: 127183, 	{'train/accuracy': 0.85498046875, 'train/loss': 0.5480813384056091, 'validation/accuracy': 0.756659984588623, 'validation/loss': 0.9674642086029053, 'validation/num_examples': 50000, 'test/accuracy': 0.6272000074386597, 'test/loss': 1.5985677242279053, 'test/num_examples': 10000, 'score': 55919.85713505745, 'total_duration': 60727.54383111, 'accumulated_submission_time': 55919.85713505745, 'accumulated_eval_time': 4795.938015937805, 'accumulated_logging_time': 5.16035270690918}
I0316 16:52:40.651932 139836417636096 logging_writer.py:48] [127183] accumulated_eval_time=4795.938016, accumulated_logging_time=5.160353, accumulated_submission_time=55919.857135, global_step=127183, preemption_count=0, score=55919.857135, test/accuracy=0.627200, test/loss=1.598568, test/num_examples=10000, total_duration=60727.543831, train/accuracy=0.854980, train/loss=0.548081, validation/accuracy=0.756660, validation/loss=0.967464, validation/num_examples=50000
I0316 16:54:57.002693 139836409243392 logging_writer.py:48] [127500] global_step=127500, grad_norm=2.731327772140503, loss=1.2821810245513916
I0316 16:58:40.405305 139836417636096 logging_writer.py:48] [128000] global_step=128000, grad_norm=2.4990830421447754, loss=2.332676887512207
I0316 16:59:41.116310 140033285822272 spec.py:321] Evaluating on the training split.
I0316 16:59:51.528705 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 17:00:15.904775 140033285822272 spec.py:349] Evaluating on the test split.
I0316 17:00:17.566134 140033285822272 submission_runner.py:420] Time since start: 61184.49s, 	Step: 128138, 	{'train/accuracy': 0.855273425579071, 'train/loss': 0.5533023476600647, 'validation/accuracy': 0.7561399936676025, 'validation/loss': 0.9704608917236328, 'validation/num_examples': 50000, 'test/accuracy': 0.6276000142097473, 'test/loss': 1.5983819961547852, 'test/num_examples': 10000, 'score': 56340.26157164574, 'total_duration': 61184.4908246994, 'accumulated_submission_time': 56340.26157164574, 'accumulated_eval_time': 4832.387828111649, 'accumulated_logging_time': 5.203810453414917}
I0316 17:00:17.597930 139836409243392 logging_writer.py:48] [128138] accumulated_eval_time=4832.387828, accumulated_logging_time=5.203810, accumulated_submission_time=56340.261572, global_step=128138, preemption_count=0, score=56340.261572, test/accuracy=0.627600, test/loss=1.598382, test/num_examples=10000, total_duration=61184.490825, train/accuracy=0.855273, train/loss=0.553302, validation/accuracy=0.756140, validation/loss=0.970461, validation/num_examples=50000
I0316 17:02:54.654271 139836417636096 logging_writer.py:48] [128500] global_step=128500, grad_norm=2.5589470863342285, loss=1.4362283945083618
I0316 17:06:37.856738 139836409243392 logging_writer.py:48] [129000] global_step=129000, grad_norm=2.8120219707489014, loss=3.625898599624634
I0316 17:07:17.631504 140033285822272 spec.py:321] Evaluating on the training split.
I0316 17:07:27.749619 140033285822272 spec.py:333] Evaluating on the validation split.
I0316 17:07:56.228016 140033285822272 spec.py:349] Evaluating on the test split.
I0316 17:07:57.911117 140033285822272 submission_runner.py:420] Time since start: 61644.84s, 	Step: 129091, 	{'train/accuracy': 0.8565039038658142, 'train/loss': 0.5440993905067444, 'validation/accuracy': 0.7568199634552002, 'validation/loss': 0.9676470160484314, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.6001191139221191, 'test/num_examples': 10000, 'score': 56760.22937917709, 'total_duration': 61644.83579325676, 'accumulated_submission_time': 56760.22937917709, 'accumulated_eval_time': 4872.667409658432, 'accumulated_logging_time': 5.245442152023315}
I0316 17:07:57.941419 139836417636096 logging_writer.py:48] [129091] accumulated_eval_time=4872.667410, accumulated_logging_time=5.245442, accumulated_submission_time=56760.229379, global_step=129091, preemption_count=0, score=56760.229379, test/accuracy=0.628800, test/loss=1.600119, test/num_examples=10000, total_duration=61644.835793, train/accuracy=0.856504, train/loss=0.544099, validation/accuracy=0.756820, validation/loss=0.967647, validation/num_examples=50000
I0316 17:07:57.963165 139836409243392 logging_writer.py:48] [129091] global_step=129091, preemption_count=0, score=56760.229379
I0316 17:07:58.303812 140033285822272 checkpoints.py:490] Saving checkpoint at step: 129091
I0316 17:07:59.374222 140033285822272 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1/checkpoint_129091
I0316 17:07:59.398053 140033285822272 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/imagenet_vit_post_ln_jax/trial_1/checkpoint_129091.
I0316 17:08:00.338047 140033285822272 submission_runner.py:593] Tuning trial 1/1
I0316 17:08:00.338312 140033285822272 submission_runner.py:594] Hyperparameters: Hyperparameters(learning_rate=0.00026032497966327757, beta1=0.9709035036599892, beta2=0.6572080806975734, warmup_steps=13999, weight_decay=0.03077045727617869)
I0316 17:08:00.345503 140033285822272 submission_runner.py:595] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0007617187220603228, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 41.08020734786987, 'total_duration': 81.16462087631226, 'accumulated_submission_time': 41.08020734786987, 'accumulated_eval_time': 40.084317207336426, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (926, {'train/accuracy': 0.006582031026482582, 'train/loss': 6.714056968688965, 'validation/accuracy': 0.006300000008195639, 'validation/loss': 6.719353675842285, 'validation/num_examples': 50000, 'test/accuracy': 0.004600000102072954, 'test/loss': 6.733641147613525, 'test/num_examples': 10000, 'score': 461.0231363773346, 'total_duration': 522.6778628826141, 'accumulated_submission_time': 461.0231363773346, 'accumulated_eval_time': 61.57937526702881, 'accumulated_logging_time': 0.02532482147216797, 'global_step': 926, 'preemption_count': 0}), (1901, {'train/accuracy': 0.016679687425494194, 'train/loss': 6.3422441482543945, 'validation/accuracy': 0.01565999910235405, 'validation/loss': 6.359914302825928, 'validation/num_examples': 50000, 'test/accuracy': 0.012800000607967377, 'test/loss': 6.409088134765625, 'test/num_examples': 10000, 'score': 881.1417100429535, 'total_duration': 964.175261259079, 'accumulated_submission_time': 881.1417100429535, 'accumulated_eval_time': 82.8766758441925, 'accumulated_logging_time': 0.0546259880065918, 'global_step': 1901, 'preemption_count': 0}), (2877, {'train/accuracy': 0.03150390461087227, 'train/loss': 5.981964111328125, 'validation/accuracy': 0.029159998521208763, 'validation/loss': 6.014761924743652, 'validation/num_examples': 50000, 'test/accuracy': 0.02410000190138817, 'test/loss': 6.1073899269104, 'test/num_examples': 10000, 'score': 1301.505422115326, 'total_duration': 1406.5620710849762, 'accumulated_submission_time': 1301.505422115326, 'accumulated_eval_time': 104.81840634346008, 'accumulated_logging_time': 0.08502578735351562, 'global_step': 2877, 'preemption_count': 0}), (3855, {'train/accuracy': 0.04957031086087227, 'train/loss': 5.680673122406006, 'validation/accuracy': 0.04731999710202217, 'validation/loss': 5.7118449211120605, 'validation/num_examples': 50000, 'test/accuracy': 0.03920000046491623, 'test/loss': 5.855755805969238, 'test/num_examples': 10000, 'score': 1721.4997999668121, 'total_duration': 1848.6213216781616, 'accumulated_submission_time': 1721.4997999668121, 'accumulated_eval_time': 126.8033504486084, 'accumulated_logging_time': 0.11359977722167969, 'global_step': 3855, 'preemption_count': 0}), (4824, {'train/accuracy': 0.06197265535593033, 'train/loss': 5.449063777923584, 'validation/accuracy': 0.06045999750494957, 'validation/loss': 5.482926845550537, 'validation/num_examples': 50000, 'test/accuracy': 0.04780000075697899, 'test/loss': 5.6592698097229, 'test/num_examples': 10000, 'score': 2141.5182423591614, 'total_duration': 2290.524486064911, 'accumulated_submission_time': 2141.5182423591614, 'accumulated_eval_time': 148.610445022583, 'accumulated_logging_time': 0.1418454647064209, 'global_step': 4824, 'preemption_count': 0}), (5789, {'train/accuracy': 0.08013671636581421, 'train/loss': 5.217288494110107, 'validation/accuracy': 0.07655999809503555, 'validation/loss': 5.264044284820557, 'validation/num_examples': 50000, 'test/accuracy': 0.05620000138878822, 'test/loss': 5.48585319519043, 'test/num_examples': 10000, 'score': 2561.473810195923, 'total_duration': 2732.53444647789, 'accumulated_submission_time': 2561.473810195923, 'accumulated_eval_time': 170.5796058177948, 'accumulated_logging_time': 0.17626452445983887, 'global_step': 5789, 'preemption_count': 0}), (6759, {'train/accuracy': 0.1013476550579071, 'train/loss': 4.993688106536865, 'validation/accuracy': 0.09341999888420105, 'validation/loss': 5.065521240234375, 'validation/num_examples': 50000, 'test/accuracy': 0.06980000436306, 'test/loss': 5.323365211486816, 'test/num_examples': 10000, 'score': 2981.527709722519, 'total_duration': 3174.414154291153, 'accumulated_submission_time': 2981.527709722519, 'accumulated_eval_time': 192.32569646835327, 'accumulated_logging_time': 0.20553112030029297, 'global_step': 6759, 'preemption_count': 0}), (7728, {'train/accuracy': 0.11998046934604645, 'train/loss': 4.808412551879883, 'validation/accuracy': 0.11267999559640884, 'validation/loss': 4.850436687469482, 'validation/num_examples': 50000, 'test/accuracy': 0.08540000766515732, 'test/loss': 5.1297783851623535, 'test/num_examples': 10000, 'score': 3401.743551969528, 'total_duration': 3616.5531113147736, 'accumulated_submission_time': 3401.743551969528, 'accumulated_eval_time': 214.16758465766907, 'accumulated_logging_time': 0.23641633987426758, 'global_step': 7728, 'preemption_count': 0}), (8699, {'train/accuracy': 0.14232420921325684, 'train/loss': 4.569924354553223, 'validation/accuracy': 0.13220000267028809, 'validation/loss': 4.647293567657471, 'validation/num_examples': 50000, 'test/accuracy': 0.10190000385046005, 'test/loss': 4.963707447052002, 'test/num_examples': 10000, 'score': 3821.985910177231, 'total_duration': 4063.7972338199615, 'accumulated_submission_time': 3821.985910177231, 'accumulated_eval_time': 241.08913397789001, 'accumulated_logging_time': 0.26611995697021484, 'global_step': 8699, 'preemption_count': 0}), (9666, {'train/accuracy': 0.16783203184604645, 'train/loss': 4.347902297973633, 'validation/accuracy': 0.15410000085830688, 'validation/loss': 4.429182529449463, 'validation/num_examples': 50000, 'test/accuracy': 0.11750000715255737, 'test/loss': 4.765655040740967, 'test/num_examples': 10000, 'score': 4241.9191472530365, 'total_duration': 4506.738534450531, 'accumulated_submission_time': 4241.9191472530365, 'accumulated_eval_time': 264.0126805305481, 'accumulated_logging_time': 0.30106043815612793, 'global_step': 9666, 'preemption_count': 0}), (10636, {'train/accuracy': 0.19873046875, 'train/loss': 4.126186370849609, 'validation/accuracy': 0.1750599890947342, 'validation/loss': 4.249802589416504, 'validation/num_examples': 50000, 'test/accuracy': 0.1315000057220459, 'test/loss': 4.625553131103516, 'test/num_examples': 10000, 'score': 4661.980578184128, 'total_duration': 4951.162081241608, 'accumulated_submission_time': 4661.980578184128, 'accumulated_eval_time': 288.2912566661835, 'accumulated_logging_time': 0.3340919017791748, 'global_step': 10636, 'preemption_count': 0}), (11602, {'train/accuracy': 0.22062499821186066, 'train/loss': 3.9403603076934814, 'validation/accuracy': 0.20306000113487244, 'validation/loss': 4.047501564025879, 'validation/num_examples': 50000, 'test/accuracy': 0.15280000865459442, 'test/loss': 4.449875354766846, 'test/num_examples': 10000, 'score': 5082.0325129032135, 'total_duration': 5397.969358682632, 'accumulated_submission_time': 5082.0325129032135, 'accumulated_eval_time': 314.96621322631836, 'accumulated_logging_time': 0.36377620697021484, 'global_step': 11602, 'preemption_count': 0}), (12566, {'train/accuracy': 0.2492968738079071, 'train/loss': 3.7531585693359375, 'validation/accuracy': 0.2243800014257431, 'validation/loss': 3.883746385574341, 'validation/num_examples': 50000, 'test/accuracy': 0.170400008559227, 'test/loss': 4.311071395874023, 'test/num_examples': 10000, 'score': 5502.110665559769, 'total_duration': 5843.170692920685, 'accumulated_submission_time': 5502.110665559769, 'accumulated_eval_time': 340.00833344459534, 'accumulated_logging_time': 0.3936030864715576, 'global_step': 12566, 'preemption_count': 0}), (13528, {'train/accuracy': 0.27210935950279236, 'train/loss': 3.5523247718811035, 'validation/accuracy': 0.2468400001525879, 'validation/loss': 3.6852965354919434, 'validation/num_examples': 50000, 'test/accuracy': 0.18460001051425934, 'test/loss': 4.1573100090026855, 'test/num_examples': 10000, 'score': 5922.427560567856, 'total_duration': 6292.57753610611, 'accumulated_submission_time': 5922.427560567856, 'accumulated_eval_time': 368.9983401298523, 'accumulated_logging_time': 0.4434661865234375, 'global_step': 13528, 'preemption_count': 0}), (14478, {'train/accuracy': 0.2886328101158142, 'train/loss': 3.419095039367676, 'validation/accuracy': 0.2662599980831146, 'validation/loss': 3.558997392654419, 'validation/num_examples': 50000, 'test/accuracy': 0.1997000128030777, 'test/loss': 4.048617839813232, 'test/num_examples': 10000, 'score': 6342.762490987778, 'total_duration': 6745.11438536644, 'accumulated_submission_time': 6342.762490987778, 'accumulated_eval_time': 401.11600852012634, 'accumulated_logging_time': 0.47854089736938477, 'global_step': 14478, 'preemption_count': 0}), (15440, {'train/accuracy': 0.31990233063697815, 'train/loss': 3.2628514766693115, 'validation/accuracy': 0.2917400002479553, 'validation/loss': 3.4116780757904053, 'validation/num_examples': 50000, 'test/accuracy': 0.22120000422000885, 'test/loss': 3.929030656814575, 'test/num_examples': 10000, 'score': 6763.496320009232, 'total_duration': 7198.937178134918, 'accumulated_submission_time': 6763.496320009232, 'accumulated_eval_time': 434.10852456092834, 'accumulated_logging_time': 0.5244593620300293, 'global_step': 15440, 'preemption_count': 0}), (16403, {'train/accuracy': 0.33998045325279236, 'train/loss': 3.1379647254943848, 'validation/accuracy': 0.3125, 'validation/loss': 3.283846139907837, 'validation/num_examples': 50000, 'test/accuracy': 0.2395000159740448, 'test/loss': 3.829561948776245, 'test/num_examples': 10000, 'score': 7183.709098100662, 'total_duration': 7652.857706308365, 'accumulated_submission_time': 7183.709098100662, 'accumulated_eval_time': 467.7331323623657, 'accumulated_logging_time': 0.5573093891143799, 'global_step': 16403, 'preemption_count': 0}), (17359, {'train/accuracy': 0.36570310592651367, 'train/loss': 2.9488189220428467, 'validation/accuracy': 0.3349599838256836, 'validation/loss': 3.1350302696228027, 'validation/num_examples': 50000, 'test/accuracy': 0.25550001859664917, 'test/loss': 3.685300588607788, 'test/num_examples': 10000, 'score': 7603.709952116013, 'total_duration': 8105.313410997391, 'accumulated_submission_time': 7603.709952116013, 'accumulated_eval_time': 500.099139213562, 'accumulated_logging_time': 0.5962083339691162, 'global_step': 17359, 'preemption_count': 0}), (18314, {'train/accuracy': 0.38001951575279236, 'train/loss': 2.8648183345794678, 'validation/accuracy': 0.3544600009918213, 'validation/loss': 3.0171849727630615, 'validation/num_examples': 50000, 'test/accuracy': 0.2752000093460083, 'test/loss': 3.5676486492156982, 'test/num_examples': 10000, 'score': 8023.856166362762, 'total_duration': 8564.771030426025, 'accumulated_submission_time': 8023.856166362762, 'accumulated_eval_time': 539.3285284042358, 'accumulated_logging_time': 0.6289534568786621, 'global_step': 18314, 'preemption_count': 0}), (19275, {'train/accuracy': 0.3986523449420929, 'train/loss': 2.756155014038086, 'validation/accuracy': 0.3685799837112427, 'validation/loss': 2.9221696853637695, 'validation/num_examples': 50000, 'test/accuracy': 0.2873000204563141, 'test/loss': 3.4840786457061768, 'test/num_examples': 10000, 'score': 8444.070172548294, 'total_duration': 9031.510703086853, 'accumulated_submission_time': 8444.070172548294, 'accumulated_eval_time': 585.7715458869934, 'accumulated_logging_time': 0.6613638401031494, 'global_step': 19275, 'preemption_count': 0}), (20240, {'train/accuracy': 0.41951170563697815, 'train/loss': 2.647538423538208, 'validation/accuracy': 0.3833400011062622, 'validation/loss': 2.8261804580688477, 'validation/num_examples': 50000, 'test/accuracy': 0.2948000133037567, 'test/loss': 3.4086766242980957, 'test/num_examples': 10000, 'score': 8864.412791013718, 'total_duration': 9490.120684146881, 'accumulated_submission_time': 8864.412791013718, 'accumulated_eval_time': 623.9557950496674, 'accumulated_logging_time': 0.6943995952606201, 'global_step': 20240, 'preemption_count': 0}), (21198, {'train/accuracy': 0.45726561546325684, 'train/loss': 2.4732565879821777, 'validation/accuracy': 0.40535998344421387, 'validation/loss': 2.72802472114563, 'validation/num_examples': 50000, 'test/accuracy': 0.3059000074863434, 'test/loss': 3.3493459224700928, 'test/num_examples': 10000, 'score': 9284.682085990906, 'total_duration': 9948.50497341156, 'accumulated_submission_time': 9284.682085990906, 'accumulated_eval_time': 661.9793405532837, 'accumulated_logging_time': 0.7352142333984375, 'global_step': 21198, 'preemption_count': 0}), (22149, {'train/accuracy': 0.4543749988079071, 'train/loss': 2.465040922164917, 'validation/accuracy': 0.41731998324394226, 'validation/loss': 2.6536571979522705, 'validation/num_examples': 50000, 'test/accuracy': 0.320900022983551, 'test/loss': 3.2446231842041016, 'test/num_examples': 10000, 'score': 9704.787395954132, 'total_duration': 10412.890138149261, 'accumulated_submission_time': 9704.787395954132, 'accumulated_eval_time': 706.1748690605164, 'accumulated_logging_time': 0.7688145637512207, 'global_step': 22149, 'preemption_count': 0}), (23105, {'train/accuracy': 0.46406248211860657, 'train/loss': 2.4436635971069336, 'validation/accuracy': 0.428879976272583, 'validation/loss': 2.617060661315918, 'validation/num_examples': 50000, 'test/accuracy': 0.329800009727478, 'test/loss': 3.222968578338623, 'test/num_examples': 10000, 'score': 10125.104326963425, 'total_duration': 10868.545593976974, 'accumulated_submission_time': 10125.104326963425, 'accumulated_eval_time': 741.4298379421234, 'accumulated_logging_time': 0.8018918037414551, 'global_step': 23105, 'preemption_count': 0}), (24064, {'train/accuracy': 0.48402342200279236, 'train/loss': 2.274030923843384, 'validation/accuracy': 0.44132000207901, 'validation/loss': 2.5044198036193848, 'validation/num_examples': 50000, 'test/accuracy': 0.33740001916885376, 'test/loss': 3.1391141414642334, 'test/num_examples': 10000, 'score': 10545.221867799759, 'total_duration': 11325.832127809525, 'accumulated_submission_time': 10545.221867799759, 'accumulated_eval_time': 778.5178802013397, 'accumulated_logging_time': 0.832313060760498, 'global_step': 24064, 'preemption_count': 0}), (25022, {'train/accuracy': 0.4825390577316284, 'train/loss': 2.341752767562866, 'validation/accuracy': 0.44105997681617737, 'validation/loss': 2.5438315868377686, 'validation/num_examples': 50000, 'test/accuracy': 0.3443000018596649, 'test/loss': 3.128399610519409, 'test/num_examples': 10000, 'score': 10965.162417888641, 'total_duration': 11779.347505807877, 'accumulated_submission_time': 10965.162417888641, 'accumulated_eval_time': 812.0153987407684, 'accumulated_logging_time': 0.8595268726348877, 'global_step': 25022, 'preemption_count': 0}), (25975, {'train/accuracy': 0.5054687261581421, 'train/loss': 2.183162212371826, 'validation/accuracy': 0.4658399820327759, 'validation/loss': 2.391172170639038, 'validation/num_examples': 50000, 'test/accuracy': 0.35450002551078796, 'test/loss': 3.0186808109283447, 'test/num_examples': 10000, 'score': 11385.145975112915, 'total_duration': 12235.697974681854, 'accumulated_submission_time': 11385.145975112915, 'accumulated_eval_time': 848.301506280899, 'accumulated_logging_time': 0.8902637958526611, 'global_step': 25975, 'preemption_count': 0}), (26931, {'train/accuracy': 0.5189648270606995, 'train/loss': 2.1033716201782227, 'validation/accuracy': 0.47925999760627747, 'validation/loss': 2.310682535171509, 'validation/num_examples': 50000, 'test/accuracy': 0.3725000321865082, 'test/loss': 2.9614574909210205, 'test/num_examples': 10000, 'score': 11805.339718580246, 'total_duration': 12688.75161910057, 'accumulated_submission_time': 11805.339718580246, 'accumulated_eval_time': 881.0709578990936, 'accumulated_logging_time': 0.9305129051208496, 'global_step': 26931, 'preemption_count': 0}), (27885, {'train/accuracy': 0.5319726467132568, 'train/loss': 2.045513153076172, 'validation/accuracy': 0.48413997888565063, 'validation/loss': 2.290728807449341, 'validation/num_examples': 50000, 'test/accuracy': 0.3693000078201294, 'test/loss': 2.930393695831299, 'test/num_examples': 10000, 'score': 12225.59505367279, 'total_duration': 13142.815021753311, 'accumulated_submission_time': 12225.59505367279, 'accumulated_eval_time': 914.799902677536, 'accumulated_logging_time': 0.9597744941711426, 'global_step': 27885, 'preemption_count': 0}), (28842, {'train/accuracy': 0.5350195169448853, 'train/loss': 2.024923324584961, 'validation/accuracy': 0.49699997901916504, 'validation/loss': 2.221653461456299, 'validation/num_examples': 50000, 'test/accuracy': 0.38350000977516174, 'test/loss': 2.8705570697784424, 'test/num_examples': 10000, 'score': 12645.94331908226, 'total_duration': 13602.059030294418, 'accumulated_submission_time': 12645.94331908226, 'accumulated_eval_time': 953.6108977794647, 'accumulated_logging_time': 0.9948720932006836, 'global_step': 28842, 'preemption_count': 0}), (29799, {'train/accuracy': 0.5426366925239563, 'train/loss': 1.9930421113967896, 'validation/accuracy': 0.49629998207092285, 'validation/loss': 2.222616195678711, 'validation/num_examples': 50000, 'test/accuracy': 0.3903000056743622, 'test/loss': 2.845533609390259, 'test/num_examples': 10000, 'score': 13065.907601118088, 'total_duration': 14066.07828116417, 'accumulated_submission_time': 13065.907601118088, 'accumulated_eval_time': 997.5766913890839, 'accumulated_logging_time': 1.0336031913757324, 'global_step': 29799, 'preemption_count': 0}), (30759, {'train/accuracy': 0.5582226514816284, 'train/loss': 1.8914048671722412, 'validation/accuracy': 0.5114200115203857, 'validation/loss': 2.1356563568115234, 'validation/num_examples': 50000, 'test/accuracy': 0.4012000262737274, 'test/loss': 2.780033826828003, 'test/num_examples': 10000, 'score': 13486.169509887695, 'total_duration': 14524.558580875397, 'accumulated_submission_time': 13486.169509887695, 'accumulated_eval_time': 1035.710154056549, 'accumulated_logging_time': 1.068241834640503, 'global_step': 30759, 'preemption_count': 0}), (31716, {'train/accuracy': 0.5696093440055847, 'train/loss': 1.8607499599456787, 'validation/accuracy': 0.5142399668693542, 'validation/loss': 2.12805438041687, 'validation/num_examples': 50000, 'test/accuracy': 0.403300017118454, 'test/loss': 2.7867681980133057, 'test/num_examples': 10000, 'score': 13906.422610759735, 'total_duration': 14980.697907924652, 'accumulated_submission_time': 13906.422610759735, 'accumulated_eval_time': 1071.5148980617523, 'accumulated_logging_time': 1.098806619644165, 'global_step': 31716, 'preemption_count': 0}), (32672, {'train/accuracy': 0.5730664134025574, 'train/loss': 1.8205695152282715, 'validation/accuracy': 0.5302799940109253, 'validation/loss': 2.033155679702759, 'validation/num_examples': 50000, 'test/accuracy': 0.4157000184059143, 'test/loss': 2.687333822250366, 'test/num_examples': 10000, 'score': 14326.388909578323, 'total_duration': 15434.29147529602, 'accumulated_submission_time': 14326.388909578323, 'accumulated_eval_time': 1105.0609011650085, 'accumulated_logging_time': 1.130598783493042, 'global_step': 32672, 'preemption_count': 0}), (33621, {'train/accuracy': 0.5838671922683716, 'train/loss': 1.7662866115570068, 'validation/accuracy': 0.535860002040863, 'validation/loss': 2.0103554725646973, 'validation/num_examples': 50000, 'test/accuracy': 0.417900025844574, 'test/loss': 2.676462411880493, 'test/num_examples': 10000, 'score': 14746.696274280548, 'total_duration': 15893.421913385391, 'accumulated_submission_time': 14746.696274280548, 'accumulated_eval_time': 1143.7952399253845, 'accumulated_logging_time': 1.1695642471313477, 'global_step': 33621, 'preemption_count': 0}), (34573, {'train/accuracy': 0.6007617115974426, 'train/loss': 1.6721882820129395, 'validation/accuracy': 0.5429800152778625, 'validation/loss': 1.9515763521194458, 'validation/num_examples': 50000, 'test/accuracy': 0.42660000920295715, 'test/loss': 2.6220309734344482, 'test/num_examples': 10000, 'score': 15166.874994754791, 'total_duration': 16353.72144317627, 'accumulated_submission_time': 15166.874994754791, 'accumulated_eval_time': 1183.8358619213104, 'accumulated_logging_time': 1.1999287605285645, 'global_step': 34573, 'preemption_count': 0}), (35530, {'train/accuracy': 0.5900585651397705, 'train/loss': 1.7342700958251953, 'validation/accuracy': 0.5461599826812744, 'validation/loss': 1.9654384851455688, 'validation/num_examples': 50000, 'test/accuracy': 0.42750000953674316, 'test/loss': 2.632882833480835, 'test/num_examples': 10000, 'score': 15586.89006471634, 'total_duration': 16807.56308698654, 'accumulated_submission_time': 15586.89006471634, 'accumulated_eval_time': 1217.5830099582672, 'accumulated_logging_time': 1.2297043800354004, 'global_step': 35530, 'preemption_count': 0}), (36484, {'train/accuracy': 0.6089453101158142, 'train/loss': 1.6495379209518433, 'validation/accuracy': 0.5564799904823303, 'validation/loss': 1.8977562189102173, 'validation/num_examples': 50000, 'test/accuracy': 0.43380001187324524, 'test/loss': 2.585392475128174, 'test/num_examples': 10000, 'score': 16006.934529304504, 'total_duration': 17263.707371473312, 'accumulated_submission_time': 16006.934529304504, 'accumulated_eval_time': 1253.5988926887512, 'accumulated_logging_time': 1.2636237144470215, 'global_step': 36484, 'preemption_count': 0}), (37440, {'train/accuracy': 0.6157616972923279, 'train/loss': 1.5937190055847168, 'validation/accuracy': 0.563759982585907, 'validation/loss': 1.8479629755020142, 'validation/num_examples': 50000, 'test/accuracy': 0.4449000358581543, 'test/loss': 2.5360238552093506, 'test/num_examples': 10000, 'score': 16427.194246530533, 'total_duration': 17729.283722162247, 'accumulated_submission_time': 16427.194246530533, 'accumulated_eval_time': 1298.8306069374084, 'accumulated_logging_time': 1.2985265254974365, 'global_step': 37440, 'preemption_count': 0}), (38400, {'train/accuracy': 0.6366210579872131, 'train/loss': 1.5172066688537598, 'validation/accuracy': 0.5677399635314941, 'validation/loss': 1.8366968631744385, 'validation/num_examples': 50000, 'test/accuracy': 0.44780001044273376, 'test/loss': 2.5162038803100586, 'test/num_examples': 10000, 'score': 16847.46401500702, 'total_duration': 18186.687578439713, 'accumulated_submission_time': 16847.46401500702, 'accumulated_eval_time': 1335.8804173469543, 'accumulated_logging_time': 1.3324460983276367, 'global_step': 38400, 'preemption_count': 0}), (39361, {'train/accuracy': 0.6253125071525574, 'train/loss': 1.5803190469741821, 'validation/accuracy': 0.5726799964904785, 'validation/loss': 1.8311997652053833, 'validation/num_examples': 50000, 'test/accuracy': 0.4498000144958496, 'test/loss': 2.4852004051208496, 'test/num_examples': 10000, 'score': 17267.515798330307, 'total_duration': 18644.169363975525, 'accumulated_submission_time': 17267.515798330307, 'accumulated_eval_time': 1373.2299056053162, 'accumulated_logging_time': 1.3624634742736816, 'global_step': 39361, 'preemption_count': 0}), (40318, {'train/accuracy': 0.636523425579071, 'train/loss': 1.5090090036392212, 'validation/accuracy': 0.5835199952125549, 'validation/loss': 1.7715173959732056, 'validation/num_examples': 50000, 'test/accuracy': 0.46490001678466797, 'test/loss': 2.445481777191162, 'test/num_examples': 10000, 'score': 17687.836143493652, 'total_duration': 19103.057171821594, 'accumulated_submission_time': 17687.836143493652, 'accumulated_eval_time': 1411.718628168106, 'accumulated_logging_time': 1.3917474746704102, 'global_step': 40318, 'preemption_count': 0}), (41265, {'train/accuracy': 0.6448046565055847, 'train/loss': 1.478863000869751, 'validation/accuracy': 0.5865399837493896, 'validation/loss': 1.761332631111145, 'validation/num_examples': 50000, 'test/accuracy': 0.4617000222206116, 'test/loss': 2.4383459091186523, 'test/num_examples': 10000, 'score': 18107.49636220932, 'total_duration': 19557.246302843094, 'accumulated_submission_time': 18107.49636220932, 'accumulated_eval_time': 1445.8699808120728, 'accumulated_logging_time': 1.7200422286987305, 'global_step': 41265, 'preemption_count': 0}), (42218, {'train/accuracy': 0.6465820074081421, 'train/loss': 1.4708688259124756, 'validation/accuracy': 0.5926600098609924, 'validation/loss': 1.7223899364471436, 'validation/num_examples': 50000, 'test/accuracy': 0.46700000762939453, 'test/loss': 2.410362958908081, 'test/num_examples': 10000, 'score': 18527.45361971855, 'total_duration': 20021.525790691376, 'accumulated_submission_time': 18527.45361971855, 'accumulated_eval_time': 1490.1058139801025, 'accumulated_logging_time': 1.7573609352111816, 'global_step': 42218, 'preemption_count': 0}), (43173, {'train/accuracy': 0.6506640315055847, 'train/loss': 1.450050950050354, 'validation/accuracy': 0.5936200022697449, 'validation/loss': 1.710167407989502, 'validation/num_examples': 50000, 'test/accuracy': 0.4692000150680542, 'test/loss': 2.394214391708374, 'test/num_examples': 10000, 'score': 18947.717879533768, 'total_duration': 20477.094908475876, 'accumulated_submission_time': 18947.717879533768, 'accumulated_eval_time': 1525.3252108097076, 'accumulated_logging_time': 1.7933471202850342, 'global_step': 43173, 'preemption_count': 0}), (44124, {'train/accuracy': 0.6599413752555847, 'train/loss': 1.3911164999008179, 'validation/accuracy': 0.6062799692153931, 'validation/loss': 1.662405252456665, 'validation/num_examples': 50000, 'test/accuracy': 0.48280003666877747, 'test/loss': 2.3503904342651367, 'test/num_examples': 10000, 'score': 19367.72512102127, 'total_duration': 20934.558821439743, 'accumulated_submission_time': 19367.72512102127, 'accumulated_eval_time': 1562.6961524486542, 'accumulated_logging_time': 1.830763339996338, 'global_step': 44124, 'preemption_count': 0}), (45079, {'train/accuracy': 0.6740429401397705, 'train/loss': 1.329019546508789, 'validation/accuracy': 0.6092399954795837, 'validation/loss': 1.6442941427230835, 'validation/num_examples': 50000, 'test/accuracy': 0.4886000156402588, 'test/loss': 2.3218066692352295, 'test/num_examples': 10000, 'score': 19787.92154598236, 'total_duration': 21389.5479490757, 'accumulated_submission_time': 19787.92154598236, 'accumulated_eval_time': 1597.4061863422394, 'accumulated_logging_time': 1.8645439147949219, 'global_step': 45079, 'preemption_count': 0}), (46037, {'train/accuracy': 0.6686718463897705, 'train/loss': 1.3530316352844238, 'validation/accuracy': 0.6150599718093872, 'validation/loss': 1.6116976737976074, 'validation/num_examples': 50000, 'test/accuracy': 0.4865000247955322, 'test/loss': 2.3106882572174072, 'test/num_examples': 10000, 'score': 20207.886675834656, 'total_duration': 21843.66777586937, 'accumulated_submission_time': 20207.886675834656, 'accumulated_eval_time': 1631.4768223762512, 'accumulated_logging_time': 1.8995838165283203, 'global_step': 46037, 'preemption_count': 0}), (46990, {'train/accuracy': 0.6719921827316284, 'train/loss': 1.3276513814926147, 'validation/accuracy': 0.6168199777603149, 'validation/loss': 1.6015956401824951, 'validation/num_examples': 50000, 'test/accuracy': 0.4887000322341919, 'test/loss': 2.290903329849243, 'test/num_examples': 10000, 'score': 20628.261212348938, 'total_duration': 22301.228451251984, 'accumulated_submission_time': 20628.261212348938, 'accumulated_eval_time': 1668.5782387256622, 'accumulated_logging_time': 1.9347178936004639, 'global_step': 46990, 'preemption_count': 0}), (47944, {'train/accuracy': 0.6779491901397705, 'train/loss': 1.3019496202468872, 'validation/accuracy': 0.6201399564743042, 'validation/loss': 1.5818183422088623, 'validation/num_examples': 50000, 'test/accuracy': 0.4913000166416168, 'test/loss': 2.2568938732147217, 'test/num_examples': 10000, 'score': 21048.45112323761, 'total_duration': 22757.770616292953, 'accumulated_submission_time': 21048.45112323761, 'accumulated_eval_time': 1704.8478543758392, 'accumulated_logging_time': 1.968759298324585, 'global_step': 47944, 'preemption_count': 0}), (48897, {'train/accuracy': 0.6955468654632568, 'train/loss': 1.2310354709625244, 'validation/accuracy': 0.6251199841499329, 'validation/loss': 1.557105302810669, 'validation/num_examples': 50000, 'test/accuracy': 0.49870002269744873, 'test/loss': 2.2372066974639893, 'test/num_examples': 10000, 'score': 21468.4367480278, 'total_duration': 23221.61490869522, 'accumulated_submission_time': 21468.4367480278, 'accumulated_eval_time': 1748.6234555244446, 'accumulated_logging_time': 2.0034050941467285, 'global_step': 48897, 'preemption_count': 0}), (49857, {'train/accuracy': 0.6855273246765137, 'train/loss': 1.2761197090148926, 'validation/accuracy': 0.6314600110054016, 'validation/loss': 1.5329201221466064, 'validation/num_examples': 50000, 'test/accuracy': 0.5034000277519226, 'test/loss': 2.21596097946167, 'test/num_examples': 10000, 'score': 21888.799356222153, 'total_duration': 23679.67661356926, 'accumulated_submission_time': 21888.799356222153, 'accumulated_eval_time': 1786.2309200763702, 'accumulated_logging_time': 2.0461082458496094, 'global_step': 49857, 'preemption_count': 0}), (50816, {'train/accuracy': 0.6879491806030273, 'train/loss': 1.267967700958252, 'validation/accuracy': 0.6278199553489685, 'validation/loss': 1.5532413721084595, 'validation/num_examples': 50000, 'test/accuracy': 0.5005000233650208, 'test/loss': 2.232085704803467, 'test/num_examples': 10000, 'score': 22309.111480474472, 'total_duration': 24134.307889938354, 'accumulated_submission_time': 22309.111480474472, 'accumulated_eval_time': 1820.4694256782532, 'accumulated_logging_time': 2.0777573585510254, 'global_step': 50816, 'preemption_count': 0}), (51769, {'train/accuracy': 0.6981835961341858, 'train/loss': 1.232142686843872, 'validation/accuracy': 0.6326000094413757, 'validation/loss': 1.5290515422821045, 'validation/num_examples': 50000, 'test/accuracy': 0.5062000155448914, 'test/loss': 2.203350782394409, 'test/num_examples': 10000, 'score': 22729.33373618126, 'total_duration': 24589.960483789444, 'accumulated_submission_time': 22729.33373618126, 'accumulated_eval_time': 1855.8110496997833, 'accumulated_logging_time': 2.117459535598755, 'global_step': 51769, 'preemption_count': 0}), (52722, {'train/accuracy': 0.6948632597923279, 'train/loss': 1.2600173950195312, 'validation/accuracy': 0.6378200054168701, 'validation/loss': 1.5118967294692993, 'validation/num_examples': 50000, 'test/accuracy': 0.5085000395774841, 'test/loss': 2.1973907947540283, 'test/num_examples': 10000, 'score': 23149.325989961624, 'total_duration': 25061.351286172867, 'accumulated_submission_time': 23149.325989961624, 'accumulated_eval_time': 1907.1239984035492, 'accumulated_logging_time': 2.1540443897247314, 'global_step': 52722, 'preemption_count': 0}), (53679, {'train/accuracy': 0.70277339220047, 'train/loss': 1.1971427202224731, 'validation/accuracy': 0.6426599621772766, 'validation/loss': 1.477855920791626, 'validation/num_examples': 50000, 'test/accuracy': 0.5153000354766846, 'test/loss': 2.1577723026275635, 'test/num_examples': 10000, 'score': 23569.422335863113, 'total_duration': 25514.248254537582, 'accumulated_submission_time': 23569.422335863113, 'accumulated_eval_time': 1939.8412914276123, 'accumulated_logging_time': 2.187542200088501, 'global_step': 53679, 'preemption_count': 0}), (54630, {'train/accuracy': 0.7091405987739563, 'train/loss': 1.1641696691513062, 'validation/accuracy': 0.6421799659729004, 'validation/loss': 1.470869541168213, 'validation/num_examples': 50000, 'test/accuracy': 0.5128999948501587, 'test/loss': 2.161769151687622, 'test/num_examples': 10000, 'score': 23989.525492668152, 'total_duration': 25968.735725164413, 'accumulated_submission_time': 23989.525492668152, 'accumulated_eval_time': 1974.1406950950623, 'accumulated_logging_time': 2.2235701084136963, 'global_step': 54630, 'preemption_count': 0}), (55583, {'train/accuracy': 0.72181636095047, 'train/loss': 1.1253297328948975, 'validation/accuracy': 0.6502199769020081, 'validation/loss': 1.4542932510375977, 'validation/num_examples': 50000, 'test/accuracy': 0.5207000374794006, 'test/loss': 2.1293928623199463, 'test/num_examples': 10000, 'score': 24409.56231069565, 'total_duration': 26433.254653453827, 'accumulated_submission_time': 24409.56231069565, 'accumulated_eval_time': 2018.5392236709595, 'accumulated_logging_time': 2.2584595680236816, 'global_step': 55583, 'preemption_count': 0}), (56541, {'train/accuracy': 0.7114452719688416, 'train/loss': 1.1574795246124268, 'validation/accuracy': 0.6506999731063843, 'validation/loss': 1.4476364850997925, 'validation/num_examples': 50000, 'test/accuracy': 0.5216000080108643, 'test/loss': 2.1287922859191895, 'test/num_examples': 10000, 'score': 24829.98928809166, 'total_duration': 26890.562438964844, 'accumulated_submission_time': 24829.98928809166, 'accumulated_eval_time': 2055.3405468463898, 'accumulated_logging_time': 2.2891829013824463, 'global_step': 56541, 'preemption_count': 0}), (57500, {'train/accuracy': 0.7221288681030273, 'train/loss': 1.1055638790130615, 'validation/accuracy': 0.6574400067329407, 'validation/loss': 1.402391791343689, 'validation/num_examples': 50000, 'test/accuracy': 0.5339000225067139, 'test/loss': 2.0681939125061035, 'test/num_examples': 10000, 'score': 25250.077412605286, 'total_duration': 27344.242587804794, 'accumulated_submission_time': 25250.077412605286, 'accumulated_eval_time': 2088.8553755283356, 'accumulated_logging_time': 2.3174197673797607, 'global_step': 57500, 'preemption_count': 0}), (58454, {'train/accuracy': 0.7285351157188416, 'train/loss': 1.0815355777740479, 'validation/accuracy': 0.6565399765968323, 'validation/loss': 1.405508041381836, 'validation/num_examples': 50000, 'test/accuracy': 0.5283000469207764, 'test/loss': 2.0920517444610596, 'test/num_examples': 10000, 'score': 25670.230689525604, 'total_duration': 27798.60959649086, 'accumulated_submission_time': 25670.230689525604, 'accumulated_eval_time': 2122.9842004776, 'accumulated_logging_time': 2.3531556129455566, 'global_step': 58454, 'preemption_count': 0}), (59402, {'train/accuracy': 0.7279687523841858, 'train/loss': 1.1011300086975098, 'validation/accuracy': 0.6636599898338318, 'validation/loss': 1.3928900957107544, 'validation/num_examples': 50000, 'test/accuracy': 0.5357000231742859, 'test/loss': 2.075573205947876, 'test/num_examples': 10000, 'score': 26090.332412958145, 'total_duration': 28255.53872179985, 'accumulated_submission_time': 26090.332412958145, 'accumulated_eval_time': 2159.7212035655975, 'accumulated_logging_time': 2.39406418800354, 'global_step': 59402, 'preemption_count': 0}), (60358, {'train/accuracy': 0.7314453125, 'train/loss': 1.0799096822738647, 'validation/accuracy': 0.6635199785232544, 'validation/loss': 1.3858510255813599, 'validation/num_examples': 50000, 'test/accuracy': 0.5383000373840332, 'test/loss': 2.071120262145996, 'test/num_examples': 10000, 'score': 26510.644585371017, 'total_duration': 28715.022350788116, 'accumulated_submission_time': 26510.644585371017, 'accumulated_eval_time': 2198.7996776103973, 'accumulated_logging_time': 2.4381754398345947, 'global_step': 60358, 'preemption_count': 0}), (61314, {'train/accuracy': 0.7382616996765137, 'train/loss': 1.0544168949127197, 'validation/accuracy': 0.6686800122261047, 'validation/loss': 1.3709102869033813, 'validation/num_examples': 50000, 'test/accuracy': 0.5408000349998474, 'test/loss': 2.0456087589263916, 'test/num_examples': 10000, 'score': 26930.717651605606, 'total_duration': 29176.056070804596, 'accumulated_submission_time': 26930.717651605606, 'accumulated_eval_time': 2239.6720128059387, 'accumulated_logging_time': 2.4774415493011475, 'global_step': 61314, 'preemption_count': 0}), (62270, {'train/accuracy': 0.7459570169448853, 'train/loss': 1.0130585432052612, 'validation/accuracy': 0.6721400022506714, 'validation/loss': 1.3495044708251953, 'validation/num_examples': 50000, 'test/accuracy': 0.5412000417709351, 'test/loss': 2.0216023921966553, 'test/num_examples': 10000, 'score': 27350.71274805069, 'total_duration': 29634.174962759018, 'accumulated_submission_time': 27350.71274805069, 'accumulated_eval_time': 2277.7150735855103, 'accumulated_logging_time': 2.5092341899871826, 'global_step': 62270, 'preemption_count': 0}), (63224, {'train/accuracy': 0.734667956829071, 'train/loss': 1.0518362522125244, 'validation/accuracy': 0.6714800000190735, 'validation/loss': 1.3484188318252563, 'validation/num_examples': 50000, 'test/accuracy': 0.5412999987602234, 'test/loss': 2.035330295562744, 'test/num_examples': 10000, 'score': 27770.708323955536, 'total_duration': 30086.828785657883, 'accumulated_submission_time': 27770.708323955536, 'accumulated_eval_time': 2310.290809392929, 'accumulated_logging_time': 2.54256534576416, 'global_step': 63224, 'preemption_count': 0}), (64177, {'train/accuracy': 0.7443554401397705, 'train/loss': 1.0113919973373413, 'validation/accuracy': 0.675879955291748, 'validation/loss': 1.3233118057250977, 'validation/num_examples': 50000, 'test/accuracy': 0.5424000024795532, 'test/loss': 1.9937825202941895, 'test/num_examples': 10000, 'score': 28190.968728780746, 'total_duration': 30545.023442029953, 'accumulated_submission_time': 28190.968728780746, 'accumulated_eval_time': 2348.144644498825, 'accumulated_logging_time': 2.5741465091705322, 'global_step': 64177, 'preemption_count': 0}), (65134, {'train/accuracy': 0.7463085651397705, 'train/loss': 1.0072282552719116, 'validation/accuracy': 0.6761400103569031, 'validation/loss': 1.3315125703811646, 'validation/num_examples': 50000, 'test/accuracy': 0.5491000413894653, 'test/loss': 2.013658285140991, 'test/num_examples': 10000, 'score': 28611.084764242172, 'total_duration': 31001.657252073288, 'accumulated_submission_time': 28611.084764242172, 'accumulated_eval_time': 2384.58016872406, 'accumulated_logging_time': 2.606630325317383, 'global_step': 65134, 'preemption_count': 0}), (66086, {'train/accuracy': 0.7609570026397705, 'train/loss': 0.9604236483573914, 'validation/accuracy': 0.6792399883270264, 'validation/loss': 1.3203444480895996, 'validation/num_examples': 50000, 'test/accuracy': 0.5486000180244446, 'test/loss': 2.0006017684936523, 'test/num_examples': 10000, 'score': 29031.25010251999, 'total_duration': 31456.091632843018, 'accumulated_submission_time': 29031.25010251999, 'accumulated_eval_time': 2418.765745639801, 'accumulated_logging_time': 2.6409361362457275, 'global_step': 66086, 'preemption_count': 0}), (67038, {'train/accuracy': 0.754101574420929, 'train/loss': 0.9889141917228699, 'validation/accuracy': 0.6852200031280518, 'validation/loss': 1.2971361875534058, 'validation/num_examples': 50000, 'test/accuracy': 0.5558000206947327, 'test/loss': 1.9769766330718994, 'test/num_examples': 10000, 'score': 29451.256382465363, 'total_duration': 31916.307639837265, 'accumulated_submission_time': 29451.256382465363, 'accumulated_eval_time': 2458.888530254364, 'accumulated_logging_time': 2.6780052185058594, 'global_step': 67038, 'preemption_count': 0}), (67993, {'train/accuracy': 0.7536523342132568, 'train/loss': 0.9675090312957764, 'validation/accuracy': 0.6839599609375, 'validation/loss': 1.2840176820755005, 'validation/num_examples': 50000, 'test/accuracy': 0.5560000538825989, 'test/loss': 1.9566236734390259, 'test/num_examples': 10000, 'score': 29871.203752994537, 'total_duration': 32372.67304301262, 'accumulated_submission_time': 29871.203752994537, 'accumulated_eval_time': 2495.221568584442, 'accumulated_logging_time': 2.713636875152588, 'global_step': 67993, 'preemption_count': 0}), (68950, {'train/accuracy': 0.7650195360183716, 'train/loss': 0.9357429146766663, 'validation/accuracy': 0.6906399726867676, 'validation/loss': 1.2731653451919556, 'validation/num_examples': 50000, 'test/accuracy': 0.5631000399589539, 'test/loss': 1.9448235034942627, 'test/num_examples': 10000, 'score': 30291.581280708313, 'total_duration': 32830.42801618576, 'accumulated_submission_time': 30291.581280708313, 'accumulated_eval_time': 2532.51881480217, 'accumulated_logging_time': 2.7444560527801514, 'global_step': 68950, 'preemption_count': 0}), (69906, {'train/accuracy': 0.7634375095367432, 'train/loss': 0.9249235987663269, 'validation/accuracy': 0.6910200119018555, 'validation/loss': 1.255893349647522, 'validation/num_examples': 50000, 'test/accuracy': 0.5622000098228455, 'test/loss': 1.9211840629577637, 'test/num_examples': 10000, 'score': 30711.692078113556, 'total_duration': 33286.7546775341, 'accumulated_submission_time': 30711.692078113556, 'accumulated_eval_time': 2568.6538326740265, 'accumulated_logging_time': 2.7768213748931885, 'global_step': 69906, 'preemption_count': 0}), (70860, {'train/accuracy': 0.7605859041213989, 'train/loss': 0.9275447726249695, 'validation/accuracy': 0.6900399923324585, 'validation/loss': 1.2489606142044067, 'validation/num_examples': 50000, 'test/accuracy': 0.5592000484466553, 'test/loss': 1.929077386856079, 'test/num_examples': 10000, 'score': 31131.98057603836, 'total_duration': 33742.599757909775, 'accumulated_submission_time': 31131.98057603836, 'accumulated_eval_time': 2604.1148250102997, 'accumulated_logging_time': 2.8237569332122803, 'global_step': 70860, 'preemption_count': 0}), (71814, {'train/accuracy': 0.7680273056030273, 'train/loss': 0.9155058264732361, 'validation/accuracy': 0.6950799822807312, 'validation/loss': 1.2489674091339111, 'validation/num_examples': 50000, 'test/accuracy': 0.563800036907196, 'test/loss': 1.9288992881774902, 'test/num_examples': 10000, 'score': 31552.173714637756, 'total_duration': 34200.98422002792, 'accumulated_submission_time': 31552.173714637756, 'accumulated_eval_time': 2642.210392475128, 'accumulated_logging_time': 2.870387315750122, 'global_step': 71814, 'preemption_count': 0}), (72769, {'train/accuracy': 0.7766796946525574, 'train/loss': 0.8705880045890808, 'validation/accuracy': 0.6983000040054321, 'validation/loss': 1.2320274114608765, 'validation/num_examples': 50000, 'test/accuracy': 0.5623000264167786, 'test/loss': 1.9119281768798828, 'test/num_examples': 10000, 'score': 31972.198963165283, 'total_duration': 34656.71481728554, 'accumulated_submission_time': 31972.198963165283, 'accumulated_eval_time': 2677.8308210372925, 'accumulated_logging_time': 2.9055275917053223, 'global_step': 72769, 'preemption_count': 0}), (73722, {'train/accuracy': 0.7681054472923279, 'train/loss': 0.910663366317749, 'validation/accuracy': 0.6999599933624268, 'validation/loss': 1.216040015220642, 'validation/num_examples': 50000, 'test/accuracy': 0.5683000087738037, 'test/loss': 1.8952546119689941, 'test/num_examples': 10000, 'score': 32392.19476556778, 'total_duration': 35112.06246328354, 'accumulated_submission_time': 32392.19476556778, 'accumulated_eval_time': 2713.08797287941, 'accumulated_logging_time': 2.951908588409424, 'global_step': 73722, 'preemption_count': 0}), (74675, {'train/accuracy': 0.7721874713897705, 'train/loss': 0.8845731019973755, 'validation/accuracy': 0.6978200078010559, 'validation/loss': 1.2194421291351318, 'validation/num_examples': 50000, 'test/accuracy': 0.5712000131607056, 'test/loss': 1.881524920463562, 'test/num_examples': 10000, 'score': 32812.25599312782, 'total_duration': 35571.33825588226, 'accumulated_submission_time': 32812.25599312782, 'accumulated_eval_time': 2752.2095618247986, 'accumulated_logging_time': 2.9954280853271484, 'global_step': 74675, 'preemption_count': 0}), (75632, {'train/accuracy': 0.774707019329071, 'train/loss': 0.8985239863395691, 'validation/accuracy': 0.7001999616622925, 'validation/loss': 1.2316291332244873, 'validation/num_examples': 50000, 'test/accuracy': 0.5731000304222107, 'test/loss': 1.8957104682922363, 'test/num_examples': 10000, 'score': 33232.49916625023, 'total_duration': 36025.13847947121, 'accumulated_submission_time': 33232.49916625023, 'accumulated_eval_time': 2785.6837685108185, 'accumulated_logging_time': 3.029832601547241, 'global_step': 75632, 'preemption_count': 0}), (76588, {'train/accuracy': 0.7801171541213989, 'train/loss': 0.83815598487854, 'validation/accuracy': 0.7055400013923645, 'validation/loss': 1.188283920288086, 'validation/num_examples': 50000, 'test/accuracy': 0.578000009059906, 'test/loss': 1.8477613925933838, 'test/num_examples': 10000, 'score': 33652.50452065468, 'total_duration': 36479.760321855545, 'accumulated_submission_time': 33652.50452065468, 'accumulated_eval_time': 2820.195548772812, 'accumulated_logging_time': 3.084975004196167, 'global_step': 76588, 'preemption_count': 0}), (77540, {'train/accuracy': 0.7811328172683716, 'train/loss': 0.8406301736831665, 'validation/accuracy': 0.7036399841308594, 'validation/loss': 1.1923822164535522, 'validation/num_examples': 50000, 'test/accuracy': 0.5746999979019165, 'test/loss': 1.8451563119888306, 'test/num_examples': 10000, 'score': 34072.47146344185, 'total_duration': 36939.40902590752, 'accumulated_submission_time': 34072.47146344185, 'accumulated_eval_time': 2859.7913534641266, 'accumulated_logging_time': 3.1218364238739014, 'global_step': 77540, 'preemption_count': 0}), (78493, {'train/accuracy': 0.7834570407867432, 'train/loss': 0.8356504440307617, 'validation/accuracy': 0.7069599628448486, 'validation/loss': 1.18317449092865, 'validation/num_examples': 50000, 'test/accuracy': 0.5753000378608704, 'test/loss': 1.847076416015625, 'test/num_examples': 10000, 'score': 34492.69671034813, 'total_duration': 37401.889246463776, 'accumulated_submission_time': 34492.69671034813, 'accumulated_eval_time': 2901.95707654953, 'accumulated_logging_time': 3.1622819900512695, 'global_step': 78493, 'preemption_count': 0}), (79450, {'train/accuracy': 0.7914257645606995, 'train/loss': 0.8288572430610657, 'validation/accuracy': 0.709559977054596, 'validation/loss': 1.1907429695129395, 'validation/num_examples': 50000, 'test/accuracy': 0.5766000151634216, 'test/loss': 1.8492708206176758, 'test/num_examples': 10000, 'score': 34912.819937705994, 'total_duration': 37855.720873594284, 'accumulated_submission_time': 34912.819937705994, 'accumulated_eval_time': 2935.5560653209686, 'accumulated_logging_time': 3.2225122451782227, 'global_step': 79450, 'preemption_count': 0}), (80403, {'train/accuracy': 0.7861523032188416, 'train/loss': 0.8298468589782715, 'validation/accuracy': 0.7110199928283691, 'validation/loss': 1.1689532995224, 'validation/num_examples': 50000, 'test/accuracy': 0.5800999999046326, 'test/loss': 1.8308848142623901, 'test/num_examples': 10000, 'score': 35333.09168720245, 'total_duration': 38313.8909406662, 'accumulated_submission_time': 35333.09168720245, 'accumulated_eval_time': 2973.366780757904, 'accumulated_logging_time': 3.261307954788208, 'global_step': 80403, 'preemption_count': 0}), (81360, {'train/accuracy': 0.7941992282867432, 'train/loss': 0.796230137348175, 'validation/accuracy': 0.7138999700546265, 'validation/loss': 1.156989574432373, 'validation/num_examples': 50000, 'test/accuracy': 0.5859000086784363, 'test/loss': 1.8184973001480103, 'test/num_examples': 10000, 'score': 35753.37743425369, 'total_duration': 38770.41054081917, 'accumulated_submission_time': 35753.37743425369, 'accumulated_eval_time': 3009.5190649032593, 'accumulated_logging_time': 3.293361186981201, 'global_step': 81360, 'preemption_count': 0}), (82315, {'train/accuracy': 0.7957226634025574, 'train/loss': 0.7792394161224365, 'validation/accuracy': 0.7140600085258484, 'validation/loss': 1.1447581052780151, 'validation/num_examples': 50000, 'test/accuracy': 0.58160001039505, 'test/loss': 1.8061102628707886, 'test/num_examples': 10000, 'score': 36173.37316656113, 'total_duration': 39227.530015707016, 'accumulated_submission_time': 36173.37316656113, 'accumulated_eval_time': 3046.5501339435577, 'accumulated_logging_time': 3.3365039825439453, 'global_step': 82315, 'preemption_count': 0}), (83271, {'train/accuracy': 0.8056054711341858, 'train/loss': 0.7583882212638855, 'validation/accuracy': 0.7160199880599976, 'validation/loss': 1.150341272354126, 'validation/num_examples': 50000, 'test/accuracy': 0.5869000554084778, 'test/loss': 1.7996519804000854, 'test/num_examples': 10000, 'score': 36593.338634729385, 'total_duration': 39681.297360658646, 'accumulated_submission_time': 36593.338634729385, 'accumulated_eval_time': 3080.266455888748, 'accumulated_logging_time': 3.372302532196045, 'global_step': 83271, 'preemption_count': 0}), (84224, {'train/accuracy': 0.79554682970047, 'train/loss': 0.7888644933700562, 'validation/accuracy': 0.716159999370575, 'validation/loss': 1.1426273584365845, 'validation/num_examples': 50000, 'test/accuracy': 0.5919000506401062, 'test/loss': 1.7864233255386353, 'test/num_examples': 10000, 'score': 37013.359367609024, 'total_duration': 40135.92939543724, 'accumulated_submission_time': 37013.359367609024, 'accumulated_eval_time': 3114.775664329529, 'accumulated_logging_time': 3.425116539001465, 'global_step': 84224, 'preemption_count': 0}), (85177, {'train/accuracy': 0.7994726300239563, 'train/loss': 0.7706484794616699, 'validation/accuracy': 0.7192999720573425, 'validation/loss': 1.1310958862304688, 'validation/num_examples': 50000, 'test/accuracy': 0.589900016784668, 'test/loss': 1.7978416681289673, 'test/num_examples': 10000, 'score': 37433.54198694229, 'total_duration': 40605.49332666397, 'accumulated_submission_time': 37433.54198694229, 'accumulated_eval_time': 3164.0677342414856, 'accumulated_logging_time': 3.4646859169006348, 'global_step': 85177, 'preemption_count': 0}), (86133, {'train/accuracy': 0.8046875, 'train/loss': 0.7627406120300293, 'validation/accuracy': 0.7196800112724304, 'validation/loss': 1.136682391166687, 'validation/num_examples': 50000, 'test/accuracy': 0.5866000056266785, 'test/loss': 1.7942957878112793, 'test/num_examples': 10000, 'score': 37853.546439647675, 'total_duration': 41061.43424797058, 'accumulated_submission_time': 37853.546439647675, 'accumulated_eval_time': 3199.920131921768, 'accumulated_logging_time': 3.4973526000976562, 'global_step': 86133, 'preemption_count': 0}), (87091, {'train/accuracy': 0.8030663728713989, 'train/loss': 0.7647061944007874, 'validation/accuracy': 0.7223799824714661, 'validation/loss': 1.1233367919921875, 'validation/num_examples': 50000, 'test/accuracy': 0.589400053024292, 'test/loss': 1.7823338508605957, 'test/num_examples': 10000, 'score': 38273.58218240738, 'total_duration': 41515.371849775314, 'accumulated_submission_time': 38273.58218240738, 'accumulated_eval_time': 3233.733690261841, 'accumulated_logging_time': 3.536593437194824, 'global_step': 87091, 'preemption_count': 0}), (88044, {'train/accuracy': 0.8049218654632568, 'train/loss': 0.75309157371521, 'validation/accuracy': 0.7244399785995483, 'validation/loss': 1.1125150918960571, 'validation/num_examples': 50000, 'test/accuracy': 0.5962000489234924, 'test/loss': 1.762255311012268, 'test/num_examples': 10000, 'score': 38693.926919698715, 'total_duration': 41972.508944272995, 'accumulated_submission_time': 38693.926919698715, 'accumulated_eval_time': 3270.441417694092, 'accumulated_logging_time': 3.5724127292633057, 'global_step': 88044, 'preemption_count': 0}), (88999, {'train/accuracy': 0.8087109327316284, 'train/loss': 0.7536008954048157, 'validation/accuracy': 0.7234599590301514, 'validation/loss': 1.1227951049804688, 'validation/num_examples': 50000, 'test/accuracy': 0.5915000438690186, 'test/loss': 1.7753443717956543, 'test/num_examples': 10000, 'score': 39114.10504937172, 'total_duration': 42433.25032758713, 'accumulated_submission_time': 39114.10504937172, 'accumulated_eval_time': 3310.922417640686, 'accumulated_logging_time': 3.605489492416382, 'global_step': 88999, 'preemption_count': 0}), (89953, {'train/accuracy': 0.8142773509025574, 'train/loss': 0.7051602005958557, 'validation/accuracy': 0.7251999974250793, 'validation/loss': 1.1013540029525757, 'validation/num_examples': 50000, 'test/accuracy': 0.5942000150680542, 'test/loss': 1.7679145336151123, 'test/num_examples': 10000, 'score': 39534.26315021515, 'total_duration': 42887.363741636276, 'accumulated_submission_time': 39534.26315021515, 'accumulated_eval_time': 3344.784425020218, 'accumulated_logging_time': 3.6490068435668945, 'global_step': 89953, 'preemption_count': 0}), (90904, {'train/accuracy': 0.8132421970367432, 'train/loss': 0.7265541553497314, 'validation/accuracy': 0.7272399663925171, 'validation/loss': 1.094468593597412, 'validation/num_examples': 50000, 'test/accuracy': 0.6000000238418579, 'test/loss': 1.7423524856567383, 'test/num_examples': 10000, 'score': 39954.48708152771, 'total_duration': 43347.0038394928, 'accumulated_submission_time': 39954.48708152771, 'accumulated_eval_time': 3384.112462282181, 'accumulated_logging_time': 3.688556671142578, 'global_step': 90904, 'preemption_count': 0}), (91861, {'train/accuracy': 0.8134374618530273, 'train/loss': 0.7182683348655701, 'validation/accuracy': 0.7279999852180481, 'validation/loss': 1.0831648111343384, 'validation/num_examples': 50000, 'test/accuracy': 0.597000002861023, 'test/loss': 1.7358157634735107, 'test/num_examples': 10000, 'score': 40374.66855120659, 'total_duration': 43803.92558503151, 'accumulated_submission_time': 40374.66855120659, 'accumulated_eval_time': 3420.7711465358734, 'accumulated_logging_time': 3.7210538387298584, 'global_step': 91861, 'preemption_count': 0}), (92817, {'train/accuracy': 0.8158593773841858, 'train/loss': 0.7073391675949097, 'validation/accuracy': 0.7292199730873108, 'validation/loss': 1.0921497344970703, 'validation/num_examples': 50000, 'test/accuracy': 0.5982000231742859, 'test/loss': 1.736130952835083, 'test/num_examples': 10000, 'score': 40794.82723855972, 'total_duration': 44262.02894735336, 'accumulated_submission_time': 40794.82723855972, 'accumulated_eval_time': 3458.633937358856, 'accumulated_logging_time': 3.7532637119293213, 'global_step': 92817, 'preemption_count': 0}), (93773, {'train/accuracy': 0.8169726133346558, 'train/loss': 0.7112701535224915, 'validation/accuracy': 0.7305999994277954, 'validation/loss': 1.0926241874694824, 'validation/num_examples': 50000, 'test/accuracy': 0.6011000275611877, 'test/loss': 1.745832920074463, 'test/num_examples': 10000, 'score': 41214.750838279724, 'total_duration': 44718.862205028534, 'accumulated_submission_time': 41214.750838279724, 'accumulated_eval_time': 3495.4579453468323, 'accumulated_logging_time': 3.7890377044677734, 'global_step': 93773, 'preemption_count': 0}), (94726, {'train/accuracy': 0.8153710961341858, 'train/loss': 0.7110303044319153, 'validation/accuracy': 0.7318999767303467, 'validation/loss': 1.0777409076690674, 'validation/num_examples': 50000, 'test/accuracy': 0.6021000146865845, 'test/loss': 1.7228293418884277, 'test/num_examples': 10000, 'score': 41634.846336603165, 'total_duration': 45175.29908680916, 'accumulated_submission_time': 41634.846336603165, 'accumulated_eval_time': 3531.705990552902, 'accumulated_logging_time': 3.833230972290039, 'global_step': 94726, 'preemption_count': 0}), (95680, {'train/accuracy': 0.8202343583106995, 'train/loss': 0.6909275054931641, 'validation/accuracy': 0.7317599654197693, 'validation/loss': 1.0739268064498901, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.729892611503601, 'test/num_examples': 10000, 'score': 42054.991592645645, 'total_duration': 45633.40091395378, 'accumulated_submission_time': 42054.991592645645, 'accumulated_eval_time': 3569.577343225479, 'accumulated_logging_time': 3.8686208724975586, 'global_step': 95680, 'preemption_count': 0}), (96636, {'train/accuracy': 0.8260937333106995, 'train/loss': 0.6657110452651978, 'validation/accuracy': 0.7340799570083618, 'validation/loss': 1.0653157234191895, 'validation/num_examples': 50000, 'test/accuracy': 0.6053000092506409, 'test/loss': 1.71260404586792, 'test/num_examples': 10000, 'score': 42475.061789512634, 'total_duration': 46087.49285745621, 'accumulated_submission_time': 42475.061789512634, 'accumulated_eval_time': 3603.5093677043915, 'accumulated_logging_time': 3.909106731414795, 'global_step': 96636, 'preemption_count': 0}), (97589, {'train/accuracy': 0.8200585842132568, 'train/loss': 0.6868795156478882, 'validation/accuracy': 0.7324999570846558, 'validation/loss': 1.0643037557601929, 'validation/num_examples': 50000, 'test/accuracy': 0.6046000123023987, 'test/loss': 1.7156270742416382, 'test/num_examples': 10000, 'score': 42895.38532233238, 'total_duration': 46548.00999832153, 'accumulated_submission_time': 42895.38532233238, 'accumulated_eval_time': 3643.6160628795624, 'accumulated_logging_time': 3.947016477584839, 'global_step': 97589, 'preemption_count': 0}), (98543, {'train/accuracy': 0.8204101324081421, 'train/loss': 0.6935621500015259, 'validation/accuracy': 0.73499995470047, 'validation/loss': 1.0708833932876587, 'validation/num_examples': 50000, 'test/accuracy': 0.6127000451087952, 'test/loss': 1.7051517963409424, 'test/num_examples': 10000, 'score': 43315.73797702789, 'total_duration': 47009.2480134964, 'accumulated_submission_time': 43315.73797702789, 'accumulated_eval_time': 3684.4163761138916, 'accumulated_logging_time': 3.9828202724456787, 'global_step': 98543, 'preemption_count': 0}), (99500, {'train/accuracy': 0.8253710865974426, 'train/loss': 0.6545591354370117, 'validation/accuracy': 0.738379955291748, 'validation/loss': 1.0376094579696655, 'validation/num_examples': 50000, 'test/accuracy': 0.6126000285148621, 'test/loss': 1.693750262260437, 'test/num_examples': 10000, 'score': 43736.02278661728, 'total_duration': 47463.83640551567, 'accumulated_submission_time': 43736.02278661728, 'accumulated_eval_time': 3718.6353046894073, 'accumulated_logging_time': 4.018874168395996, 'global_step': 99500, 'preemption_count': 0}), (100453, {'train/accuracy': 0.8338866829872131, 'train/loss': 0.6379420161247253, 'validation/accuracy': 0.738860011100769, 'validation/loss': 1.0469478368759155, 'validation/num_examples': 50000, 'test/accuracy': 0.6131000518798828, 'test/loss': 1.6931209564208984, 'test/num_examples': 10000, 'score': 44156.01625561714, 'total_duration': 47923.90005874634, 'accumulated_submission_time': 44156.01625561714, 'accumulated_eval_time': 3758.6141781806946, 'accumulated_logging_time': 4.060467004776001, 'global_step': 100453, 'preemption_count': 0}), (101411, {'train/accuracy': 0.8299999833106995, 'train/loss': 0.6550570726394653, 'validation/accuracy': 0.7392399907112122, 'validation/loss': 1.0426398515701294, 'validation/num_examples': 50000, 'test/accuracy': 0.6136000156402588, 'test/loss': 1.6880282163619995, 'test/num_examples': 10000, 'score': 44576.21703314781, 'total_duration': 48379.08273267746, 'accumulated_submission_time': 44576.21703314781, 'accumulated_eval_time': 3793.5126116275787, 'accumulated_logging_time': 4.094937324523926, 'global_step': 101411, 'preemption_count': 0}), (102368, {'train/accuracy': 0.830859363079071, 'train/loss': 0.6350476145744324, 'validation/accuracy': 0.7415199875831604, 'validation/loss': 1.0304890871047974, 'validation/num_examples': 50000, 'test/accuracy': 0.6151000261306763, 'test/loss': 1.665448546409607, 'test/num_examples': 10000, 'score': 44996.19522190094, 'total_duration': 48834.636696100235, 'accumulated_submission_time': 44996.19522190094, 'accumulated_eval_time': 3828.9989156723022, 'accumulated_logging_time': 4.135974168777466, 'global_step': 102368, 'preemption_count': 0}), (103323, {'train/accuracy': 0.8330858945846558, 'train/loss': 0.6300832033157349, 'validation/accuracy': 0.7407199740409851, 'validation/loss': 1.0317474603652954, 'validation/num_examples': 50000, 'test/accuracy': 0.6196000576019287, 'test/loss': 1.660083293914795, 'test/num_examples': 10000, 'score': 45416.143211364746, 'total_duration': 49294.09208750725, 'accumulated_submission_time': 45416.143211364746, 'accumulated_eval_time': 3868.4166038036346, 'accumulated_logging_time': 4.176782608032227, 'global_step': 103323, 'preemption_count': 0}), (104279, {'train/accuracy': 0.8360155820846558, 'train/loss': 0.6268386840820312, 'validation/accuracy': 0.74263995885849, 'validation/loss': 1.0254026651382446, 'validation/num_examples': 50000, 'test/accuracy': 0.6196000576019287, 'test/loss': 1.662506103515625, 'test/num_examples': 10000, 'score': 45836.07455945015, 'total_duration': 49747.9315226078, 'accumulated_submission_time': 45836.07455945015, 'accumulated_eval_time': 3902.240537881851, 'accumulated_logging_time': 4.212025880813599, 'global_step': 104279, 'preemption_count': 0}), (105231, {'train/accuracy': 0.8339452743530273, 'train/loss': 0.6383870244026184, 'validation/accuracy': 0.7439999580383301, 'validation/loss': 1.0282624959945679, 'validation/num_examples': 50000, 'test/accuracy': 0.6152000427246094, 'test/loss': 1.6659941673278809, 'test/num_examples': 10000, 'score': 46255.99170088768, 'total_duration': 50206.38493061066, 'accumulated_submission_time': 46255.99170088768, 'accumulated_eval_time': 3940.6857392787933, 'accumulated_logging_time': 4.254321336746216, 'global_step': 105231, 'preemption_count': 0}), (106188, {'train/accuracy': 0.8370898365974426, 'train/loss': 0.6287381052970886, 'validation/accuracy': 0.7427799701690674, 'validation/loss': 1.0315252542495728, 'validation/num_examples': 50000, 'test/accuracy': 0.615600049495697, 'test/loss': 1.6683176755905151, 'test/num_examples': 10000, 'score': 46675.97735834122, 'total_duration': 50659.869463443756, 'accumulated_submission_time': 46675.97735834122, 'accumulated_eval_time': 3974.10001039505, 'accumulated_logging_time': 4.2895667552948, 'global_step': 106188, 'preemption_count': 0}), (107141, {'train/accuracy': 0.8447070121765137, 'train/loss': 0.5922766327857971, 'validation/accuracy': 0.7450599670410156, 'validation/loss': 1.0159118175506592, 'validation/num_examples': 50000, 'test/accuracy': 0.6181000471115112, 'test/loss': 1.6559442281723022, 'test/num_examples': 10000, 'score': 47096.05894970894, 'total_duration': 51121.369712114334, 'accumulated_submission_time': 47096.05894970894, 'accumulated_eval_time': 4015.430284500122, 'accumulated_logging_time': 4.329180955886841, 'global_step': 107141, 'preemption_count': 0}), (108092, {'train/accuracy': 0.8363671898841858, 'train/loss': 0.6227496862411499, 'validation/accuracy': 0.74617999792099, 'validation/loss': 1.0163707733154297, 'validation/num_examples': 50000, 'test/accuracy': 0.6180000305175781, 'test/loss': 1.650549292564392, 'test/num_examples': 10000, 'score': 47516.14053821564, 'total_duration': 51581.18294215202, 'accumulated_submission_time': 47516.14053821564, 'accumulated_eval_time': 4055.074747800827, 'accumulated_logging_time': 4.367753982543945, 'global_step': 108092, 'preemption_count': 0}), (109045, {'train/accuracy': 0.8378320336341858, 'train/loss': 0.6192162036895752, 'validation/accuracy': 0.7454800009727478, 'validation/loss': 1.0157496929168701, 'validation/num_examples': 50000, 'test/accuracy': 0.619700014591217, 'test/loss': 1.6563630104064941, 'test/num_examples': 10000, 'score': 47936.36020040512, 'total_duration': 52042.38684606552, 'accumulated_submission_time': 47936.36020040512, 'accumulated_eval_time': 4095.97256565094, 'accumulated_logging_time': 4.40497350692749, 'global_step': 109045, 'preemption_count': 0}), (110003, {'train/accuracy': 0.8412694931030273, 'train/loss': 0.6067090630531311, 'validation/accuracy': 0.7469399571418762, 'validation/loss': 1.0047023296356201, 'validation/num_examples': 50000, 'test/accuracy': 0.6170000433921814, 'test/loss': 1.6504782438278198, 'test/num_examples': 10000, 'score': 48356.365557193756, 'total_duration': 52496.501323223114, 'accumulated_submission_time': 48356.365557193756, 'accumulated_eval_time': 4129.997729063034, 'accumulated_logging_time': 4.440007448196411, 'global_step': 110003, 'preemption_count': 0}), (110958, {'train/accuracy': 0.8490819931030273, 'train/loss': 0.5812028646469116, 'validation/accuracy': 0.7455199956893921, 'validation/loss': 1.0081909894943237, 'validation/num_examples': 50000, 'test/accuracy': 0.6190000176429749, 'test/loss': 1.6425085067749023, 'test/num_examples': 10000, 'score': 48776.686744213104, 'total_duration': 52953.426795721054, 'accumulated_submission_time': 48776.686744213104, 'accumulated_eval_time': 4166.511432647705, 'accumulated_logging_time': 4.481417894363403, 'global_step': 110958, 'preemption_count': 0}), (111914, {'train/accuracy': 0.8423241972923279, 'train/loss': 0.5987648367881775, 'validation/accuracy': 0.7480199933052063, 'validation/loss': 0.9991421103477478, 'validation/num_examples': 50000, 'test/accuracy': 0.6178000569343567, 'test/loss': 1.642221212387085, 'test/num_examples': 10000, 'score': 49196.83443522453, 'total_duration': 53410.34250831604, 'accumulated_submission_time': 49196.83443522453, 'accumulated_eval_time': 4203.194106340408, 'accumulated_logging_time': 4.517452716827393, 'global_step': 111914, 'preemption_count': 0}), (112866, {'train/accuracy': 0.84486323595047, 'train/loss': 0.590288519859314, 'validation/accuracy': 0.7480799555778503, 'validation/loss': 1.0019407272338867, 'validation/num_examples': 50000, 'test/accuracy': 0.6195000410079956, 'test/loss': 1.6393332481384277, 'test/num_examples': 10000, 'score': 49616.911490917206, 'total_duration': 53864.761655807495, 'accumulated_submission_time': 49616.911490917206, 'accumulated_eval_time': 4237.439774990082, 'accumulated_logging_time': 4.564082384109497, 'global_step': 112866, 'preemption_count': 0}), (113818, {'train/accuracy': 0.8456445336341858, 'train/loss': 0.5927426815032959, 'validation/accuracy': 0.7485799789428711, 'validation/loss': 1.003954291343689, 'validation/num_examples': 50000, 'test/accuracy': 0.6198000311851501, 'test/loss': 1.6341878175735474, 'test/num_examples': 10000, 'score': 50036.90283083916, 'total_duration': 54327.484815359116, 'accumulated_submission_time': 50036.90283083916, 'accumulated_eval_time': 4280.078495264053, 'accumulated_logging_time': 4.607403755187988, 'global_step': 113818, 'preemption_count': 0}), (114775, {'train/accuracy': 0.8468554615974426, 'train/loss': 0.5843576788902283, 'validation/accuracy': 0.7496199607849121, 'validation/loss': 0.9976999759674072, 'validation/num_examples': 50000, 'test/accuracy': 0.6207000017166138, 'test/loss': 1.6386059522628784, 'test/num_examples': 10000, 'score': 50457.13864898682, 'total_duration': 54782.779359579086, 'accumulated_submission_time': 50457.13864898682, 'accumulated_eval_time': 4315.04980134964, 'accumulated_logging_time': 4.645892381668091, 'global_step': 114775, 'preemption_count': 0}), (115730, {'train/accuracy': 0.8459765315055847, 'train/loss': 0.5903598070144653, 'validation/accuracy': 0.750059962272644, 'validation/loss': 0.9998406171798706, 'validation/num_examples': 50000, 'test/accuracy': 0.6201000213623047, 'test/loss': 1.6393582820892334, 'test/num_examples': 10000, 'score': 50877.113295555115, 'total_duration': 55237.44309091568, 'accumulated_submission_time': 50877.113295555115, 'accumulated_eval_time': 4349.649586200714, 'accumulated_logging_time': 4.686129331588745, 'global_step': 115730, 'preemption_count': 0}), (116683, {'train/accuracy': 0.8506445288658142, 'train/loss': 0.5619098544120789, 'validation/accuracy': 0.749779999256134, 'validation/loss': 0.9848576188087463, 'validation/num_examples': 50000, 'test/accuracy': 0.6219000220298767, 'test/loss': 1.6262645721435547, 'test/num_examples': 10000, 'score': 51297.29220557213, 'total_duration': 55697.39147853851, 'accumulated_submission_time': 51297.29220557213, 'accumulated_eval_time': 4389.330322742462, 'accumulated_logging_time': 4.725714683532715, 'global_step': 116683, 'preemption_count': 0}), (117635, {'train/accuracy': 0.85218745470047, 'train/loss': 0.5644310712814331, 'validation/accuracy': 0.7512800097465515, 'validation/loss': 0.9909461736679077, 'validation/num_examples': 50000, 'test/accuracy': 0.6231000423431396, 'test/loss': 1.6262131929397583, 'test/num_examples': 10000, 'score': 51717.43297958374, 'total_duration': 56153.70263981819, 'accumulated_submission_time': 51717.43297958374, 'accumulated_eval_time': 4425.405205488205, 'accumulated_logging_time': 4.772045850753784, 'global_step': 117635, 'preemption_count': 0}), (118590, {'train/accuracy': 0.8519335985183716, 'train/loss': 0.5597919821739197, 'validation/accuracy': 0.7525599598884583, 'validation/loss': 0.9866520762443542, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.6207976341247559, 'test/num_examples': 10000, 'score': 52137.802012205124, 'total_duration': 56608.75700259209, 'accumulated_submission_time': 52137.802012205124, 'accumulated_eval_time': 4459.998586654663, 'accumulated_logging_time': 4.8138206005096436, 'global_step': 118590, 'preemption_count': 0}), (119544, {'train/accuracy': 0.8473632335662842, 'train/loss': 0.5713116526603699, 'validation/accuracy': 0.7536199688911438, 'validation/loss': 0.9778622984886169, 'validation/num_examples': 50000, 'test/accuracy': 0.6262000203132629, 'test/loss': 1.6168922185897827, 'test/num_examples': 10000, 'score': 52557.78605103493, 'total_duration': 57065.97317624092, 'accumulated_submission_time': 52557.78605103493, 'accumulated_eval_time': 4497.1472289562225, 'accumulated_logging_time': 4.847980976104736, 'global_step': 119544, 'preemption_count': 0}), (120499, {'train/accuracy': 0.8544335961341858, 'train/loss': 0.5522642135620117, 'validation/accuracy': 0.7531799674034119, 'validation/loss': 0.9789881110191345, 'validation/num_examples': 50000, 'test/accuracy': 0.6262000203132629, 'test/loss': 1.6122066974639893, 'test/num_examples': 10000, 'score': 52977.94923663139, 'total_duration': 57522.64027953148, 'accumulated_submission_time': 52977.94923663139, 'accumulated_eval_time': 4533.566967010498, 'accumulated_logging_time': 4.882195711135864, 'global_step': 120499, 'preemption_count': 0}), (121454, {'train/accuracy': 0.8498241901397705, 'train/loss': 0.5694214701652527, 'validation/accuracy': 0.7528199553489685, 'validation/loss': 0.9818065166473389, 'validation/num_examples': 50000, 'test/accuracy': 0.6256000399589539, 'test/loss': 1.615452766418457, 'test/num_examples': 10000, 'score': 53398.238001823425, 'total_duration': 57978.176491975784, 'accumulated_submission_time': 53398.238001823425, 'accumulated_eval_time': 4568.727827787399, 'accumulated_logging_time': 4.91951847076416, 'global_step': 121454, 'preemption_count': 0}), (122407, {'train/accuracy': 0.8509570360183716, 'train/loss': 0.5583187341690063, 'validation/accuracy': 0.7542600035667419, 'validation/loss': 0.9754990339279175, 'validation/num_examples': 50000, 'test/accuracy': 0.6246000528335571, 'test/loss': 1.6070241928100586, 'test/num_examples': 10000, 'score': 53818.574295282364, 'total_duration': 58438.1224565506, 'accumulated_submission_time': 53818.574295282364, 'accumulated_eval_time': 4608.24661231041, 'accumulated_logging_time': 4.96071720123291, 'global_step': 122407, 'preemption_count': 0}), (123362, {'train/accuracy': 0.8512694835662842, 'train/loss': 0.5596078634262085, 'validation/accuracy': 0.7537999749183655, 'validation/loss': 0.9762325286865234, 'validation/num_examples': 50000, 'test/accuracy': 0.625, 'test/loss': 1.6111570596694946, 'test/num_examples': 10000, 'score': 54238.704822063446, 'total_duration': 58894.75551557541, 'accumulated_submission_time': 54238.704822063446, 'accumulated_eval_time': 4644.657539606094, 'accumulated_logging_time': 5.002605438232422, 'global_step': 123362, 'preemption_count': 0}), (124316, {'train/accuracy': 0.8517382740974426, 'train/loss': 0.559052050113678, 'validation/accuracy': 0.7544599771499634, 'validation/loss': 0.9752328395843506, 'validation/num_examples': 50000, 'test/accuracy': 0.6267000436782837, 'test/loss': 1.606034278869629, 'test/num_examples': 10000, 'score': 54659.079010009766, 'total_duration': 59349.08994650841, 'accumulated_submission_time': 54659.079010009766, 'accumulated_eval_time': 4678.526756763458, 'accumulated_logging_time': 5.044040679931641, 'global_step': 124316, 'preemption_count': 0}), (125269, {'train/accuracy': 0.8548241853713989, 'train/loss': 0.5492197871208191, 'validation/accuracy': 0.7552599906921387, 'validation/loss': 0.9727584719657898, 'validation/num_examples': 50000, 'test/accuracy': 0.6283000111579895, 'test/loss': 1.6030774116516113, 'test/num_examples': 10000, 'score': 55079.44510221481, 'total_duration': 59812.55849838257, 'accumulated_submission_time': 55079.44510221481, 'accumulated_eval_time': 4721.533430814743, 'accumulated_logging_time': 5.090787410736084, 'global_step': 125269, 'preemption_count': 0}), (126226, {'train/accuracy': 0.85462886095047, 'train/loss': 0.5483165979385376, 'validation/accuracy': 0.7567200064659119, 'validation/loss': 0.9677868485450745, 'validation/num_examples': 50000, 'test/accuracy': 0.6284000277519226, 'test/loss': 1.5996743440628052, 'test/num_examples': 10000, 'score': 55499.55207681656, 'total_duration': 60271.06962299347, 'accumulated_submission_time': 55499.55207681656, 'accumulated_eval_time': 4759.852556467056, 'accumulated_logging_time': 5.126350402832031, 'global_step': 126226, 'preemption_count': 0}), (127183, {'train/accuracy': 0.85498046875, 'train/loss': 0.5480813384056091, 'validation/accuracy': 0.756659984588623, 'validation/loss': 0.9674642086029053, 'validation/num_examples': 50000, 'test/accuracy': 0.6272000074386597, 'test/loss': 1.5985677242279053, 'test/num_examples': 10000, 'score': 55919.85713505745, 'total_duration': 60727.54383111, 'accumulated_submission_time': 55919.85713505745, 'accumulated_eval_time': 4795.938015937805, 'accumulated_logging_time': 5.16035270690918, 'global_step': 127183, 'preemption_count': 0}), (128138, {'train/accuracy': 0.855273425579071, 'train/loss': 0.5533023476600647, 'validation/accuracy': 0.7561399936676025, 'validation/loss': 0.9704608917236328, 'validation/num_examples': 50000, 'test/accuracy': 0.6276000142097473, 'test/loss': 1.5983819961547852, 'test/num_examples': 10000, 'score': 56340.26157164574, 'total_duration': 61184.4908246994, 'accumulated_submission_time': 56340.26157164574, 'accumulated_eval_time': 4832.387828111649, 'accumulated_logging_time': 5.203810453414917, 'global_step': 128138, 'preemption_count': 0}), (129091, {'train/accuracy': 0.8565039038658142, 'train/loss': 0.5440993905067444, 'validation/accuracy': 0.7568199634552002, 'validation/loss': 0.9676470160484314, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.6001191139221191, 'test/num_examples': 10000, 'score': 56760.22937917709, 'total_duration': 61644.83579325676, 'accumulated_submission_time': 56760.22937917709, 'accumulated_eval_time': 4872.667409658432, 'accumulated_logging_time': 5.245442152023315, 'global_step': 129091, 'preemption_count': 0})], 'global_step': 129091}
I0316 17:08:00.346075 140033285822272 submission_runner.py:596] Timing: 56760.22937917709
I0316 17:08:00.346150 140033285822272 submission_runner.py:598] Total number of evals: 136
I0316 17:08:00.346195 140033285822272 submission_runner.py:599] ====================
I0316 17:08:00.346499 140033285822272 submission_runner.py:683] Final imagenet_vit_post_ln score: 0

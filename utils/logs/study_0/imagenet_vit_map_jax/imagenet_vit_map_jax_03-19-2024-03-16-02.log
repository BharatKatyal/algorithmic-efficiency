python3 submission_runner.py --framework=jax --workload=imagenet_vit_map --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=1286235446 --max_global_steps=186666 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_vit_map/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/imagenet_vit_map_jax_03-19-2024-03-16-02.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0319 03:16:25.444724 139793440028480 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax.
I0319 03:16:26.488198 139793440028480 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0319 03:16:26.488887 139793440028480 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0319 03:16:26.489052 139793440028480 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0319 03:16:26.495297 139793440028480 submission_runner.py:554] Using RNG seed 1286235446
I0319 03:16:27.629832 139793440028480 submission_runner.py:563] --- Tuning run 1/1 ---
I0319 03:16:27.630049 139793440028480 submission_runner.py:568] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1.
I0319 03:16:27.630226 139793440028480 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1/hparams.json.
I0319 03:16:27.813787 139793440028480 submission_runner.py:209] Initializing dataset.
I0319 03:16:27.829647 139793440028480 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:16:27.846806 139793440028480 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0319 03:16:28.231808 139793440028480 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:16:36.763496 139793440028480 submission_runner.py:220] Initializing model.
I0319 03:16:46.437251 139793440028480 submission_runner.py:262] Initializing optimizer.
I0319 03:16:47.466753 139793440028480 submission_runner.py:269] Initializing metrics bundle.
I0319 03:16:47.466988 139793440028480 submission_runner.py:287] Initializing checkpoint and logger.
I0319 03:16:47.468253 139793440028480 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1 with prefix checkpoint_
I0319 03:16:47.468386 139793440028480 submission_runner.py:307] Saving meta data to /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0319 03:16:47.792925 139793440028480 logger_utils.py:220] Unable to record git information. Continuing without it.
I0319 03:16:48.091146 139793440028480 submission_runner.py:311] Saving flags to /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1/flags_0.json.
I0319 03:16:48.101269 139793440028480 submission_runner.py:321] Starting training loop.
I0319 03:17:31.249896 139630356416256 logging_writer.py:48] [0] global_step=0, grad_norm=0.3923417329788208, loss=6.9077558517456055
I0319 03:17:31.267216 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:17:31.275102 139793440028480 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:17:31.283882 139793440028480 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0319 03:17:31.364866 139793440028480 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:17:47.994995 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:17:48.004667 139793440028480 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:17:48.021100 139793440028480 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0319 03:17:48.086542 139793440028480 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0319 03:18:05.784544 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:18:05.792223 139793440028480 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0319 03:18:05.798282 139793440028480 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0319 03:18:05.847246 139793440028480 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0319 03:18:11.014146 139793440028480 submission_runner.py:420] Time since start: 82.91s, 	Step: 1, 	{'train/accuracy': 0.0009570312104187906, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 43.16585683822632, 'total_duration': 82.91282558441162, 'accumulated_submission_time': 43.16585683822632, 'accumulated_eval_time': 39.746883153915405, 'accumulated_logging_time': 0}
I0319 03:18:11.029840 139592091014912 logging_writer.py:48] [1] accumulated_eval_time=39.746883, accumulated_logging_time=0, accumulated_submission_time=43.165857, global_step=1, preemption_count=0, score=43.165857, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=82.912826, train/accuracy=0.000957, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0319 03:18:35.849274 139628359177984 logging_writer.py:48] [1] global_step=1, grad_norm=0.3923485577106476, loss=6.9077558517456055
I0319 03:18:36.243993 139628367570688 logging_writer.py:48] [2] global_step=2, grad_norm=0.38004499673843384, loss=6.907754421234131
I0319 03:18:36.650594 139628359177984 logging_writer.py:48] [3] global_step=3, grad_norm=0.3875373601913452, loss=6.907759189605713
I0319 03:18:37.055306 139628367570688 logging_writer.py:48] [4] global_step=4, grad_norm=0.3746882677078247, loss=6.907754898071289
I0319 03:18:37.465384 139628359177984 logging_writer.py:48] [5] global_step=5, grad_norm=0.3844185173511505, loss=6.907751083374023
I0319 03:18:37.872040 139628367570688 logging_writer.py:48] [6] global_step=6, grad_norm=0.3991667926311493, loss=6.907744407653809
I0319 03:18:38.278711 139628359177984 logging_writer.py:48] [7] global_step=7, grad_norm=0.390410840511322, loss=6.907754421234131
I0319 03:18:38.690249 139628367570688 logging_writer.py:48] [8] global_step=8, grad_norm=0.37340831756591797, loss=6.907754898071289
I0319 03:18:39.100911 139628359177984 logging_writer.py:48] [9] global_step=9, grad_norm=0.3989790380001068, loss=6.907741546630859
I0319 03:18:39.508986 139628367570688 logging_writer.py:48] [10] global_step=10, grad_norm=0.3737572133541107, loss=6.907749176025391
I0319 03:18:39.918668 139628359177984 logging_writer.py:48] [11] global_step=11, grad_norm=0.4040062129497528, loss=6.907748699188232
I0319 03:18:40.328657 139628367570688 logging_writer.py:48] [12] global_step=12, grad_norm=0.3750499188899994, loss=6.9077253341674805
I0319 03:18:40.736668 139628359177984 logging_writer.py:48] [13] global_step=13, grad_norm=0.4021536111831665, loss=6.9077229499816895
I0319 03:18:41.150449 139628367570688 logging_writer.py:48] [14] global_step=14, grad_norm=0.3737594485282898, loss=6.907745361328125
I0319 03:18:41.559763 139628359177984 logging_writer.py:48] [15] global_step=15, grad_norm=0.3943192958831787, loss=6.907759189605713
I0319 03:18:41.975026 139628367570688 logging_writer.py:48] [16] global_step=16, grad_norm=0.37838152050971985, loss=6.907703399658203
I0319 03:18:42.385483 139628359177984 logging_writer.py:48] [17] global_step=17, grad_norm=0.40048542618751526, loss=6.9076995849609375
I0319 03:18:42.796324 139628367570688 logging_writer.py:48] [18] global_step=18, grad_norm=0.3680283725261688, loss=6.907753944396973
I0319 03:18:43.213868 139628359177984 logging_writer.py:48] [19] global_step=19, grad_norm=0.3959503471851349, loss=6.907736778259277
I0319 03:18:43.633475 139628367570688 logging_writer.py:48] [20] global_step=20, grad_norm=0.37101617455482483, loss=6.907684326171875
I0319 03:18:44.048046 139628359177984 logging_writer.py:48] [21] global_step=21, grad_norm=0.39617323875427246, loss=6.907695293426514
I0319 03:18:44.459097 139628367570688 logging_writer.py:48] [22] global_step=22, grad_norm=0.3799636662006378, loss=6.907705307006836
I0319 03:18:44.869448 139628359177984 logging_writer.py:48] [23] global_step=23, grad_norm=0.392593115568161, loss=6.907655239105225
I0319 03:18:45.280103 139628367570688 logging_writer.py:48] [24] global_step=24, grad_norm=0.40306150913238525, loss=6.907600402832031
I0319 03:18:45.693175 139628359177984 logging_writer.py:48] [25] global_step=25, grad_norm=0.4020540714263916, loss=6.907639980316162
I0319 03:18:46.106192 139628367570688 logging_writer.py:48] [26] global_step=26, grad_norm=0.38035663962364197, loss=6.907707691192627
I0319 03:18:46.521710 139628359177984 logging_writer.py:48] [27] global_step=27, grad_norm=0.39520710706710815, loss=6.907651901245117
I0319 03:18:46.931453 139628367570688 logging_writer.py:48] [28] global_step=28, grad_norm=0.4057713747024536, loss=6.9076361656188965
I0319 03:18:47.346605 139628359177984 logging_writer.py:48] [29] global_step=29, grad_norm=0.3983427584171295, loss=6.907700538635254
I0319 03:18:47.756088 139628367570688 logging_writer.py:48] [30] global_step=30, grad_norm=0.4048977494239807, loss=6.9076738357543945
I0319 03:18:48.172363 139628359177984 logging_writer.py:48] [31] global_step=31, grad_norm=0.40237340331077576, loss=6.907589435577393
I0319 03:18:48.595889 139628367570688 logging_writer.py:48] [32] global_step=32, grad_norm=0.41003257036209106, loss=6.907623767852783
I0319 03:18:49.011783 139628359177984 logging_writer.py:48] [33] global_step=33, grad_norm=0.4013189971446991, loss=6.907495975494385
I0319 03:18:49.416722 139628367570688 logging_writer.py:48] [34] global_step=34, grad_norm=0.4067399203777313, loss=6.907567024230957
I0319 03:18:49.836020 139628359177984 logging_writer.py:48] [35] global_step=35, grad_norm=0.3716049790382385, loss=6.907565116882324
I0319 03:18:50.248021 139628367570688 logging_writer.py:48] [36] global_step=36, grad_norm=0.4034624397754669, loss=6.907437324523926
I0319 03:18:50.665586 139628359177984 logging_writer.py:48] [37] global_step=37, grad_norm=0.40890538692474365, loss=6.9074320793151855
I0319 03:18:51.076865 139628367570688 logging_writer.py:48] [38] global_step=38, grad_norm=0.3827023208141327, loss=6.9074602127075195
I0319 03:18:51.491841 139628359177984 logging_writer.py:48] [39] global_step=39, grad_norm=0.37876465916633606, loss=6.907543182373047
I0319 03:18:51.908494 139628367570688 logging_writer.py:48] [40] global_step=40, grad_norm=0.3976473808288574, loss=6.907400608062744
I0319 03:18:52.322019 139628359177984 logging_writer.py:48] [41] global_step=41, grad_norm=0.42001157999038696, loss=6.907466411590576
I0319 03:18:52.739677 139628367570688 logging_writer.py:48] [42] global_step=42, grad_norm=0.39423084259033203, loss=6.907553672790527
I0319 03:18:53.156412 139628359177984 logging_writer.py:48] [43] global_step=43, grad_norm=0.39582324028015137, loss=6.907248020172119
I0319 03:18:53.570061 139628367570688 logging_writer.py:48] [44] global_step=44, grad_norm=0.4138301610946655, loss=6.907209396362305
I0319 03:18:53.978651 139628359177984 logging_writer.py:48] [45] global_step=45, grad_norm=0.38121968507766724, loss=6.907377243041992
I0319 03:18:54.386812 139628367570688 logging_writer.py:48] [46] global_step=46, grad_norm=0.39762863516807556, loss=6.907512664794922
I0319 03:18:54.791652 139628359177984 logging_writer.py:48] [47] global_step=47, grad_norm=0.43229949474334717, loss=6.907146453857422
I0319 03:18:55.201056 139628367570688 logging_writer.py:48] [48] global_step=48, grad_norm=0.43210968375205994, loss=6.907252311706543
I0319 03:18:55.607638 139628359177984 logging_writer.py:48] [49] global_step=49, grad_norm=0.4429888427257538, loss=6.907034397125244
I0319 03:18:56.025340 139628367570688 logging_writer.py:48] [50] global_step=50, grad_norm=0.43973344564437866, loss=6.90704870223999
I0319 03:18:56.437307 139628359177984 logging_writer.py:48] [51] global_step=51, grad_norm=0.43249258399009705, loss=6.907006740570068
I0319 03:18:56.846639 139628367570688 logging_writer.py:48] [52] global_step=52, grad_norm=0.4458296000957489, loss=6.906996726989746
I0319 03:18:57.255555 139628359177984 logging_writer.py:48] [53] global_step=53, grad_norm=0.3943905830383301, loss=6.906985282897949
I0319 03:18:57.681749 139628367570688 logging_writer.py:48] [54] global_step=54, grad_norm=0.44652384519577026, loss=6.9065842628479
I0319 03:18:58.094835 139628359177984 logging_writer.py:48] [55] global_step=55, grad_norm=0.45270416140556335, loss=6.906946659088135
I0319 03:18:58.509991 139628367570688 logging_writer.py:48] [56] global_step=56, grad_norm=0.4443415105342865, loss=6.906877517700195
I0319 03:18:58.928395 139628359177984 logging_writer.py:48] [57] global_step=57, grad_norm=0.4409099221229553, loss=6.906769752502441
I0319 03:18:59.342627 139628367570688 logging_writer.py:48] [58] global_step=58, grad_norm=0.45370227098464966, loss=6.906500339508057
I0319 03:18:59.757339 139628359177984 logging_writer.py:48] [59] global_step=59, grad_norm=0.4300207197666168, loss=6.906786918640137
I0319 03:19:00.165454 139628367570688 logging_writer.py:48] [60] global_step=60, grad_norm=0.46573349833488464, loss=6.906398296356201
I0319 03:19:00.575950 139628359177984 logging_writer.py:48] [61] global_step=61, grad_norm=0.4374011754989624, loss=6.906272888183594
I0319 03:19:00.987088 139628367570688 logging_writer.py:48] [62] global_step=62, grad_norm=0.45037326216697693, loss=6.906197547912598
I0319 03:19:01.394478 139628359177984 logging_writer.py:48] [63] global_step=63, grad_norm=0.39652198553085327, loss=6.906914234161377
I0319 03:19:01.804192 139628367570688 logging_writer.py:48] [64] global_step=64, grad_norm=0.4360094964504242, loss=6.906302452087402
I0319 03:19:02.232443 139628359177984 logging_writer.py:48] [65] global_step=65, grad_norm=0.42493772506713867, loss=6.906735420227051
I0319 03:19:02.643503 139628367570688 logging_writer.py:48] [66] global_step=66, grad_norm=0.4859175682067871, loss=6.905872821807861
I0319 03:19:03.051861 139628359177984 logging_writer.py:48] [67] global_step=67, grad_norm=0.455456018447876, loss=6.906002998352051
I0319 03:19:03.470044 139628367570688 logging_writer.py:48] [68] global_step=68, grad_norm=0.40788620710372925, loss=6.906597137451172
I0319 03:19:03.889652 139628359177984 logging_writer.py:48] [69] global_step=69, grad_norm=0.47923630475997925, loss=6.90590238571167
I0319 03:19:04.309595 139628367570688 logging_writer.py:48] [70] global_step=70, grad_norm=0.4364089071750641, loss=6.906669616699219
I0319 03:19:04.729276 139628359177984 logging_writer.py:48] [71] global_step=71, grad_norm=0.42870521545410156, loss=6.905755996704102
I0319 03:19:05.147496 139628367570688 logging_writer.py:48] [72] global_step=72, grad_norm=0.4575923979282379, loss=6.9058732986450195
I0319 03:19:05.568304 139628359177984 logging_writer.py:48] [73] global_step=73, grad_norm=0.4065728783607483, loss=6.906320095062256
I0319 03:19:05.980555 139628367570688 logging_writer.py:48] [74] global_step=74, grad_norm=0.4765516519546509, loss=6.905385971069336
I0319 03:19:06.393697 139628359177984 logging_writer.py:48] [75] global_step=75, grad_norm=0.4860784113407135, loss=6.905501842498779
I0319 03:19:06.811826 139628367570688 logging_writer.py:48] [76] global_step=76, grad_norm=0.5065592527389526, loss=6.9049763679504395
I0319 03:19:07.227782 139628359177984 logging_writer.py:48] [77] global_step=77, grad_norm=0.5082146525382996, loss=6.904453754425049
I0319 03:19:07.644449 139628367570688 logging_writer.py:48] [78] global_step=78, grad_norm=0.4307555854320526, loss=6.905486106872559
I0319 03:19:08.053306 139628359177984 logging_writer.py:48] [79] global_step=79, grad_norm=0.4797598719596863, loss=6.905397415161133
I0319 03:19:08.467092 139628367570688 logging_writer.py:48] [80] global_step=80, grad_norm=0.49514079093933105, loss=6.9038543701171875
I0319 03:19:08.880325 139628359177984 logging_writer.py:48] [81] global_step=81, grad_norm=0.4758206903934479, loss=6.9035258293151855
I0319 03:19:09.295003 139628367570688 logging_writer.py:48] [82] global_step=82, grad_norm=0.5070748925209045, loss=6.904073238372803
I0319 03:19:09.717039 139628359177984 logging_writer.py:48] [83] global_step=83, grad_norm=0.5231589674949646, loss=6.903465270996094
I0319 03:19:10.134654 139628367570688 logging_writer.py:48] [84] global_step=84, grad_norm=0.5309736132621765, loss=6.904680252075195
I0319 03:19:10.556995 139628359177984 logging_writer.py:48] [85] global_step=85, grad_norm=0.516476571559906, loss=6.904383182525635
I0319 03:19:10.975142 139628367570688 logging_writer.py:48] [86] global_step=86, grad_norm=0.46645161509513855, loss=6.90440559387207
I0319 03:19:11.385635 139628359177984 logging_writer.py:48] [87] global_step=87, grad_norm=0.44660094380378723, loss=6.903837203979492
I0319 03:19:11.799573 139628367570688 logging_writer.py:48] [88] global_step=88, grad_norm=0.5116867423057556, loss=6.902742385864258
I0319 03:19:12.222818 139628359177984 logging_writer.py:48] [89] global_step=89, grad_norm=0.525126576423645, loss=6.902405261993408
I0319 03:19:12.637310 139628367570688 logging_writer.py:48] [90] global_step=90, grad_norm=0.5280630588531494, loss=6.90277624130249
I0319 03:19:13.054115 139628359177984 logging_writer.py:48] [91] global_step=91, grad_norm=0.5394647121429443, loss=6.902224540710449
I0319 03:19:13.468611 139628367570688 logging_writer.py:48] [92] global_step=92, grad_norm=0.5255193114280701, loss=6.901590347290039
I0319 03:19:13.884284 139628359177984 logging_writer.py:48] [93] global_step=93, grad_norm=0.4473772644996643, loss=6.903806686401367
I0319 03:19:14.304873 139628367570688 logging_writer.py:48] [94] global_step=94, grad_norm=0.5337128043174744, loss=6.902283668518066
I0319 03:19:14.724390 139628359177984 logging_writer.py:48] [95] global_step=95, grad_norm=0.49830734729766846, loss=6.901839256286621
I0319 03:19:15.137063 139628367570688 logging_writer.py:48] [96] global_step=96, grad_norm=0.5098371505737305, loss=6.9014892578125
I0319 03:19:15.559912 139628359177984 logging_writer.py:48] [97] global_step=97, grad_norm=0.5341997742652893, loss=6.902791976928711
I0319 03:19:15.974231 139628367570688 logging_writer.py:48] [98] global_step=98, grad_norm=0.4691062867641449, loss=6.901588439941406
I0319 03:19:16.380130 139628359177984 logging_writer.py:48] [99] global_step=99, grad_norm=0.5457556843757629, loss=6.900816440582275
I0319 03:19:16.792435 139628367570688 logging_writer.py:48] [100] global_step=100, grad_norm=0.45954251289367676, loss=6.902003765106201
I0319 03:22:10.100714 139628359177984 logging_writer.py:48] [500] global_step=500, grad_norm=1.0004082918167114, loss=6.699007987976074
I0319 03:25:11.315121 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:25:22.958438 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:25:31.060621 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:25:32.700343 139793440028480 submission_runner.py:420] Time since start: 524.60s, 	Step: 909, 	{'train/accuracy': 0.018046874552965164, 'train/loss': 6.2387213706970215, 'validation/accuracy': 0.017799999564886093, 'validation/loss': 6.249222755432129, 'validation/num_examples': 50000, 'test/accuracy': 0.014100000262260437, 'test/loss': 6.312887191772461, 'test/num_examples': 10000, 'score': 463.3900761604309, 'total_duration': 524.5990114212036, 'accumulated_submission_time': 463.3900761604309, 'accumulated_eval_time': 61.13209390640259, 'accumulated_logging_time': 0.024669647216796875}
I0319 03:25:32.718334 139592099407616 logging_writer.py:48] [909] accumulated_eval_time=61.132094, accumulated_logging_time=0.024670, accumulated_submission_time=463.390076, global_step=909, preemption_count=0, score=463.390076, test/accuracy=0.014100, test/loss=6.312887, test/num_examples=10000, total_duration=524.599011, train/accuracy=0.018047, train/loss=6.238721, validation/accuracy=0.017800, validation/loss=6.249223, validation/num_examples=50000
I0319 03:26:09.817176 139592107800320 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.350551724433899, loss=6.530638217926025
I0319 03:29:50.027401 139592099407616 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.6662734746932983, loss=6.170865058898926
I0319 03:32:33.029680 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:32:44.572722 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:32:52.660751 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:32:54.280503 139793440028480 submission_runner.py:420] Time since start: 966.18s, 	Step: 1870, 	{'train/accuracy': 0.04398437216877937, 'train/loss': 5.696121692657471, 'validation/accuracy': 0.04211999848484993, 'validation/loss': 5.730832576751709, 'validation/num_examples': 50000, 'test/accuracy': 0.0340999998152256, 'test/loss': 5.867914199829102, 'test/num_examples': 10000, 'score': 883.6368682384491, 'total_duration': 966.1791715621948, 'accumulated_submission_time': 883.6368682384491, 'accumulated_eval_time': 82.38292145729065, 'accumulated_logging_time': 0.053483009338378906}
I0319 03:32:54.299031 139592107800320 logging_writer.py:48] [1870] accumulated_eval_time=82.382921, accumulated_logging_time=0.053483, accumulated_submission_time=883.636868, global_step=1870, preemption_count=0, score=883.636868, test/accuracy=0.034100, test/loss=5.867914, test/num_examples=10000, total_duration=966.179172, train/accuracy=0.043984, train/loss=5.696122, validation/accuracy=0.042120, validation/loss=5.730833, validation/num_examples=50000
I0319 03:33:46.841672 139592099407616 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.186124324798584, loss=6.605830669403076
I0319 03:37:27.972666 139592107800320 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.7252264022827148, loss=5.899511337280273
I0319 03:39:54.938233 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:40:06.244851 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:40:14.417221 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:40:16.041544 139793440028480 submission_runner.py:420] Time since start: 1407.94s, 	Step: 2834, 	{'train/accuracy': 0.07347656041383743, 'train/loss': 5.280451774597168, 'validation/accuracy': 0.06678000092506409, 'validation/loss': 5.336838722229004, 'validation/num_examples': 50000, 'test/accuracy': 0.05400000140070915, 'test/loss': 5.536876678466797, 'test/num_examples': 10000, 'score': 1304.212679862976, 'total_duration': 1407.9402105808258, 'accumulated_submission_time': 1304.212679862976, 'accumulated_eval_time': 103.48623061180115, 'accumulated_logging_time': 0.08181452751159668}
I0319 03:40:16.059283 139592099407616 logging_writer.py:48] [2834] accumulated_eval_time=103.486231, accumulated_logging_time=0.081815, accumulated_submission_time=1304.212680, global_step=2834, preemption_count=0, score=1304.212680, test/accuracy=0.054000, test/loss=5.536877, test/num_examples=10000, total_duration=1407.940211, train/accuracy=0.073477, train/loss=5.280452, validation/accuracy=0.066780, validation/loss=5.336839, validation/num_examples=50000
I0319 03:41:24.562924 139592107800320 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.3163979053497314, loss=5.684362411499023
I0319 03:45:05.616439 139592099407616 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.5148266553878784, loss=5.581650257110596
I0319 03:47:16.407892 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:47:28.041964 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:47:36.965843 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:47:38.585672 139793440028480 submission_runner.py:420] Time since start: 1850.48s, 	Step: 3798, 	{'train/accuracy': 0.11041015386581421, 'train/loss': 4.8983073234558105, 'validation/accuracy': 0.10261999815702438, 'validation/loss': 4.945130825042725, 'validation/num_examples': 50000, 'test/accuracy': 0.08060000091791153, 'test/loss': 5.208343982696533, 'test/num_examples': 10000, 'score': 1724.487268447876, 'total_duration': 1850.4843425750732, 'accumulated_submission_time': 1724.487268447876, 'accumulated_eval_time': 125.66406631469727, 'accumulated_logging_time': 0.11260151863098145}
I0319 03:47:38.603794 139592107800320 logging_writer.py:48] [3798] accumulated_eval_time=125.664066, accumulated_logging_time=0.112602, accumulated_submission_time=1724.487268, global_step=3798, preemption_count=0, score=1724.487268, test/accuracy=0.080600, test/loss=5.208344, test/num_examples=10000, total_duration=1850.484343, train/accuracy=0.110410, train/loss=4.898307, validation/accuracy=0.102620, validation/loss=4.945131, validation/num_examples=50000
I0319 03:49:03.300440 139592099407616 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.4906758069992065, loss=5.340146541595459
I0319 03:52:44.573875 139592107800320 logging_writer.py:48] [4500] global_step=4500, grad_norm=1.3708311319351196, loss=5.2117462158203125
I0319 03:54:38.683132 139793440028480 spec.py:321] Evaluating on the training split.
I0319 03:54:50.412152 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 03:54:58.732018 139793440028480 spec.py:349] Evaluating on the test split.
I0319 03:55:00.357857 139793440028480 submission_runner.py:420] Time since start: 2292.26s, 	Step: 4758, 	{'train/accuracy': 0.1586328148841858, 'train/loss': 4.414804935455322, 'validation/accuracy': 0.14963999390602112, 'validation/loss': 4.490406036376953, 'validation/num_examples': 50000, 'test/accuracy': 0.11150000244379044, 'test/loss': 4.83000373840332, 'test/num_examples': 10000, 'score': 2144.5049920082092, 'total_duration': 2292.2565217018127, 'accumulated_submission_time': 2144.5049920082092, 'accumulated_eval_time': 147.33879375457764, 'accumulated_logging_time': 0.14018559455871582}
I0319 03:55:00.376371 139592099407616 logging_writer.py:48] [4758] accumulated_eval_time=147.338794, accumulated_logging_time=0.140186, accumulated_submission_time=2144.504992, global_step=4758, preemption_count=0, score=2144.504992, test/accuracy=0.111500, test/loss=4.830004, test/num_examples=10000, total_duration=2292.256522, train/accuracy=0.158633, train/loss=4.414805, validation/accuracy=0.149640, validation/loss=4.490406, validation/num_examples=50000
I0319 03:56:43.098263 139592107800320 logging_writer.py:48] [5000] global_step=5000, grad_norm=1.3528032302856445, loss=5.056283473968506
I0319 04:00:24.933320 139592099407616 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.101552128791809, loss=6.415231704711914
I0319 04:02:00.711416 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:02:12.365238 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:02:20.434781 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:02:22.048547 139793440028480 submission_runner.py:420] Time since start: 2733.95s, 	Step: 5718, 	{'train/accuracy': 0.21044921875, 'train/loss': 4.0167927742004395, 'validation/accuracy': 0.19209998846054077, 'validation/loss': 4.121342658996582, 'validation/num_examples': 50000, 'test/accuracy': 0.14480000734329224, 'test/loss': 4.527491569519043, 'test/num_examples': 10000, 'score': 2564.7776367664337, 'total_duration': 2733.9472160339355, 'accumulated_submission_time': 2564.7776367664337, 'accumulated_eval_time': 168.67592430114746, 'accumulated_logging_time': 0.16823530197143555}
I0319 04:02:22.065690 139592107800320 logging_writer.py:48] [5718] accumulated_eval_time=168.675924, accumulated_logging_time=0.168235, accumulated_submission_time=2564.777637, global_step=5718, preemption_count=0, score=2564.777637, test/accuracy=0.144800, test/loss=4.527492, test/num_examples=10000, total_duration=2733.947216, train/accuracy=0.210449, train/loss=4.016793, validation/accuracy=0.192100, validation/loss=4.121343, validation/num_examples=50000
I0319 04:04:22.025360 139592099407616 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.5262742042541504, loss=4.716116428375244
I0319 04:08:05.649770 139592107800320 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.5210963487625122, loss=4.704891204833984
I0319 04:09:22.465637 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:09:34.056731 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:09:42.064891 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:09:43.705651 139793440028480 submission_runner.py:420] Time since start: 3175.60s, 	Step: 6675, 	{'train/accuracy': 0.2644335925579071, 'train/loss': 3.6136574745178223, 'validation/accuracy': 0.23173999786376953, 'validation/loss': 3.811569929122925, 'validation/num_examples': 50000, 'test/accuracy': 0.17500001192092896, 'test/loss': 4.2633867263793945, 'test/num_examples': 10000, 'score': 2985.114411830902, 'total_duration': 3175.604325056076, 'accumulated_submission_time': 2985.114411830902, 'accumulated_eval_time': 189.9159426689148, 'accumulated_logging_time': 0.19598150253295898}
I0319 04:09:43.727397 139592099407616 logging_writer.py:48] [6675] accumulated_eval_time=189.915943, accumulated_logging_time=0.195982, accumulated_submission_time=2985.114412, global_step=6675, preemption_count=0, score=2985.114412, test/accuracy=0.175000, test/loss=4.263387, test/num_examples=10000, total_duration=3175.604325, train/accuracy=0.264434, train/loss=3.613657, validation/accuracy=0.231740, validation/loss=3.811570, validation/num_examples=50000
I0319 04:12:03.068893 139592107800320 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.1900359392166138, loss=5.56115198135376
I0319 04:15:46.170436 139592099407616 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.6188240051269531, loss=4.480567932128906
I0319 04:16:43.845117 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:16:55.470072 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:17:03.528813 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:17:05.146429 139793440028480 submission_runner.py:420] Time since start: 3617.05s, 	Step: 7630, 	{'train/accuracy': 0.2835937440395355, 'train/loss': 3.490403413772583, 'validation/accuracy': 0.26909998059272766, 'validation/loss': 3.595759868621826, 'validation/num_examples': 50000, 'test/accuracy': 0.20190000534057617, 'test/loss': 4.105603218078613, 'test/num_examples': 10000, 'score': 3405.1694016456604, 'total_duration': 3617.045097589493, 'accumulated_submission_time': 3405.1694016456604, 'accumulated_eval_time': 211.21724128723145, 'accumulated_logging_time': 0.22757172584533691}
I0319 04:17:05.169498 139592107800320 logging_writer.py:48] [7630] accumulated_eval_time=211.217241, accumulated_logging_time=0.227572, accumulated_submission_time=3405.169402, global_step=7630, preemption_count=0, score=3405.169402, test/accuracy=0.201900, test/loss=4.105603, test/num_examples=10000, total_duration=3617.045098, train/accuracy=0.283594, train/loss=3.490403, validation/accuracy=0.269100, validation/loss=3.595760, validation/num_examples=50000
I0319 04:19:45.109717 139592099407616 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.031019687652588, loss=5.245437145233154
I0319 04:23:26.939880 139592107800320 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.5708884000778198, loss=4.163447380065918
I0319 04:24:05.404283 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:24:17.037360 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:24:27.940196 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:24:29.551803 139793440028480 submission_runner.py:420] Time since start: 4061.45s, 	Step: 8588, 	{'train/accuracy': 0.33900389075279236, 'train/loss': 3.164844036102295, 'validation/accuracy': 0.3127000033855438, 'validation/loss': 3.313385248184204, 'validation/num_examples': 50000, 'test/accuracy': 0.23730000853538513, 'test/loss': 3.838170051574707, 'test/num_examples': 10000, 'score': 3825.339316368103, 'total_duration': 4061.4504537582397, 'accumulated_submission_time': 3825.339316368103, 'accumulated_eval_time': 235.36473417282104, 'accumulated_logging_time': 0.2624244689941406}
I0319 04:24:29.574245 139592099407616 logging_writer.py:48] [8588] accumulated_eval_time=235.364734, accumulated_logging_time=0.262424, accumulated_submission_time=3825.339316, global_step=8588, preemption_count=0, score=3825.339316, test/accuracy=0.237300, test/loss=3.838170, test/num_examples=10000, total_duration=4061.450454, train/accuracy=0.339004, train/loss=3.164844, validation/accuracy=0.312700, validation/loss=3.313385, validation/num_examples=50000
I0319 04:27:28.414655 139592107800320 logging_writer.py:48] [9000] global_step=9000, grad_norm=1.2849980592727661, loss=4.218286991119385
I0319 04:31:09.996857 139592099407616 logging_writer.py:48] [9500] global_step=9500, grad_norm=1.4213227033615112, loss=3.923218250274658
I0319 04:31:29.580162 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:31:41.394551 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:31:53.744595 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:31:55.363320 139793440028480 submission_runner.py:420] Time since start: 4507.26s, 	Step: 9546, 	{'train/accuracy': 0.374824196100235, 'train/loss': 2.909634828567505, 'validation/accuracy': 0.3432999849319458, 'validation/loss': 3.0872015953063965, 'validation/num_examples': 50000, 'test/accuracy': 0.2647000253200531, 'test/loss': 3.6340298652648926, 'test/num_examples': 10000, 'score': 4245.2809009552, 'total_duration': 4507.261991262436, 'accumulated_submission_time': 4245.2809009552, 'accumulated_eval_time': 261.14787244796753, 'accumulated_logging_time': 0.2952415943145752}
I0319 04:31:55.384188 139592107800320 logging_writer.py:48] [9546] accumulated_eval_time=261.147872, accumulated_logging_time=0.295242, accumulated_submission_time=4245.280901, global_step=9546, preemption_count=0, score=4245.280901, test/accuracy=0.264700, test/loss=3.634030, test/num_examples=10000, total_duration=4507.261991, train/accuracy=0.374824, train/loss=2.909635, validation/accuracy=0.343300, validation/loss=3.087202, validation/num_examples=50000
I0319 04:35:12.853936 139592099407616 logging_writer.py:48] [10000] global_step=10000, grad_norm=1.3034666776657104, loss=3.6223998069763184
I0319 04:38:55.366632 139592107800320 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.2221944332122803, loss=3.994659900665283
I0319 04:38:55.380511 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:39:07.121255 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:39:20.368798 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:39:21.987666 139793440028480 submission_runner.py:420] Time since start: 4953.89s, 	Step: 10501, 	{'train/accuracy': 0.4027148485183716, 'train/loss': 2.7752459049224854, 'validation/accuracy': 0.372439980506897, 'validation/loss': 2.9269795417785645, 'validation/num_examples': 50000, 'test/accuracy': 0.287200003862381, 'test/loss': 3.4903852939605713, 'test/num_examples': 10000, 'score': 4665.211783647537, 'total_duration': 4953.886339187622, 'accumulated_submission_time': 4665.211783647537, 'accumulated_eval_time': 287.75501561164856, 'accumulated_logging_time': 0.32796216011047363}
I0319 04:39:22.009156 139592099407616 logging_writer.py:48] [10501] accumulated_eval_time=287.755016, accumulated_logging_time=0.327962, accumulated_submission_time=4665.211784, global_step=10501, preemption_count=0, score=4665.211784, test/accuracy=0.287200, test/loss=3.490385, test/num_examples=10000, total_duration=4953.886339, train/accuracy=0.402715, train/loss=2.775246, validation/accuracy=0.372440, validation/loss=2.926980, validation/num_examples=50000
I0319 04:42:59.200715 139592107800320 logging_writer.py:48] [11000] global_step=11000, grad_norm=1.355424404144287, loss=3.681642532348633
I0319 04:46:22.423892 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:46:34.376125 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:46:51.978579 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:46:53.585892 139793440028480 submission_runner.py:420] Time since start: 5405.48s, 	Step: 11459, 	{'train/accuracy': 0.42878904938697815, 'train/loss': 2.601086378097534, 'validation/accuracy': 0.40073999762535095, 'validation/loss': 2.763827085494995, 'validation/num_examples': 50000, 'test/accuracy': 0.3108000159263611, 'test/loss': 3.3482494354248047, 'test/num_examples': 10000, 'score': 5085.5621728897095, 'total_duration': 5405.4845468997955, 'accumulated_submission_time': 5085.5621728897095, 'accumulated_eval_time': 318.9169981479645, 'accumulated_logging_time': 0.361297607421875}
I0319 04:46:53.605801 139592099407616 logging_writer.py:48] [11459] accumulated_eval_time=318.916998, accumulated_logging_time=0.361298, accumulated_submission_time=5085.562173, global_step=11459, preemption_count=0, score=5085.562173, test/accuracy=0.310800, test/loss=3.348249, test/num_examples=10000, total_duration=5405.484547, train/accuracy=0.428789, train/loss=2.601086, validation/accuracy=0.400740, validation/loss=2.763827, validation/num_examples=50000
I0319 04:47:10.432395 139592107800320 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.2756694555282593, loss=3.7338500022888184
I0319 04:50:48.593098 139592099407616 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.2399592399597168, loss=3.5675976276397705
I0319 04:53:53.725490 139793440028480 spec.py:321] Evaluating on the training split.
I0319 04:54:05.775272 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 04:54:16.974889 139793440028480 spec.py:349] Evaluating on the test split.
I0319 04:54:18.588916 139793440028480 submission_runner.py:420] Time since start: 5850.49s, 	Step: 12418, 	{'train/accuracy': 0.46140623092651367, 'train/loss': 2.4328789710998535, 'validation/accuracy': 0.41995999217033386, 'validation/loss': 2.623626232147217, 'validation/num_examples': 50000, 'test/accuracy': 0.3296000063419342, 'test/loss': 3.1954219341278076, 'test/num_examples': 10000, 'score': 5505.618812322617, 'total_duration': 5850.48757815361, 'accumulated_submission_time': 5505.618812322617, 'accumulated_eval_time': 343.7804172039032, 'accumulated_logging_time': 0.3915243148803711}
I0319 04:54:18.608200 139592107800320 logging_writer.py:48] [12418] accumulated_eval_time=343.780417, accumulated_logging_time=0.391524, accumulated_submission_time=5505.618812, global_step=12418, preemption_count=0, score=5505.618812, test/accuracy=0.329600, test/loss=3.195422, test/num_examples=10000, total_duration=5850.487578, train/accuracy=0.461406, train/loss=2.432879, validation/accuracy=0.419960, validation/loss=2.623626, validation/num_examples=50000
I0319 04:54:51.877146 139592099407616 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.2841500043869019, loss=3.692626714706421
I0319 04:58:32.831018 139592107800320 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.3763697147369385, loss=3.3372583389282227
I0319 05:01:19.096201 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:01:30.729774 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:01:42.755694 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:01:44.368947 139793440028480 submission_runner.py:420] Time since start: 6296.27s, 	Step: 13374, 	{'train/accuracy': 0.4901757836341858, 'train/loss': 2.264934778213501, 'validation/accuracy': 0.441679984331131, 'validation/loss': 2.504922389984131, 'validation/num_examples': 50000, 'test/accuracy': 0.34700000286102295, 'test/loss': 3.0967447757720947, 'test/num_examples': 10000, 'score': 5926.041017532349, 'total_duration': 6296.2676157951355, 'accumulated_submission_time': 5926.041017532349, 'accumulated_eval_time': 369.05315804481506, 'accumulated_logging_time': 0.4241065979003906}
I0319 05:01:44.390809 139592099407616 logging_writer.py:48] [13374] accumulated_eval_time=369.053158, accumulated_logging_time=0.424107, accumulated_submission_time=5926.041018, global_step=13374, preemption_count=0, score=5926.041018, test/accuracy=0.347000, test/loss=3.096745, test/num_examples=10000, total_duration=6296.267616, train/accuracy=0.490176, train/loss=2.264935, validation/accuracy=0.441680, validation/loss=2.504922, validation/num_examples=50000
I0319 05:02:36.183764 139592107800320 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.207876443862915, loss=3.2413551807403564
I0319 05:06:18.523320 139592099407616 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.1396229267120361, loss=4.13105583190918
I0319 05:08:44.650634 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:08:57.093663 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:09:12.194601 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:09:13.847156 139793440028480 submission_runner.py:420] Time since start: 6745.75s, 	Step: 14329, 	{'train/accuracy': 0.4932616949081421, 'train/loss': 2.2300097942352295, 'validation/accuracy': 0.4592999815940857, 'validation/loss': 2.401749610900879, 'validation/num_examples': 50000, 'test/accuracy': 0.3603000044822693, 'test/loss': 3.0184385776519775, 'test/num_examples': 10000, 'score': 6346.238476514816, 'total_duration': 6745.745825767517, 'accumulated_submission_time': 6346.238476514816, 'accumulated_eval_time': 398.2497239112854, 'accumulated_logging_time': 0.4554910659790039}
I0319 05:09:13.865614 139592107800320 logging_writer.py:48] [14329] accumulated_eval_time=398.249724, accumulated_logging_time=0.455491, accumulated_submission_time=6346.238477, global_step=14329, preemption_count=0, score=6346.238477, test/accuracy=0.360300, test/loss=3.018439, test/num_examples=10000, total_duration=6745.745826, train/accuracy=0.493262, train/loss=2.230010, validation/accuracy=0.459300, validation/loss=2.401750, validation/num_examples=50000
I0319 05:10:23.796316 139592099407616 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.2333403825759888, loss=3.096102476119995
I0319 05:14:06.550581 139592107800320 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.246605634689331, loss=3.023937463760376
I0319 05:16:14.280201 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:16:27.765126 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:16:45.586014 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:16:47.193164 139793440028480 submission_runner.py:420] Time since start: 7199.09s, 	Step: 15288, 	{'train/accuracy': 0.5074804425239563, 'train/loss': 2.169114112854004, 'validation/accuracy': 0.47303998470306396, 'validation/loss': 2.3563408851623535, 'validation/num_examples': 50000, 'test/accuracy': 0.3693000078201294, 'test/loss': 2.9735970497131348, 'test/num_examples': 10000, 'score': 6766.591676712036, 'total_duration': 7199.091827392578, 'accumulated_submission_time': 6766.591676712036, 'accumulated_eval_time': 431.16269087791443, 'accumulated_logging_time': 0.48230671882629395}
I0319 05:16:47.212660 139592099407616 logging_writer.py:48] [15288] accumulated_eval_time=431.162691, accumulated_logging_time=0.482307, accumulated_submission_time=6766.591677, global_step=15288, preemption_count=0, score=6766.591677, test/accuracy=0.369300, test/loss=2.973597, test/num_examples=10000, total_duration=7199.091827, train/accuracy=0.507480, train/loss=2.169114, validation/accuracy=0.473040, validation/loss=2.356341, validation/num_examples=50000
I0319 05:18:15.815201 139592107800320 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.2654287815093994, loss=3.086660623550415
I0319 05:21:58.499712 139592099407616 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.0343589782714844, loss=4.858191967010498
I0319 05:23:47.560300 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:24:02.258629 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:24:18.869755 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:24:20.493942 139793440028480 submission_runner.py:420] Time since start: 7652.39s, 	Step: 16246, 	{'train/accuracy': 0.5291991829872131, 'train/loss': 2.0571389198303223, 'validation/accuracy': 0.4845399856567383, 'validation/loss': 2.272536516189575, 'validation/num_examples': 50000, 'test/accuracy': 0.38130003213882446, 'test/loss': 2.9030184745788574, 'test/num_examples': 10000, 'score': 7186.874831676483, 'total_duration': 7652.392613887787, 'accumulated_submission_time': 7186.874831676483, 'accumulated_eval_time': 464.09634351730347, 'accumulated_logging_time': 0.5127396583557129}
I0319 05:24:20.515130 139592107800320 logging_writer.py:48] [16246] accumulated_eval_time=464.096344, accumulated_logging_time=0.512740, accumulated_submission_time=7186.874832, global_step=16246, preemption_count=0, score=7186.874832, test/accuracy=0.381300, test/loss=2.903018, test/num_examples=10000, total_duration=7652.392614, train/accuracy=0.529199, train/loss=2.057139, validation/accuracy=0.484540, validation/loss=2.272537, validation/num_examples=50000
I0319 05:26:10.723804 139592099407616 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.9774395823478699, loss=4.813337326049805
I0319 05:29:54.210873 139592107800320 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.117252230644226, loss=4.450883388519287
I0319 05:31:20.509709 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:31:35.385435 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:31:51.679409 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:31:53.287999 139793440028480 submission_runner.py:420] Time since start: 8105.19s, 	Step: 17196, 	{'train/accuracy': 0.5538085699081421, 'train/loss': 1.9544509649276733, 'validation/accuracy': 0.497219979763031, 'validation/loss': 2.227579355239868, 'validation/num_examples': 50000, 'test/accuracy': 0.3929000198841095, 'test/loss': 2.8477354049682617, 'test/num_examples': 10000, 'score': 7606.806395292282, 'total_duration': 8105.186660289764, 'accumulated_submission_time': 7606.806395292282, 'accumulated_eval_time': 496.8746225833893, 'accumulated_logging_time': 0.544755220413208}
I0319 05:31:53.310327 139592099407616 logging_writer.py:48] [17196] accumulated_eval_time=496.874623, accumulated_logging_time=0.544755, accumulated_submission_time=7606.806395, global_step=17196, preemption_count=0, score=7606.806395, test/accuracy=0.392900, test/loss=2.847735, test/num_examples=10000, total_duration=8105.186660, train/accuracy=0.553809, train/loss=1.954451, validation/accuracy=0.497220, validation/loss=2.227579, validation/num_examples=50000
I0319 05:34:05.682632 139592107800320 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.2492460012435913, loss=3.1145966053009033
I0319 05:37:50.540118 139592099407616 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.9882234930992126, loss=4.692961692810059
I0319 05:38:53.505693 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:39:08.321271 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:39:27.926126 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:39:29.528106 139793440028480 submission_runner.py:420] Time since start: 8561.43s, 	Step: 18142, 	{'train/accuracy': 0.5469335913658142, 'train/loss': 1.9713891744613647, 'validation/accuracy': 0.5078799724578857, 'validation/loss': 2.1587042808532715, 'validation/num_examples': 50000, 'test/accuracy': 0.39730000495910645, 'test/loss': 2.7942819595336914, 'test/num_examples': 10000, 'score': 8026.940294504166, 'total_duration': 8561.426780700684, 'accumulated_submission_time': 8026.940294504166, 'accumulated_eval_time': 532.8970324993134, 'accumulated_logging_time': 0.5767190456390381}
I0319 05:39:29.546492 139592107800320 logging_writer.py:48] [18142] accumulated_eval_time=532.897032, accumulated_logging_time=0.576719, accumulated_submission_time=8026.940295, global_step=18142, preemption_count=0, score=8026.940295, test/accuracy=0.397300, test/loss=2.794282, test/num_examples=10000, total_duration=8561.426781, train/accuracy=0.546934, train/loss=1.971389, validation/accuracy=0.507880, validation/loss=2.158704, validation/num_examples=50000
I0319 05:42:03.480701 139592099407616 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.2971065044403076, loss=3.1714203357696533
I0319 05:45:47.720522 139592107800320 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.2931182384490967, loss=2.9441776275634766
I0319 05:46:30.013038 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:46:44.806921 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:47:06.980491 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:47:08.585287 139793440028480 submission_runner.py:420] Time since start: 9020.48s, 	Step: 19096, 	{'train/accuracy': 0.5603125095367432, 'train/loss': 1.8923168182373047, 'validation/accuracy': 0.5165599584579468, 'validation/loss': 2.1050305366516113, 'validation/num_examples': 50000, 'test/accuracy': 0.406900018453598, 'test/loss': 2.755641222000122, 'test/num_examples': 10000, 'score': 8447.345478773117, 'total_duration': 9020.483969926834, 'accumulated_submission_time': 8447.345478773117, 'accumulated_eval_time': 571.469304561615, 'accumulated_logging_time': 0.6045756340026855}
I0319 05:47:08.603589 139592099407616 logging_writer.py:48] [19096] accumulated_eval_time=571.469305, accumulated_logging_time=0.604576, accumulated_submission_time=8447.345479, global_step=19096, preemption_count=0, score=8447.345479, test/accuracy=0.406900, test/loss=2.755641, test/num_examples=10000, total_duration=9020.483970, train/accuracy=0.560313, train/loss=1.892317, validation/accuracy=0.516560, validation/loss=2.105031, validation/num_examples=50000
I0319 05:50:03.601549 139592107800320 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.448486328125, loss=2.8797688484191895
I0319 05:53:45.564484 139592099407616 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.3451255559921265, loss=2.7555904388427734
I0319 05:54:08.779581 139793440028480 spec.py:321] Evaluating on the training split.
I0319 05:54:22.686720 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 05:54:46.443847 139793440028480 spec.py:349] Evaluating on the test split.
I0319 05:54:48.049835 139793440028480 submission_runner.py:420] Time since start: 9479.95s, 	Step: 20053, 	{'train/accuracy': 0.5743359327316284, 'train/loss': 1.8197087049484253, 'validation/accuracy': 0.5245999693870544, 'validation/loss': 2.067073345184326, 'validation/num_examples': 50000, 'test/accuracy': 0.41590002179145813, 'test/loss': 2.6983675956726074, 'test/num_examples': 10000, 'score': 8867.457782268524, 'total_duration': 9479.948509216309, 'accumulated_submission_time': 8867.457782268524, 'accumulated_eval_time': 610.7395515441895, 'accumulated_logging_time': 0.6343317031860352}
I0319 05:54:48.067730 139592107800320 logging_writer.py:48] [20053] accumulated_eval_time=610.739552, accumulated_logging_time=0.634332, accumulated_submission_time=8867.457782, global_step=20053, preemption_count=0, score=8867.457782, test/accuracy=0.415900, test/loss=2.698368, test/num_examples=10000, total_duration=9479.948509, train/accuracy=0.574336, train/loss=1.819709, validation/accuracy=0.524600, validation/loss=2.067073, validation/num_examples=50000
I0319 05:58:03.894927 139592099407616 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.1868268251419067, loss=3.6148602962493896
I0319 06:01:47.225834 139592107800320 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.3473941087722778, loss=3.0429859161376953
I0319 06:01:48.317000 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:02:02.496178 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:02:24.462857 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:02:26.090214 139793440028480 submission_runner.py:420] Time since start: 9937.99s, 	Step: 21004, 	{'train/accuracy': 0.5786718726158142, 'train/loss': 1.80045747756958, 'validation/accuracy': 0.5393199920654297, 'validation/loss': 1.980970859527588, 'validation/num_examples': 50000, 'test/accuracy': 0.429500013589859, 'test/loss': 2.6035759449005127, 'test/num_examples': 10000, 'score': 9287.645205974579, 'total_duration': 9937.988888502121, 'accumulated_submission_time': 9287.645205974579, 'accumulated_eval_time': 648.5127742290497, 'accumulated_logging_time': 0.6619973182678223}
I0319 06:02:26.113582 139592099407616 logging_writer.py:48] [21004] accumulated_eval_time=648.512774, accumulated_logging_time=0.661997, accumulated_submission_time=9287.645206, global_step=21004, preemption_count=0, score=9287.645206, test/accuracy=0.429500, test/loss=2.603576, test/num_examples=10000, total_duration=9937.988889, train/accuracy=0.578672, train/loss=1.800457, validation/accuracy=0.539320, validation/loss=1.980971, validation/num_examples=50000
I0319 06:06:04.737618 139592107800320 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.3061528205871582, loss=2.9564599990844727
I0319 06:09:26.208259 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:09:40.793661 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:10:00.515425 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:10:02.135244 139793440028480 submission_runner.py:420] Time since start: 10394.03s, 	Step: 21948, 	{'train/accuracy': 0.5824413895606995, 'train/loss': 1.7962543964385986, 'validation/accuracy': 0.5390200018882751, 'validation/loss': 2.003816843032837, 'validation/num_examples': 50000, 'test/accuracy': 0.42980003356933594, 'test/loss': 2.6617414951324463, 'test/num_examples': 10000, 'score': 9707.678730726242, 'total_duration': 10394.033889055252, 'accumulated_submission_time': 9707.678730726242, 'accumulated_eval_time': 684.4397387504578, 'accumulated_logging_time': 0.695131778717041}
I0319 06:10:02.161803 139592099407616 logging_writer.py:48] [21948] accumulated_eval_time=684.439739, accumulated_logging_time=0.695132, accumulated_submission_time=9707.678731, global_step=21948, preemption_count=0, score=9707.678731, test/accuracy=0.429800, test/loss=2.661741, test/num_examples=10000, total_duration=10394.033889, train/accuracy=0.582441, train/loss=1.796254, validation/accuracy=0.539020, validation/loss=2.003817, validation/num_examples=50000
I0319 06:10:23.421393 139592107800320 logging_writer.py:48] [22000] global_step=22000, grad_norm=1.1069762706756592, loss=4.196591854095459
I0319 06:14:06.117296 139592099407616 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.2135765552520752, loss=5.080378532409668
I0319 06:17:02.364677 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:17:13.050820 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:17:35.555066 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:17:37.159638 139793440028480 submission_runner.py:420] Time since start: 10849.06s, 	Step: 22893, 	{'train/accuracy': 0.5976952910423279, 'train/loss': 1.7223659753799438, 'validation/accuracy': 0.5474599599838257, 'validation/loss': 1.9510140419006348, 'validation/num_examples': 50000, 'test/accuracy': 0.4353000223636627, 'test/loss': 2.588578224182129, 'test/num_examples': 10000, 'score': 10127.819084882736, 'total_duration': 10849.058310508728, 'accumulated_submission_time': 10127.819084882736, 'accumulated_eval_time': 719.2346954345703, 'accumulated_logging_time': 0.7334194183349609}
I0319 06:17:37.177234 139592107800320 logging_writer.py:48] [22893] accumulated_eval_time=719.234695, accumulated_logging_time=0.733419, accumulated_submission_time=10127.819085, global_step=22893, preemption_count=0, score=10127.819085, test/accuracy=0.435300, test/loss=2.588578, test/num_examples=10000, total_duration=10849.058311, train/accuracy=0.597695, train/loss=1.722366, validation/accuracy=0.547460, validation/loss=1.951014, validation/num_examples=50000
I0319 06:18:20.416865 139592099407616 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.4203543663024902, loss=2.7390332221984863
I0319 06:22:03.451525 139592107800320 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.2760335206985474, loss=2.6255199909210205
I0319 06:24:37.250976 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:24:48.153576 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:25:08.675745 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:25:10.281903 139793440028480 submission_runner.py:420] Time since start: 11302.18s, 	Step: 23845, 	{'train/accuracy': 0.6253319978713989, 'train/loss': 1.5792518854141235, 'validation/accuracy': 0.559179961681366, 'validation/loss': 1.8945820331573486, 'validation/num_examples': 50000, 'test/accuracy': 0.4418000280857086, 'test/loss': 2.5550386905670166, 'test/num_examples': 10000, 'score': 10547.828410625458, 'total_duration': 11302.18057179451, 'accumulated_submission_time': 10547.828410625458, 'accumulated_eval_time': 752.2656173706055, 'accumulated_logging_time': 0.7631549835205078}
I0319 06:25:10.312101 139592099407616 logging_writer.py:48] [23845] accumulated_eval_time=752.265617, accumulated_logging_time=0.763155, accumulated_submission_time=10547.828411, global_step=23845, preemption_count=0, score=10547.828411, test/accuracy=0.441800, test/loss=2.555039, test/num_examples=10000, total_duration=11302.180572, train/accuracy=0.625332, train/loss=1.579252, validation/accuracy=0.559180, validation/loss=1.894582, validation/num_examples=50000
I0319 06:26:15.117422 139592107800320 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.5457274913787842, loss=2.857672691345215
I0319 06:29:59.945240 139592099407616 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.386843204498291, loss=2.76306414604187
I0319 06:32:10.649319 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:32:21.217854 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:32:41.647151 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:32:43.262655 139793440028480 submission_runner.py:420] Time since start: 11755.16s, 	Step: 24793, 	{'train/accuracy': 0.6098437309265137, 'train/loss': 1.6432502269744873, 'validation/accuracy': 0.5692200064659119, 'validation/loss': 1.8410288095474243, 'validation/num_examples': 50000, 'test/accuracy': 0.4513000249862671, 'test/loss': 2.485306739807129, 'test/num_examples': 10000, 'score': 10968.10272693634, 'total_duration': 11755.16133093834, 'accumulated_submission_time': 10968.10272693634, 'accumulated_eval_time': 784.8789601325989, 'accumulated_logging_time': 0.804556131362915}
I0319 06:32:43.280634 139592107800320 logging_writer.py:48] [24793] accumulated_eval_time=784.878960, accumulated_logging_time=0.804556, accumulated_submission_time=10968.102727, global_step=24793, preemption_count=0, score=10968.102727, test/accuracy=0.451300, test/loss=2.485307, test/num_examples=10000, total_duration=11755.161331, train/accuracy=0.609844, train/loss=1.643250, validation/accuracy=0.569220, validation/loss=1.841029, validation/num_examples=50000
I0319 06:34:10.990359 139592099407616 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.082851767539978, loss=5.411211967468262
I0319 06:37:55.843203 139592107800320 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.099556565284729, loss=4.0825347900390625
I0319 06:39:43.292318 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:39:53.468536 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:40:14.491104 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:40:16.101050 139793440028480 submission_runner.py:420] Time since start: 12208.00s, 	Step: 25742, 	{'train/accuracy': 0.6162499785423279, 'train/loss': 1.6152305603027344, 'validation/accuracy': 0.5685799717903137, 'validation/loss': 1.8381229639053345, 'validation/num_examples': 50000, 'test/accuracy': 0.4571000337600708, 'test/loss': 2.490128517150879, 'test/num_examples': 10000, 'score': 11388.05167388916, 'total_duration': 12207.999715566635, 'accumulated_submission_time': 11388.05167388916, 'accumulated_eval_time': 817.6876864433289, 'accumulated_logging_time': 0.8331425189971924}
I0319 06:40:16.118671 139592099407616 logging_writer.py:48] [25742] accumulated_eval_time=817.687686, accumulated_logging_time=0.833143, accumulated_submission_time=11388.051674, global_step=25742, preemption_count=0, score=11388.051674, test/accuracy=0.457100, test/loss=2.490129, test/num_examples=10000, total_duration=12207.999716, train/accuracy=0.616250, train/loss=1.615231, validation/accuracy=0.568580, validation/loss=1.838123, validation/num_examples=50000
I0319 06:42:06.488230 139592107800320 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.2611452341079712, loss=2.755286931991577
I0319 06:45:50.334099 139592099407616 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.3613688945770264, loss=2.8078675270080566
I0319 06:47:16.247858 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:47:26.507219 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:47:49.667265 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:47:51.260776 139793440028480 submission_runner.py:420] Time since start: 12663.16s, 	Step: 26694, 	{'train/accuracy': 0.6269335746765137, 'train/loss': 1.5706802606582642, 'validation/accuracy': 0.5753399729728699, 'validation/loss': 1.8144735097885132, 'validation/num_examples': 50000, 'test/accuracy': 0.45600003004074097, 'test/loss': 2.4600064754486084, 'test/num_examples': 10000, 'score': 11808.117844104767, 'total_duration': 12663.159456729889, 'accumulated_submission_time': 11808.117844104767, 'accumulated_eval_time': 852.7006220817566, 'accumulated_logging_time': 0.8609375953674316}
I0319 06:47:51.278333 139592107800320 logging_writer.py:48] [26694] accumulated_eval_time=852.700622, accumulated_logging_time=0.860938, accumulated_submission_time=11808.117844, global_step=26694, preemption_count=0, score=11808.117844, test/accuracy=0.456000, test/loss=2.460006, test/num_examples=10000, total_duration=12663.159457, train/accuracy=0.626934, train/loss=1.570680, validation/accuracy=0.575340, validation/loss=1.814474, validation/num_examples=50000
I0319 06:50:03.886143 139592099407616 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.3320890665054321, loss=2.619628429412842
I0319 06:53:47.404539 139592107800320 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.0837571620941162, loss=4.455069541931152
I0319 06:54:51.622917 139793440028480 spec.py:321] Evaluating on the training split.
I0319 06:55:01.767661 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 06:55:25.378565 139793440028480 spec.py:349] Evaluating on the test split.
I0319 06:55:26.974603 139793440028480 submission_runner.py:420] Time since start: 13118.87s, 	Step: 27644, 	{'train/accuracy': 0.6217382550239563, 'train/loss': 1.6179511547088623, 'validation/accuracy': 0.5809400081634521, 'validation/loss': 1.8126275539398193, 'validation/num_examples': 50000, 'test/accuracy': 0.4626000225543976, 'test/loss': 2.4590179920196533, 'test/num_examples': 10000, 'score': 12228.40169930458, 'total_duration': 13118.873286247253, 'accumulated_submission_time': 12228.40169930458, 'accumulated_eval_time': 888.0523357391357, 'accumulated_logging_time': 0.8876233100891113}
I0319 06:55:26.995508 139592099407616 logging_writer.py:48] [27644] accumulated_eval_time=888.052336, accumulated_logging_time=0.887623, accumulated_submission_time=12228.401699, global_step=27644, preemption_count=0, score=12228.401699, test/accuracy=0.462600, test/loss=2.459018, test/num_examples=10000, total_duration=13118.873286, train/accuracy=0.621738, train/loss=1.617951, validation/accuracy=0.580940, validation/loss=1.812628, validation/num_examples=50000
I0319 06:58:02.571492 139592107800320 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.1189134120941162, loss=5.272117614746094
I0319 07:01:46.188598 139592099407616 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.2606003284454346, loss=2.927685499191284
I0319 07:02:27.092885 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:02:37.560768 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:02:58.494340 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:03:00.107257 139793440028480 submission_runner.py:420] Time since start: 13572.01s, 	Step: 28593, 	{'train/accuracy': 0.6262304782867432, 'train/loss': 1.588721752166748, 'validation/accuracy': 0.5800399780273438, 'validation/loss': 1.7903332710266113, 'validation/num_examples': 50000, 'test/accuracy': 0.4634000360965729, 'test/loss': 2.4371824264526367, 'test/num_examples': 10000, 'score': 12648.437604665756, 'total_duration': 13572.005926132202, 'accumulated_submission_time': 12648.437604665756, 'accumulated_eval_time': 921.0666959285736, 'accumulated_logging_time': 0.9176719188690186}
I0319 07:03:00.129391 139592107800320 logging_writer.py:48] [28593] accumulated_eval_time=921.066696, accumulated_logging_time=0.917672, accumulated_submission_time=12648.437605, global_step=28593, preemption_count=0, score=12648.437605, test/accuracy=0.463400, test/loss=2.437182, test/num_examples=10000, total_duration=13572.005926, train/accuracy=0.626230, train/loss=1.588722, validation/accuracy=0.580040, validation/loss=1.790333, validation/num_examples=50000
I0319 07:05:58.849573 139592099407616 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.1749967336654663, loss=3.366719961166382
I0319 07:09:42.975940 139592107800320 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.339693307876587, loss=2.5332531929016113
I0319 07:10:00.431410 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:10:10.979199 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:10:33.107957 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:10:34.712537 139793440028480 submission_runner.py:420] Time since start: 14026.61s, 	Step: 29541, 	{'train/accuracy': 0.6416601538658142, 'train/loss': 1.495627522468567, 'validation/accuracy': 0.5916599631309509, 'validation/loss': 1.7349510192871094, 'validation/num_examples': 50000, 'test/accuracy': 0.4750000238418579, 'test/loss': 2.368985891342163, 'test/num_examples': 10000, 'score': 13068.677939653397, 'total_duration': 14026.611220121384, 'accumulated_submission_time': 13068.677939653397, 'accumulated_eval_time': 955.3478348255157, 'accumulated_logging_time': 0.9493212699890137}
I0319 07:10:34.729521 139592099407616 logging_writer.py:48] [29541] accumulated_eval_time=955.347835, accumulated_logging_time=0.949321, accumulated_submission_time=13068.677940, global_step=29541, preemption_count=0, score=13068.677940, test/accuracy=0.475000, test/loss=2.368986, test/num_examples=10000, total_duration=14026.611220, train/accuracy=0.641660, train/loss=1.495628, validation/accuracy=0.591660, validation/loss=1.734951, validation/num_examples=50000
I0319 07:13:56.037868 139592107800320 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.206122636795044, loss=5.120236396789551
I0319 07:17:34.850473 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:17:44.967936 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:18:08.277778 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:18:09.886666 139793440028480 submission_runner.py:420] Time since start: 14481.79s, 	Step: 30487, 	{'train/accuracy': 0.6626757383346558, 'train/loss': 1.4161900281906128, 'validation/accuracy': 0.5930399894714355, 'validation/loss': 1.7210310697555542, 'validation/num_examples': 50000, 'test/accuracy': 0.4743000268936157, 'test/loss': 2.373077869415283, 'test/num_examples': 10000, 'score': 13488.736578464508, 'total_duration': 14481.785346269608, 'accumulated_submission_time': 13488.736578464508, 'accumulated_eval_time': 990.3840420246124, 'accumulated_logging_time': 0.9769237041473389}
I0319 07:18:09.904753 139592099407616 logging_writer.py:48] [30487] accumulated_eval_time=990.384042, accumulated_logging_time=0.976924, accumulated_submission_time=13488.736578, global_step=30487, preemption_count=0, score=13488.736578, test/accuracy=0.474300, test/loss=2.373078, test/num_examples=10000, total_duration=14481.785346, train/accuracy=0.662676, train/loss=1.416190, validation/accuracy=0.593040, validation/loss=1.721031, validation/num_examples=50000
I0319 07:18:15.507218 139592107800320 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.2609450817108154, loss=3.9316508769989014
I0319 07:21:55.481967 139592099407616 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.325124979019165, loss=2.543081521987915
I0319 07:25:10.032585 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:25:20.503172 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:25:44.203985 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:25:45.808290 139793440028480 submission_runner.py:420] Time since start: 14937.71s, 	Step: 31435, 	{'train/accuracy': 0.6389257907867432, 'train/loss': 1.495690941810608, 'validation/accuracy': 0.5963000059127808, 'validation/loss': 1.6960092782974243, 'validation/num_examples': 50000, 'test/accuracy': 0.4808000326156616, 'test/loss': 2.3537442684173584, 'test/num_examples': 10000, 'score': 13908.802273988724, 'total_duration': 14937.706971168518, 'accumulated_submission_time': 13908.802273988724, 'accumulated_eval_time': 1026.1597921848297, 'accumulated_logging_time': 1.0043036937713623}
I0319 07:25:45.826245 139592107800320 logging_writer.py:48] [31435] accumulated_eval_time=1026.159792, accumulated_logging_time=1.004304, accumulated_submission_time=13908.802274, global_step=31435, preemption_count=0, score=13908.802274, test/accuracy=0.480800, test/loss=2.353744, test/num_examples=10000, total_duration=14937.706971, train/accuracy=0.638926, train/loss=1.495691, validation/accuracy=0.596300, validation/loss=1.696009, validation/num_examples=50000
I0319 07:26:12.264510 139592099407616 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.2758537530899048, loss=2.592177629470825
I0319 07:29:54.765989 139592107800320 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.3422822952270508, loss=2.5301530361175537
I0319 07:32:46.159759 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:32:56.806035 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:33:17.462816 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:33:19.067502 139793440028480 submission_runner.py:420] Time since start: 15390.97s, 	Step: 32384, 	{'train/accuracy': 0.6537694931030273, 'train/loss': 1.425926685333252, 'validation/accuracy': 0.6037999987602234, 'validation/loss': 1.657766342163086, 'validation/num_examples': 50000, 'test/accuracy': 0.48410001397132874, 'test/loss': 2.30265212059021, 'test/num_examples': 10000, 'score': 14329.074410438538, 'total_duration': 15390.966176271439, 'accumulated_submission_time': 14329.074410438538, 'accumulated_eval_time': 1059.067539691925, 'accumulated_logging_time': 1.0317492485046387}
I0319 07:33:19.087684 139592099407616 logging_writer.py:48] [32384] accumulated_eval_time=1059.067540, accumulated_logging_time=1.031749, accumulated_submission_time=14329.074410, global_step=32384, preemption_count=0, score=14329.074410, test/accuracy=0.484100, test/loss=2.302652, test/num_examples=10000, total_duration=15390.966176, train/accuracy=0.653769, train/loss=1.425927, validation/accuracy=0.603800, validation/loss=1.657766, validation/num_examples=50000
I0319 07:34:06.519882 139592107800320 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.1218544244766235, loss=5.028632640838623
I0319 07:37:51.207100 139592099407616 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.3369139432907104, loss=2.4405853748321533
I0319 07:40:19.079756 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:40:29.643871 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:40:50.358290 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:40:51.973402 139793440028480 submission_runner.py:420] Time since start: 15843.87s, 	Step: 33332, 	{'train/accuracy': 0.6590429544448853, 'train/loss': 1.4059785604476929, 'validation/accuracy': 0.6047199964523315, 'validation/loss': 1.661354899406433, 'validation/num_examples': 50000, 'test/accuracy': 0.4824000298976898, 'test/loss': 2.321087121963501, 'test/num_examples': 10000, 'score': 14749.003374099731, 'total_duration': 15843.872071027756, 'accumulated_submission_time': 14749.003374099731, 'accumulated_eval_time': 1091.961189031601, 'accumulated_logging_time': 1.0624501705169678}
I0319 07:40:51.996708 139592107800320 logging_writer.py:48] [33332] accumulated_eval_time=1091.961189, accumulated_logging_time=1.062450, accumulated_submission_time=14749.003374, global_step=33332, preemption_count=0, score=14749.003374, test/accuracy=0.482400, test/loss=2.321087, test/num_examples=10000, total_duration=15843.872071, train/accuracy=0.659043, train/loss=1.405979, validation/accuracy=0.604720, validation/loss=1.661355, validation/num_examples=50000
I0319 07:42:03.606229 139592099407616 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.23431396484375, loss=5.181795120239258
I0319 07:45:47.879312 139592107800320 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.157982587814331, loss=5.1944684982299805
I0319 07:47:52.214277 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:48:02.633040 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:48:24.406834 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:48:26.019233 139793440028480 submission_runner.py:420] Time since start: 16297.92s, 	Step: 34279, 	{'train/accuracy': 0.660937488079071, 'train/loss': 1.4096660614013672, 'validation/accuracy': 0.6099599599838257, 'validation/loss': 1.627068042755127, 'validation/num_examples': 50000, 'test/accuracy': 0.49410003423690796, 'test/loss': 2.2648959159851074, 'test/num_examples': 10000, 'score': 15169.159571886063, 'total_duration': 16297.917911052704, 'accumulated_submission_time': 15169.159571886063, 'accumulated_eval_time': 1125.7661588191986, 'accumulated_logging_time': 1.0957262516021729}
I0319 07:48:26.040793 139592099407616 logging_writer.py:48] [34279] accumulated_eval_time=1125.766159, accumulated_logging_time=1.095726, accumulated_submission_time=15169.159572, global_step=34279, preemption_count=0, score=15169.159572, test/accuracy=0.494100, test/loss=2.264896, test/num_examples=10000, total_duration=16297.917911, train/accuracy=0.660937, train/loss=1.409666, validation/accuracy=0.609960, validation/loss=1.627068, validation/num_examples=50000
I0319 07:50:01.080258 139592107800320 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.3216747045516968, loss=2.335186004638672
I0319 07:53:45.423410 139592099407616 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.3042995929718018, loss=2.54325532913208
I0319 07:55:26.256992 139793440028480 spec.py:321] Evaluating on the training split.
I0319 07:55:36.813369 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 07:56:00.552755 139793440028480 spec.py:349] Evaluating on the test split.
I0319 07:56:02.164427 139793440028480 submission_runner.py:420] Time since start: 16754.06s, 	Step: 35226, 	{'train/accuracy': 0.6612108945846558, 'train/loss': 1.4239627122879028, 'validation/accuracy': 0.6139400005340576, 'validation/loss': 1.642770767211914, 'validation/num_examples': 50000, 'test/accuracy': 0.49320003390312195, 'test/loss': 2.291342258453369, 'test/num_examples': 10000, 'score': 15589.314702033997, 'total_duration': 16754.06310224533, 'accumulated_submission_time': 15589.314702033997, 'accumulated_eval_time': 1161.6736254692078, 'accumulated_logging_time': 1.1264140605926514}
I0319 07:56:02.182506 139592107800320 logging_writer.py:48] [35226] accumulated_eval_time=1161.673625, accumulated_logging_time=1.126414, accumulated_submission_time=15589.314702, global_step=35226, preemption_count=0, score=15589.314702, test/accuracy=0.493200, test/loss=2.291342, test/num_examples=10000, total_duration=16754.063102, train/accuracy=0.661211, train/loss=1.423963, validation/accuracy=0.613940, validation/loss=1.642771, validation/num_examples=50000
I0319 07:58:00.669298 139592099407616 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.259874939918518, loss=3.3039047718048096
I0319 08:01:44.752707 139592107800320 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.3320037126541138, loss=2.2458012104034424
I0319 08:03:02.369546 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:03:12.636471 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:03:33.072607 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:03:34.693093 139793440028480 submission_runner.py:420] Time since start: 17206.59s, 	Step: 36175, 	{'train/accuracy': 0.6728515625, 'train/loss': 1.3312591314315796, 'validation/accuracy': 0.6194999814033508, 'validation/loss': 1.580639362335205, 'validation/num_examples': 50000, 'test/accuracy': 0.49650001525878906, 'test/loss': 2.235912561416626, 'test/num_examples': 10000, 'score': 16009.440279960632, 'total_duration': 17206.59175515175, 'accumulated_submission_time': 16009.440279960632, 'accumulated_eval_time': 1193.9971752166748, 'accumulated_logging_time': 1.1534278392791748}
I0319 08:03:34.716095 139592099407616 logging_writer.py:48] [36175] accumulated_eval_time=1193.997175, accumulated_logging_time=1.153428, accumulated_submission_time=16009.440280, global_step=36175, preemption_count=0, score=16009.440280, test/accuracy=0.496500, test/loss=2.235913, test/num_examples=10000, total_duration=17206.591755, train/accuracy=0.672852, train/loss=1.331259, validation/accuracy=0.619500, validation/loss=1.580639, validation/num_examples=50000
I0319 08:05:57.401787 139592107800320 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.2253769636154175, loss=4.243633270263672
I0319 08:09:41.562973 139592099407616 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.2550108432769775, loss=3.0718955993652344
I0319 08:10:34.723426 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:10:45.179535 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:11:05.313288 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:11:06.926263 139793440028480 submission_runner.py:420] Time since start: 17658.82s, 	Step: 37120, 	{'train/accuracy': 0.6825780868530273, 'train/loss': 1.2980029582977295, 'validation/accuracy': 0.6173999905586243, 'validation/loss': 1.5963057279586792, 'validation/num_examples': 50000, 'test/accuracy': 0.49410003423690796, 'test/loss': 2.2541465759277344, 'test/num_examples': 10000, 'score': 16429.387169122696, 'total_duration': 17658.824934005737, 'accumulated_submission_time': 16429.387169122696, 'accumulated_eval_time': 1226.2000088691711, 'accumulated_logging_time': 1.1858303546905518}
I0319 08:11:06.950443 139592107800320 logging_writer.py:48] [37120] accumulated_eval_time=1226.200009, accumulated_logging_time=1.185830, accumulated_submission_time=16429.387169, global_step=37120, preemption_count=0, score=16429.387169, test/accuracy=0.494100, test/loss=2.254147, test/num_examples=10000, total_duration=17658.824934, train/accuracy=0.682578, train/loss=1.298003, validation/accuracy=0.617400, validation/loss=1.596306, validation/num_examples=50000
I0319 08:13:53.849069 139592099407616 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.4418169260025024, loss=2.2615909576416016
I0319 08:17:38.517453 139592107800320 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.2974480390548706, loss=2.4117331504821777
I0319 08:18:06.931279 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:18:17.338129 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:18:40.721267 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:18:42.325104 139793440028480 submission_runner.py:420] Time since start: 18114.22s, 	Step: 38065, 	{'train/accuracy': 0.6715039014816284, 'train/loss': 1.361115574836731, 'validation/accuracy': 0.6234599947929382, 'validation/loss': 1.5808427333831787, 'validation/num_examples': 50000, 'test/accuracy': 0.49500003457069397, 'test/loss': 2.2400283813476562, 'test/num_examples': 10000, 'score': 16849.301491498947, 'total_duration': 18114.223784923553, 'accumulated_submission_time': 16849.301491498947, 'accumulated_eval_time': 1261.5938396453857, 'accumulated_logging_time': 1.2241370677947998}
I0319 08:18:42.346924 139592099407616 logging_writer.py:48] [38065] accumulated_eval_time=1261.593840, accumulated_logging_time=1.224137, accumulated_submission_time=16849.301491, global_step=38065, preemption_count=0, score=16849.301491, test/accuracy=0.495000, test/loss=2.240028, test/num_examples=10000, total_duration=18114.223785, train/accuracy=0.671504, train/loss=1.361116, validation/accuracy=0.623460, validation/loss=1.580843, validation/num_examples=50000
I0319 08:21:53.135072 139592107800320 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.3100666999816895, loss=2.4818291664123535
I0319 08:25:37.583287 139592099407616 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.2510281801223755, loss=3.4464027881622314
I0319 08:25:42.676126 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:25:53.029701 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:26:16.205783 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:26:17.812050 139793440028480 submission_runner.py:420] Time since start: 18569.71s, 	Step: 39013, 	{'train/accuracy': 0.6758398413658142, 'train/loss': 1.339189887046814, 'validation/accuracy': 0.6258999705314636, 'validation/loss': 1.5784555673599243, 'validation/num_examples': 50000, 'test/accuracy': 0.5058000087738037, 'test/loss': 2.232527017593384, 'test/num_examples': 10000, 'score': 17269.56613779068, 'total_duration': 18569.710734844208, 'accumulated_submission_time': 17269.56613779068, 'accumulated_eval_time': 1296.7297668457031, 'accumulated_logging_time': 1.2588355541229248}
I0319 08:26:17.831883 139592107800320 logging_writer.py:48] [39013] accumulated_eval_time=1296.729767, accumulated_logging_time=1.258836, accumulated_submission_time=17269.566138, global_step=39013, preemption_count=0, score=17269.566138, test/accuracy=0.505800, test/loss=2.232527, test/num_examples=10000, total_duration=18569.710735, train/accuracy=0.675840, train/loss=1.339190, validation/accuracy=0.625900, validation/loss=1.578456, validation/num_examples=50000
I0319 08:29:52.119685 139592099407616 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.2783201932907104, loss=3.457026481628418
I0319 08:33:17.982425 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:33:28.564280 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:33:51.395850 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:33:52.999204 139793440028480 submission_runner.py:420] Time since start: 19024.90s, 	Step: 39961, 	{'train/accuracy': 0.6796289086341858, 'train/loss': 1.3091715574264526, 'validation/accuracy': 0.6236000061035156, 'validation/loss': 1.5663096904754639, 'validation/num_examples': 50000, 'test/accuracy': 0.5023000240325928, 'test/loss': 2.229196548461914, 'test/num_examples': 10000, 'score': 17689.657068014145, 'total_duration': 19024.8978869915, 'accumulated_submission_time': 17689.657068014145, 'accumulated_eval_time': 1331.7465584278107, 'accumulated_logging_time': 1.286801815032959}
I0319 08:33:53.017891 139592107800320 logging_writer.py:48] [39961] accumulated_eval_time=1331.746558, accumulated_logging_time=1.286802, accumulated_submission_time=17689.657068, global_step=39961, preemption_count=0, score=17689.657068, test/accuracy=0.502300, test/loss=2.229197, test/num_examples=10000, total_duration=19024.897887, train/accuracy=0.679629, train/loss=1.309172, validation/accuracy=0.623600, validation/loss=1.566310, validation/num_examples=50000
I0319 08:34:09.407101 139592099407616 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.3691831827163696, loss=2.3640544414520264
I0319 08:37:54.117606 139592107800320 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.2611000537872314, loss=4.297980785369873
I0319 08:40:53.450973 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:41:04.509127 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:41:27.737732 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:41:29.343702 139793440028480 submission_runner.py:420] Time since start: 19481.24s, 	Step: 40900, 	{'train/accuracy': 0.6773437261581421, 'train/loss': 1.3334202766418457, 'validation/accuracy': 0.6313799619674683, 'validation/loss': 1.557999610900879, 'validation/num_examples': 50000, 'test/accuracy': 0.5042999982833862, 'test/loss': 2.2077109813690186, 'test/num_examples': 10000, 'score': 18109.708364248276, 'total_duration': 19481.242381095886, 'accumulated_submission_time': 18109.708364248276, 'accumulated_eval_time': 1367.6392889022827, 'accumulated_logging_time': 1.6361103057861328}
I0319 08:41:29.365068 139592099407616 logging_writer.py:48] [40900] accumulated_eval_time=1367.639289, accumulated_logging_time=1.636110, accumulated_submission_time=18109.708364, global_step=40900, preemption_count=0, score=18109.708364, test/accuracy=0.504300, test/loss=2.207711, test/num_examples=10000, total_duration=19481.242381, train/accuracy=0.677344, train/loss=1.333420, validation/accuracy=0.631380, validation/loss=1.558000, validation/num_examples=50000
I0319 08:42:10.024194 139592107800320 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.4048553705215454, loss=2.2899370193481445
I0319 08:45:55.554517 139592099407616 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.5340206623077393, loss=2.4167895317077637
I0319 08:48:29.628379 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:48:40.074156 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:49:00.826623 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:49:02.440982 139793440028480 submission_runner.py:420] Time since start: 19934.34s, 	Step: 41844, 	{'train/accuracy': 0.6817968487739563, 'train/loss': 1.2940773963928223, 'validation/accuracy': 0.6334599852561951, 'validation/loss': 1.516237497329712, 'validation/num_examples': 50000, 'test/accuracy': 0.5106000304222107, 'test/loss': 2.169159412384033, 'test/num_examples': 10000, 'score': 18529.90984416008, 'total_duration': 19934.339613437653, 'accumulated_submission_time': 18529.90984416008, 'accumulated_eval_time': 1400.451861858368, 'accumulated_logging_time': 1.6668717861175537}
I0319 08:49:02.467480 139592107800320 logging_writer.py:48] [41844] accumulated_eval_time=1400.451862, accumulated_logging_time=1.666872, accumulated_submission_time=18529.909844, global_step=41844, preemption_count=0, score=18529.909844, test/accuracy=0.510600, test/loss=2.169159, test/num_examples=10000, total_duration=19934.339613, train/accuracy=0.681797, train/loss=1.294077, validation/accuracy=0.633460, validation/loss=1.516237, validation/num_examples=50000
I0319 08:50:08.915677 139592099407616 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.217827558517456, loss=4.743370056152344
I0319 08:53:53.358599 139592107800320 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.2218809127807617, loss=3.069617509841919
I0319 08:56:02.762448 139793440028480 spec.py:321] Evaluating on the training split.
I0319 08:56:13.284267 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 08:56:35.968001 139793440028480 spec.py:349] Evaluating on the test split.
I0319 08:56:37.588633 139793440028480 submission_runner.py:420] Time since start: 20389.49s, 	Step: 42788, 	{'train/accuracy': 0.6926367282867432, 'train/loss': 1.2557886838912964, 'validation/accuracy': 0.6359399557113647, 'validation/loss': 1.5043929815292358, 'validation/num_examples': 50000, 'test/accuracy': 0.511900007724762, 'test/loss': 2.1608686447143555, 'test/num_examples': 10000, 'score': 18950.14275956154, 'total_duration': 20389.487313508987, 'accumulated_submission_time': 18950.14275956154, 'accumulated_eval_time': 1435.2780511379242, 'accumulated_logging_time': 1.7039804458618164}
I0319 08:56:37.607994 139592099407616 logging_writer.py:48] [42788] accumulated_eval_time=1435.278051, accumulated_logging_time=1.703980, accumulated_submission_time=18950.142760, global_step=42788, preemption_count=0, score=18950.142760, test/accuracy=0.511900, test/loss=2.160869, test/num_examples=10000, total_duration=20389.487314, train/accuracy=0.692637, train/loss=1.255789, validation/accuracy=0.635940, validation/loss=1.504393, validation/num_examples=50000
I0319 08:58:08.432619 139592107800320 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.445748209953308, loss=2.3585751056671143
I0319 09:01:53.555867 139592099407616 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.2468844652175903, loss=3.8020057678222656
I0319 09:03:37.627706 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:03:47.923527 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:04:10.541494 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:04:12.136629 139793440028480 submission_runner.py:420] Time since start: 20844.04s, 	Step: 43734, 	{'train/accuracy': 0.7052538990974426, 'train/loss': 1.2022165060043335, 'validation/accuracy': 0.6338799595832825, 'validation/loss': 1.5196545124053955, 'validation/num_examples': 50000, 'test/accuracy': 0.5142000317573547, 'test/loss': 2.166313409805298, 'test/num_examples': 10000, 'score': 19370.101238012314, 'total_duration': 20844.03530550003, 'accumulated_submission_time': 19370.101238012314, 'accumulated_eval_time': 1469.7869713306427, 'accumulated_logging_time': 1.7324120998382568}
I0319 09:04:12.158148 139592107800320 logging_writer.py:48] [43734] accumulated_eval_time=1469.786971, accumulated_logging_time=1.732412, accumulated_submission_time=19370.101238, global_step=43734, preemption_count=0, score=19370.101238, test/accuracy=0.514200, test/loss=2.166313, test/num_examples=10000, total_duration=20844.035306, train/accuracy=0.705254, train/loss=1.202217, validation/accuracy=0.633880, validation/loss=1.519655, validation/num_examples=50000
I0319 09:06:07.484148 139592099407616 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.3540542125701904, loss=3.222801446914673
I0319 09:09:52.054644 139592107800320 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.3855265378952026, loss=2.823371648788452
I0319 09:11:12.402498 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:11:22.947683 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:11:43.829066 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:11:45.447950 139793440028480 submission_runner.py:420] Time since start: 21297.35s, 	Step: 44680, 	{'train/accuracy': 0.6914843320846558, 'train/loss': 1.2457656860351562, 'validation/accuracy': 0.6407999992370605, 'validation/loss': 1.4878202676773071, 'validation/num_examples': 50000, 'test/accuracy': 0.5178000330924988, 'test/loss': 2.1108908653259277, 'test/num_examples': 10000, 'score': 19790.28397512436, 'total_duration': 21297.346603393555, 'accumulated_submission_time': 19790.28397512436, 'accumulated_eval_time': 1502.832401752472, 'accumulated_logging_time': 1.763868808746338}
I0319 09:11:45.471117 139592099407616 logging_writer.py:48] [44680] accumulated_eval_time=1502.832402, accumulated_logging_time=1.763869, accumulated_submission_time=19790.283975, global_step=44680, preemption_count=0, score=19790.283975, test/accuracy=0.517800, test/loss=2.110891, test/num_examples=10000, total_duration=21297.346603, train/accuracy=0.691484, train/loss=1.245766, validation/accuracy=0.640800, validation/loss=1.487820, validation/num_examples=50000
I0319 09:14:04.870305 139592107800320 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.3891606330871582, loss=2.7249443531036377
I0319 09:17:50.050043 139592099407616 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.3577258586883545, loss=3.00978422164917
I0319 09:18:45.475387 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:18:56.028760 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:19:16.527797 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:19:18.144761 139793440028480 submission_runner.py:420] Time since start: 21750.04s, 	Step: 45625, 	{'train/accuracy': 0.6982421875, 'train/loss': 1.2468092441558838, 'validation/accuracy': 0.6459800004959106, 'validation/loss': 1.486478567123413, 'validation/num_examples': 50000, 'test/accuracy': 0.5195000171661377, 'test/loss': 2.132629156112671, 'test/num_examples': 10000, 'score': 20210.225008249283, 'total_duration': 21750.043441295624, 'accumulated_submission_time': 20210.225008249283, 'accumulated_eval_time': 1535.5017747879028, 'accumulated_logging_time': 1.7983663082122803}
I0319 09:19:18.168496 139592107800320 logging_writer.py:48] [45625] accumulated_eval_time=1535.501775, accumulated_logging_time=1.798366, accumulated_submission_time=20210.225008, global_step=45625, preemption_count=0, score=20210.225008, test/accuracy=0.519500, test/loss=2.132629, test/num_examples=10000, total_duration=21750.043441, train/accuracy=0.698242, train/loss=1.246809, validation/accuracy=0.645980, validation/loss=1.486479, validation/num_examples=50000
I0319 09:22:02.150659 139592099407616 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.4037564992904663, loss=2.340090036392212
I0319 09:25:46.754942 139592107800320 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.3244242668151855, loss=2.864885091781616
I0319 09:26:18.280696 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:26:28.542872 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:26:49.114741 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:26:50.735551 139793440028480 submission_runner.py:420] Time since start: 22202.63s, 	Step: 46572, 	{'train/accuracy': 0.7062695026397705, 'train/loss': 1.19102144241333, 'validation/accuracy': 0.6459999680519104, 'validation/loss': 1.4620285034179688, 'validation/num_examples': 50000, 'test/accuracy': 0.5289000272750854, 'test/loss': 2.0980584621429443, 'test/num_examples': 10000, 'score': 20630.27354669571, 'total_duration': 22202.634214401245, 'accumulated_submission_time': 20630.27354669571, 'accumulated_eval_time': 1567.9566090106964, 'accumulated_logging_time': 1.8339488506317139}
I0319 09:26:50.760848 139592099407616 logging_writer.py:48] [46572] accumulated_eval_time=1567.956609, accumulated_logging_time=1.833949, accumulated_submission_time=20630.273547, global_step=46572, preemption_count=0, score=20630.273547, test/accuracy=0.528900, test/loss=2.098058, test/num_examples=10000, total_duration=22202.634214, train/accuracy=0.706270, train/loss=1.191021, validation/accuracy=0.646000, validation/loss=1.462029, validation/num_examples=50000
I0319 09:29:59.623726 139592107800320 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.2920116186141968, loss=4.498195171356201
I0319 09:33:43.824688 139592099407616 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.2878429889678955, loss=4.3905863761901855
I0319 09:33:51.111974 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:34:01.175522 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:34:22.820206 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:34:24.429507 139793440028480 submission_runner.py:420] Time since start: 22656.33s, 	Step: 47518, 	{'train/accuracy': 0.69789057970047, 'train/loss': 1.2307801246643066, 'validation/accuracy': 0.6480599641799927, 'validation/loss': 1.466400146484375, 'validation/num_examples': 50000, 'test/accuracy': 0.5198000073432922, 'test/loss': 2.1328284740448, 'test/num_examples': 10000, 'score': 21050.563070058823, 'total_duration': 22656.3281750679, 'accumulated_submission_time': 21050.563070058823, 'accumulated_eval_time': 1601.2741181850433, 'accumulated_logging_time': 1.8691518306732178}
I0319 09:34:24.451959 139592107800320 logging_writer.py:48] [47518] accumulated_eval_time=1601.274118, accumulated_logging_time=1.869152, accumulated_submission_time=21050.563070, global_step=47518, preemption_count=0, score=21050.563070, test/accuracy=0.519800, test/loss=2.132828, test/num_examples=10000, total_duration=22656.328175, train/accuracy=0.697891, train/loss=1.230780, validation/accuracy=0.648060, validation/loss=1.466400, validation/num_examples=50000
I0319 09:37:57.078582 139592099407616 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.3279846906661987, loss=2.2015271186828613
I0319 09:41:24.469951 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:41:34.728384 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:41:54.819932 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:41:56.429734 139793440028480 submission_runner.py:420] Time since start: 23108.33s, 	Step: 48463, 	{'train/accuracy': 0.702441394329071, 'train/loss': 1.1959295272827148, 'validation/accuracy': 0.6495800018310547, 'validation/loss': 1.4339760541915894, 'validation/num_examples': 50000, 'test/accuracy': 0.5285000205039978, 'test/loss': 2.080435037612915, 'test/num_examples': 10000, 'score': 21470.519675970078, 'total_duration': 23108.328401088715, 'accumulated_submission_time': 21470.519675970078, 'accumulated_eval_time': 1633.2338995933533, 'accumulated_logging_time': 1.90122389793396}
I0319 09:41:56.452899 139592107800320 logging_writer.py:48] [48463] accumulated_eval_time=1633.233900, accumulated_logging_time=1.901224, accumulated_submission_time=21470.519676, global_step=48463, preemption_count=0, score=21470.519676, test/accuracy=0.528500, test/loss=2.080435, test/num_examples=10000, total_duration=23108.328401, train/accuracy=0.702441, train/loss=1.195930, validation/accuracy=0.649580, validation/loss=1.433976, validation/num_examples=50000
I0319 09:42:11.706166 139592099407616 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.366066813468933, loss=3.9563915729522705
I0319 09:45:53.873445 139592107800320 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.2733008861541748, loss=3.7208213806152344
I0319 09:48:56.562789 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:49:06.789895 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:49:29.895785 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:49:31.497507 139793440028480 submission_runner.py:420] Time since start: 23563.40s, 	Step: 49408, 	{'train/accuracy': 0.7056054472923279, 'train/loss': 1.1989738941192627, 'validation/accuracy': 0.6522600054740906, 'validation/loss': 1.4502296447753906, 'validation/num_examples': 50000, 'test/accuracy': 0.5303000211715698, 'test/loss': 2.094193696975708, 'test/num_examples': 10000, 'score': 21890.56763291359, 'total_duration': 23563.396186590195, 'accumulated_submission_time': 21890.56763291359, 'accumulated_eval_time': 1668.1686403751373, 'accumulated_logging_time': 1.935361623764038}
I0319 09:49:31.518937 139592099407616 logging_writer.py:48] [49408] accumulated_eval_time=1668.168640, accumulated_logging_time=1.935362, accumulated_submission_time=21890.567633, global_step=49408, preemption_count=0, score=21890.567633, test/accuracy=0.530300, test/loss=2.094194, test/num_examples=10000, total_duration=23563.396187, train/accuracy=0.705605, train/loss=1.198974, validation/accuracy=0.652260, validation/loss=1.450230, validation/num_examples=50000
I0319 09:50:08.787341 139592107800320 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.4301804304122925, loss=2.2543888092041016
I0319 09:53:52.802256 139592099407616 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.3567765951156616, loss=2.174875020980835
I0319 09:56:31.599656 139793440028480 spec.py:321] Evaluating on the training split.
I0319 09:56:41.812848 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 09:57:00.998417 139793440028480 spec.py:349] Evaluating on the test split.
I0319 09:57:02.615264 139793440028480 submission_runner.py:420] Time since start: 24014.51s, 	Step: 50354, 	{'train/accuracy': 0.722460925579071, 'train/loss': 1.118489146232605, 'validation/accuracy': 0.6571399569511414, 'validation/loss': 1.4201762676239014, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.0712265968322754, 'test/num_examples': 10000, 'score': 22310.586025238037, 'total_duration': 24014.513936042786, 'accumulated_submission_time': 22310.586025238037, 'accumulated_eval_time': 1699.1842534542084, 'accumulated_logging_time': 1.9668974876403809}
I0319 09:57:02.641583 139592107800320 logging_writer.py:48] [50354] accumulated_eval_time=1699.184253, accumulated_logging_time=1.966897, accumulated_submission_time=22310.586025, global_step=50354, preemption_count=0, score=22310.586025, test/accuracy=0.531200, test/loss=2.071227, test/num_examples=10000, total_duration=24014.513936, train/accuracy=0.722461, train/loss=1.118489, validation/accuracy=0.657140, validation/loss=1.420176, validation/num_examples=50000
I0319 09:58:04.509876 139592099407616 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.3484364748001099, loss=4.885905742645264
I0319 10:01:49.440369 139592107800320 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.5364243984222412, loss=2.2095112800598145
I0319 10:04:02.984738 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:04:13.469740 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:04:33.583021 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:04:35.208666 139793440028480 submission_runner.py:420] Time since start: 24467.11s, 	Step: 51298, 	{'train/accuracy': 0.7073632478713989, 'train/loss': 1.1812729835510254, 'validation/accuracy': 0.659280002117157, 'validation/loss': 1.4107974767684937, 'validation/num_examples': 50000, 'test/accuracy': 0.5348000526428223, 'test/loss': 2.0475263595581055, 'test/num_examples': 10000, 'score': 22730.86786866188, 'total_duration': 24467.10733628273, 'accumulated_submission_time': 22730.86786866188, 'accumulated_eval_time': 1731.4081916809082, 'accumulated_logging_time': 2.0030345916748047}
I0319 10:04:35.237686 139592099407616 logging_writer.py:48] [51298] accumulated_eval_time=1731.408192, accumulated_logging_time=2.003035, accumulated_submission_time=22730.867869, global_step=51298, preemption_count=0, score=22730.867869, test/accuracy=0.534800, test/loss=2.047526, test/num_examples=10000, total_duration=24467.107336, train/accuracy=0.707363, train/loss=1.181273, validation/accuracy=0.659280, validation/loss=1.410797, validation/num_examples=50000
I0319 10:06:02.068797 139592107800320 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.4875226020812988, loss=2.1351003646850586
I0319 10:09:47.271973 139592099407616 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.3568624258041382, loss=2.7871828079223633
I0319 10:11:35.580561 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:11:45.987605 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:12:05.720897 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:12:07.333566 139793440028480 submission_runner.py:420] Time since start: 24919.23s, 	Step: 52242, 	{'train/accuracy': 0.712890625, 'train/loss': 1.1680288314819336, 'validation/accuracy': 0.6553599834442139, 'validation/loss': 1.410423994064331, 'validation/num_examples': 50000, 'test/accuracy': 0.5373000502586365, 'test/loss': 2.0474627017974854, 'test/num_examples': 10000, 'score': 23151.14921760559, 'total_duration': 24919.23223924637, 'accumulated_submission_time': 23151.14921760559, 'accumulated_eval_time': 1763.161215543747, 'accumulated_logging_time': 2.041849374771118}
I0319 10:12:07.357474 139592107800320 logging_writer.py:48] [52242] accumulated_eval_time=1763.161216, accumulated_logging_time=2.041849, accumulated_submission_time=23151.149218, global_step=52242, preemption_count=0, score=23151.149218, test/accuracy=0.537300, test/loss=2.047463, test/num_examples=10000, total_duration=24919.232239, train/accuracy=0.712891, train/loss=1.168029, validation/accuracy=0.655360, validation/loss=1.410424, validation/num_examples=50000
I0319 10:13:58.601082 139592099407616 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.334483027458191, loss=3.0658700466156006
I0319 10:17:43.545255 139592107800320 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.5350184440612793, loss=2.380197048187256
I0319 10:19:07.636793 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:19:17.971064 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:19:40.050592 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:19:41.656655 139793440028480 submission_runner.py:420] Time since start: 25373.56s, 	Step: 53189, 	{'train/accuracy': 0.7213671803474426, 'train/loss': 1.1424052715301514, 'validation/accuracy': 0.6587399840354919, 'validation/loss': 1.4117166996002197, 'validation/num_examples': 50000, 'test/accuracy': 0.5398000478744507, 'test/loss': 2.046475648880005, 'test/num_examples': 10000, 'score': 23571.366389513016, 'total_duration': 25373.55533504486, 'accumulated_submission_time': 23571.366389513016, 'accumulated_eval_time': 1797.1810853481293, 'accumulated_logging_time': 2.0759410858154297}
I0319 10:19:41.680886 139592099407616 logging_writer.py:48] [53189] accumulated_eval_time=1797.181085, accumulated_logging_time=2.075941, accumulated_submission_time=23571.366390, global_step=53189, preemption_count=0, score=23571.366390, test/accuracy=0.539800, test/loss=2.046476, test/num_examples=10000, total_duration=25373.555335, train/accuracy=0.721367, train/loss=1.142405, validation/accuracy=0.658740, validation/loss=1.411717, validation/num_examples=50000
I0319 10:21:56.498614 139592107800320 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.4189473390579224, loss=2.370284080505371
I0319 10:25:40.535499 139592099407616 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.281341314315796, loss=3.2493860721588135
I0319 10:26:41.784009 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:26:52.089590 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:27:13.595478 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:27:15.202650 139793440028480 submission_runner.py:420] Time since start: 25827.10s, 	Step: 54138, 	{'train/accuracy': 0.7173827886581421, 'train/loss': 1.1344820261001587, 'validation/accuracy': 0.6624199748039246, 'validation/loss': 1.3856710195541382, 'validation/num_examples': 50000, 'test/accuracy': 0.5407000184059143, 'test/loss': 2.0176327228546143, 'test/num_examples': 10000, 'score': 23991.405400276184, 'total_duration': 25827.10133099556, 'accumulated_submission_time': 23991.405400276184, 'accumulated_eval_time': 1830.5997319221497, 'accumulated_logging_time': 2.112729072570801}
I0319 10:27:15.225672 139592107800320 logging_writer.py:48] [54138] accumulated_eval_time=1830.599732, accumulated_logging_time=2.112729, accumulated_submission_time=23991.405400, global_step=54138, preemption_count=0, score=23991.405400, test/accuracy=0.540700, test/loss=2.017633, test/num_examples=10000, total_duration=25827.101331, train/accuracy=0.717383, train/loss=1.134482, validation/accuracy=0.662420, validation/loss=1.385671, validation/num_examples=50000
I0319 10:29:53.470311 139592099407616 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.4637236595153809, loss=2.405325412750244
I0319 10:33:38.339008 139592107800320 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.337457537651062, loss=3.09205961227417
I0319 10:34:15.394712 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:34:25.763834 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:34:47.146112 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:34:48.765024 139793440028480 submission_runner.py:420] Time since start: 26280.66s, 	Step: 55084, 	{'train/accuracy': 0.7164648175239563, 'train/loss': 1.1465487480163574, 'validation/accuracy': 0.6601200103759766, 'validation/loss': 1.3903496265411377, 'validation/num_examples': 50000, 'test/accuracy': 0.5400000214576721, 'test/loss': 2.028998851776123, 'test/num_examples': 10000, 'score': 24411.513561964035, 'total_duration': 26280.66367840767, 'accumulated_submission_time': 24411.513561964035, 'accumulated_eval_time': 1863.9700202941895, 'accumulated_logging_time': 2.145425796508789}
I0319 10:34:48.788944 139592099407616 logging_writer.py:48] [55084] accumulated_eval_time=1863.970020, accumulated_logging_time=2.145426, accumulated_submission_time=24411.513562, global_step=55084, preemption_count=0, score=24411.513562, test/accuracy=0.540000, test/loss=2.028999, test/num_examples=10000, total_duration=26280.663678, train/accuracy=0.716465, train/loss=1.146549, validation/accuracy=0.660120, validation/loss=1.390350, validation/num_examples=50000
I0319 10:37:52.197111 139592107800320 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.497021198272705, loss=2.119913101196289
I0319 10:41:37.503289 139592099407616 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.2662265300750732, loss=4.342633247375488
I0319 10:41:48.886953 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:41:59.245048 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:42:20.124430 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:42:21.746564 139793440028480 submission_runner.py:420] Time since start: 26733.65s, 	Step: 56027, 	{'train/accuracy': 0.7238476276397705, 'train/loss': 1.1132664680480957, 'validation/accuracy': 0.6629799604415894, 'validation/loss': 1.37566339969635, 'validation/num_examples': 50000, 'test/accuracy': 0.5439000129699707, 'test/loss': 2.011918544769287, 'test/num_examples': 10000, 'score': 24831.5508518219, 'total_duration': 26733.64523267746, 'accumulated_submission_time': 24831.5508518219, 'accumulated_eval_time': 1896.8296167850494, 'accumulated_logging_time': 2.1788289546966553}
I0319 10:42:21.769505 139592107800320 logging_writer.py:48] [56027] accumulated_eval_time=1896.829617, accumulated_logging_time=2.178829, accumulated_submission_time=24831.550852, global_step=56027, preemption_count=0, score=24831.550852, test/accuracy=0.543900, test/loss=2.011919, test/num_examples=10000, total_duration=26733.645233, train/accuracy=0.723848, train/loss=1.113266, validation/accuracy=0.662980, validation/loss=1.375663, validation/num_examples=50000
I0319 10:45:49.843182 139592099407616 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.4311463832855225, loss=2.098341226577759
I0319 10:49:22.184639 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:49:32.602266 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:49:52.952504 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:49:54.569236 139793440028480 submission_runner.py:420] Time since start: 27186.47s, 	Step: 56974, 	{'train/accuracy': 0.7383788824081421, 'train/loss': 1.0461022853851318, 'validation/accuracy': 0.6661799550056458, 'validation/loss': 1.3634791374206543, 'validation/num_examples': 50000, 'test/accuracy': 0.5414000153541565, 'test/loss': 2.0018365383148193, 'test/num_examples': 10000, 'score': 25251.902649641037, 'total_duration': 27186.46790075302, 'accumulated_submission_time': 25251.902649641037, 'accumulated_eval_time': 1929.2142486572266, 'accumulated_logging_time': 2.213578462600708}
I0319 10:49:54.596172 139592107800320 logging_writer.py:48] [56974] accumulated_eval_time=1929.214249, accumulated_logging_time=2.213578, accumulated_submission_time=25251.902650, global_step=56974, preemption_count=0, score=25251.902650, test/accuracy=0.541400, test/loss=2.001837, test/num_examples=10000, total_duration=27186.467901, train/accuracy=0.738379, train/loss=1.046102, validation/accuracy=0.666180, validation/loss=1.363479, validation/num_examples=50000
I0319 10:50:05.608113 139592099407616 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.3859819173812866, loss=2.73760986328125
I0319 10:53:46.617615 139592107800320 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.4780268669128418, loss=4.615656852722168
I0319 10:56:54.807941 139793440028480 spec.py:321] Evaluating on the training split.
I0319 10:57:05.341577 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 10:57:24.933296 139793440028480 spec.py:349] Evaluating on the test split.
I0319 10:57:26.550311 139793440028480 submission_runner.py:420] Time since start: 27638.45s, 	Step: 57919, 	{'train/accuracy': 0.7252734303474426, 'train/loss': 1.1150798797607422, 'validation/accuracy': 0.669160008430481, 'validation/loss': 1.3615590333938599, 'validation/num_examples': 50000, 'test/accuracy': 0.5476000308990479, 'test/loss': 2.0163185596466064, 'test/num_examples': 10000, 'score': 25672.05046892166, 'total_duration': 27638.448981523514, 'accumulated_submission_time': 25672.05046892166, 'accumulated_eval_time': 1960.95663022995, 'accumulated_logging_time': 2.252743721008301}
I0319 10:57:26.577218 139592099407616 logging_writer.py:48] [57919] accumulated_eval_time=1960.956630, accumulated_logging_time=2.252744, accumulated_submission_time=25672.050469, global_step=57919, preemption_count=0, score=25672.050469, test/accuracy=0.547600, test/loss=2.016319, test/num_examples=10000, total_duration=27638.448982, train/accuracy=0.725273, train/loss=1.115080, validation/accuracy=0.669160, validation/loss=1.361559, validation/num_examples=50000
I0319 10:57:59.454063 139592107800320 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.4657424688339233, loss=1.9531818628311157
I0319 11:01:43.509586 139592099407616 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.4539153575897217, loss=3.077510118484497
I0319 11:04:26.624940 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:04:36.779615 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:04:58.701882 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:05:00.312268 139793440028480 submission_runner.py:420] Time since start: 28092.21s, 	Step: 58866, 	{'train/accuracy': 0.7296679615974426, 'train/loss': 1.0787262916564941, 'validation/accuracy': 0.6721599698066711, 'validation/loss': 1.3411825895309448, 'validation/num_examples': 50000, 'test/accuracy': 0.5482000112533569, 'test/loss': 1.9719829559326172, 'test/num_examples': 10000, 'score': 26092.036076784134, 'total_duration': 28092.210947752, 'accumulated_submission_time': 26092.036076784134, 'accumulated_eval_time': 1994.6439800262451, 'accumulated_logging_time': 2.2900073528289795}
I0319 11:05:00.332799 139592107800320 logging_writer.py:48] [58866] accumulated_eval_time=1994.643980, accumulated_logging_time=2.290007, accumulated_submission_time=26092.036077, global_step=58866, preemption_count=0, score=26092.036077, test/accuracy=0.548200, test/loss=1.971983, test/num_examples=10000, total_duration=28092.210948, train/accuracy=0.729668, train/loss=1.078726, validation/accuracy=0.672160, validation/loss=1.341183, validation/num_examples=50000
I0319 11:05:55.993520 139592099407616 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.5595099925994873, loss=2.3433899879455566
I0319 11:09:40.911984 139592107800320 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.55630362033844, loss=2.013298988342285
I0319 11:12:00.323168 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:12:10.662947 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:12:32.793475 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:12:34.396272 139793440028480 submission_runner.py:420] Time since start: 28546.29s, 	Step: 59811, 	{'train/accuracy': 0.7402734160423279, 'train/loss': 1.0445926189422607, 'validation/accuracy': 0.6759999990463257, 'validation/loss': 1.3289766311645508, 'validation/num_examples': 50000, 'test/accuracy': 0.5515000224113464, 'test/loss': 1.9670867919921875, 'test/num_examples': 10000, 'score': 26511.96447300911, 'total_duration': 28546.29495382309, 'accumulated_submission_time': 26511.96447300911, 'accumulated_eval_time': 2028.7171030044556, 'accumulated_logging_time': 2.3205950260162354}
I0319 11:12:34.417146 139592099407616 logging_writer.py:48] [59811] accumulated_eval_time=2028.717103, accumulated_logging_time=2.320595, accumulated_submission_time=26511.964473, global_step=59811, preemption_count=0, score=26511.964473, test/accuracy=0.551500, test/loss=1.967087, test/num_examples=10000, total_duration=28546.294954, train/accuracy=0.740273, train/loss=1.044593, validation/accuracy=0.676000, validation/loss=1.328977, validation/num_examples=50000
I0319 11:13:54.243862 139592107800320 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.4117887020111084, loss=3.6755268573760986
I0319 11:17:39.481021 139592099407616 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.3888745307922363, loss=3.9004807472229004
I0319 11:19:34.822367 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:19:45.438999 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:20:07.246007 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:20:08.850689 139793440028480 submission_runner.py:420] Time since start: 29000.75s, 	Step: 60759, 	{'train/accuracy': 0.7403320074081421, 'train/loss': 1.049425482749939, 'validation/accuracy': 0.6758999824523926, 'validation/loss': 1.322865605354309, 'validation/num_examples': 50000, 'test/accuracy': 0.5538000464439392, 'test/loss': 1.9534657001495361, 'test/num_examples': 10000, 'score': 26932.308787107468, 'total_duration': 29000.749348402023, 'accumulated_submission_time': 26932.308787107468, 'accumulated_eval_time': 2062.7454237937927, 'accumulated_logging_time': 2.3511340618133545}
I0319 11:20:08.875722 139592107800320 logging_writer.py:48] [60759] accumulated_eval_time=2062.745424, accumulated_logging_time=2.351134, accumulated_submission_time=26932.308787, global_step=60759, preemption_count=0, score=26932.308787, test/accuracy=0.553800, test/loss=1.953466, test/num_examples=10000, total_duration=29000.749348, train/accuracy=0.740332, train/loss=1.049425, validation/accuracy=0.675900, validation/loss=1.322866, validation/num_examples=50000
I0319 11:21:52.698958 139592099407616 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.4940340518951416, loss=4.758410930633545
I0319 11:25:37.675031 139592107800320 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.3115379810333252, loss=3.2463674545288086
I0319 11:27:09.037374 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:27:19.647812 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:27:39.707397 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:27:41.322940 139793440028480 submission_runner.py:420] Time since start: 29453.22s, 	Step: 61705, 	{'train/accuracy': 0.7339453101158142, 'train/loss': 1.0520697832107544, 'validation/accuracy': 0.6786800026893616, 'validation/loss': 1.3079254627227783, 'validation/num_examples': 50000, 'test/accuracy': 0.5556000471115112, 'test/loss': 1.9485647678375244, 'test/num_examples': 10000, 'score': 27352.409881591797, 'total_duration': 29453.221601247787, 'accumulated_submission_time': 27352.409881591797, 'accumulated_eval_time': 2095.030975818634, 'accumulated_logging_time': 2.385249614715576}
I0319 11:27:41.357173 139592099407616 logging_writer.py:48] [61705] accumulated_eval_time=2095.030976, accumulated_logging_time=2.385250, accumulated_submission_time=27352.409882, global_step=61705, preemption_count=0, score=27352.409882, test/accuracy=0.555600, test/loss=1.948565, test/num_examples=10000, total_duration=29453.221601, train/accuracy=0.733945, train/loss=1.052070, validation/accuracy=0.678680, validation/loss=1.307925, validation/num_examples=50000
I0319 11:29:50.164538 139592107800320 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.5431209802627563, loss=1.919967532157898
I0319 11:33:34.464003 139592099407616 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.4277831315994263, loss=3.231130838394165
I0319 11:34:41.642076 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:34:52.090369 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:35:13.471966 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:35:15.082956 139793440028480 submission_runner.py:420] Time since start: 29906.98s, 	Step: 62651, 	{'train/accuracy': 0.7387109398841858, 'train/loss': 1.0528830289840698, 'validation/accuracy': 0.6791799664497375, 'validation/loss': 1.321641206741333, 'validation/num_examples': 50000, 'test/accuracy': 0.551800012588501, 'test/loss': 1.9544039964675903, 'test/num_examples': 10000, 'score': 27772.632388591766, 'total_duration': 29906.981637239456, 'accumulated_submission_time': 27772.632388591766, 'accumulated_eval_time': 2128.471873998642, 'accumulated_logging_time': 2.4299964904785156}
I0319 11:35:15.109185 139592107800320 logging_writer.py:48] [62651] accumulated_eval_time=2128.471874, accumulated_logging_time=2.429996, accumulated_submission_time=27772.632389, global_step=62651, preemption_count=0, score=27772.632389, test/accuracy=0.551800, test/loss=1.954404, test/num_examples=10000, total_duration=29906.981637, train/accuracy=0.738711, train/loss=1.052883, validation/accuracy=0.679180, validation/loss=1.321641, validation/num_examples=50000
I0319 11:37:47.786264 139592099407616 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.4177912473678589, loss=2.647893190383911
I0319 11:41:32.443538 139592107800320 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.498894453048706, loss=2.4776673316955566
I0319 11:42:15.154505 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:42:25.386035 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:42:47.860148 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:42:49.463589 139793440028480 submission_runner.py:420] Time since start: 30361.36s, 	Step: 63597, 	{'train/accuracy': 0.750781238079071, 'train/loss': 0.9847334027290344, 'validation/accuracy': 0.6816799640655518, 'validation/loss': 1.2952712774276733, 'validation/num_examples': 50000, 'test/accuracy': 0.5585000514984131, 'test/loss': 1.9365578889846802, 'test/num_examples': 10000, 'score': 28192.61453294754, 'total_duration': 30361.36227083206, 'accumulated_submission_time': 28192.61453294754, 'accumulated_eval_time': 2162.7809953689575, 'accumulated_logging_time': 2.4671192169189453}
I0319 11:42:49.484681 139592099407616 logging_writer.py:48] [63597] accumulated_eval_time=2162.780995, accumulated_logging_time=2.467119, accumulated_submission_time=28192.614533, global_step=63597, preemption_count=0, score=28192.614533, test/accuracy=0.558500, test/loss=1.936558, test/num_examples=10000, total_duration=30361.362271, train/accuracy=0.750781, train/loss=0.984733, validation/accuracy=0.681680, validation/loss=1.295271, validation/num_examples=50000
I0319 11:45:46.422487 139592107800320 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.4518884420394897, loss=3.8102059364318848
I0319 11:49:31.541679 139592099407616 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.4555485248565674, loss=3.54103684425354
I0319 11:49:49.750642 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:50:00.176489 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:50:23.539839 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:50:25.143308 139793440028480 submission_runner.py:420] Time since start: 30817.04s, 	Step: 64542, 	{'train/accuracy': 0.7407031059265137, 'train/loss': 1.0386791229248047, 'validation/accuracy': 0.6838200092315674, 'validation/loss': 1.28839910030365, 'validation/num_examples': 50000, 'test/accuracy': 0.5594000220298767, 'test/loss': 1.9351783990859985, 'test/num_examples': 10000, 'score': 28612.81815481186, 'total_duration': 30817.041990041733, 'accumulated_submission_time': 28612.81815481186, 'accumulated_eval_time': 2198.1737167835236, 'accumulated_logging_time': 2.4979283809661865}
I0319 11:50:25.163908 139592107800320 logging_writer.py:48] [64542] accumulated_eval_time=2198.173717, accumulated_logging_time=2.497928, accumulated_submission_time=28612.818155, global_step=64542, preemption_count=0, score=28612.818155, test/accuracy=0.559400, test/loss=1.935178, test/num_examples=10000, total_duration=30817.041990, train/accuracy=0.740703, train/loss=1.038679, validation/accuracy=0.683820, validation/loss=1.288399, validation/num_examples=50000
I0319 11:53:46.670666 139592099407616 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.4209600687026978, loss=3.9410126209259033
I0319 11:57:25.469880 139793440028480 spec.py:321] Evaluating on the training split.
I0319 11:57:36.032072 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 11:57:57.959859 139793440028480 spec.py:349] Evaluating on the test split.
I0319 11:57:59.565171 139793440028480 submission_runner.py:420] Time since start: 31271.46s, 	Step: 65486, 	{'train/accuracy': 0.7449609041213989, 'train/loss': 1.0040644407272339, 'validation/accuracy': 0.6847599744796753, 'validation/loss': 1.2756867408752441, 'validation/num_examples': 50000, 'test/accuracy': 0.5587000250816345, 'test/loss': 1.92477548122406, 'test/num_examples': 10000, 'score': 29033.064285755157, 'total_duration': 31271.463845729828, 'accumulated_submission_time': 29033.064285755157, 'accumulated_eval_time': 2232.2690222263336, 'accumulated_logging_time': 2.527261972427368}
I0319 11:57:59.589162 139592107800320 logging_writer.py:48] [65486] accumulated_eval_time=2232.269022, accumulated_logging_time=2.527262, accumulated_submission_time=29033.064286, global_step=65486, preemption_count=0, score=29033.064286, test/accuracy=0.558700, test/loss=1.924775, test/num_examples=10000, total_duration=31271.463846, train/accuracy=0.744961, train/loss=1.004064, validation/accuracy=0.684760, validation/loss=1.275687, validation/num_examples=50000
I0319 11:58:05.600176 139592099407616 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.4466021060943604, loss=4.098649024963379
I0319 12:01:47.323683 139592107800320 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.3942724466323853, loss=3.2967710494995117
I0319 12:04:59.698859 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:05:10.098373 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:05:31.345132 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:05:32.964350 139793440028480 submission_runner.py:420] Time since start: 31724.86s, 	Step: 66429, 	{'train/accuracy': 0.7562304735183716, 'train/loss': 0.9694955348968506, 'validation/accuracy': 0.6888999938964844, 'validation/loss': 1.2655874490737915, 'validation/num_examples': 50000, 'test/accuracy': 0.5600000023841858, 'test/loss': 1.8977373838424683, 'test/num_examples': 10000, 'score': 29453.113102674484, 'total_duration': 31724.86300420761, 'accumulated_submission_time': 29453.113102674484, 'accumulated_eval_time': 2265.5344891548157, 'accumulated_logging_time': 2.560814142227173}
I0319 12:05:32.989634 139592099407616 logging_writer.py:48] [66429] accumulated_eval_time=2265.534489, accumulated_logging_time=2.560814, accumulated_submission_time=29453.113103, global_step=66429, preemption_count=0, score=29453.113103, test/accuracy=0.560000, test/loss=1.897737, test/num_examples=10000, total_duration=31724.863004, train/accuracy=0.756230, train/loss=0.969496, validation/accuracy=0.688900, validation/loss=1.265587, validation/num_examples=50000
I0319 12:06:02.018168 139592107800320 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.819180965423584, loss=4.491843223571777
I0319 12:09:46.155893 139592099407616 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.5307352542877197, loss=2.271627426147461
I0319 12:12:33.034474 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:12:43.378136 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:13:05.964940 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:13:07.583015 139793440028480 submission_runner.py:420] Time since start: 32179.48s, 	Step: 67373, 	{'train/accuracy': 0.7611523270606995, 'train/loss': 0.9611263871192932, 'validation/accuracy': 0.6914799809455872, 'validation/loss': 1.266859531402588, 'validation/num_examples': 50000, 'test/accuracy': 0.5624000430107117, 'test/loss': 1.8967227935791016, 'test/num_examples': 10000, 'score': 29873.096399784088, 'total_duration': 32179.481694698334, 'accumulated_submission_time': 29873.096399784088, 'accumulated_eval_time': 2300.0830450057983, 'accumulated_logging_time': 2.5963993072509766}
I0319 12:13:07.604436 139592107800320 logging_writer.py:48] [67373] accumulated_eval_time=2300.083045, accumulated_logging_time=2.596399, accumulated_submission_time=29873.096400, global_step=67373, preemption_count=0, score=29873.096400, test/accuracy=0.562400, test/loss=1.896723, test/num_examples=10000, total_duration=32179.481695, train/accuracy=0.761152, train/loss=0.961126, validation/accuracy=0.691480, validation/loss=1.266860, validation/num_examples=50000
I0319 12:14:00.453071 139592099407616 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.6350576877593994, loss=1.8780734539031982
I0319 12:17:46.095232 139592107800320 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.5351396799087524, loss=2.2651889324188232
I0319 12:20:07.687222 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:20:18.148770 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:20:40.702881 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:20:42.306308 139793440028480 submission_runner.py:420] Time since start: 32634.20s, 	Step: 68316, 	{'train/accuracy': 0.7525976300239563, 'train/loss': 0.9816879034042358, 'validation/accuracy': 0.6916399598121643, 'validation/loss': 1.2475214004516602, 'validation/num_examples': 50000, 'test/accuracy': 0.5639000535011292, 'test/loss': 1.897086262702942, 'test/num_examples': 10000, 'score': 30293.118802070618, 'total_duration': 32634.204987049103, 'accumulated_submission_time': 30293.118802070618, 'accumulated_eval_time': 2334.70215010643, 'accumulated_logging_time': 2.626979351043701}
I0319 12:20:42.327388 139592099407616 logging_writer.py:48] [68316] accumulated_eval_time=2334.702150, accumulated_logging_time=2.626979, accumulated_submission_time=30293.118802, global_step=68316, preemption_count=0, score=30293.118802, test/accuracy=0.563900, test/loss=1.897086, test/num_examples=10000, total_duration=32634.204987, train/accuracy=0.752598, train/loss=0.981688, validation/accuracy=0.691640, validation/loss=1.247521, validation/num_examples=50000
I0319 12:22:00.202181 139592107800320 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.37001371383667, loss=3.6806674003601074
I0319 12:25:45.424501 139592099407616 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.7014808654785156, loss=2.720628261566162
I0319 12:27:42.652355 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:27:53.204759 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:28:13.415772 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:28:15.028798 139793440028480 submission_runner.py:420] Time since start: 33086.93s, 	Step: 69263, 	{'train/accuracy': 0.756054699420929, 'train/loss': 0.9686293601989746, 'validation/accuracy': 0.6932199597358704, 'validation/loss': 1.24394953250885, 'validation/num_examples': 50000, 'test/accuracy': 0.5648000240325928, 'test/loss': 1.8903024196624756, 'test/num_examples': 10000, 'score': 30713.382395505905, 'total_duration': 33086.927471637726, 'accumulated_submission_time': 30713.382395505905, 'accumulated_eval_time': 2367.0785982608795, 'accumulated_logging_time': 2.6575088500976562}
I0319 12:28:15.053612 139592107800320 logging_writer.py:48] [69263] accumulated_eval_time=2367.078598, accumulated_logging_time=2.657509, accumulated_submission_time=30713.382396, global_step=69263, preemption_count=0, score=30713.382396, test/accuracy=0.564800, test/loss=1.890302, test/num_examples=10000, total_duration=33086.927472, train/accuracy=0.756055, train/loss=0.968629, validation/accuracy=0.693220, validation/loss=1.243950, validation/num_examples=50000
I0319 12:29:57.247727 139592099407616 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.710340142250061, loss=1.9042431116104126
I0319 12:33:42.315296 139592107800320 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.449737787246704, loss=4.3305230140686035
I0319 12:35:15.305075 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:35:25.728398 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:35:46.331902 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:35:47.948878 139793440028480 submission_runner.py:420] Time since start: 33539.85s, 	Step: 70208, 	{'train/accuracy': 0.7694140672683716, 'train/loss': 0.9334357380867004, 'validation/accuracy': 0.6912399530410767, 'validation/loss': 1.2634446620941162, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 1.8879430294036865, 'test/num_examples': 10000, 'score': 31133.573318243027, 'total_duration': 33539.84754896164, 'accumulated_submission_time': 31133.573318243027, 'accumulated_eval_time': 2399.722409725189, 'accumulated_logging_time': 2.6915690898895264}
I0319 12:35:47.976506 139592099407616 logging_writer.py:48] [70208] accumulated_eval_time=2399.722410, accumulated_logging_time=2.691569, accumulated_submission_time=31133.573318, global_step=70208, preemption_count=0, score=31133.573318, test/accuracy=0.566600, test/loss=1.887943, test/num_examples=10000, total_duration=33539.847549, train/accuracy=0.769414, train/loss=0.933436, validation/accuracy=0.691240, validation/loss=1.263445, validation/num_examples=50000
I0319 12:37:55.089631 139592107800320 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.7707723379135132, loss=1.7583017349243164
I0319 12:41:40.364676 139592099407616 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.6966941356658936, loss=1.9334086179733276
I0319 12:42:48.285435 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:42:58.720189 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:43:21.493373 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:43:23.100394 139793440028480 submission_runner.py:420] Time since start: 33995.00s, 	Step: 71153, 	{'train/accuracy': 0.7538671493530273, 'train/loss': 0.9688629508018494, 'validation/accuracy': 0.6976000070571899, 'validation/loss': 1.2291446924209595, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 1.8841079473495483, 'test/num_examples': 10000, 'score': 31553.820833921432, 'total_duration': 33994.99906754494, 'accumulated_submission_time': 31553.820833921432, 'accumulated_eval_time': 2434.5373516082764, 'accumulated_logging_time': 2.7289319038391113}
I0319 12:43:23.124464 139592107800320 logging_writer.py:48] [71153] accumulated_eval_time=2434.537352, accumulated_logging_time=2.728932, accumulated_submission_time=31553.820834, global_step=71153, preemption_count=0, score=31553.820834, test/accuracy=0.566600, test/loss=1.884108, test/num_examples=10000, total_duration=33994.999068, train/accuracy=0.753867, train/loss=0.968863, validation/accuracy=0.697600, validation/loss=1.229145, validation/num_examples=50000
I0319 12:45:55.278667 139592099407616 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.5245643854141235, loss=2.764441967010498
I0319 12:49:39.908469 139592107800320 logging_writer.py:48] [72000] global_step=72000, grad_norm=1.6544119119644165, loss=3.826936960220337
I0319 12:50:23.148529 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:50:33.617069 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:50:56.388218 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:50:57.988140 139793440028480 submission_runner.py:420] Time since start: 34449.89s, 	Step: 72098, 	{'train/accuracy': 0.7606835961341858, 'train/loss': 0.9398583769798279, 'validation/accuracy': 0.6979799866676331, 'validation/loss': 1.2170993089675903, 'validation/num_examples': 50000, 'test/accuracy': 0.5753000378608704, 'test/loss': 1.8367221355438232, 'test/num_examples': 10000, 'score': 31973.78252720833, 'total_duration': 34449.886823415756, 'accumulated_submission_time': 31973.78252720833, 'accumulated_eval_time': 2469.376969099045, 'accumulated_logging_time': 2.7636160850524902}
I0319 12:50:58.009160 139592099407616 logging_writer.py:48] [72098] accumulated_eval_time=2469.376969, accumulated_logging_time=2.763616, accumulated_submission_time=31973.782527, global_step=72098, preemption_count=0, score=31973.782527, test/accuracy=0.575300, test/loss=1.836722, test/num_examples=10000, total_duration=34449.886823, train/accuracy=0.760684, train/loss=0.939858, validation/accuracy=0.697980, validation/loss=1.217099, validation/num_examples=50000
I0319 12:53:54.260621 139592107800320 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.613615870475769, loss=3.8737151622772217
I0319 12:57:39.511944 139592099407616 logging_writer.py:48] [73000] global_step=73000, grad_norm=1.536119818687439, loss=3.8383419513702393
I0319 12:57:58.366468 139793440028480 spec.py:321] Evaluating on the training split.
I0319 12:58:08.727015 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 12:58:28.193648 139793440028480 spec.py:349] Evaluating on the test split.
I0319 12:58:29.805843 139793440028480 submission_runner.py:420] Time since start: 34901.70s, 	Step: 73043, 	{'train/accuracy': 0.767578125, 'train/loss': 0.9278136491775513, 'validation/accuracy': 0.7011199593544006, 'validation/loss': 1.2232838869094849, 'validation/num_examples': 50000, 'test/accuracy': 0.5733000040054321, 'test/loss': 1.8401832580566406, 'test/num_examples': 10000, 'score': 32394.079025506973, 'total_duration': 34901.70451760292, 'accumulated_submission_time': 32394.079025506973, 'accumulated_eval_time': 2500.8163340091705, 'accumulated_logging_time': 2.7940104007720947}
I0319 12:58:29.832218 139592107800320 logging_writer.py:48] [73043] accumulated_eval_time=2500.816334, accumulated_logging_time=2.794010, accumulated_submission_time=32394.079026, global_step=73043, preemption_count=0, score=32394.079026, test/accuracy=0.573300, test/loss=1.840183, test/num_examples=10000, total_duration=34901.704518, train/accuracy=0.767578, train/loss=0.927814, validation/accuracy=0.701120, validation/loss=1.223284, validation/num_examples=50000
I0319 13:01:51.886968 139592099407616 logging_writer.py:48] [73500] global_step=73500, grad_norm=1.5866972208023071, loss=1.7738728523254395
I0319 13:05:30.154449 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:05:40.690999 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:06:01.038352 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:06:02.654256 139793440028480 submission_runner.py:420] Time since start: 35354.55s, 	Step: 73987, 	{'train/accuracy': 0.7697070240974426, 'train/loss': 0.9041791558265686, 'validation/accuracy': 0.701479971408844, 'validation/loss': 1.1972858905792236, 'validation/num_examples': 50000, 'test/accuracy': 0.57750004529953, 'test/loss': 1.8152793645858765, 'test/num_examples': 10000, 'score': 32814.340690374374, 'total_duration': 35354.55292868614, 'accumulated_submission_time': 32814.340690374374, 'accumulated_eval_time': 2533.3161249160767, 'accumulated_logging_time': 2.829845905303955}
I0319 13:06:02.679536 139592107800320 logging_writer.py:48] [73987] accumulated_eval_time=2533.316125, accumulated_logging_time=2.829846, accumulated_submission_time=32814.340690, global_step=73987, preemption_count=0, score=32814.340690, test/accuracy=0.577500, test/loss=1.815279, test/num_examples=10000, total_duration=35354.552929, train/accuracy=0.769707, train/loss=0.904179, validation/accuracy=0.701480, validation/loss=1.197286, validation/num_examples=50000
I0319 13:06:08.315873 139592099407616 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.5466808080673218, loss=3.594010829925537
I0319 13:09:49.368889 139592107800320 logging_writer.py:48] [74500] global_step=74500, grad_norm=1.57532799243927, loss=1.8353865146636963
I0319 13:13:02.761256 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:13:13.111108 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:13:35.302252 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:13:36.907472 139793440028480 submission_runner.py:420] Time since start: 35808.81s, 	Step: 74932, 	{'train/accuracy': 0.7698827981948853, 'train/loss': 0.9079320430755615, 'validation/accuracy': 0.7064200043678284, 'validation/loss': 1.1868194341659546, 'validation/num_examples': 50000, 'test/accuracy': 0.5814000368118286, 'test/loss': 1.7989803552627563, 'test/num_examples': 10000, 'score': 33234.36085677147, 'total_duration': 35808.806149721146, 'accumulated_submission_time': 33234.36085677147, 'accumulated_eval_time': 2567.4623601436615, 'accumulated_logging_time': 2.8648629188537598}
I0319 13:13:36.929499 139592099407616 logging_writer.py:48] [74932] accumulated_eval_time=2567.462360, accumulated_logging_time=2.864863, accumulated_submission_time=33234.360857, global_step=74932, preemption_count=0, score=33234.360857, test/accuracy=0.581400, test/loss=1.798980, test/num_examples=10000, total_duration=35808.806150, train/accuracy=0.769883, train/loss=0.907932, validation/accuracy=0.706420, validation/loss=1.186819, validation/num_examples=50000
I0319 13:14:04.706174 139592107800320 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.6304824352264404, loss=2.0606801509857178
I0319 13:17:47.969987 139592099407616 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.5913273096084595, loss=2.2862355709075928
I0319 13:20:37.149590 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:20:47.487455 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:21:11.852264 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:21:13.458613 139793440028480 submission_runner.py:420] Time since start: 36265.36s, 	Step: 75879, 	{'train/accuracy': 0.7769335508346558, 'train/loss': 0.885880708694458, 'validation/accuracy': 0.7059800028800964, 'validation/loss': 1.1775133609771729, 'validation/num_examples': 50000, 'test/accuracy': 0.5808000564575195, 'test/loss': 1.8071162700653076, 'test/num_examples': 10000, 'score': 33654.51966834068, 'total_duration': 36265.357288360596, 'accumulated_submission_time': 33654.51966834068, 'accumulated_eval_time': 2603.771483182907, 'accumulated_logging_time': 2.895900249481201}
I0319 13:21:13.482928 139592107800320 logging_writer.py:48] [75879] accumulated_eval_time=2603.771483, accumulated_logging_time=2.895900, accumulated_submission_time=33654.519668, global_step=75879, preemption_count=0, score=33654.519668, test/accuracy=0.580800, test/loss=1.807116, test/num_examples=10000, total_duration=36265.357288, train/accuracy=0.776934, train/loss=0.885881, validation/accuracy=0.705980, validation/loss=1.177513, validation/num_examples=50000
I0319 13:22:03.415082 139592099407616 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.7147668600082397, loss=1.7940137386322021
I0319 13:25:48.970839 139592107800320 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.567448377609253, loss=2.972461223602295
I0319 13:28:13.570395 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:28:23.977867 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:28:44.679248 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:28:46.298918 139793440028480 submission_runner.py:420] Time since start: 36718.20s, 	Step: 76823, 	{'train/accuracy': 0.7836523056030273, 'train/loss': 0.8550135493278503, 'validation/accuracy': 0.7077400088310242, 'validation/loss': 1.1789422035217285, 'validation/num_examples': 50000, 'test/accuracy': 0.5837000012397766, 'test/loss': 1.8055514097213745, 'test/num_examples': 10000, 'score': 34074.54490470886, 'total_duration': 36718.19757246971, 'accumulated_submission_time': 34074.54490470886, 'accumulated_eval_time': 2636.499994277954, 'accumulated_logging_time': 2.9304416179656982}
I0319 13:28:46.328525 139592099407616 logging_writer.py:48] [76823] accumulated_eval_time=2636.499994, accumulated_logging_time=2.930442, accumulated_submission_time=34074.544905, global_step=76823, preemption_count=0, score=34074.544905, test/accuracy=0.583700, test/loss=1.805551, test/num_examples=10000, total_duration=36718.197572, train/accuracy=0.783652, train/loss=0.855014, validation/accuracy=0.707740, validation/loss=1.178942, validation/num_examples=50000
I0319 13:30:01.883743 139592107800320 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.4534395933151245, loss=3.2616124153137207
I0319 13:33:47.187829 139592099407616 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.5167664289474487, loss=3.6299185752868652
I0319 13:35:46.684180 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:35:57.378696 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:36:17.543902 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:36:19.152758 139793440028480 submission_runner.py:420] Time since start: 37171.05s, 	Step: 77765, 	{'train/accuracy': 0.7697460651397705, 'train/loss': 0.9096236228942871, 'validation/accuracy': 0.7121599912643433, 'validation/loss': 1.169438362121582, 'validation/num_examples': 50000, 'test/accuracy': 0.5838000178337097, 'test/loss': 1.8050917387008667, 'test/num_examples': 10000, 'score': 34494.83773326874, 'total_duration': 37171.05143284798, 'accumulated_submission_time': 34494.83773326874, 'accumulated_eval_time': 2668.9685966968536, 'accumulated_logging_time': 2.9714202880859375}
I0319 13:36:19.178148 139592107800320 logging_writer.py:48] [77765] accumulated_eval_time=2668.968597, accumulated_logging_time=2.971420, accumulated_submission_time=34494.837733, global_step=77765, preemption_count=0, score=34494.837733, test/accuracy=0.583800, test/loss=1.805092, test/num_examples=10000, total_duration=37171.051433, train/accuracy=0.769746, train/loss=0.909624, validation/accuracy=0.712160, validation/loss=1.169438, validation/num_examples=50000
I0319 13:38:00.579328 139592099407616 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.6403330564498901, loss=1.8381017446517944
I0319 13:41:45.611406 139592107800320 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.582659363746643, loss=4.16527795791626
I0319 13:43:19.402576 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:43:29.876157 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:43:51.564645 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:43:53.180463 139793440028480 submission_runner.py:420] Time since start: 37625.08s, 	Step: 78711, 	{'train/accuracy': 0.7758398056030273, 'train/loss': 0.8823391795158386, 'validation/accuracy': 0.711959958076477, 'validation/loss': 1.1605439186096191, 'validation/num_examples': 50000, 'test/accuracy': 0.5857000350952148, 'test/loss': 1.7880895137786865, 'test/num_examples': 10000, 'score': 34915.00114774704, 'total_duration': 37625.079139471054, 'accumulated_submission_time': 34915.00114774704, 'accumulated_eval_time': 2702.7465002536774, 'accumulated_logging_time': 3.0059759616851807}
I0319 13:43:53.202420 139592099407616 logging_writer.py:48] [78711] accumulated_eval_time=2702.746500, accumulated_logging_time=3.005976, accumulated_submission_time=34915.001148, global_step=78711, preemption_count=0, score=34915.001148, test/accuracy=0.585700, test/loss=1.788090, test/num_examples=10000, total_duration=37625.079139, train/accuracy=0.775840, train/loss=0.882339, validation/accuracy=0.711960, validation/loss=1.160544, validation/num_examples=50000
I0319 13:45:58.905905 139592107800320 logging_writer.py:48] [79000] global_step=79000, grad_norm=1.662620186805725, loss=2.2319931983947754
I0319 13:49:43.776147 139592099407616 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.8081785440444946, loss=4.317095756530762
I0319 13:50:53.531100 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:51:04.090517 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:51:26.393208 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:51:28.007108 139793440028480 submission_runner.py:420] Time since start: 38079.91s, 	Step: 79657, 	{'train/accuracy': 0.7816210985183716, 'train/loss': 0.8461682200431824, 'validation/accuracy': 0.7140799760818481, 'validation/loss': 1.1480047702789307, 'validation/num_examples': 50000, 'test/accuracy': 0.5919000506401062, 'test/loss': 1.765407919883728, 'test/num_examples': 10000, 'score': 35335.26860022545, 'total_duration': 38079.90578985214, 'accumulated_submission_time': 35335.26860022545, 'accumulated_eval_time': 2737.222516298294, 'accumulated_logging_time': 3.0372495651245117}
I0319 13:51:28.033359 139592107800320 logging_writer.py:48] [79657] accumulated_eval_time=2737.222516, accumulated_logging_time=3.037250, accumulated_submission_time=35335.268600, global_step=79657, preemption_count=0, score=35335.268600, test/accuracy=0.591900, test/loss=1.765408, test/num_examples=10000, total_duration=38079.905790, train/accuracy=0.781621, train/loss=0.846168, validation/accuracy=0.714080, validation/loss=1.148005, validation/num_examples=50000
I0319 13:53:58.443669 139592099407616 logging_writer.py:48] [80000] global_step=80000, grad_norm=1.5933997631072998, loss=2.5946102142333984
I0319 13:57:43.973724 139592107800320 logging_writer.py:48] [80500] global_step=80500, grad_norm=1.7879360914230347, loss=1.7729007005691528
I0319 13:58:28.249957 139793440028480 spec.py:321] Evaluating on the training split.
I0319 13:58:38.595944 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 13:59:01.059001 139793440028480 spec.py:349] Evaluating on the test split.
I0319 13:59:02.674841 139793440028480 submission_runner.py:420] Time since start: 38534.57s, 	Step: 80600, 	{'train/accuracy': 0.7875390648841858, 'train/loss': 0.8281233906745911, 'validation/accuracy': 0.7124800086021423, 'validation/loss': 1.151130199432373, 'validation/num_examples': 50000, 'test/accuracy': 0.5859000086784363, 'test/loss': 1.781424641609192, 'test/num_examples': 10000, 'score': 35755.42396569252, 'total_duration': 38534.573508262634, 'accumulated_submission_time': 35755.42396569252, 'accumulated_eval_time': 2771.6473848819733, 'accumulated_logging_time': 3.0723280906677246}
I0319 13:59:02.700152 139592099407616 logging_writer.py:48] [80600] accumulated_eval_time=2771.647385, accumulated_logging_time=3.072328, accumulated_submission_time=35755.423966, global_step=80600, preemption_count=0, score=35755.423966, test/accuracy=0.585900, test/loss=1.781425, test/num_examples=10000, total_duration=38534.573508, train/accuracy=0.787539, train/loss=0.828123, validation/accuracy=0.712480, validation/loss=1.151130, validation/num_examples=50000
I0319 14:01:58.117554 139592107800320 logging_writer.py:48] [81000] global_step=81000, grad_norm=1.890838861465454, loss=1.7673332691192627
I0319 14:05:42.985323 139592099407616 logging_writer.py:48] [81500] global_step=81500, grad_norm=1.6619594097137451, loss=2.9473488330841064
I0319 14:06:02.864776 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:06:13.441079 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:06:33.086076 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:06:34.702891 139793440028480 submission_runner.py:420] Time since start: 38986.60s, 	Step: 81546, 	{'train/accuracy': 0.7818945050239563, 'train/loss': 0.8708837628364563, 'validation/accuracy': 0.7129999995231628, 'validation/loss': 1.1647069454193115, 'validation/num_examples': 50000, 'test/accuracy': 0.5901000499725342, 'test/loss': 1.7958334684371948, 'test/num_examples': 10000, 'score': 36175.52549481392, 'total_duration': 38986.60156083107, 'accumulated_submission_time': 36175.52549481392, 'accumulated_eval_time': 2803.4854793548584, 'accumulated_logging_time': 3.1088600158691406}
I0319 14:06:34.729988 139592107800320 logging_writer.py:48] [81546] accumulated_eval_time=2803.485479, accumulated_logging_time=3.108860, accumulated_submission_time=36175.525495, global_step=81546, preemption_count=0, score=36175.525495, test/accuracy=0.590100, test/loss=1.795833, test/num_examples=10000, total_duration=38986.601561, train/accuracy=0.781895, train/loss=0.870884, validation/accuracy=0.713000, validation/loss=1.164707, validation/num_examples=50000
I0319 14:09:54.955813 139592099407616 logging_writer.py:48] [82000] global_step=82000, grad_norm=1.705829381942749, loss=3.5715017318725586
I0319 14:13:34.774752 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:13:45.384738 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:14:06.602630 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:14:08.207520 139793440028480 submission_runner.py:420] Time since start: 39440.11s, 	Step: 82491, 	{'train/accuracy': 0.7884765267372131, 'train/loss': 0.8577178716659546, 'validation/accuracy': 0.7178599834442139, 'validation/loss': 1.1544245481491089, 'validation/num_examples': 50000, 'test/accuracy': 0.5913000106811523, 'test/loss': 1.7814141511917114, 'test/num_examples': 10000, 'score': 36595.509464502335, 'total_duration': 39440.10619926453, 'accumulated_submission_time': 36595.509464502335, 'accumulated_eval_time': 2836.9182636737823, 'accumulated_logging_time': 3.1451468467712402}
I0319 14:14:08.229475 139592107800320 logging_writer.py:48] [82491] accumulated_eval_time=2836.918264, accumulated_logging_time=3.145147, accumulated_submission_time=36595.509465, global_step=82491, preemption_count=0, score=36595.509465, test/accuracy=0.591300, test/loss=1.781414, test/num_examples=10000, total_duration=39440.106199, train/accuracy=0.788477, train/loss=0.857718, validation/accuracy=0.717860, validation/loss=1.154425, validation/num_examples=50000
I0319 14:14:12.235122 139592099407616 logging_writer.py:48] [82500] global_step=82500, grad_norm=1.722770094871521, loss=1.6837871074676514
I0319 14:17:53.030156 139592107800320 logging_writer.py:48] [83000] global_step=83000, grad_norm=2.191340684890747, loss=4.31515645980835
I0319 14:21:08.455056 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:21:18.637709 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:21:41.632517 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:21:43.242710 139793440028480 submission_runner.py:420] Time since start: 39895.14s, 	Step: 83437, 	{'train/accuracy': 0.7953515648841858, 'train/loss': 0.8039199709892273, 'validation/accuracy': 0.7190799713134766, 'validation/loss': 1.1275643110275269, 'validation/num_examples': 50000, 'test/accuracy': 0.5945000052452087, 'test/loss': 1.7498276233673096, 'test/num_examples': 10000, 'score': 37015.672527074814, 'total_duration': 39895.141380786896, 'accumulated_submission_time': 37015.672527074814, 'accumulated_eval_time': 2871.7059211730957, 'accumulated_logging_time': 3.1772243976593018}
I0319 14:21:43.268883 139592099407616 logging_writer.py:48] [83437] accumulated_eval_time=2871.705921, accumulated_logging_time=3.177224, accumulated_submission_time=37015.672527, global_step=83437, preemption_count=0, score=37015.672527, test/accuracy=0.594500, test/loss=1.749828, test/num_examples=10000, total_duration=39895.141381, train/accuracy=0.795352, train/loss=0.803920, validation/accuracy=0.719080, validation/loss=1.127564, validation/num_examples=50000
I0319 14:22:08.916428 139592107800320 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.8129328489303589, loss=2.087815761566162
I0319 14:25:51.335593 139592099407616 logging_writer.py:48] [84000] global_step=84000, grad_norm=1.9168726205825806, loss=1.6706202030181885
I0319 14:28:43.650198 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:28:53.921828 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:29:15.330605 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:29:16.945915 139793440028480 submission_runner.py:420] Time since start: 40348.84s, 	Step: 84385, 	{'train/accuracy': 0.78431636095047, 'train/loss': 0.8333121538162231, 'validation/accuracy': 0.7215799689292908, 'validation/loss': 1.1099660396575928, 'validation/num_examples': 50000, 'test/accuracy': 0.5943000316619873, 'test/loss': 1.739061951637268, 'test/num_examples': 10000, 'score': 37435.992270469666, 'total_duration': 40348.84459066391, 'accumulated_submission_time': 37435.992270469666, 'accumulated_eval_time': 2905.0016555786133, 'accumulated_logging_time': 3.212794780731201}
I0319 14:29:16.974341 139592107800320 logging_writer.py:48] [84385] accumulated_eval_time=2905.001656, accumulated_logging_time=3.212795, accumulated_submission_time=37435.992270, global_step=84385, preemption_count=0, score=37435.992270, test/accuracy=0.594300, test/loss=1.739062, test/num_examples=10000, total_duration=40348.844591, train/accuracy=0.784316, train/loss=0.833312, validation/accuracy=0.721580, validation/loss=1.109966, validation/num_examples=50000
I0319 14:30:04.083441 139592099407616 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.9181431531906128, loss=4.178997993469238
I0319 14:33:48.747084 139592107800320 logging_writer.py:48] [85000] global_step=85000, grad_norm=1.800266981124878, loss=2.293973207473755
I0319 14:36:17.402403 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:36:28.019904 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:36:49.770658 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:36:51.390703 139793440028480 submission_runner.py:420] Time since start: 40803.29s, 	Step: 85329, 	{'train/accuracy': 0.7906445264816284, 'train/loss': 0.8078277111053467, 'validation/accuracy': 0.7192800045013428, 'validation/loss': 1.1236505508422852, 'validation/num_examples': 50000, 'test/accuracy': 0.5951000452041626, 'test/loss': 1.7393476963043213, 'test/num_examples': 10000, 'score': 37856.35889649391, 'total_duration': 40803.289375305176, 'accumulated_submission_time': 37856.35889649391, 'accumulated_eval_time': 2938.9899594783783, 'accumulated_logging_time': 3.250253677368164}
I0319 14:36:51.420469 139592099407616 logging_writer.py:48] [85329] accumulated_eval_time=2938.989959, accumulated_logging_time=3.250254, accumulated_submission_time=37856.358896, global_step=85329, preemption_count=0, score=37856.358896, test/accuracy=0.595100, test/loss=1.739348, test/num_examples=10000, total_duration=40803.289375, train/accuracy=0.790645, train/loss=0.807828, validation/accuracy=0.719280, validation/loss=1.123651, validation/num_examples=50000
I0319 14:38:04.162112 139592107800320 logging_writer.py:48] [85500] global_step=85500, grad_norm=1.794904351234436, loss=3.102081298828125
I0319 14:41:49.435288 139592099407616 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.6187461614608765, loss=2.4275503158569336
I0319 14:43:51.465663 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:44:01.791716 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:44:21.250463 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:44:22.860682 139793440028480 submission_runner.py:420] Time since start: 41254.76s, 	Step: 86273, 	{'train/accuracy': 0.798535168170929, 'train/loss': 0.7840611338615417, 'validation/accuracy': 0.725600004196167, 'validation/loss': 1.0962775945663452, 'validation/num_examples': 50000, 'test/accuracy': 0.5938000082969666, 'test/loss': 1.7202932834625244, 'test/num_examples': 10000, 'score': 38276.34303474426, 'total_duration': 41254.75935173035, 'accumulated_submission_time': 38276.34303474426, 'accumulated_eval_time': 2970.384974718094, 'accumulated_logging_time': 3.2900712490081787}
I0319 14:44:22.889544 139592107800320 logging_writer.py:48] [86273] accumulated_eval_time=2970.384975, accumulated_logging_time=3.290071, accumulated_submission_time=38276.343035, global_step=86273, preemption_count=0, score=38276.343035, test/accuracy=0.593800, test/loss=1.720293, test/num_examples=10000, total_duration=41254.759352, train/accuracy=0.798535, train/loss=0.784061, validation/accuracy=0.725600, validation/loss=1.096278, validation/num_examples=50000
I0319 14:46:01.560237 139592099407616 logging_writer.py:48] [86500] global_step=86500, grad_norm=1.664296269416809, loss=2.578881025314331
I0319 14:49:46.590288 139592107800320 logging_writer.py:48] [87000] global_step=87000, grad_norm=1.6168489456176758, loss=3.5044915676116943
I0319 14:51:23.182591 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:51:33.720164 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:51:55.013738 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:51:56.628621 139793440028480 submission_runner.py:420] Time since start: 41708.53s, 	Step: 87217, 	{'train/accuracy': 0.806933581829071, 'train/loss': 0.7684230804443359, 'validation/accuracy': 0.7239199876785278, 'validation/loss': 1.1109713315963745, 'validation/num_examples': 50000, 'test/accuracy': 0.595300018787384, 'test/loss': 1.7254667282104492, 'test/num_examples': 10000, 'score': 38696.57227444649, 'total_duration': 41708.5273001194, 'accumulated_submission_time': 38696.57227444649, 'accumulated_eval_time': 3003.8310148715973, 'accumulated_logging_time': 3.3293609619140625}
I0319 14:51:56.653457 139592099407616 logging_writer.py:48] [87217] accumulated_eval_time=3003.831015, accumulated_logging_time=3.329361, accumulated_submission_time=38696.572274, global_step=87217, preemption_count=0, score=38696.572274, test/accuracy=0.595300, test/loss=1.725467, test/num_examples=10000, total_duration=41708.527300, train/accuracy=0.806934, train/loss=0.768423, validation/accuracy=0.723920, validation/loss=1.110971, validation/num_examples=50000
I0319 14:53:58.944385 139592107800320 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.7997162342071533, loss=1.6128206253051758
I0319 14:57:44.674047 139592099407616 logging_writer.py:48] [88000] global_step=88000, grad_norm=1.775376796722412, loss=3.0662050247192383
I0319 14:58:56.928704 139793440028480 spec.py:321] Evaluating on the training split.
I0319 14:59:07.301743 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 14:59:29.035841 139793440028480 spec.py:349] Evaluating on the test split.
I0319 14:59:30.641074 139793440028480 submission_runner.py:420] Time since start: 42162.54s, 	Step: 88162, 	{'train/accuracy': 0.791699230670929, 'train/loss': 0.8004516959190369, 'validation/accuracy': 0.7252599596977234, 'validation/loss': 1.0912268161773682, 'validation/num_examples': 50000, 'test/accuracy': 0.6039000153541565, 'test/loss': 1.7035795450210571, 'test/num_examples': 10000, 'score': 39116.784254550934, 'total_duration': 42162.53975176811, 'accumulated_submission_time': 39116.784254550934, 'accumulated_eval_time': 3037.5434033870697, 'accumulated_logging_time': 3.3656725883483887}
I0319 14:59:30.664037 139592107800320 logging_writer.py:48] [88162] accumulated_eval_time=3037.543403, accumulated_logging_time=3.365673, accumulated_submission_time=39116.784255, global_step=88162, preemption_count=0, score=39116.784255, test/accuracy=0.603900, test/loss=1.703580, test/num_examples=10000, total_duration=42162.539752, train/accuracy=0.791699, train/loss=0.800452, validation/accuracy=0.725260, validation/loss=1.091227, validation/num_examples=50000
I0319 15:01:57.858266 139592099407616 logging_writer.py:48] [88500] global_step=88500, grad_norm=1.7561111450195312, loss=3.8704428672790527
I0319 15:05:43.003069 139592107800320 logging_writer.py:48] [89000] global_step=89000, grad_norm=1.826722502708435, loss=2.030482053756714
I0319 15:06:30.846503 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:06:41.131960 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:07:03.569175 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:07:05.179842 139793440028480 submission_runner.py:420] Time since start: 42617.08s, 	Step: 89108, 	{'train/accuracy': 0.8007421493530273, 'train/loss': 0.7903771996498108, 'validation/accuracy': 0.7258999943733215, 'validation/loss': 1.101864218711853, 'validation/num_examples': 50000, 'test/accuracy': 0.5979000329971313, 'test/loss': 1.7177833318710327, 'test/num_examples': 10000, 'score': 39536.90453696251, 'total_duration': 42617.078525066376, 'accumulated_submission_time': 39536.90453696251, 'accumulated_eval_time': 3071.8767664432526, 'accumulated_logging_time': 3.3986270427703857}
I0319 15:07:05.204077 139592099407616 logging_writer.py:48] [89108] accumulated_eval_time=3071.876766, accumulated_logging_time=3.398627, accumulated_submission_time=39536.904537, global_step=89108, preemption_count=0, score=39536.904537, test/accuracy=0.597900, test/loss=1.717783, test/num_examples=10000, total_duration=42617.078525, train/accuracy=0.800742, train/loss=0.790377, validation/accuracy=0.725900, validation/loss=1.101864, validation/num_examples=50000
I0319 15:09:57.132818 139592107800320 logging_writer.py:48] [89500] global_step=89500, grad_norm=1.7683552503585815, loss=3.810225486755371
I0319 15:13:41.781050 139592099407616 logging_writer.py:48] [90000] global_step=90000, grad_norm=2.004854679107666, loss=3.6643083095550537
I0319 15:14:05.209550 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:14:15.531665 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:14:34.811730 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:14:36.426325 139793440028480 submission_runner.py:420] Time since start: 43068.32s, 	Step: 90054, 	{'train/accuracy': 0.8122069835662842, 'train/loss': 0.7413570880889893, 'validation/accuracy': 0.7295199632644653, 'validation/loss': 1.0877870321273804, 'validation/num_examples': 50000, 'test/accuracy': 0.6009000539779663, 'test/loss': 1.7063565254211426, 'test/num_examples': 10000, 'score': 39956.84877586365, 'total_duration': 43068.3249976635, 'accumulated_submission_time': 39956.84877586365, 'accumulated_eval_time': 3103.093540430069, 'accumulated_logging_time': 3.431971788406372}
I0319 15:14:36.454200 139592107800320 logging_writer.py:48] [90054] accumulated_eval_time=3103.093540, accumulated_logging_time=3.431972, accumulated_submission_time=39956.848776, global_step=90054, preemption_count=0, score=39956.848776, test/accuracy=0.600900, test/loss=1.706357, test/num_examples=10000, total_duration=43068.324998, train/accuracy=0.812207, train/loss=0.741357, validation/accuracy=0.729520, validation/loss=1.087787, validation/num_examples=50000
I0319 15:17:54.012982 139592099407616 logging_writer.py:48] [90500] global_step=90500, grad_norm=1.9459922313690186, loss=1.9180970191955566
I0319 15:21:36.528226 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:21:47.105616 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:22:10.225708 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:22:11.839340 139793440028480 submission_runner.py:420] Time since start: 43523.74s, 	Step: 90996, 	{'train/accuracy': 0.8010351657867432, 'train/loss': 0.7723552584648132, 'validation/accuracy': 0.7313999533653259, 'validation/loss': 1.0754905939102173, 'validation/num_examples': 50000, 'test/accuracy': 0.6005000472068787, 'test/loss': 1.6922496557235718, 'test/num_examples': 10000, 'score': 40376.85789036751, 'total_duration': 43523.73801469803, 'accumulated_submission_time': 40376.85789036751, 'accumulated_eval_time': 3138.4046683311462, 'accumulated_logging_time': 3.471984386444092}
I0319 15:22:11.864663 139592107800320 logging_writer.py:48] [90996] accumulated_eval_time=3138.404668, accumulated_logging_time=3.471984, accumulated_submission_time=40376.857890, global_step=90996, preemption_count=0, score=40376.857890, test/accuracy=0.600500, test/loss=1.692250, test/num_examples=10000, total_duration=43523.738015, train/accuracy=0.801035, train/loss=0.772355, validation/accuracy=0.731400, validation/loss=1.075491, validation/num_examples=50000
I0319 15:22:13.865420 139592099407616 logging_writer.py:48] [91000] global_step=91000, grad_norm=2.001110315322876, loss=1.6470460891723633
I0319 15:25:54.383244 139592107800320 logging_writer.py:48] [91500] global_step=91500, grad_norm=1.9176527261734009, loss=2.2344603538513184
I0319 15:29:12.091122 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:29:22.232114 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:29:45.120062 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:29:46.721924 139793440028480 submission_runner.py:420] Time since start: 43978.62s, 	Step: 91940, 	{'train/accuracy': 0.8031640648841858, 'train/loss': 0.7608716487884521, 'validation/accuracy': 0.7321799993515015, 'validation/loss': 1.074285864830017, 'validation/num_examples': 50000, 'test/accuracy': 0.6092000007629395, 'test/loss': 1.6871871948242188, 'test/num_examples': 10000, 'score': 40797.02273106575, 'total_duration': 43978.620604753494, 'accumulated_submission_time': 40797.02273106575, 'accumulated_eval_time': 3173.0354750156403, 'accumulated_logging_time': 3.5066089630126953}
I0319 15:29:46.747296 139592099407616 logging_writer.py:48] [91940] accumulated_eval_time=3173.035475, accumulated_logging_time=3.506609, accumulated_submission_time=40797.022731, global_step=91940, preemption_count=0, score=40797.022731, test/accuracy=0.609200, test/loss=1.687187, test/num_examples=10000, total_duration=43978.620605, train/accuracy=0.803164, train/loss=0.760872, validation/accuracy=0.732180, validation/loss=1.074286, validation/num_examples=50000
I0319 15:30:11.180944 139592107800320 logging_writer.py:48] [92000] global_step=92000, grad_norm=1.794956922531128, loss=1.5826078653335571
I0319 15:33:54.229952 139592099407616 logging_writer.py:48] [92500] global_step=92500, grad_norm=1.750235676765442, loss=1.795262336730957
I0319 15:36:46.953470 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:36:57.596766 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:37:18.301386 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:37:19.902255 139793440028480 submission_runner.py:420] Time since start: 44431.80s, 	Step: 92885, 	{'train/accuracy': 0.8125780820846558, 'train/loss': 0.7432088851928711, 'validation/accuracy': 0.7317599654197693, 'validation/loss': 1.080646276473999, 'validation/num_examples': 50000, 'test/accuracy': 0.610200047492981, 'test/loss': 1.6884973049163818, 'test/num_examples': 10000, 'score': 41217.16759157181, 'total_duration': 44431.800936460495, 'accumulated_submission_time': 41217.16759157181, 'accumulated_eval_time': 3205.9842755794525, 'accumulated_logging_time': 3.541409969329834}
I0319 15:37:19.925622 139592107800320 logging_writer.py:48] [92885] accumulated_eval_time=3205.984276, accumulated_logging_time=3.541410, accumulated_submission_time=41217.167592, global_step=92885, preemption_count=0, score=41217.167592, test/accuracy=0.610200, test/loss=1.688497, test/num_examples=10000, total_duration=44431.800936, train/accuracy=0.812578, train/loss=0.743209, validation/accuracy=0.731760, validation/loss=1.080646, validation/num_examples=50000
I0319 15:38:06.991236 139592099407616 logging_writer.py:48] [93000] global_step=93000, grad_norm=1.7449121475219727, loss=2.5311942100524902
I0319 15:41:51.130488 139592107800320 logging_writer.py:48] [93500] global_step=93500, grad_norm=1.8590153455734253, loss=1.5364413261413574
I0319 15:44:20.084243 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:44:30.239171 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:44:54.193391 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:44:55.794032 139793440028480 submission_runner.py:420] Time since start: 44887.69s, 	Step: 93833, 	{'train/accuracy': 0.8225781321525574, 'train/loss': 0.6907076835632324, 'validation/accuracy': 0.736579954624176, 'validation/loss': 1.04587721824646, 'validation/num_examples': 50000, 'test/accuracy': 0.6124000549316406, 'test/loss': 1.6616320610046387, 'test/num_examples': 10000, 'score': 41637.26306915283, 'total_duration': 44887.69271564484, 'accumulated_submission_time': 41637.26306915283, 'accumulated_eval_time': 3241.694093942642, 'accumulated_logging_time': 3.575056791305542}
I0319 15:44:55.819303 139592099407616 logging_writer.py:48] [93833] accumulated_eval_time=3241.694094, accumulated_logging_time=3.575057, accumulated_submission_time=41637.263069, global_step=93833, preemption_count=0, score=41637.263069, test/accuracy=0.612400, test/loss=1.661632, test/num_examples=10000, total_duration=44887.692716, train/accuracy=0.822578, train/loss=0.690708, validation/accuracy=0.736580, validation/loss=1.045877, validation/num_examples=50000
I0319 15:46:06.915157 139592107800320 logging_writer.py:48] [94000] global_step=94000, grad_norm=1.9761532545089722, loss=1.5258113145828247
I0319 15:49:51.975498 139592099407616 logging_writer.py:48] [94500] global_step=94500, grad_norm=2.1992547512054443, loss=1.6475616693496704
I0319 15:51:55.983214 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:52:06.490108 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 15:52:29.046032 139793440028480 spec.py:349] Evaluating on the test split.
I0319 15:52:30.660941 139793440028480 submission_runner.py:420] Time since start: 45342.56s, 	Step: 94778, 	{'train/accuracy': 0.8091992139816284, 'train/loss': 0.7314270734786987, 'validation/accuracy': 0.7390999794006348, 'validation/loss': 1.0349777936935425, 'validation/num_examples': 50000, 'test/accuracy': 0.6151000261306763, 'test/loss': 1.6441214084625244, 'test/num_examples': 10000, 'score': 42057.36578083038, 'total_duration': 45342.55961918831, 'accumulated_submission_time': 42057.36578083038, 'accumulated_eval_time': 3276.3718383312225, 'accumulated_logging_time': 3.6096181869506836}
I0319 15:52:30.683929 139592107800320 logging_writer.py:48] [94778] accumulated_eval_time=3276.371838, accumulated_logging_time=3.609618, accumulated_submission_time=42057.365781, global_step=94778, preemption_count=0, score=42057.365781, test/accuracy=0.615100, test/loss=1.644121, test/num_examples=10000, total_duration=45342.559619, train/accuracy=0.809199, train/loss=0.731427, validation/accuracy=0.739100, validation/loss=1.034978, validation/num_examples=50000
I0319 15:54:05.997278 139592099407616 logging_writer.py:48] [95000] global_step=95000, grad_norm=1.894190788269043, loss=2.510021686553955
I0319 15:57:51.458627 139592107800320 logging_writer.py:48] [95500] global_step=95500, grad_norm=1.7335604429244995, loss=2.893515110015869
I0319 15:59:30.874523 139793440028480 spec.py:321] Evaluating on the training split.
I0319 15:59:41.241940 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:00:03.999884 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:00:05.603875 139793440028480 submission_runner.py:420] Time since start: 45797.50s, 	Step: 95722, 	{'train/accuracy': 0.8138671517372131, 'train/loss': 0.7235919833183289, 'validation/accuracy': 0.736739993095398, 'validation/loss': 1.0535563230514526, 'validation/num_examples': 50000, 'test/accuracy': 0.6057000160217285, 'test/loss': 1.680138349533081, 'test/num_examples': 10000, 'score': 42477.49273610115, 'total_duration': 45797.50256180763, 'accumulated_submission_time': 42477.49273610115, 'accumulated_eval_time': 3311.101194858551, 'accumulated_logging_time': 3.6434314250946045}
I0319 16:00:05.627015 139592099407616 logging_writer.py:48] [95722] accumulated_eval_time=3311.101195, accumulated_logging_time=3.643431, accumulated_submission_time=42477.492736, global_step=95722, preemption_count=0, score=42477.492736, test/accuracy=0.605700, test/loss=1.680138, test/num_examples=10000, total_duration=45797.502562, train/accuracy=0.813867, train/loss=0.723592, validation/accuracy=0.736740, validation/loss=1.053556, validation/num_examples=50000
I0319 16:02:05.711359 139592107800320 logging_writer.py:48] [96000] global_step=96000, grad_norm=2.1182076930999756, loss=4.18105936050415
I0319 16:05:51.693085 139592099407616 logging_writer.py:48] [96500] global_step=96500, grad_norm=2.0905728340148926, loss=1.5207054615020752
I0319 16:07:05.831884 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:07:16.169242 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:07:36.263233 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:07:37.874055 139793440028480 submission_runner.py:420] Time since start: 46249.77s, 	Step: 96667, 	{'train/accuracy': 0.8196484446525574, 'train/loss': 0.704096257686615, 'validation/accuracy': 0.73853999376297, 'validation/loss': 1.0456427335739136, 'validation/num_examples': 50000, 'test/accuracy': 0.6146000027656555, 'test/loss': 1.6553770303726196, 'test/num_examples': 10000, 'score': 42897.63587832451, 'total_duration': 46249.7727265358, 'accumulated_submission_time': 42897.63587832451, 'accumulated_eval_time': 3343.1433713436127, 'accumulated_logging_time': 3.676774024963379}
I0319 16:07:37.902746 139592107800320 logging_writer.py:48] [96667] accumulated_eval_time=3343.143371, accumulated_logging_time=3.676774, accumulated_submission_time=42897.635878, global_step=96667, preemption_count=0, score=42897.635878, test/accuracy=0.614600, test/loss=1.655377, test/num_examples=10000, total_duration=46249.772727, train/accuracy=0.819648, train/loss=0.704096, validation/accuracy=0.738540, validation/loss=1.045643, validation/num_examples=50000
I0319 16:10:04.259744 139592099407616 logging_writer.py:48] [97000] global_step=97000, grad_norm=1.9208964109420776, loss=2.5538487434387207
I0319 16:13:49.213873 139592107800320 logging_writer.py:48] [97500] global_step=97500, grad_norm=2.039010763168335, loss=1.5569541454315186
I0319 16:14:38.335163 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:14:49.053819 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:15:11.196947 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:15:12.799508 139793440028480 submission_runner.py:420] Time since start: 46704.70s, 	Step: 97610, 	{'train/accuracy': 0.8161913752555847, 'train/loss': 0.7107599377632141, 'validation/accuracy': 0.7409999966621399, 'validation/loss': 1.0231674909591675, 'validation/num_examples': 50000, 'test/accuracy': 0.6165000200271606, 'test/loss': 1.6399441957473755, 'test/num_examples': 10000, 'score': 43318.00505113602, 'total_duration': 46704.69818735123, 'accumulated_submission_time': 43318.00505113602, 'accumulated_eval_time': 3377.6077132225037, 'accumulated_logging_time': 3.7166271209716797}
I0319 16:15:12.823377 139592099407616 logging_writer.py:48] [97610] accumulated_eval_time=3377.607713, accumulated_logging_time=3.716627, accumulated_submission_time=43318.005051, global_step=97610, preemption_count=0, score=43318.005051, test/accuracy=0.616500, test/loss=1.639944, test/num_examples=10000, total_duration=46704.698187, train/accuracy=0.816191, train/loss=0.710760, validation/accuracy=0.741000, validation/loss=1.023167, validation/num_examples=50000
I0319 16:18:03.778924 139592107800320 logging_writer.py:48] [98000] global_step=98000, grad_norm=1.9057615995407104, loss=2.290475845336914
I0319 16:21:48.684340 139592099407616 logging_writer.py:48] [98500] global_step=98500, grad_norm=2.363520383834839, loss=4.071584224700928
I0319 16:22:13.186519 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:22:23.463091 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:22:47.291057 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:22:48.899721 139793440028480 submission_runner.py:420] Time since start: 47160.80s, 	Step: 98556, 	{'train/accuracy': 0.8185741901397705, 'train/loss': 0.699514627456665, 'validation/accuracy': 0.7416399717330933, 'validation/loss': 1.0216460227966309, 'validation/num_examples': 50000, 'test/accuracy': 0.6168000102043152, 'test/loss': 1.6231310367584229, 'test/num_examples': 10000, 'score': 43738.30462694168, 'total_duration': 47160.798404455185, 'accumulated_submission_time': 43738.30462694168, 'accumulated_eval_time': 3413.3209006786346, 'accumulated_logging_time': 3.751324415206909}
I0319 16:22:48.921416 139592107800320 logging_writer.py:48] [98556] accumulated_eval_time=3413.320901, accumulated_logging_time=3.751324, accumulated_submission_time=43738.304627, global_step=98556, preemption_count=0, score=43738.304627, test/accuracy=0.616800, test/loss=1.623131, test/num_examples=10000, total_duration=47160.798404, train/accuracy=0.818574, train/loss=0.699515, validation/accuracy=0.741640, validation/loss=1.021646, validation/num_examples=50000
I0319 16:26:04.215715 139592099407616 logging_writer.py:48] [99000] global_step=99000, grad_norm=2.260319948196411, loss=3.138547658920288
I0319 16:29:49.574503 139592107800320 logging_writer.py:48] [99500] global_step=99500, grad_norm=2.049774408340454, loss=1.4657061100006104
I0319 16:29:49.588746 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:30:00.153578 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:30:21.467126 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:30:23.082195 139793440028480 submission_runner.py:420] Time since start: 47614.98s, 	Step: 99501, 	{'train/accuracy': 0.8238476514816284, 'train/loss': 0.6778075098991394, 'validation/accuracy': 0.7441200017929077, 'validation/loss': 1.0106030702590942, 'validation/num_examples': 50000, 'test/accuracy': 0.6188000440597534, 'test/loss': 1.6165797710418701, 'test/num_examples': 10000, 'score': 44158.91107749939, 'total_duration': 47614.98087024689, 'accumulated_submission_time': 44158.91107749939, 'accumulated_eval_time': 3446.814339160919, 'accumulated_logging_time': 3.7815587520599365}
I0319 16:30:23.112462 139592099407616 logging_writer.py:48] [99501] accumulated_eval_time=3446.814339, accumulated_logging_time=3.781559, accumulated_submission_time=44158.911077, global_step=99501, preemption_count=0, score=44158.911077, test/accuracy=0.618800, test/loss=1.616580, test/num_examples=10000, total_duration=47614.980870, train/accuracy=0.823848, train/loss=0.677808, validation/accuracy=0.744120, validation/loss=1.010603, validation/num_examples=50000
I0319 16:34:03.635950 139592107800320 logging_writer.py:48] [100000] global_step=100000, grad_norm=2.250927209854126, loss=1.501192569732666
I0319 16:37:23.153887 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:37:34.072246 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:37:56.785753 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:37:58.395020 139793440028480 submission_runner.py:420] Time since start: 48070.29s, 	Step: 100444, 	{'train/accuracy': 0.8323046565055847, 'train/loss': 0.6562907099723816, 'validation/accuracy': 0.7439799904823303, 'validation/loss': 1.0213578939437866, 'validation/num_examples': 50000, 'test/accuracy': 0.6168000102043152, 'test/loss': 1.6335022449493408, 'test/num_examples': 10000, 'score': 44578.8914835453, 'total_duration': 48070.29369139671, 'accumulated_submission_time': 44578.8914835453, 'accumulated_eval_time': 3482.0554757118225, 'accumulated_logging_time': 3.821136474609375}
I0319 16:37:58.419205 139592099407616 logging_writer.py:48] [100444] accumulated_eval_time=3482.055476, accumulated_logging_time=3.821136, accumulated_submission_time=44578.891484, global_step=100444, preemption_count=0, score=44578.891484, test/accuracy=0.616800, test/loss=1.633502, test/num_examples=10000, total_duration=48070.293691, train/accuracy=0.832305, train/loss=0.656291, validation/accuracy=0.743980, validation/loss=1.021358, validation/num_examples=50000
I0319 16:38:21.245462 139592107800320 logging_writer.py:48] [100500] global_step=100500, grad_norm=1.9209073781967163, loss=3.1163337230682373
I0319 16:42:04.565795 139592099407616 logging_writer.py:48] [101000] global_step=101000, grad_norm=2.0051095485687256, loss=3.3721728324890137
I0319 16:44:58.549404 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:45:08.887719 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:45:29.799617 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:45:31.413433 139793440028480 submission_runner.py:420] Time since start: 48523.31s, 	Step: 101388, 	{'train/accuracy': 0.8255273103713989, 'train/loss': 0.6668426394462585, 'validation/accuracy': 0.7452600002288818, 'validation/loss': 1.003542184829712, 'validation/num_examples': 50000, 'test/accuracy': 0.6236000061035156, 'test/loss': 1.609777808189392, 'test/num_examples': 10000, 'score': 44998.959970235825, 'total_duration': 48523.312101364136, 'accumulated_submission_time': 44998.959970235825, 'accumulated_eval_time': 3514.9195449352264, 'accumulated_logging_time': 3.8547041416168213}
I0319 16:45:31.447776 139592107800320 logging_writer.py:48] [101388] accumulated_eval_time=3514.919545, accumulated_logging_time=3.854704, accumulated_submission_time=44998.959970, global_step=101388, preemption_count=0, score=44998.959970, test/accuracy=0.623600, test/loss=1.609778, test/num_examples=10000, total_duration=48523.312101, train/accuracy=0.825527, train/loss=0.666843, validation/accuracy=0.745260, validation/loss=1.003542, validation/num_examples=50000
I0319 16:46:17.638207 139592099407616 logging_writer.py:48] [101500] global_step=101500, grad_norm=1.9216089248657227, loss=2.6846625804901123
I0319 16:50:03.628520 139592107800320 logging_writer.py:48] [102000] global_step=102000, grad_norm=2.12296199798584, loss=1.4354991912841797
I0319 16:52:31.490164 139793440028480 spec.py:321] Evaluating on the training split.
I0319 16:52:41.951889 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 16:53:05.582541 139793440028480 spec.py:349] Evaluating on the test split.
I0319 16:53:07.190433 139793440028480 submission_runner.py:420] Time since start: 48979.09s, 	Step: 102330, 	{'train/accuracy': 0.8272460699081421, 'train/loss': 0.6679974794387817, 'validation/accuracy': 0.7484399676322937, 'validation/loss': 1.0021166801452637, 'validation/num_examples': 50000, 'test/accuracy': 0.6233000159263611, 'test/loss': 1.6095317602157593, 'test/num_examples': 10000, 'score': 45418.93943095207, 'total_duration': 48979.08910894394, 'accumulated_submission_time': 45418.93943095207, 'accumulated_eval_time': 3550.6198267936707, 'accumulated_logging_time': 3.8995537757873535}
I0319 16:53:07.214736 139592099407616 logging_writer.py:48] [102330] accumulated_eval_time=3550.619827, accumulated_logging_time=3.899554, accumulated_submission_time=45418.939431, global_step=102330, preemption_count=0, score=45418.939431, test/accuracy=0.623300, test/loss=1.609532, test/num_examples=10000, total_duration=48979.089109, train/accuracy=0.827246, train/loss=0.667997, validation/accuracy=0.748440, validation/loss=1.002117, validation/num_examples=50000
I0319 16:54:18.978002 139592107800320 logging_writer.py:48] [102500] global_step=102500, grad_norm=2.0519602298736572, loss=3.0613155364990234
I0319 16:58:03.793840 139592099407616 logging_writer.py:48] [103000] global_step=103000, grad_norm=2.1587841510772705, loss=1.4828815460205078
I0319 17:00:07.246246 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:00:17.520286 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:00:38.483033 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:00:40.096154 139793440028480 submission_runner.py:420] Time since start: 49431.99s, 	Step: 103276, 	{'train/accuracy': 0.833789050579071, 'train/loss': 0.6367660164833069, 'validation/accuracy': 0.7475000023841858, 'validation/loss': 0.9865875244140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6249000430107117, 'test/loss': 1.5951905250549316, 'test/num_examples': 10000, 'score': 45838.909757614136, 'total_duration': 49431.99482727051, 'accumulated_submission_time': 45838.909757614136, 'accumulated_eval_time': 3583.4697527885437, 'accumulated_logging_time': 3.932786464691162}
I0319 17:00:40.119693 139592107800320 logging_writer.py:48] [103276] accumulated_eval_time=3583.469753, accumulated_logging_time=3.932786, accumulated_submission_time=45838.909758, global_step=103276, preemption_count=0, score=45838.909758, test/accuracy=0.624900, test/loss=1.595191, test/num_examples=10000, total_duration=49431.994827, train/accuracy=0.833789, train/loss=0.636766, validation/accuracy=0.747500, validation/loss=0.986588, validation/num_examples=50000
I0319 17:02:16.813252 139592099407616 logging_writer.py:48] [103500] global_step=103500, grad_norm=2.1794545650482178, loss=1.8129429817199707
I0319 17:06:02.633951 139592107800320 logging_writer.py:48] [104000] global_step=104000, grad_norm=2.1084628105163574, loss=1.8190925121307373
I0319 17:07:40.189565 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:07:50.799186 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:08:10.159944 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:08:11.777644 139793440028480 submission_runner.py:420] Time since start: 49883.68s, 	Step: 104218, 	{'train/accuracy': 0.8297656178474426, 'train/loss': 0.6642767786979675, 'validation/accuracy': 0.7516399621963501, 'validation/loss': 0.994663655757904, 'validation/num_examples': 50000, 'test/accuracy': 0.6238000392913818, 'test/loss': 1.6038514375686646, 'test/num_examples': 10000, 'score': 46258.91853380203, 'total_duration': 49883.67628288269, 'accumulated_submission_time': 46258.91853380203, 'accumulated_eval_time': 3615.0578157901764, 'accumulated_logging_time': 3.9654600620269775}
I0319 17:08:11.827981 139592099407616 logging_writer.py:48] [104218] accumulated_eval_time=3615.057816, accumulated_logging_time=3.965460, accumulated_submission_time=46258.918534, global_step=104218, preemption_count=0, score=46258.918534, test/accuracy=0.623800, test/loss=1.603851, test/num_examples=10000, total_duration=49883.676283, train/accuracy=0.829766, train/loss=0.664277, validation/accuracy=0.751640, validation/loss=0.994664, validation/num_examples=50000
I0319 17:10:15.182466 139592107800320 logging_writer.py:48] [104500] global_step=104500, grad_norm=1.9900357723236084, loss=1.6080816984176636
I0319 17:14:00.221758 139592099407616 logging_writer.py:48] [105000] global_step=105000, grad_norm=2.360697031021118, loss=3.6423065662384033
I0319 17:15:12.123687 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:15:22.446790 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:15:43.489147 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:15:45.099405 139793440028480 submission_runner.py:420] Time since start: 50337.00s, 	Step: 105160, 	{'train/accuracy': 0.8348437547683716, 'train/loss': 0.6299718618392944, 'validation/accuracy': 0.753059983253479, 'validation/loss': 0.9723790287971497, 'validation/num_examples': 50000, 'test/accuracy': 0.6304000020027161, 'test/loss': 1.5898592472076416, 'test/num_examples': 10000, 'score': 46679.14871048927, 'total_duration': 50336.998074769974, 'accumulated_submission_time': 46679.14871048927, 'accumulated_eval_time': 3648.033533334732, 'accumulated_logging_time': 4.029381513595581}
I0319 17:15:45.130603 139592107800320 logging_writer.py:48] [105160] accumulated_eval_time=3648.033533, accumulated_logging_time=4.029382, accumulated_submission_time=46679.148710, global_step=105160, preemption_count=0, score=46679.148710, test/accuracy=0.630400, test/loss=1.589859, test/num_examples=10000, total_duration=50336.998075, train/accuracy=0.834844, train/loss=0.629972, validation/accuracy=0.753060, validation/loss=0.972379, validation/num_examples=50000
I0319 17:18:13.523112 139592099407616 logging_writer.py:48] [105500] global_step=105500, grad_norm=2.1897730827331543, loss=1.4803093671798706
I0319 17:21:58.203419 139592107800320 logging_writer.py:48] [106000] global_step=106000, grad_norm=2.373365640640259, loss=1.4252828359603882
I0319 17:22:45.213954 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:22:55.522493 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:23:17.322930 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:23:18.931303 139793440028480 submission_runner.py:420] Time since start: 50790.83s, 	Step: 106106, 	{'train/accuracy': 0.8372851610183716, 'train/loss': 0.6215903759002686, 'validation/accuracy': 0.7533999681472778, 'validation/loss': 0.9754841327667236, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.5825921297073364, 'test/num_examples': 10000, 'score': 47099.167150735855, 'total_duration': 50790.82998538017, 'accumulated_submission_time': 47099.167150735855, 'accumulated_eval_time': 3681.750886440277, 'accumulated_logging_time': 4.073232889175415}
I0319 17:23:18.957217 139592099407616 logging_writer.py:48] [106106] accumulated_eval_time=3681.750886, accumulated_logging_time=4.073233, accumulated_submission_time=47099.167151, global_step=106106, preemption_count=0, score=47099.167151, test/accuracy=0.628800, test/loss=1.582592, test/num_examples=10000, total_duration=50790.829985, train/accuracy=0.837285, train/loss=0.621590, validation/accuracy=0.753400, validation/loss=0.975484, validation/num_examples=50000
I0319 17:26:11.650959 139592107800320 logging_writer.py:48] [106500] global_step=106500, grad_norm=2.1416304111480713, loss=1.8158711194992065
I0319 17:29:56.906332 139592099407616 logging_writer.py:48] [107000] global_step=107000, grad_norm=2.072605609893799, loss=1.5121822357177734
I0319 17:30:19.235563 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:30:29.694024 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:30:50.041416 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:30:51.652112 139793440028480 submission_runner.py:420] Time since start: 51243.55s, 	Step: 107051, 	{'train/accuracy': 0.8421874642372131, 'train/loss': 0.6038376688957214, 'validation/accuracy': 0.7533400058746338, 'validation/loss': 0.9784523844718933, 'validation/num_examples': 50000, 'test/accuracy': 0.6310000419616699, 'test/loss': 1.5913622379302979, 'test/num_examples': 10000, 'score': 47519.38187241554, 'total_duration': 51243.55078268051, 'accumulated_submission_time': 47519.38187241554, 'accumulated_eval_time': 3714.167423725128, 'accumulated_logging_time': 4.110680103302002}
I0319 17:30:51.683573 139592107800320 logging_writer.py:48] [107051] accumulated_eval_time=3714.167424, accumulated_logging_time=4.110680, accumulated_submission_time=47519.381872, global_step=107051, preemption_count=0, score=47519.381872, test/accuracy=0.631000, test/loss=1.591362, test/num_examples=10000, total_duration=51243.550783, train/accuracy=0.842187, train/loss=0.603838, validation/accuracy=0.753340, validation/loss=0.978452, validation/num_examples=50000
I0319 17:34:09.466576 139592099407616 logging_writer.py:48] [107500] global_step=107500, grad_norm=2.2301902770996094, loss=2.56180477142334
I0319 17:37:51.709816 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:38:02.204301 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:38:24.691293 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:38:26.298474 139793440028480 submission_runner.py:420] Time since start: 51698.20s, 	Step: 107994, 	{'train/accuracy': 0.8350781202316284, 'train/loss': 0.6316884756088257, 'validation/accuracy': 0.7540199756622314, 'validation/loss': 0.968947172164917, 'validation/num_examples': 50000, 'test/accuracy': 0.6300000548362732, 'test/loss': 1.5743050575256348, 'test/num_examples': 10000, 'score': 47939.34608221054, 'total_duration': 51698.19714593887, 'accumulated_submission_time': 47939.34608221054, 'accumulated_eval_time': 3748.756111383438, 'accumulated_logging_time': 4.151872634887695}
I0319 17:38:26.325079 139592107800320 logging_writer.py:48] [107994] accumulated_eval_time=3748.756111, accumulated_logging_time=4.151873, accumulated_submission_time=47939.346082, global_step=107994, preemption_count=0, score=47939.346082, test/accuracy=0.630000, test/loss=1.574305, test/num_examples=10000, total_duration=51698.197146, train/accuracy=0.835078, train/loss=0.631688, validation/accuracy=0.754020, validation/loss=0.968947, validation/num_examples=50000
I0319 17:38:29.135248 139592099407616 logging_writer.py:48] [108000] global_step=108000, grad_norm=2.1211764812469482, loss=1.5436408519744873
I0319 17:42:09.922573 139592107800320 logging_writer.py:48] [108500] global_step=108500, grad_norm=2.1272683143615723, loss=2.993192195892334
I0319 17:45:26.559370 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:45:37.000067 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:45:57.886944 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:45:59.504551 139793440028480 submission_runner.py:420] Time since start: 52151.40s, 	Step: 108939, 	{'train/accuracy': 0.8401757478713989, 'train/loss': 0.6095958352088928, 'validation/accuracy': 0.7569599747657776, 'validation/loss': 0.9585469961166382, 'validation/num_examples': 50000, 'test/accuracy': 0.6322000026702881, 'test/loss': 1.5597306489944458, 'test/num_examples': 10000, 'score': 48359.519057273865, 'total_duration': 52151.403217315674, 'accumulated_submission_time': 48359.519057273865, 'accumulated_eval_time': 3781.701289653778, 'accumulated_logging_time': 4.187899827957153}
I0319 17:45:59.537822 139592099407616 logging_writer.py:48] [108939] accumulated_eval_time=3781.701290, accumulated_logging_time=4.187900, accumulated_submission_time=48359.519057, global_step=108939, preemption_count=0, score=48359.519057, test/accuracy=0.632200, test/loss=1.559731, test/num_examples=10000, total_duration=52151.403217, train/accuracy=0.840176, train/loss=0.609596, validation/accuracy=0.756960, validation/loss=0.958547, validation/num_examples=50000
I0319 17:46:24.388231 139592107800320 logging_writer.py:48] [109000] global_step=109000, grad_norm=2.0761098861694336, loss=2.816209316253662
I0319 17:50:08.085828 139592099407616 logging_writer.py:48] [109500] global_step=109500, grad_norm=2.025739908218384, loss=2.528885841369629
I0319 17:52:59.922101 139793440028480 spec.py:321] Evaluating on the training split.
I0319 17:53:10.642233 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 17:53:34.245608 139793440028480 spec.py:349] Evaluating on the test split.
I0319 17:53:35.855166 139793440028480 submission_runner.py:420] Time since start: 52607.75s, 	Step: 109884, 	{'train/accuracy': 0.8474804759025574, 'train/loss': 0.5809025168418884, 'validation/accuracy': 0.7572599649429321, 'validation/loss': 0.9565075039863586, 'validation/num_examples': 50000, 'test/accuracy': 0.6308000087738037, 'test/loss': 1.5641238689422607, 'test/num_examples': 10000, 'score': 48779.83942055702, 'total_duration': 52607.753846883774, 'accumulated_submission_time': 48779.83942055702, 'accumulated_eval_time': 3817.634386777878, 'accumulated_logging_time': 4.231295108795166}
I0319 17:53:35.884385 139592107800320 logging_writer.py:48] [109884] accumulated_eval_time=3817.634387, accumulated_logging_time=4.231295, accumulated_submission_time=48779.839421, global_step=109884, preemption_count=0, score=48779.839421, test/accuracy=0.630800, test/loss=1.564124, test/num_examples=10000, total_duration=52607.753847, train/accuracy=0.847480, train/loss=0.580903, validation/accuracy=0.757260, validation/loss=0.956508, validation/num_examples=50000
I0319 17:54:23.413222 139592099407616 logging_writer.py:48] [110000] global_step=110000, grad_norm=2.314227819442749, loss=1.5337198972702026
I0319 17:58:08.931405 139592107800320 logging_writer.py:48] [110500] global_step=110500, grad_norm=2.3992624282836914, loss=1.5719672441482544
I0319 18:00:35.993908 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:00:46.301992 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:01:08.359498 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:01:09.961337 139793440028480 submission_runner.py:420] Time since start: 53061.86s, 	Step: 110830, 	{'train/accuracy': 0.84130859375, 'train/loss': 0.611589789390564, 'validation/accuracy': 0.7575799822807312, 'validation/loss': 0.9555621147155762, 'validation/num_examples': 50000, 'test/accuracy': 0.6379000544548035, 'test/loss': 1.555673360824585, 'test/num_examples': 10000, 'score': 49199.886014938354, 'total_duration': 53061.86001467705, 'accumulated_submission_time': 49199.886014938354, 'accumulated_eval_time': 3851.6018323898315, 'accumulated_logging_time': 4.2699151039123535}
I0319 18:01:09.988209 139592099407616 logging_writer.py:48] [110830] accumulated_eval_time=3851.601832, accumulated_logging_time=4.269915, accumulated_submission_time=49199.886015, global_step=110830, preemption_count=0, score=49199.886015, test/accuracy=0.637900, test/loss=1.555673, test/num_examples=10000, total_duration=53061.860015, train/accuracy=0.841309, train/loss=0.611590, validation/accuracy=0.757580, validation/loss=0.955562, validation/num_examples=50000
I0319 18:02:21.931875 139592107800320 logging_writer.py:48] [111000] global_step=111000, grad_norm=2.5354573726654053, loss=1.4404574632644653
I0319 18:06:06.647395 139592099407616 logging_writer.py:48] [111500] global_step=111500, grad_norm=2.3156001567840576, loss=2.804616928100586
I0319 18:08:10.093421 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:08:20.688180 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:08:43.279080 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:08:44.882605 139793440028480 submission_runner.py:420] Time since start: 53516.78s, 	Step: 111776, 	{'train/accuracy': 0.8459570407867432, 'train/loss': 0.5894351005554199, 'validation/accuracy': 0.7598599791526794, 'validation/loss': 0.9470462799072266, 'validation/num_examples': 50000, 'test/accuracy': 0.6331000328063965, 'test/loss': 1.547625184059143, 'test/num_examples': 10000, 'score': 49619.927680015564, 'total_duration': 53516.78128504753, 'accumulated_submission_time': 49619.927680015564, 'accumulated_eval_time': 3886.3910517692566, 'accumulated_logging_time': 4.307658910751343}
I0319 18:08:44.907225 139592107800320 logging_writer.py:48] [111776] accumulated_eval_time=3886.391052, accumulated_logging_time=4.307659, accumulated_submission_time=49619.927680, global_step=111776, preemption_count=0, score=49619.927680, test/accuracy=0.633100, test/loss=1.547625, test/num_examples=10000, total_duration=53516.781285, train/accuracy=0.845957, train/loss=0.589435, validation/accuracy=0.759860, validation/loss=0.947046, validation/num_examples=50000
I0319 18:10:20.720512 139592099407616 logging_writer.py:48] [112000] global_step=112000, grad_norm=2.489290475845337, loss=1.424668788909912
I0319 18:14:05.821176 139592107800320 logging_writer.py:48] [112500] global_step=112500, grad_norm=2.5110254287719727, loss=3.2085001468658447
I0319 18:15:44.977278 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:15:55.546835 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:16:15.923782 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:16:17.532342 139793440028480 submission_runner.py:420] Time since start: 53969.43s, 	Step: 112720, 	{'train/accuracy': 0.84619140625, 'train/loss': 0.5805347561836243, 'validation/accuracy': 0.7622799873352051, 'validation/loss': 0.9378506541252136, 'validation/num_examples': 50000, 'test/accuracy': 0.6384000182151794, 'test/loss': 1.5401344299316406, 'test/num_examples': 10000, 'score': 50039.9345574379, 'total_duration': 53969.43102359772, 'accumulated_submission_time': 50039.9345574379, 'accumulated_eval_time': 3918.946114063263, 'accumulated_logging_time': 4.342726469039917}
I0319 18:16:17.559512 139592099407616 logging_writer.py:48] [112720] accumulated_eval_time=3918.946114, accumulated_logging_time=4.342726, accumulated_submission_time=50039.934557, global_step=112720, preemption_count=0, score=50039.934557, test/accuracy=0.638400, test/loss=1.540134, test/num_examples=10000, total_duration=53969.431024, train/accuracy=0.846191, train/loss=0.580535, validation/accuracy=0.762280, validation/loss=0.937851, validation/num_examples=50000
I0319 18:18:19.936052 139592107800320 logging_writer.py:48] [113000] global_step=113000, grad_norm=2.677462339401245, loss=1.4348368644714355
I0319 18:22:05.233812 139592099407616 logging_writer.py:48] [113500] global_step=113500, grad_norm=2.3763372898101807, loss=1.3067710399627686
I0319 18:23:17.659545 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:23:28.216017 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:23:51.713739 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:23:53.316215 139793440028480 submission_runner.py:420] Time since start: 54425.21s, 	Step: 113662, 	{'train/accuracy': 0.8561522960662842, 'train/loss': 0.5643961429595947, 'validation/accuracy': 0.7628399729728699, 'validation/loss': 0.9491704702377319, 'validation/num_examples': 50000, 'test/accuracy': 0.6375000476837158, 'test/loss': 1.5496562719345093, 'test/num_examples': 10000, 'score': 50459.97273135185, 'total_duration': 54425.21489691734, 'accumulated_submission_time': 50459.97273135185, 'accumulated_eval_time': 3954.6028020381927, 'accumulated_logging_time': 4.378979921340942}
I0319 18:23:53.340266 139592107800320 logging_writer.py:48] [113662] accumulated_eval_time=3954.602802, accumulated_logging_time=4.378980, accumulated_submission_time=50459.972731, global_step=113662, preemption_count=0, score=50459.972731, test/accuracy=0.637500, test/loss=1.549656, test/num_examples=10000, total_duration=54425.214897, train/accuracy=0.856152, train/loss=0.564396, validation/accuracy=0.762840, validation/loss=0.949170, validation/num_examples=50000
I0319 18:26:21.481366 139592099407616 logging_writer.py:48] [114000] global_step=114000, grad_norm=2.1909337043762207, loss=2.3884952068328857
I0319 18:30:07.054444 139592107800320 logging_writer.py:48] [114500] global_step=114500, grad_norm=2.168255567550659, loss=3.0811703205108643
I0319 18:30:53.374465 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:31:03.731394 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:31:25.587908 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:31:27.201760 139793440028480 submission_runner.py:420] Time since start: 54879.10s, 	Step: 114604, 	{'train/accuracy': 0.8505468368530273, 'train/loss': 0.5697076320648193, 'validation/accuracy': 0.7631799578666687, 'validation/loss': 0.931150496006012, 'validation/num_examples': 50000, 'test/accuracy': 0.6397000551223755, 'test/loss': 1.5249947309494019, 'test/num_examples': 10000, 'score': 50879.94529294968, 'total_duration': 54879.10041451454, 'accumulated_submission_time': 50879.94529294968, 'accumulated_eval_time': 3988.4300713539124, 'accumulated_logging_time': 4.412188529968262}
I0319 18:31:27.234550 139592099407616 logging_writer.py:48] [114604] accumulated_eval_time=3988.430071, accumulated_logging_time=4.412189, accumulated_submission_time=50879.945293, global_step=114604, preemption_count=0, score=50879.945293, test/accuracy=0.639700, test/loss=1.524995, test/num_examples=10000, total_duration=54879.100415, train/accuracy=0.850547, train/loss=0.569708, validation/accuracy=0.763180, validation/loss=0.931150, validation/num_examples=50000
I0319 18:34:21.358263 139592107800320 logging_writer.py:48] [115000] global_step=115000, grad_norm=2.6272988319396973, loss=3.7061538696289062
I0319 18:38:07.214679 139592099407616 logging_writer.py:48] [115500] global_step=115500, grad_norm=2.5284266471862793, loss=1.4621100425720215
I0319 18:38:27.452531 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:38:37.906712 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:38:58.143060 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:38:59.755272 139793440028480 submission_runner.py:420] Time since start: 55331.65s, 	Step: 115547, 	{'train/accuracy': 0.8536718487739563, 'train/loss': 0.5610446929931641, 'validation/accuracy': 0.7638999819755554, 'validation/loss': 0.9312052726745605, 'validation/num_examples': 50000, 'test/accuracy': 0.6373000144958496, 'test/loss': 1.5294908285140991, 'test/num_examples': 10000, 'score': 51300.09628677368, 'total_duration': 55331.65394306183, 'accumulated_submission_time': 51300.09628677368, 'accumulated_eval_time': 4020.7327842712402, 'accumulated_logging_time': 4.459543704986572}
I0319 18:38:59.785337 139592107800320 logging_writer.py:48] [115547] accumulated_eval_time=4020.732784, accumulated_logging_time=4.459544, accumulated_submission_time=51300.096287, global_step=115547, preemption_count=0, score=51300.096287, test/accuracy=0.637300, test/loss=1.529491, test/num_examples=10000, total_duration=55331.653943, train/accuracy=0.853672, train/loss=0.561045, validation/accuracy=0.763900, validation/loss=0.931205, validation/num_examples=50000
I0319 18:42:19.765565 139592099407616 logging_writer.py:48] [116000] global_step=116000, grad_norm=2.566307783126831, loss=1.5288130044937134
I0319 18:46:00.147233 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:46:10.543884 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:46:31.905103 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:46:33.533591 139793440028480 submission_runner.py:420] Time since start: 55785.43s, 	Step: 116490, 	{'train/accuracy': 0.8540233969688416, 'train/loss': 0.5607977509498596, 'validation/accuracy': 0.7656799554824829, 'validation/loss': 0.9310572147369385, 'validation/num_examples': 50000, 'test/accuracy': 0.6445000171661377, 'test/loss': 1.5323371887207031, 'test/num_examples': 10000, 'score': 51720.394916534424, 'total_duration': 55785.432247400284, 'accumulated_submission_time': 51720.394916534424, 'accumulated_eval_time': 4054.1191594600677, 'accumulated_logging_time': 4.499362468719482}
I0319 18:46:33.562564 139592107800320 logging_writer.py:48] [116490] accumulated_eval_time=4054.119159, accumulated_logging_time=4.499362, accumulated_submission_time=51720.394917, global_step=116490, preemption_count=0, score=51720.394917, test/accuracy=0.644500, test/loss=1.532337, test/num_examples=10000, total_duration=55785.432247, train/accuracy=0.854023, train/loss=0.560798, validation/accuracy=0.765680, validation/loss=0.931057, validation/num_examples=50000
I0319 18:46:37.991525 139592099407616 logging_writer.py:48] [116500] global_step=116500, grad_norm=2.2456228733062744, loss=2.736477851867676
I0319 18:50:18.940895 139592107800320 logging_writer.py:48] [117000] global_step=117000, grad_norm=2.604966878890991, loss=3.701939582824707
I0319 18:53:33.594738 139793440028480 spec.py:321] Evaluating on the training split.
I0319 18:53:43.952313 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 18:54:08.233531 139793440028480 spec.py:349] Evaluating on the test split.
I0319 18:54:09.838981 139793440028480 submission_runner.py:420] Time since start: 56241.74s, 	Step: 117434, 	{'train/accuracy': 0.8561718463897705, 'train/loss': 0.5504412055015564, 'validation/accuracy': 0.7667399644851685, 'validation/loss': 0.9199657440185547, 'validation/num_examples': 50000, 'test/accuracy': 0.6425000429153442, 'test/loss': 1.5176986455917358, 'test/num_examples': 10000, 'score': 52140.364542007446, 'total_duration': 56241.737661123276, 'accumulated_submission_time': 52140.364542007446, 'accumulated_eval_time': 4090.3634123802185, 'accumulated_logging_time': 4.538177728652954}
I0319 18:54:09.866860 139592099407616 logging_writer.py:48] [117434] accumulated_eval_time=4090.363412, accumulated_logging_time=4.538178, accumulated_submission_time=52140.364542, global_step=117434, preemption_count=0, score=52140.364542, test/accuracy=0.642500, test/loss=1.517699, test/num_examples=10000, total_duration=56241.737661, train/accuracy=0.856172, train/loss=0.550441, validation/accuracy=0.766740, validation/loss=0.919966, validation/num_examples=50000
I0319 18:54:36.688519 139592107800320 logging_writer.py:48] [117500] global_step=117500, grad_norm=2.5073158740997314, loss=1.4955191612243652
I0319 18:58:19.722301 139592099407616 logging_writer.py:48] [118000] global_step=118000, grad_norm=2.520632743835449, loss=1.3232967853546143
I0319 19:01:10.185825 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:01:20.642322 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:01:42.770014 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:01:44.371359 139793440028480 submission_runner.py:420] Time since start: 56696.27s, 	Step: 118382, 	{'train/accuracy': 0.8539453148841858, 'train/loss': 0.5580064058303833, 'validation/accuracy': 0.7667799592018127, 'validation/loss': 0.9167547225952148, 'validation/num_examples': 50000, 'test/accuracy': 0.64410001039505, 'test/loss': 1.512929081916809, 'test/num_examples': 10000, 'score': 52560.621530056, 'total_duration': 56696.270032167435, 'accumulated_submission_time': 52560.621530056, 'accumulated_eval_time': 4124.5489621162415, 'accumulated_logging_time': 4.575566053390503}
I0319 19:01:44.397015 139592107800320 logging_writer.py:48] [118382] accumulated_eval_time=4124.548962, accumulated_logging_time=4.575566, accumulated_submission_time=52560.621530, global_step=118382, preemption_count=0, score=52560.621530, test/accuracy=0.644100, test/loss=1.512929, test/num_examples=10000, total_duration=56696.270032, train/accuracy=0.853945, train/loss=0.558006, validation/accuracy=0.766780, validation/loss=0.916755, validation/num_examples=50000
I0319 19:02:32.958980 139592099407616 logging_writer.py:48] [118500] global_step=118500, grad_norm=2.8473713397979736, loss=3.1723010540008545
I0319 19:06:18.161522 139592107800320 logging_writer.py:48] [119000] global_step=119000, grad_norm=2.6526546478271484, loss=1.5923329591751099
I0319 19:08:44.501650 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:08:54.987456 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:09:15.175450 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:09:16.784658 139793440028480 submission_runner.py:420] Time since start: 57148.68s, 	Step: 119327, 	{'train/accuracy': 0.8578320145606995, 'train/loss': 0.5392902493476868, 'validation/accuracy': 0.7668399810791016, 'validation/loss': 0.9132672548294067, 'validation/num_examples': 50000, 'test/accuracy': 0.6463000178337097, 'test/loss': 1.503037691116333, 'test/num_examples': 10000, 'score': 52980.662798166275, 'total_duration': 57148.683334350586, 'accumulated_submission_time': 52980.662798166275, 'accumulated_eval_time': 4156.831968307495, 'accumulated_logging_time': 4.611612796783447}
I0319 19:09:16.808946 139592099407616 logging_writer.py:48] [119327] accumulated_eval_time=4156.831968, accumulated_logging_time=4.611613, accumulated_submission_time=52980.662798, global_step=119327, preemption_count=0, score=52980.662798, test/accuracy=0.646300, test/loss=1.503038, test/num_examples=10000, total_duration=57148.683334, train/accuracy=0.857832, train/loss=0.539290, validation/accuracy=0.766840, validation/loss=0.913267, validation/num_examples=50000
I0319 19:10:30.343707 139592107800320 logging_writer.py:48] [119500] global_step=119500, grad_norm=2.4259297847747803, loss=1.2689176797866821
I0319 19:14:15.441833 139592099407616 logging_writer.py:48] [120000] global_step=120000, grad_norm=2.6675028800964355, loss=1.421124815940857
I0319 19:16:16.942556 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:16:27.294867 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:16:47.900948 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:16:49.519574 139793440028480 submission_runner.py:420] Time since start: 57601.42s, 	Step: 120271, 	{'train/accuracy': 0.8631249666213989, 'train/loss': 0.5213625431060791, 'validation/accuracy': 0.769059956073761, 'validation/loss': 0.909471869468689, 'validation/num_examples': 50000, 'test/accuracy': 0.647100031375885, 'test/loss': 1.4938733577728271, 'test/num_examples': 10000, 'score': 53400.73462295532, 'total_duration': 57601.41824054718, 'accumulated_submission_time': 53400.73462295532, 'accumulated_eval_time': 4189.408996105194, 'accumulated_logging_time': 4.6450583934783936}
I0319 19:16:49.556639 139592107800320 logging_writer.py:48] [120271] accumulated_eval_time=4189.408996, accumulated_logging_time=4.645058, accumulated_submission_time=53400.734623, global_step=120271, preemption_count=0, score=53400.734623, test/accuracy=0.647100, test/loss=1.493873, test/num_examples=10000, total_duration=57601.418241, train/accuracy=0.863125, train/loss=0.521363, validation/accuracy=0.769060, validation/loss=0.909472, validation/num_examples=50000
I0319 19:18:28.477206 139592099407616 logging_writer.py:48] [120500] global_step=120500, grad_norm=2.4165215492248535, loss=1.6385612487792969
I0319 19:22:13.990838 139592107800320 logging_writer.py:48] [121000] global_step=121000, grad_norm=2.668788194656372, loss=1.4112669229507446
I0319 19:23:49.543533 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:23:59.981215 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:24:21.130230 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:24:22.738578 139793440028480 submission_runner.py:420] Time since start: 58054.64s, 	Step: 121213, 	{'train/accuracy': 0.8573827743530273, 'train/loss': 0.5495367050170898, 'validation/accuracy': 0.7687599658966064, 'validation/loss': 0.9154432415962219, 'validation/num_examples': 50000, 'test/accuracy': 0.6465000510215759, 'test/loss': 1.504189372062683, 'test/num_examples': 10000, 'score': 53820.65683197975, 'total_duration': 58054.6372487545, 'accumulated_submission_time': 53820.65683197975, 'accumulated_eval_time': 4222.604034662247, 'accumulated_logging_time': 4.694658279418945}
I0319 19:24:22.771208 139592099407616 logging_writer.py:48] [121213] accumulated_eval_time=4222.604035, accumulated_logging_time=4.694658, accumulated_submission_time=53820.656832, global_step=121213, preemption_count=0, score=53820.656832, test/accuracy=0.646500, test/loss=1.504189, test/num_examples=10000, total_duration=58054.637249, train/accuracy=0.857383, train/loss=0.549537, validation/accuracy=0.768760, validation/loss=0.915443, validation/num_examples=50000
I0319 19:26:27.950068 139592107800320 logging_writer.py:48] [121500] global_step=121500, grad_norm=2.4255411624908447, loss=1.451640009880066
I0319 19:30:13.098458 139592099407616 logging_writer.py:48] [122000] global_step=122000, grad_norm=2.3279926776885986, loss=1.9031156301498413
I0319 19:31:22.920455 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:31:33.705227 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:31:56.039302 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:31:57.647926 139793440028480 submission_runner.py:420] Time since start: 58509.55s, 	Step: 122156, 	{'train/accuracy': 0.8579882383346558, 'train/loss': 0.5272805094718933, 'validation/accuracy': 0.7706999778747559, 'validation/loss': 0.9024597406387329, 'validation/num_examples': 50000, 'test/accuracy': 0.65010005235672, 'test/loss': 1.487162470817566, 'test/num_examples': 10000, 'score': 54240.74327278137, 'total_duration': 58509.546602249146, 'accumulated_submission_time': 54240.74327278137, 'accumulated_eval_time': 4257.331519842148, 'accumulated_logging_time': 4.7378764152526855}
I0319 19:31:57.679586 139592107800320 logging_writer.py:48] [122156] accumulated_eval_time=4257.331520, accumulated_logging_time=4.737876, accumulated_submission_time=54240.743273, global_step=122156, preemption_count=0, score=54240.743273, test/accuracy=0.650100, test/loss=1.487162, test/num_examples=10000, total_duration=58509.546602, train/accuracy=0.857988, train/loss=0.527281, validation/accuracy=0.770700, validation/loss=0.902460, validation/num_examples=50000
I0319 19:34:27.739249 139592099407616 logging_writer.py:48] [122500] global_step=122500, grad_norm=2.6216788291931152, loss=1.3145089149475098
I0319 19:38:12.849613 139592107800320 logging_writer.py:48] [123000] global_step=123000, grad_norm=2.6140635013580322, loss=1.3963346481323242
I0319 19:38:57.902012 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:39:08.147357 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:39:28.720475 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:39:30.335445 139793440028480 submission_runner.py:420] Time since start: 58962.23s, 	Step: 123102, 	{'train/accuracy': 0.8630273342132568, 'train/loss': 0.52430260181427, 'validation/accuracy': 0.769819974899292, 'validation/loss': 0.9018756747245789, 'validation/num_examples': 50000, 'test/accuracy': 0.6461000442504883, 'test/loss': 1.4945242404937744, 'test/num_examples': 10000, 'score': 54660.90355968475, 'total_duration': 58962.234115600586, 'accumulated_submission_time': 54660.90355968475, 'accumulated_eval_time': 4289.764947891235, 'accumulated_logging_time': 4.778675556182861}
I0319 19:39:30.368578 139592099407616 logging_writer.py:48] [123102] accumulated_eval_time=4289.764948, accumulated_logging_time=4.778676, accumulated_submission_time=54660.903560, global_step=123102, preemption_count=0, score=54660.903560, test/accuracy=0.646100, test/loss=1.494524, test/num_examples=10000, total_duration=58962.234116, train/accuracy=0.863027, train/loss=0.524303, validation/accuracy=0.769820, validation/loss=0.901876, validation/num_examples=50000
I0319 19:42:25.396193 139592107800320 logging_writer.py:48] [123500] global_step=123500, grad_norm=2.4524660110473633, loss=2.331660747528076
I0319 19:46:10.828223 139592099407616 logging_writer.py:48] [124000] global_step=124000, grad_norm=2.638317823410034, loss=1.1999025344848633
I0319 19:46:30.731737 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:46:41.194249 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:47:03.869681 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:47:05.481158 139793440028480 submission_runner.py:420] Time since start: 59417.38s, 	Step: 124046, 	{'train/accuracy': 0.8626952767372131, 'train/loss': 0.5199557542800903, 'validation/accuracy': 0.7716799974441528, 'validation/loss': 0.8945387005805969, 'validation/num_examples': 50000, 'test/accuracy': 0.6510000228881836, 'test/loss': 1.4852551221847534, 'test/num_examples': 10000, 'score': 55081.20386981964, 'total_duration': 59417.379841566086, 'accumulated_submission_time': 55081.20386981964, 'accumulated_eval_time': 4324.514363765717, 'accumulated_logging_time': 4.8217689990997314}
I0319 19:47:05.506180 139592107800320 logging_writer.py:48] [124046] accumulated_eval_time=4324.514364, accumulated_logging_time=4.821769, accumulated_submission_time=55081.203870, global_step=124046, preemption_count=0, score=55081.203870, test/accuracy=0.651000, test/loss=1.485255, test/num_examples=10000, total_duration=59417.379842, train/accuracy=0.862695, train/loss=0.519956, validation/accuracy=0.771680, validation/loss=0.894539, validation/num_examples=50000
I0319 19:50:25.169751 139592099407616 logging_writer.py:48] [124500] global_step=124500, grad_norm=2.808210611343384, loss=1.2807722091674805
I0319 19:54:05.888759 139793440028480 spec.py:321] Evaluating on the training split.
I0319 19:54:16.089851 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 19:54:38.500084 139793440028480 spec.py:349] Evaluating on the test split.
I0319 19:54:40.108324 139793440028480 submission_runner.py:420] Time since start: 59872.01s, 	Step: 124992, 	{'train/accuracy': 0.8640234470367432, 'train/loss': 0.5254991054534912, 'validation/accuracy': 0.7728999853134155, 'validation/loss': 0.8978889584541321, 'validation/num_examples': 50000, 'test/accuracy': 0.6508000493049622, 'test/loss': 1.4892643690109253, 'test/num_examples': 10000, 'score': 55501.52442550659, 'total_duration': 59872.0070066452, 'accumulated_submission_time': 55501.52442550659, 'accumulated_eval_time': 4358.733941078186, 'accumulated_logging_time': 4.85650110244751}
I0319 19:54:40.133649 139592107800320 logging_writer.py:48] [124992] accumulated_eval_time=4358.733941, accumulated_logging_time=4.856501, accumulated_submission_time=55501.524426, global_step=124992, preemption_count=0, score=55501.524426, test/accuracy=0.650800, test/loss=1.489264, test/num_examples=10000, total_duration=59872.007007, train/accuracy=0.864023, train/loss=0.525499, validation/accuracy=0.772900, validation/loss=0.897889, validation/num_examples=50000
I0319 19:54:43.739855 139592099407616 logging_writer.py:48] [125000] global_step=125000, grad_norm=2.582019567489624, loss=1.2955659627914429
I0319 19:58:24.465518 139592107800320 logging_writer.py:48] [125500] global_step=125500, grad_norm=2.6643834114074707, loss=1.3231472969055176
I0319 20:01:40.158004 139793440028480 spec.py:321] Evaluating on the training split.
I0319 20:01:50.643780 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 20:02:12.700125 139793440028480 spec.py:349] Evaluating on the test split.
I0319 20:02:14.314553 139793440028480 submission_runner.py:420] Time since start: 60326.21s, 	Step: 125937, 	{'train/accuracy': 0.86328125, 'train/loss': 0.5222283601760864, 'validation/accuracy': 0.7728399634361267, 'validation/loss': 0.8917573094367981, 'validation/num_examples': 50000, 'test/accuracy': 0.6516000032424927, 'test/loss': 1.4831252098083496, 'test/num_examples': 10000, 'score': 55921.4867773056, 'total_duration': 60326.21323823929, 'accumulated_submission_time': 55921.4867773056, 'accumulated_eval_time': 4392.890504360199, 'accumulated_logging_time': 4.890900135040283}
I0319 20:02:14.343432 139592099407616 logging_writer.py:48] [125937] accumulated_eval_time=4392.890504, accumulated_logging_time=4.890900, accumulated_submission_time=55921.486777, global_step=125937, preemption_count=0, score=55921.486777, test/accuracy=0.651600, test/loss=1.483125, test/num_examples=10000, total_duration=60326.213238, train/accuracy=0.863281, train/loss=0.522228, validation/accuracy=0.772840, validation/loss=0.891757, validation/num_examples=50000
I0319 20:02:39.974240 139592107800320 logging_writer.py:48] [126000] global_step=126000, grad_norm=2.4943764209747314, loss=1.632447600364685
I0319 20:06:23.694337 139592099407616 logging_writer.py:48] [126500] global_step=126500, grad_norm=2.3985023498535156, loss=1.9669007062911987
I0319 20:09:14.651340 139793440028480 spec.py:321] Evaluating on the training split.
I0319 20:09:25.157599 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 20:09:46.511626 139793440028480 spec.py:349] Evaluating on the test split.
I0319 20:09:48.130375 139793440028480 submission_runner.py:420] Time since start: 60780.03s, 	Step: 126882, 	{'train/accuracy': 0.8663085699081421, 'train/loss': 0.5123443007469177, 'validation/accuracy': 0.7719399929046631, 'validation/loss': 0.8921030163764954, 'validation/num_examples': 50000, 'test/accuracy': 0.6491000056266785, 'test/loss': 1.481019377708435, 'test/num_examples': 10000, 'score': 56341.7328619957, 'total_duration': 60780.02904462814, 'accumulated_submission_time': 56341.7328619957, 'accumulated_eval_time': 4426.36954665184, 'accumulated_logging_time': 4.929235935211182}
I0319 20:09:48.162093 139592107800320 logging_writer.py:48] [126882] accumulated_eval_time=4426.369547, accumulated_logging_time=4.929236, accumulated_submission_time=56341.732862, global_step=126882, preemption_count=0, score=56341.732862, test/accuracy=0.649100, test/loss=1.481019, test/num_examples=10000, total_duration=60780.029045, train/accuracy=0.866309, train/loss=0.512344, validation/accuracy=0.771940, validation/loss=0.892103, validation/num_examples=50000
I0319 20:10:37.116049 139592099407616 logging_writer.py:48] [127000] global_step=127000, grad_norm=2.479074001312256, loss=2.0446090698242188
I0319 20:14:22.107203 139592107800320 logging_writer.py:48] [127500] global_step=127500, grad_norm=2.9170215129852295, loss=1.317293405532837
I0319 20:16:48.142174 139793440028480 spec.py:321] Evaluating on the training split.
I0319 20:16:58.437395 139793440028480 spec.py:333] Evaluating on the validation split.
I0319 20:17:21.427540 139793440028480 spec.py:349] Evaluating on the test split.
I0319 20:17:23.033526 139793440028480 submission_runner.py:420] Time since start: 61234.93s, 	Step: 127826, 	{'train/accuracy': 0.8672655820846558, 'train/loss': 0.5014148354530334, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8846955299377441, 'validation/num_examples': 50000, 'test/accuracy': 0.6528000235557556, 'test/loss': 1.466226577758789, 'test/num_examples': 10000, 'score': 56761.648509025574, 'total_duration': 61234.93220591545, 'accumulated_submission_time': 56761.648509025574, 'accumulated_eval_time': 4461.260905742645, 'accumulated_logging_time': 4.972701072692871}
I0319 20:17:23.061958 139592099407616 logging_writer.py:48] [127826] accumulated_eval_time=4461.260906, accumulated_logging_time=4.972701, accumulated_submission_time=56761.648509, global_step=127826, preemption_count=0, score=56761.648509, test/accuracy=0.652800, test/loss=1.466227, test/num_examples=10000, total_duration=61234.932206, train/accuracy=0.867266, train/loss=0.501415, validation/accuracy=0.774300, validation/loss=0.884696, validation/num_examples=50000
I0319 20:17:23.082977 139592107800320 logging_writer.py:48] [127826] global_step=127826, preemption_count=0, score=56761.648509
I0319 20:17:23.425138 139793440028480 checkpoints.py:490] Saving checkpoint at step: 127826
I0319 20:17:24.160472 139793440028480 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1/checkpoint_127826
I0319 20:17:24.165158 139793440028480 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/imagenet_vit_map_jax/trial_1/checkpoint_127826.
I0319 20:17:25.067952 139793440028480 submission_runner.py:593] Tuning trial 1/1
I0319 20:17:25.068189 139793440028480 submission_runner.py:594] Hyperparameters: Hyperparameters(learning_rate=0.0008445074561975979, beta1=0.8895758153482813, beta2=0.9978504782314613, warmup_steps=6999, weight_decay=0.08135402759553023)
I0319 20:17:25.074299 139793440028480 submission_runner.py:595] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009570312104187906, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 43.16585683822632, 'total_duration': 82.91282558441162, 'accumulated_submission_time': 43.16585683822632, 'accumulated_eval_time': 39.746883153915405, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (909, {'train/accuracy': 0.018046874552965164, 'train/loss': 6.2387213706970215, 'validation/accuracy': 0.017799999564886093, 'validation/loss': 6.249222755432129, 'validation/num_examples': 50000, 'test/accuracy': 0.014100000262260437, 'test/loss': 6.312887191772461, 'test/num_examples': 10000, 'score': 463.3900761604309, 'total_duration': 524.5990114212036, 'accumulated_submission_time': 463.3900761604309, 'accumulated_eval_time': 61.13209390640259, 'accumulated_logging_time': 0.024669647216796875, 'global_step': 909, 'preemption_count': 0}), (1870, {'train/accuracy': 0.04398437216877937, 'train/loss': 5.696121692657471, 'validation/accuracy': 0.04211999848484993, 'validation/loss': 5.730832576751709, 'validation/num_examples': 50000, 'test/accuracy': 0.0340999998152256, 'test/loss': 5.867914199829102, 'test/num_examples': 10000, 'score': 883.6368682384491, 'total_duration': 966.1791715621948, 'accumulated_submission_time': 883.6368682384491, 'accumulated_eval_time': 82.38292145729065, 'accumulated_logging_time': 0.053483009338378906, 'global_step': 1870, 'preemption_count': 0}), (2834, {'train/accuracy': 0.07347656041383743, 'train/loss': 5.280451774597168, 'validation/accuracy': 0.06678000092506409, 'validation/loss': 5.336838722229004, 'validation/num_examples': 50000, 'test/accuracy': 0.05400000140070915, 'test/loss': 5.536876678466797, 'test/num_examples': 10000, 'score': 1304.212679862976, 'total_duration': 1407.9402105808258, 'accumulated_submission_time': 1304.212679862976, 'accumulated_eval_time': 103.48623061180115, 'accumulated_logging_time': 0.08181452751159668, 'global_step': 2834, 'preemption_count': 0}), (3798, {'train/accuracy': 0.11041015386581421, 'train/loss': 4.8983073234558105, 'validation/accuracy': 0.10261999815702438, 'validation/loss': 4.945130825042725, 'validation/num_examples': 50000, 'test/accuracy': 0.08060000091791153, 'test/loss': 5.208343982696533, 'test/num_examples': 10000, 'score': 1724.487268447876, 'total_duration': 1850.4843425750732, 'accumulated_submission_time': 1724.487268447876, 'accumulated_eval_time': 125.66406631469727, 'accumulated_logging_time': 0.11260151863098145, 'global_step': 3798, 'preemption_count': 0}), (4758, {'train/accuracy': 0.1586328148841858, 'train/loss': 4.414804935455322, 'validation/accuracy': 0.14963999390602112, 'validation/loss': 4.490406036376953, 'validation/num_examples': 50000, 'test/accuracy': 0.11150000244379044, 'test/loss': 4.83000373840332, 'test/num_examples': 10000, 'score': 2144.5049920082092, 'total_duration': 2292.2565217018127, 'accumulated_submission_time': 2144.5049920082092, 'accumulated_eval_time': 147.33879375457764, 'accumulated_logging_time': 0.14018559455871582, 'global_step': 4758, 'preemption_count': 0}), (5718, {'train/accuracy': 0.21044921875, 'train/loss': 4.0167927742004395, 'validation/accuracy': 0.19209998846054077, 'validation/loss': 4.121342658996582, 'validation/num_examples': 50000, 'test/accuracy': 0.14480000734329224, 'test/loss': 4.527491569519043, 'test/num_examples': 10000, 'score': 2564.7776367664337, 'total_duration': 2733.9472160339355, 'accumulated_submission_time': 2564.7776367664337, 'accumulated_eval_time': 168.67592430114746, 'accumulated_logging_time': 0.16823530197143555, 'global_step': 5718, 'preemption_count': 0}), (6675, {'train/accuracy': 0.2644335925579071, 'train/loss': 3.6136574745178223, 'validation/accuracy': 0.23173999786376953, 'validation/loss': 3.811569929122925, 'validation/num_examples': 50000, 'test/accuracy': 0.17500001192092896, 'test/loss': 4.2633867263793945, 'test/num_examples': 10000, 'score': 2985.114411830902, 'total_duration': 3175.604325056076, 'accumulated_submission_time': 2985.114411830902, 'accumulated_eval_time': 189.9159426689148, 'accumulated_logging_time': 0.19598150253295898, 'global_step': 6675, 'preemption_count': 0}), (7630, {'train/accuracy': 0.2835937440395355, 'train/loss': 3.490403413772583, 'validation/accuracy': 0.26909998059272766, 'validation/loss': 3.595759868621826, 'validation/num_examples': 50000, 'test/accuracy': 0.20190000534057617, 'test/loss': 4.105603218078613, 'test/num_examples': 10000, 'score': 3405.1694016456604, 'total_duration': 3617.045097589493, 'accumulated_submission_time': 3405.1694016456604, 'accumulated_eval_time': 211.21724128723145, 'accumulated_logging_time': 0.22757172584533691, 'global_step': 7630, 'preemption_count': 0}), (8588, {'train/accuracy': 0.33900389075279236, 'train/loss': 3.164844036102295, 'validation/accuracy': 0.3127000033855438, 'validation/loss': 3.313385248184204, 'validation/num_examples': 50000, 'test/accuracy': 0.23730000853538513, 'test/loss': 3.838170051574707, 'test/num_examples': 10000, 'score': 3825.339316368103, 'total_duration': 4061.4504537582397, 'accumulated_submission_time': 3825.339316368103, 'accumulated_eval_time': 235.36473417282104, 'accumulated_logging_time': 0.2624244689941406, 'global_step': 8588, 'preemption_count': 0}), (9546, {'train/accuracy': 0.374824196100235, 'train/loss': 2.909634828567505, 'validation/accuracy': 0.3432999849319458, 'validation/loss': 3.0872015953063965, 'validation/num_examples': 50000, 'test/accuracy': 0.2647000253200531, 'test/loss': 3.6340298652648926, 'test/num_examples': 10000, 'score': 4245.2809009552, 'total_duration': 4507.261991262436, 'accumulated_submission_time': 4245.2809009552, 'accumulated_eval_time': 261.14787244796753, 'accumulated_logging_time': 0.2952415943145752, 'global_step': 9546, 'preemption_count': 0}), (10501, {'train/accuracy': 0.4027148485183716, 'train/loss': 2.7752459049224854, 'validation/accuracy': 0.372439980506897, 'validation/loss': 2.9269795417785645, 'validation/num_examples': 50000, 'test/accuracy': 0.287200003862381, 'test/loss': 3.4903852939605713, 'test/num_examples': 10000, 'score': 4665.211783647537, 'total_duration': 4953.886339187622, 'accumulated_submission_time': 4665.211783647537, 'accumulated_eval_time': 287.75501561164856, 'accumulated_logging_time': 0.32796216011047363, 'global_step': 10501, 'preemption_count': 0}), (11459, {'train/accuracy': 0.42878904938697815, 'train/loss': 2.601086378097534, 'validation/accuracy': 0.40073999762535095, 'validation/loss': 2.763827085494995, 'validation/num_examples': 50000, 'test/accuracy': 0.3108000159263611, 'test/loss': 3.3482494354248047, 'test/num_examples': 10000, 'score': 5085.5621728897095, 'total_duration': 5405.4845468997955, 'accumulated_submission_time': 5085.5621728897095, 'accumulated_eval_time': 318.9169981479645, 'accumulated_logging_time': 0.361297607421875, 'global_step': 11459, 'preemption_count': 0}), (12418, {'train/accuracy': 0.46140623092651367, 'train/loss': 2.4328789710998535, 'validation/accuracy': 0.41995999217033386, 'validation/loss': 2.623626232147217, 'validation/num_examples': 50000, 'test/accuracy': 0.3296000063419342, 'test/loss': 3.1954219341278076, 'test/num_examples': 10000, 'score': 5505.618812322617, 'total_duration': 5850.48757815361, 'accumulated_submission_time': 5505.618812322617, 'accumulated_eval_time': 343.7804172039032, 'accumulated_logging_time': 0.3915243148803711, 'global_step': 12418, 'preemption_count': 0}), (13374, {'train/accuracy': 0.4901757836341858, 'train/loss': 2.264934778213501, 'validation/accuracy': 0.441679984331131, 'validation/loss': 2.504922389984131, 'validation/num_examples': 50000, 'test/accuracy': 0.34700000286102295, 'test/loss': 3.0967447757720947, 'test/num_examples': 10000, 'score': 5926.041017532349, 'total_duration': 6296.2676157951355, 'accumulated_submission_time': 5926.041017532349, 'accumulated_eval_time': 369.05315804481506, 'accumulated_logging_time': 0.4241065979003906, 'global_step': 13374, 'preemption_count': 0}), (14329, {'train/accuracy': 0.4932616949081421, 'train/loss': 2.2300097942352295, 'validation/accuracy': 0.4592999815940857, 'validation/loss': 2.401749610900879, 'validation/num_examples': 50000, 'test/accuracy': 0.3603000044822693, 'test/loss': 3.0184385776519775, 'test/num_examples': 10000, 'score': 6346.238476514816, 'total_duration': 6745.745825767517, 'accumulated_submission_time': 6346.238476514816, 'accumulated_eval_time': 398.2497239112854, 'accumulated_logging_time': 0.4554910659790039, 'global_step': 14329, 'preemption_count': 0}), (15288, {'train/accuracy': 0.5074804425239563, 'train/loss': 2.169114112854004, 'validation/accuracy': 0.47303998470306396, 'validation/loss': 2.3563408851623535, 'validation/num_examples': 50000, 'test/accuracy': 0.3693000078201294, 'test/loss': 2.9735970497131348, 'test/num_examples': 10000, 'score': 6766.591676712036, 'total_duration': 7199.091827392578, 'accumulated_submission_time': 6766.591676712036, 'accumulated_eval_time': 431.16269087791443, 'accumulated_logging_time': 0.48230671882629395, 'global_step': 15288, 'preemption_count': 0}), (16246, {'train/accuracy': 0.5291991829872131, 'train/loss': 2.0571389198303223, 'validation/accuracy': 0.4845399856567383, 'validation/loss': 2.272536516189575, 'validation/num_examples': 50000, 'test/accuracy': 0.38130003213882446, 'test/loss': 2.9030184745788574, 'test/num_examples': 10000, 'score': 7186.874831676483, 'total_duration': 7652.392613887787, 'accumulated_submission_time': 7186.874831676483, 'accumulated_eval_time': 464.09634351730347, 'accumulated_logging_time': 0.5127396583557129, 'global_step': 16246, 'preemption_count': 0}), (17196, {'train/accuracy': 0.5538085699081421, 'train/loss': 1.9544509649276733, 'validation/accuracy': 0.497219979763031, 'validation/loss': 2.227579355239868, 'validation/num_examples': 50000, 'test/accuracy': 0.3929000198841095, 'test/loss': 2.8477354049682617, 'test/num_examples': 10000, 'score': 7606.806395292282, 'total_duration': 8105.186660289764, 'accumulated_submission_time': 7606.806395292282, 'accumulated_eval_time': 496.8746225833893, 'accumulated_logging_time': 0.544755220413208, 'global_step': 17196, 'preemption_count': 0}), (18142, {'train/accuracy': 0.5469335913658142, 'train/loss': 1.9713891744613647, 'validation/accuracy': 0.5078799724578857, 'validation/loss': 2.1587042808532715, 'validation/num_examples': 50000, 'test/accuracy': 0.39730000495910645, 'test/loss': 2.7942819595336914, 'test/num_examples': 10000, 'score': 8026.940294504166, 'total_duration': 8561.426780700684, 'accumulated_submission_time': 8026.940294504166, 'accumulated_eval_time': 532.8970324993134, 'accumulated_logging_time': 0.5767190456390381, 'global_step': 18142, 'preemption_count': 0}), (19096, {'train/accuracy': 0.5603125095367432, 'train/loss': 1.8923168182373047, 'validation/accuracy': 0.5165599584579468, 'validation/loss': 2.1050305366516113, 'validation/num_examples': 50000, 'test/accuracy': 0.406900018453598, 'test/loss': 2.755641222000122, 'test/num_examples': 10000, 'score': 8447.345478773117, 'total_duration': 9020.483969926834, 'accumulated_submission_time': 8447.345478773117, 'accumulated_eval_time': 571.469304561615, 'accumulated_logging_time': 0.6045756340026855, 'global_step': 19096, 'preemption_count': 0}), (20053, {'train/accuracy': 0.5743359327316284, 'train/loss': 1.8197087049484253, 'validation/accuracy': 0.5245999693870544, 'validation/loss': 2.067073345184326, 'validation/num_examples': 50000, 'test/accuracy': 0.41590002179145813, 'test/loss': 2.6983675956726074, 'test/num_examples': 10000, 'score': 8867.457782268524, 'total_duration': 9479.948509216309, 'accumulated_submission_time': 8867.457782268524, 'accumulated_eval_time': 610.7395515441895, 'accumulated_logging_time': 0.6343317031860352, 'global_step': 20053, 'preemption_count': 0}), (21004, {'train/accuracy': 0.5786718726158142, 'train/loss': 1.80045747756958, 'validation/accuracy': 0.5393199920654297, 'validation/loss': 1.980970859527588, 'validation/num_examples': 50000, 'test/accuracy': 0.429500013589859, 'test/loss': 2.6035759449005127, 'test/num_examples': 10000, 'score': 9287.645205974579, 'total_duration': 9937.988888502121, 'accumulated_submission_time': 9287.645205974579, 'accumulated_eval_time': 648.5127742290497, 'accumulated_logging_time': 0.6619973182678223, 'global_step': 21004, 'preemption_count': 0}), (21948, {'train/accuracy': 0.5824413895606995, 'train/loss': 1.7962543964385986, 'validation/accuracy': 0.5390200018882751, 'validation/loss': 2.003816843032837, 'validation/num_examples': 50000, 'test/accuracy': 0.42980003356933594, 'test/loss': 2.6617414951324463, 'test/num_examples': 10000, 'score': 9707.678730726242, 'total_duration': 10394.033889055252, 'accumulated_submission_time': 9707.678730726242, 'accumulated_eval_time': 684.4397387504578, 'accumulated_logging_time': 0.695131778717041, 'global_step': 21948, 'preemption_count': 0}), (22893, {'train/accuracy': 0.5976952910423279, 'train/loss': 1.7223659753799438, 'validation/accuracy': 0.5474599599838257, 'validation/loss': 1.9510140419006348, 'validation/num_examples': 50000, 'test/accuracy': 0.4353000223636627, 'test/loss': 2.588578224182129, 'test/num_examples': 10000, 'score': 10127.819084882736, 'total_duration': 10849.058310508728, 'accumulated_submission_time': 10127.819084882736, 'accumulated_eval_time': 719.2346954345703, 'accumulated_logging_time': 0.7334194183349609, 'global_step': 22893, 'preemption_count': 0}), (23845, {'train/accuracy': 0.6253319978713989, 'train/loss': 1.5792518854141235, 'validation/accuracy': 0.559179961681366, 'validation/loss': 1.8945820331573486, 'validation/num_examples': 50000, 'test/accuracy': 0.4418000280857086, 'test/loss': 2.5550386905670166, 'test/num_examples': 10000, 'score': 10547.828410625458, 'total_duration': 11302.18057179451, 'accumulated_submission_time': 10547.828410625458, 'accumulated_eval_time': 752.2656173706055, 'accumulated_logging_time': 0.7631549835205078, 'global_step': 23845, 'preemption_count': 0}), (24793, {'train/accuracy': 0.6098437309265137, 'train/loss': 1.6432502269744873, 'validation/accuracy': 0.5692200064659119, 'validation/loss': 1.8410288095474243, 'validation/num_examples': 50000, 'test/accuracy': 0.4513000249862671, 'test/loss': 2.485306739807129, 'test/num_examples': 10000, 'score': 10968.10272693634, 'total_duration': 11755.16133093834, 'accumulated_submission_time': 10968.10272693634, 'accumulated_eval_time': 784.8789601325989, 'accumulated_logging_time': 0.804556131362915, 'global_step': 24793, 'preemption_count': 0}), (25742, {'train/accuracy': 0.6162499785423279, 'train/loss': 1.6152305603027344, 'validation/accuracy': 0.5685799717903137, 'validation/loss': 1.8381229639053345, 'validation/num_examples': 50000, 'test/accuracy': 0.4571000337600708, 'test/loss': 2.490128517150879, 'test/num_examples': 10000, 'score': 11388.05167388916, 'total_duration': 12207.999715566635, 'accumulated_submission_time': 11388.05167388916, 'accumulated_eval_time': 817.6876864433289, 'accumulated_logging_time': 0.8331425189971924, 'global_step': 25742, 'preemption_count': 0}), (26694, {'train/accuracy': 0.6269335746765137, 'train/loss': 1.5706802606582642, 'validation/accuracy': 0.5753399729728699, 'validation/loss': 1.8144735097885132, 'validation/num_examples': 50000, 'test/accuracy': 0.45600003004074097, 'test/loss': 2.4600064754486084, 'test/num_examples': 10000, 'score': 11808.117844104767, 'total_duration': 12663.159456729889, 'accumulated_submission_time': 11808.117844104767, 'accumulated_eval_time': 852.7006220817566, 'accumulated_logging_time': 0.8609375953674316, 'global_step': 26694, 'preemption_count': 0}), (27644, {'train/accuracy': 0.6217382550239563, 'train/loss': 1.6179511547088623, 'validation/accuracy': 0.5809400081634521, 'validation/loss': 1.8126275539398193, 'validation/num_examples': 50000, 'test/accuracy': 0.4626000225543976, 'test/loss': 2.4590179920196533, 'test/num_examples': 10000, 'score': 12228.40169930458, 'total_duration': 13118.873286247253, 'accumulated_submission_time': 12228.40169930458, 'accumulated_eval_time': 888.0523357391357, 'accumulated_logging_time': 0.8876233100891113, 'global_step': 27644, 'preemption_count': 0}), (28593, {'train/accuracy': 0.6262304782867432, 'train/loss': 1.588721752166748, 'validation/accuracy': 0.5800399780273438, 'validation/loss': 1.7903332710266113, 'validation/num_examples': 50000, 'test/accuracy': 0.4634000360965729, 'test/loss': 2.4371824264526367, 'test/num_examples': 10000, 'score': 12648.437604665756, 'total_duration': 13572.005926132202, 'accumulated_submission_time': 12648.437604665756, 'accumulated_eval_time': 921.0666959285736, 'accumulated_logging_time': 0.9176719188690186, 'global_step': 28593, 'preemption_count': 0}), (29541, {'train/accuracy': 0.6416601538658142, 'train/loss': 1.495627522468567, 'validation/accuracy': 0.5916599631309509, 'validation/loss': 1.7349510192871094, 'validation/num_examples': 50000, 'test/accuracy': 0.4750000238418579, 'test/loss': 2.368985891342163, 'test/num_examples': 10000, 'score': 13068.677939653397, 'total_duration': 14026.611220121384, 'accumulated_submission_time': 13068.677939653397, 'accumulated_eval_time': 955.3478348255157, 'accumulated_logging_time': 0.9493212699890137, 'global_step': 29541, 'preemption_count': 0}), (30487, {'train/accuracy': 0.6626757383346558, 'train/loss': 1.4161900281906128, 'validation/accuracy': 0.5930399894714355, 'validation/loss': 1.7210310697555542, 'validation/num_examples': 50000, 'test/accuracy': 0.4743000268936157, 'test/loss': 2.373077869415283, 'test/num_examples': 10000, 'score': 13488.736578464508, 'total_duration': 14481.785346269608, 'accumulated_submission_time': 13488.736578464508, 'accumulated_eval_time': 990.3840420246124, 'accumulated_logging_time': 0.9769237041473389, 'global_step': 30487, 'preemption_count': 0}), (31435, {'train/accuracy': 0.6389257907867432, 'train/loss': 1.495690941810608, 'validation/accuracy': 0.5963000059127808, 'validation/loss': 1.6960092782974243, 'validation/num_examples': 50000, 'test/accuracy': 0.4808000326156616, 'test/loss': 2.3537442684173584, 'test/num_examples': 10000, 'score': 13908.802273988724, 'total_duration': 14937.706971168518, 'accumulated_submission_time': 13908.802273988724, 'accumulated_eval_time': 1026.1597921848297, 'accumulated_logging_time': 1.0043036937713623, 'global_step': 31435, 'preemption_count': 0}), (32384, {'train/accuracy': 0.6537694931030273, 'train/loss': 1.425926685333252, 'validation/accuracy': 0.6037999987602234, 'validation/loss': 1.657766342163086, 'validation/num_examples': 50000, 'test/accuracy': 0.48410001397132874, 'test/loss': 2.30265212059021, 'test/num_examples': 10000, 'score': 14329.074410438538, 'total_duration': 15390.966176271439, 'accumulated_submission_time': 14329.074410438538, 'accumulated_eval_time': 1059.067539691925, 'accumulated_logging_time': 1.0317492485046387, 'global_step': 32384, 'preemption_count': 0}), (33332, {'train/accuracy': 0.6590429544448853, 'train/loss': 1.4059785604476929, 'validation/accuracy': 0.6047199964523315, 'validation/loss': 1.661354899406433, 'validation/num_examples': 50000, 'test/accuracy': 0.4824000298976898, 'test/loss': 2.321087121963501, 'test/num_examples': 10000, 'score': 14749.003374099731, 'total_duration': 15843.872071027756, 'accumulated_submission_time': 14749.003374099731, 'accumulated_eval_time': 1091.961189031601, 'accumulated_logging_time': 1.0624501705169678, 'global_step': 33332, 'preemption_count': 0}), (34279, {'train/accuracy': 0.660937488079071, 'train/loss': 1.4096660614013672, 'validation/accuracy': 0.6099599599838257, 'validation/loss': 1.627068042755127, 'validation/num_examples': 50000, 'test/accuracy': 0.49410003423690796, 'test/loss': 2.2648959159851074, 'test/num_examples': 10000, 'score': 15169.159571886063, 'total_duration': 16297.917911052704, 'accumulated_submission_time': 15169.159571886063, 'accumulated_eval_time': 1125.7661588191986, 'accumulated_logging_time': 1.0957262516021729, 'global_step': 34279, 'preemption_count': 0}), (35226, {'train/accuracy': 0.6612108945846558, 'train/loss': 1.4239627122879028, 'validation/accuracy': 0.6139400005340576, 'validation/loss': 1.642770767211914, 'validation/num_examples': 50000, 'test/accuracy': 0.49320003390312195, 'test/loss': 2.291342258453369, 'test/num_examples': 10000, 'score': 15589.314702033997, 'total_duration': 16754.06310224533, 'accumulated_submission_time': 15589.314702033997, 'accumulated_eval_time': 1161.6736254692078, 'accumulated_logging_time': 1.1264140605926514, 'global_step': 35226, 'preemption_count': 0}), (36175, {'train/accuracy': 0.6728515625, 'train/loss': 1.3312591314315796, 'validation/accuracy': 0.6194999814033508, 'validation/loss': 1.580639362335205, 'validation/num_examples': 50000, 'test/accuracy': 0.49650001525878906, 'test/loss': 2.235912561416626, 'test/num_examples': 10000, 'score': 16009.440279960632, 'total_duration': 17206.59175515175, 'accumulated_submission_time': 16009.440279960632, 'accumulated_eval_time': 1193.9971752166748, 'accumulated_logging_time': 1.1534278392791748, 'global_step': 36175, 'preemption_count': 0}), (37120, {'train/accuracy': 0.6825780868530273, 'train/loss': 1.2980029582977295, 'validation/accuracy': 0.6173999905586243, 'validation/loss': 1.5963057279586792, 'validation/num_examples': 50000, 'test/accuracy': 0.49410003423690796, 'test/loss': 2.2541465759277344, 'test/num_examples': 10000, 'score': 16429.387169122696, 'total_duration': 17658.824934005737, 'accumulated_submission_time': 16429.387169122696, 'accumulated_eval_time': 1226.2000088691711, 'accumulated_logging_time': 1.1858303546905518, 'global_step': 37120, 'preemption_count': 0}), (38065, {'train/accuracy': 0.6715039014816284, 'train/loss': 1.361115574836731, 'validation/accuracy': 0.6234599947929382, 'validation/loss': 1.5808427333831787, 'validation/num_examples': 50000, 'test/accuracy': 0.49500003457069397, 'test/loss': 2.2400283813476562, 'test/num_examples': 10000, 'score': 16849.301491498947, 'total_duration': 18114.223784923553, 'accumulated_submission_time': 16849.301491498947, 'accumulated_eval_time': 1261.5938396453857, 'accumulated_logging_time': 1.2241370677947998, 'global_step': 38065, 'preemption_count': 0}), (39013, {'train/accuracy': 0.6758398413658142, 'train/loss': 1.339189887046814, 'validation/accuracy': 0.6258999705314636, 'validation/loss': 1.5784555673599243, 'validation/num_examples': 50000, 'test/accuracy': 0.5058000087738037, 'test/loss': 2.232527017593384, 'test/num_examples': 10000, 'score': 17269.56613779068, 'total_duration': 18569.710734844208, 'accumulated_submission_time': 17269.56613779068, 'accumulated_eval_time': 1296.7297668457031, 'accumulated_logging_time': 1.2588355541229248, 'global_step': 39013, 'preemption_count': 0}), (39961, {'train/accuracy': 0.6796289086341858, 'train/loss': 1.3091715574264526, 'validation/accuracy': 0.6236000061035156, 'validation/loss': 1.5663096904754639, 'validation/num_examples': 50000, 'test/accuracy': 0.5023000240325928, 'test/loss': 2.229196548461914, 'test/num_examples': 10000, 'score': 17689.657068014145, 'total_duration': 19024.8978869915, 'accumulated_submission_time': 17689.657068014145, 'accumulated_eval_time': 1331.7465584278107, 'accumulated_logging_time': 1.286801815032959, 'global_step': 39961, 'preemption_count': 0}), (40900, {'train/accuracy': 0.6773437261581421, 'train/loss': 1.3334202766418457, 'validation/accuracy': 0.6313799619674683, 'validation/loss': 1.557999610900879, 'validation/num_examples': 50000, 'test/accuracy': 0.5042999982833862, 'test/loss': 2.2077109813690186, 'test/num_examples': 10000, 'score': 18109.708364248276, 'total_duration': 19481.242381095886, 'accumulated_submission_time': 18109.708364248276, 'accumulated_eval_time': 1367.6392889022827, 'accumulated_logging_time': 1.6361103057861328, 'global_step': 40900, 'preemption_count': 0}), (41844, {'train/accuracy': 0.6817968487739563, 'train/loss': 1.2940773963928223, 'validation/accuracy': 0.6334599852561951, 'validation/loss': 1.516237497329712, 'validation/num_examples': 50000, 'test/accuracy': 0.5106000304222107, 'test/loss': 2.169159412384033, 'test/num_examples': 10000, 'score': 18529.90984416008, 'total_duration': 19934.339613437653, 'accumulated_submission_time': 18529.90984416008, 'accumulated_eval_time': 1400.451861858368, 'accumulated_logging_time': 1.6668717861175537, 'global_step': 41844, 'preemption_count': 0}), (42788, {'train/accuracy': 0.6926367282867432, 'train/loss': 1.2557886838912964, 'validation/accuracy': 0.6359399557113647, 'validation/loss': 1.5043929815292358, 'validation/num_examples': 50000, 'test/accuracy': 0.511900007724762, 'test/loss': 2.1608686447143555, 'test/num_examples': 10000, 'score': 18950.14275956154, 'total_duration': 20389.487313508987, 'accumulated_submission_time': 18950.14275956154, 'accumulated_eval_time': 1435.2780511379242, 'accumulated_logging_time': 1.7039804458618164, 'global_step': 42788, 'preemption_count': 0}), (43734, {'train/accuracy': 0.7052538990974426, 'train/loss': 1.2022165060043335, 'validation/accuracy': 0.6338799595832825, 'validation/loss': 1.5196545124053955, 'validation/num_examples': 50000, 'test/accuracy': 0.5142000317573547, 'test/loss': 2.166313409805298, 'test/num_examples': 10000, 'score': 19370.101238012314, 'total_duration': 20844.03530550003, 'accumulated_submission_time': 19370.101238012314, 'accumulated_eval_time': 1469.7869713306427, 'accumulated_logging_time': 1.7324120998382568, 'global_step': 43734, 'preemption_count': 0}), (44680, {'train/accuracy': 0.6914843320846558, 'train/loss': 1.2457656860351562, 'validation/accuracy': 0.6407999992370605, 'validation/loss': 1.4878202676773071, 'validation/num_examples': 50000, 'test/accuracy': 0.5178000330924988, 'test/loss': 2.1108908653259277, 'test/num_examples': 10000, 'score': 19790.28397512436, 'total_duration': 21297.346603393555, 'accumulated_submission_time': 19790.28397512436, 'accumulated_eval_time': 1502.832401752472, 'accumulated_logging_time': 1.763868808746338, 'global_step': 44680, 'preemption_count': 0}), (45625, {'train/accuracy': 0.6982421875, 'train/loss': 1.2468092441558838, 'validation/accuracy': 0.6459800004959106, 'validation/loss': 1.486478567123413, 'validation/num_examples': 50000, 'test/accuracy': 0.5195000171661377, 'test/loss': 2.132629156112671, 'test/num_examples': 10000, 'score': 20210.225008249283, 'total_duration': 21750.043441295624, 'accumulated_submission_time': 20210.225008249283, 'accumulated_eval_time': 1535.5017747879028, 'accumulated_logging_time': 1.7983663082122803, 'global_step': 45625, 'preemption_count': 0}), (46572, {'train/accuracy': 0.7062695026397705, 'train/loss': 1.19102144241333, 'validation/accuracy': 0.6459999680519104, 'validation/loss': 1.4620285034179688, 'validation/num_examples': 50000, 'test/accuracy': 0.5289000272750854, 'test/loss': 2.0980584621429443, 'test/num_examples': 10000, 'score': 20630.27354669571, 'total_duration': 22202.634214401245, 'accumulated_submission_time': 20630.27354669571, 'accumulated_eval_time': 1567.9566090106964, 'accumulated_logging_time': 1.8339488506317139, 'global_step': 46572, 'preemption_count': 0}), (47518, {'train/accuracy': 0.69789057970047, 'train/loss': 1.2307801246643066, 'validation/accuracy': 0.6480599641799927, 'validation/loss': 1.466400146484375, 'validation/num_examples': 50000, 'test/accuracy': 0.5198000073432922, 'test/loss': 2.1328284740448, 'test/num_examples': 10000, 'score': 21050.563070058823, 'total_duration': 22656.3281750679, 'accumulated_submission_time': 21050.563070058823, 'accumulated_eval_time': 1601.2741181850433, 'accumulated_logging_time': 1.8691518306732178, 'global_step': 47518, 'preemption_count': 0}), (48463, {'train/accuracy': 0.702441394329071, 'train/loss': 1.1959295272827148, 'validation/accuracy': 0.6495800018310547, 'validation/loss': 1.4339760541915894, 'validation/num_examples': 50000, 'test/accuracy': 0.5285000205039978, 'test/loss': 2.080435037612915, 'test/num_examples': 10000, 'score': 21470.519675970078, 'total_duration': 23108.328401088715, 'accumulated_submission_time': 21470.519675970078, 'accumulated_eval_time': 1633.2338995933533, 'accumulated_logging_time': 1.90122389793396, 'global_step': 48463, 'preemption_count': 0}), (49408, {'train/accuracy': 0.7056054472923279, 'train/loss': 1.1989738941192627, 'validation/accuracy': 0.6522600054740906, 'validation/loss': 1.4502296447753906, 'validation/num_examples': 50000, 'test/accuracy': 0.5303000211715698, 'test/loss': 2.094193696975708, 'test/num_examples': 10000, 'score': 21890.56763291359, 'total_duration': 23563.396186590195, 'accumulated_submission_time': 21890.56763291359, 'accumulated_eval_time': 1668.1686403751373, 'accumulated_logging_time': 1.935361623764038, 'global_step': 49408, 'preemption_count': 0}), (50354, {'train/accuracy': 0.722460925579071, 'train/loss': 1.118489146232605, 'validation/accuracy': 0.6571399569511414, 'validation/loss': 1.4201762676239014, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.0712265968322754, 'test/num_examples': 10000, 'score': 22310.586025238037, 'total_duration': 24014.513936042786, 'accumulated_submission_time': 22310.586025238037, 'accumulated_eval_time': 1699.1842534542084, 'accumulated_logging_time': 1.9668974876403809, 'global_step': 50354, 'preemption_count': 0}), (51298, {'train/accuracy': 0.7073632478713989, 'train/loss': 1.1812729835510254, 'validation/accuracy': 0.659280002117157, 'validation/loss': 1.4107974767684937, 'validation/num_examples': 50000, 'test/accuracy': 0.5348000526428223, 'test/loss': 2.0475263595581055, 'test/num_examples': 10000, 'score': 22730.86786866188, 'total_duration': 24467.10733628273, 'accumulated_submission_time': 22730.86786866188, 'accumulated_eval_time': 1731.4081916809082, 'accumulated_logging_time': 2.0030345916748047, 'global_step': 51298, 'preemption_count': 0}), (52242, {'train/accuracy': 0.712890625, 'train/loss': 1.1680288314819336, 'validation/accuracy': 0.6553599834442139, 'validation/loss': 1.410423994064331, 'validation/num_examples': 50000, 'test/accuracy': 0.5373000502586365, 'test/loss': 2.0474627017974854, 'test/num_examples': 10000, 'score': 23151.14921760559, 'total_duration': 24919.23223924637, 'accumulated_submission_time': 23151.14921760559, 'accumulated_eval_time': 1763.161215543747, 'accumulated_logging_time': 2.041849374771118, 'global_step': 52242, 'preemption_count': 0}), (53189, {'train/accuracy': 0.7213671803474426, 'train/loss': 1.1424052715301514, 'validation/accuracy': 0.6587399840354919, 'validation/loss': 1.4117166996002197, 'validation/num_examples': 50000, 'test/accuracy': 0.5398000478744507, 'test/loss': 2.046475648880005, 'test/num_examples': 10000, 'score': 23571.366389513016, 'total_duration': 25373.55533504486, 'accumulated_submission_time': 23571.366389513016, 'accumulated_eval_time': 1797.1810853481293, 'accumulated_logging_time': 2.0759410858154297, 'global_step': 53189, 'preemption_count': 0}), (54138, {'train/accuracy': 0.7173827886581421, 'train/loss': 1.1344820261001587, 'validation/accuracy': 0.6624199748039246, 'validation/loss': 1.3856710195541382, 'validation/num_examples': 50000, 'test/accuracy': 0.5407000184059143, 'test/loss': 2.0176327228546143, 'test/num_examples': 10000, 'score': 23991.405400276184, 'total_duration': 25827.10133099556, 'accumulated_submission_time': 23991.405400276184, 'accumulated_eval_time': 1830.5997319221497, 'accumulated_logging_time': 2.112729072570801, 'global_step': 54138, 'preemption_count': 0}), (55084, {'train/accuracy': 0.7164648175239563, 'train/loss': 1.1465487480163574, 'validation/accuracy': 0.6601200103759766, 'validation/loss': 1.3903496265411377, 'validation/num_examples': 50000, 'test/accuracy': 0.5400000214576721, 'test/loss': 2.028998851776123, 'test/num_examples': 10000, 'score': 24411.513561964035, 'total_duration': 26280.66367840767, 'accumulated_submission_time': 24411.513561964035, 'accumulated_eval_time': 1863.9700202941895, 'accumulated_logging_time': 2.145425796508789, 'global_step': 55084, 'preemption_count': 0}), (56027, {'train/accuracy': 0.7238476276397705, 'train/loss': 1.1132664680480957, 'validation/accuracy': 0.6629799604415894, 'validation/loss': 1.37566339969635, 'validation/num_examples': 50000, 'test/accuracy': 0.5439000129699707, 'test/loss': 2.011918544769287, 'test/num_examples': 10000, 'score': 24831.5508518219, 'total_duration': 26733.64523267746, 'accumulated_submission_time': 24831.5508518219, 'accumulated_eval_time': 1896.8296167850494, 'accumulated_logging_time': 2.1788289546966553, 'global_step': 56027, 'preemption_count': 0}), (56974, {'train/accuracy': 0.7383788824081421, 'train/loss': 1.0461022853851318, 'validation/accuracy': 0.6661799550056458, 'validation/loss': 1.3634791374206543, 'validation/num_examples': 50000, 'test/accuracy': 0.5414000153541565, 'test/loss': 2.0018365383148193, 'test/num_examples': 10000, 'score': 25251.902649641037, 'total_duration': 27186.46790075302, 'accumulated_submission_time': 25251.902649641037, 'accumulated_eval_time': 1929.2142486572266, 'accumulated_logging_time': 2.213578462600708, 'global_step': 56974, 'preemption_count': 0}), (57919, {'train/accuracy': 0.7252734303474426, 'train/loss': 1.1150798797607422, 'validation/accuracy': 0.669160008430481, 'validation/loss': 1.3615590333938599, 'validation/num_examples': 50000, 'test/accuracy': 0.5476000308990479, 'test/loss': 2.0163185596466064, 'test/num_examples': 10000, 'score': 25672.05046892166, 'total_duration': 27638.448981523514, 'accumulated_submission_time': 25672.05046892166, 'accumulated_eval_time': 1960.95663022995, 'accumulated_logging_time': 2.252743721008301, 'global_step': 57919, 'preemption_count': 0}), (58866, {'train/accuracy': 0.7296679615974426, 'train/loss': 1.0787262916564941, 'validation/accuracy': 0.6721599698066711, 'validation/loss': 1.3411825895309448, 'validation/num_examples': 50000, 'test/accuracy': 0.5482000112533569, 'test/loss': 1.9719829559326172, 'test/num_examples': 10000, 'score': 26092.036076784134, 'total_duration': 28092.210947752, 'accumulated_submission_time': 26092.036076784134, 'accumulated_eval_time': 1994.6439800262451, 'accumulated_logging_time': 2.2900073528289795, 'global_step': 58866, 'preemption_count': 0}), (59811, {'train/accuracy': 0.7402734160423279, 'train/loss': 1.0445926189422607, 'validation/accuracy': 0.6759999990463257, 'validation/loss': 1.3289766311645508, 'validation/num_examples': 50000, 'test/accuracy': 0.5515000224113464, 'test/loss': 1.9670867919921875, 'test/num_examples': 10000, 'score': 26511.96447300911, 'total_duration': 28546.29495382309, 'accumulated_submission_time': 26511.96447300911, 'accumulated_eval_time': 2028.7171030044556, 'accumulated_logging_time': 2.3205950260162354, 'global_step': 59811, 'preemption_count': 0}), (60759, {'train/accuracy': 0.7403320074081421, 'train/loss': 1.049425482749939, 'validation/accuracy': 0.6758999824523926, 'validation/loss': 1.322865605354309, 'validation/num_examples': 50000, 'test/accuracy': 0.5538000464439392, 'test/loss': 1.9534657001495361, 'test/num_examples': 10000, 'score': 26932.308787107468, 'total_duration': 29000.749348402023, 'accumulated_submission_time': 26932.308787107468, 'accumulated_eval_time': 2062.7454237937927, 'accumulated_logging_time': 2.3511340618133545, 'global_step': 60759, 'preemption_count': 0}), (61705, {'train/accuracy': 0.7339453101158142, 'train/loss': 1.0520697832107544, 'validation/accuracy': 0.6786800026893616, 'validation/loss': 1.3079254627227783, 'validation/num_examples': 50000, 'test/accuracy': 0.5556000471115112, 'test/loss': 1.9485647678375244, 'test/num_examples': 10000, 'score': 27352.409881591797, 'total_duration': 29453.221601247787, 'accumulated_submission_time': 27352.409881591797, 'accumulated_eval_time': 2095.030975818634, 'accumulated_logging_time': 2.385249614715576, 'global_step': 61705, 'preemption_count': 0}), (62651, {'train/accuracy': 0.7387109398841858, 'train/loss': 1.0528830289840698, 'validation/accuracy': 0.6791799664497375, 'validation/loss': 1.321641206741333, 'validation/num_examples': 50000, 'test/accuracy': 0.551800012588501, 'test/loss': 1.9544039964675903, 'test/num_examples': 10000, 'score': 27772.632388591766, 'total_duration': 29906.981637239456, 'accumulated_submission_time': 27772.632388591766, 'accumulated_eval_time': 2128.471873998642, 'accumulated_logging_time': 2.4299964904785156, 'global_step': 62651, 'preemption_count': 0}), (63597, {'train/accuracy': 0.750781238079071, 'train/loss': 0.9847334027290344, 'validation/accuracy': 0.6816799640655518, 'validation/loss': 1.2952712774276733, 'validation/num_examples': 50000, 'test/accuracy': 0.5585000514984131, 'test/loss': 1.9365578889846802, 'test/num_examples': 10000, 'score': 28192.61453294754, 'total_duration': 30361.36227083206, 'accumulated_submission_time': 28192.61453294754, 'accumulated_eval_time': 2162.7809953689575, 'accumulated_logging_time': 2.4671192169189453, 'global_step': 63597, 'preemption_count': 0}), (64542, {'train/accuracy': 0.7407031059265137, 'train/loss': 1.0386791229248047, 'validation/accuracy': 0.6838200092315674, 'validation/loss': 1.28839910030365, 'validation/num_examples': 50000, 'test/accuracy': 0.5594000220298767, 'test/loss': 1.9351783990859985, 'test/num_examples': 10000, 'score': 28612.81815481186, 'total_duration': 30817.041990041733, 'accumulated_submission_time': 28612.81815481186, 'accumulated_eval_time': 2198.1737167835236, 'accumulated_logging_time': 2.4979283809661865, 'global_step': 64542, 'preemption_count': 0}), (65486, {'train/accuracy': 0.7449609041213989, 'train/loss': 1.0040644407272339, 'validation/accuracy': 0.6847599744796753, 'validation/loss': 1.2756867408752441, 'validation/num_examples': 50000, 'test/accuracy': 0.5587000250816345, 'test/loss': 1.92477548122406, 'test/num_examples': 10000, 'score': 29033.064285755157, 'total_duration': 31271.463845729828, 'accumulated_submission_time': 29033.064285755157, 'accumulated_eval_time': 2232.2690222263336, 'accumulated_logging_time': 2.527261972427368, 'global_step': 65486, 'preemption_count': 0}), (66429, {'train/accuracy': 0.7562304735183716, 'train/loss': 0.9694955348968506, 'validation/accuracy': 0.6888999938964844, 'validation/loss': 1.2655874490737915, 'validation/num_examples': 50000, 'test/accuracy': 0.5600000023841858, 'test/loss': 1.8977373838424683, 'test/num_examples': 10000, 'score': 29453.113102674484, 'total_duration': 31724.86300420761, 'accumulated_submission_time': 29453.113102674484, 'accumulated_eval_time': 2265.5344891548157, 'accumulated_logging_time': 2.560814142227173, 'global_step': 66429, 'preemption_count': 0}), (67373, {'train/accuracy': 0.7611523270606995, 'train/loss': 0.9611263871192932, 'validation/accuracy': 0.6914799809455872, 'validation/loss': 1.266859531402588, 'validation/num_examples': 50000, 'test/accuracy': 0.5624000430107117, 'test/loss': 1.8967227935791016, 'test/num_examples': 10000, 'score': 29873.096399784088, 'total_duration': 32179.481694698334, 'accumulated_submission_time': 29873.096399784088, 'accumulated_eval_time': 2300.0830450057983, 'accumulated_logging_time': 2.5963993072509766, 'global_step': 67373, 'preemption_count': 0}), (68316, {'train/accuracy': 0.7525976300239563, 'train/loss': 0.9816879034042358, 'validation/accuracy': 0.6916399598121643, 'validation/loss': 1.2475214004516602, 'validation/num_examples': 50000, 'test/accuracy': 0.5639000535011292, 'test/loss': 1.897086262702942, 'test/num_examples': 10000, 'score': 30293.118802070618, 'total_duration': 32634.204987049103, 'accumulated_submission_time': 30293.118802070618, 'accumulated_eval_time': 2334.70215010643, 'accumulated_logging_time': 2.626979351043701, 'global_step': 68316, 'preemption_count': 0}), (69263, {'train/accuracy': 0.756054699420929, 'train/loss': 0.9686293601989746, 'validation/accuracy': 0.6932199597358704, 'validation/loss': 1.24394953250885, 'validation/num_examples': 50000, 'test/accuracy': 0.5648000240325928, 'test/loss': 1.8903024196624756, 'test/num_examples': 10000, 'score': 30713.382395505905, 'total_duration': 33086.927471637726, 'accumulated_submission_time': 30713.382395505905, 'accumulated_eval_time': 2367.0785982608795, 'accumulated_logging_time': 2.6575088500976562, 'global_step': 69263, 'preemption_count': 0}), (70208, {'train/accuracy': 0.7694140672683716, 'train/loss': 0.9334357380867004, 'validation/accuracy': 0.6912399530410767, 'validation/loss': 1.2634446620941162, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 1.8879430294036865, 'test/num_examples': 10000, 'score': 31133.573318243027, 'total_duration': 33539.84754896164, 'accumulated_submission_time': 31133.573318243027, 'accumulated_eval_time': 2399.722409725189, 'accumulated_logging_time': 2.6915690898895264, 'global_step': 70208, 'preemption_count': 0}), (71153, {'train/accuracy': 0.7538671493530273, 'train/loss': 0.9688629508018494, 'validation/accuracy': 0.6976000070571899, 'validation/loss': 1.2291446924209595, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 1.8841079473495483, 'test/num_examples': 10000, 'score': 31553.820833921432, 'total_duration': 33994.99906754494, 'accumulated_submission_time': 31553.820833921432, 'accumulated_eval_time': 2434.5373516082764, 'accumulated_logging_time': 2.7289319038391113, 'global_step': 71153, 'preemption_count': 0}), (72098, {'train/accuracy': 0.7606835961341858, 'train/loss': 0.9398583769798279, 'validation/accuracy': 0.6979799866676331, 'validation/loss': 1.2170993089675903, 'validation/num_examples': 50000, 'test/accuracy': 0.5753000378608704, 'test/loss': 1.8367221355438232, 'test/num_examples': 10000, 'score': 31973.78252720833, 'total_duration': 34449.886823415756, 'accumulated_submission_time': 31973.78252720833, 'accumulated_eval_time': 2469.376969099045, 'accumulated_logging_time': 2.7636160850524902, 'global_step': 72098, 'preemption_count': 0}), (73043, {'train/accuracy': 0.767578125, 'train/loss': 0.9278136491775513, 'validation/accuracy': 0.7011199593544006, 'validation/loss': 1.2232838869094849, 'validation/num_examples': 50000, 'test/accuracy': 0.5733000040054321, 'test/loss': 1.8401832580566406, 'test/num_examples': 10000, 'score': 32394.079025506973, 'total_duration': 34901.70451760292, 'accumulated_submission_time': 32394.079025506973, 'accumulated_eval_time': 2500.8163340091705, 'accumulated_logging_time': 2.7940104007720947, 'global_step': 73043, 'preemption_count': 0}), (73987, {'train/accuracy': 0.7697070240974426, 'train/loss': 0.9041791558265686, 'validation/accuracy': 0.701479971408844, 'validation/loss': 1.1972858905792236, 'validation/num_examples': 50000, 'test/accuracy': 0.57750004529953, 'test/loss': 1.8152793645858765, 'test/num_examples': 10000, 'score': 32814.340690374374, 'total_duration': 35354.55292868614, 'accumulated_submission_time': 32814.340690374374, 'accumulated_eval_time': 2533.3161249160767, 'accumulated_logging_time': 2.829845905303955, 'global_step': 73987, 'preemption_count': 0}), (74932, {'train/accuracy': 0.7698827981948853, 'train/loss': 0.9079320430755615, 'validation/accuracy': 0.7064200043678284, 'validation/loss': 1.1868194341659546, 'validation/num_examples': 50000, 'test/accuracy': 0.5814000368118286, 'test/loss': 1.7989803552627563, 'test/num_examples': 10000, 'score': 33234.36085677147, 'total_duration': 35808.806149721146, 'accumulated_submission_time': 33234.36085677147, 'accumulated_eval_time': 2567.4623601436615, 'accumulated_logging_time': 2.8648629188537598, 'global_step': 74932, 'preemption_count': 0}), (75879, {'train/accuracy': 0.7769335508346558, 'train/loss': 0.885880708694458, 'validation/accuracy': 0.7059800028800964, 'validation/loss': 1.1775133609771729, 'validation/num_examples': 50000, 'test/accuracy': 0.5808000564575195, 'test/loss': 1.8071162700653076, 'test/num_examples': 10000, 'score': 33654.51966834068, 'total_duration': 36265.357288360596, 'accumulated_submission_time': 33654.51966834068, 'accumulated_eval_time': 2603.771483182907, 'accumulated_logging_time': 2.895900249481201, 'global_step': 75879, 'preemption_count': 0}), (76823, {'train/accuracy': 0.7836523056030273, 'train/loss': 0.8550135493278503, 'validation/accuracy': 0.7077400088310242, 'validation/loss': 1.1789422035217285, 'validation/num_examples': 50000, 'test/accuracy': 0.5837000012397766, 'test/loss': 1.8055514097213745, 'test/num_examples': 10000, 'score': 34074.54490470886, 'total_duration': 36718.19757246971, 'accumulated_submission_time': 34074.54490470886, 'accumulated_eval_time': 2636.499994277954, 'accumulated_logging_time': 2.9304416179656982, 'global_step': 76823, 'preemption_count': 0}), (77765, {'train/accuracy': 0.7697460651397705, 'train/loss': 0.9096236228942871, 'validation/accuracy': 0.7121599912643433, 'validation/loss': 1.169438362121582, 'validation/num_examples': 50000, 'test/accuracy': 0.5838000178337097, 'test/loss': 1.8050917387008667, 'test/num_examples': 10000, 'score': 34494.83773326874, 'total_duration': 37171.05143284798, 'accumulated_submission_time': 34494.83773326874, 'accumulated_eval_time': 2668.9685966968536, 'accumulated_logging_time': 2.9714202880859375, 'global_step': 77765, 'preemption_count': 0}), (78711, {'train/accuracy': 0.7758398056030273, 'train/loss': 0.8823391795158386, 'validation/accuracy': 0.711959958076477, 'validation/loss': 1.1605439186096191, 'validation/num_examples': 50000, 'test/accuracy': 0.5857000350952148, 'test/loss': 1.7880895137786865, 'test/num_examples': 10000, 'score': 34915.00114774704, 'total_duration': 37625.079139471054, 'accumulated_submission_time': 34915.00114774704, 'accumulated_eval_time': 2702.7465002536774, 'accumulated_logging_time': 3.0059759616851807, 'global_step': 78711, 'preemption_count': 0}), (79657, {'train/accuracy': 0.7816210985183716, 'train/loss': 0.8461682200431824, 'validation/accuracy': 0.7140799760818481, 'validation/loss': 1.1480047702789307, 'validation/num_examples': 50000, 'test/accuracy': 0.5919000506401062, 'test/loss': 1.765407919883728, 'test/num_examples': 10000, 'score': 35335.26860022545, 'total_duration': 38079.90578985214, 'accumulated_submission_time': 35335.26860022545, 'accumulated_eval_time': 2737.222516298294, 'accumulated_logging_time': 3.0372495651245117, 'global_step': 79657, 'preemption_count': 0}), (80600, {'train/accuracy': 0.7875390648841858, 'train/loss': 0.8281233906745911, 'validation/accuracy': 0.7124800086021423, 'validation/loss': 1.151130199432373, 'validation/num_examples': 50000, 'test/accuracy': 0.5859000086784363, 'test/loss': 1.781424641609192, 'test/num_examples': 10000, 'score': 35755.42396569252, 'total_duration': 38534.573508262634, 'accumulated_submission_time': 35755.42396569252, 'accumulated_eval_time': 2771.6473848819733, 'accumulated_logging_time': 3.0723280906677246, 'global_step': 80600, 'preemption_count': 0}), (81546, {'train/accuracy': 0.7818945050239563, 'train/loss': 0.8708837628364563, 'validation/accuracy': 0.7129999995231628, 'validation/loss': 1.1647069454193115, 'validation/num_examples': 50000, 'test/accuracy': 0.5901000499725342, 'test/loss': 1.7958334684371948, 'test/num_examples': 10000, 'score': 36175.52549481392, 'total_duration': 38986.60156083107, 'accumulated_submission_time': 36175.52549481392, 'accumulated_eval_time': 2803.4854793548584, 'accumulated_logging_time': 3.1088600158691406, 'global_step': 81546, 'preemption_count': 0}), (82491, {'train/accuracy': 0.7884765267372131, 'train/loss': 0.8577178716659546, 'validation/accuracy': 0.7178599834442139, 'validation/loss': 1.1544245481491089, 'validation/num_examples': 50000, 'test/accuracy': 0.5913000106811523, 'test/loss': 1.7814141511917114, 'test/num_examples': 10000, 'score': 36595.509464502335, 'total_duration': 39440.10619926453, 'accumulated_submission_time': 36595.509464502335, 'accumulated_eval_time': 2836.9182636737823, 'accumulated_logging_time': 3.1451468467712402, 'global_step': 82491, 'preemption_count': 0}), (83437, {'train/accuracy': 0.7953515648841858, 'train/loss': 0.8039199709892273, 'validation/accuracy': 0.7190799713134766, 'validation/loss': 1.1275643110275269, 'validation/num_examples': 50000, 'test/accuracy': 0.5945000052452087, 'test/loss': 1.7498276233673096, 'test/num_examples': 10000, 'score': 37015.672527074814, 'total_duration': 39895.141380786896, 'accumulated_submission_time': 37015.672527074814, 'accumulated_eval_time': 2871.7059211730957, 'accumulated_logging_time': 3.1772243976593018, 'global_step': 83437, 'preemption_count': 0}), (84385, {'train/accuracy': 0.78431636095047, 'train/loss': 0.8333121538162231, 'validation/accuracy': 0.7215799689292908, 'validation/loss': 1.1099660396575928, 'validation/num_examples': 50000, 'test/accuracy': 0.5943000316619873, 'test/loss': 1.739061951637268, 'test/num_examples': 10000, 'score': 37435.992270469666, 'total_duration': 40348.84459066391, 'accumulated_submission_time': 37435.992270469666, 'accumulated_eval_time': 2905.0016555786133, 'accumulated_logging_time': 3.212794780731201, 'global_step': 84385, 'preemption_count': 0}), (85329, {'train/accuracy': 0.7906445264816284, 'train/loss': 0.8078277111053467, 'validation/accuracy': 0.7192800045013428, 'validation/loss': 1.1236505508422852, 'validation/num_examples': 50000, 'test/accuracy': 0.5951000452041626, 'test/loss': 1.7393476963043213, 'test/num_examples': 10000, 'score': 37856.35889649391, 'total_duration': 40803.289375305176, 'accumulated_submission_time': 37856.35889649391, 'accumulated_eval_time': 2938.9899594783783, 'accumulated_logging_time': 3.250253677368164, 'global_step': 85329, 'preemption_count': 0}), (86273, {'train/accuracy': 0.798535168170929, 'train/loss': 0.7840611338615417, 'validation/accuracy': 0.725600004196167, 'validation/loss': 1.0962775945663452, 'validation/num_examples': 50000, 'test/accuracy': 0.5938000082969666, 'test/loss': 1.7202932834625244, 'test/num_examples': 10000, 'score': 38276.34303474426, 'total_duration': 41254.75935173035, 'accumulated_submission_time': 38276.34303474426, 'accumulated_eval_time': 2970.384974718094, 'accumulated_logging_time': 3.2900712490081787, 'global_step': 86273, 'preemption_count': 0}), (87217, {'train/accuracy': 0.806933581829071, 'train/loss': 0.7684230804443359, 'validation/accuracy': 0.7239199876785278, 'validation/loss': 1.1109713315963745, 'validation/num_examples': 50000, 'test/accuracy': 0.595300018787384, 'test/loss': 1.7254667282104492, 'test/num_examples': 10000, 'score': 38696.57227444649, 'total_duration': 41708.5273001194, 'accumulated_submission_time': 38696.57227444649, 'accumulated_eval_time': 3003.8310148715973, 'accumulated_logging_time': 3.3293609619140625, 'global_step': 87217, 'preemption_count': 0}), (88162, {'train/accuracy': 0.791699230670929, 'train/loss': 0.8004516959190369, 'validation/accuracy': 0.7252599596977234, 'validation/loss': 1.0912268161773682, 'validation/num_examples': 50000, 'test/accuracy': 0.6039000153541565, 'test/loss': 1.7035795450210571, 'test/num_examples': 10000, 'score': 39116.784254550934, 'total_duration': 42162.53975176811, 'accumulated_submission_time': 39116.784254550934, 'accumulated_eval_time': 3037.5434033870697, 'accumulated_logging_time': 3.3656725883483887, 'global_step': 88162, 'preemption_count': 0}), (89108, {'train/accuracy': 0.8007421493530273, 'train/loss': 0.7903771996498108, 'validation/accuracy': 0.7258999943733215, 'validation/loss': 1.101864218711853, 'validation/num_examples': 50000, 'test/accuracy': 0.5979000329971313, 'test/loss': 1.7177833318710327, 'test/num_examples': 10000, 'score': 39536.90453696251, 'total_duration': 42617.078525066376, 'accumulated_submission_time': 39536.90453696251, 'accumulated_eval_time': 3071.8767664432526, 'accumulated_logging_time': 3.3986270427703857, 'global_step': 89108, 'preemption_count': 0}), (90054, {'train/accuracy': 0.8122069835662842, 'train/loss': 0.7413570880889893, 'validation/accuracy': 0.7295199632644653, 'validation/loss': 1.0877870321273804, 'validation/num_examples': 50000, 'test/accuracy': 0.6009000539779663, 'test/loss': 1.7063565254211426, 'test/num_examples': 10000, 'score': 39956.84877586365, 'total_duration': 43068.3249976635, 'accumulated_submission_time': 39956.84877586365, 'accumulated_eval_time': 3103.093540430069, 'accumulated_logging_time': 3.431971788406372, 'global_step': 90054, 'preemption_count': 0}), (90996, {'train/accuracy': 0.8010351657867432, 'train/loss': 0.7723552584648132, 'validation/accuracy': 0.7313999533653259, 'validation/loss': 1.0754905939102173, 'validation/num_examples': 50000, 'test/accuracy': 0.6005000472068787, 'test/loss': 1.6922496557235718, 'test/num_examples': 10000, 'score': 40376.85789036751, 'total_duration': 43523.73801469803, 'accumulated_submission_time': 40376.85789036751, 'accumulated_eval_time': 3138.4046683311462, 'accumulated_logging_time': 3.471984386444092, 'global_step': 90996, 'preemption_count': 0}), (91940, {'train/accuracy': 0.8031640648841858, 'train/loss': 0.7608716487884521, 'validation/accuracy': 0.7321799993515015, 'validation/loss': 1.074285864830017, 'validation/num_examples': 50000, 'test/accuracy': 0.6092000007629395, 'test/loss': 1.6871871948242188, 'test/num_examples': 10000, 'score': 40797.02273106575, 'total_duration': 43978.620604753494, 'accumulated_submission_time': 40797.02273106575, 'accumulated_eval_time': 3173.0354750156403, 'accumulated_logging_time': 3.5066089630126953, 'global_step': 91940, 'preemption_count': 0}), (92885, {'train/accuracy': 0.8125780820846558, 'train/loss': 0.7432088851928711, 'validation/accuracy': 0.7317599654197693, 'validation/loss': 1.080646276473999, 'validation/num_examples': 50000, 'test/accuracy': 0.610200047492981, 'test/loss': 1.6884973049163818, 'test/num_examples': 10000, 'score': 41217.16759157181, 'total_duration': 44431.800936460495, 'accumulated_submission_time': 41217.16759157181, 'accumulated_eval_time': 3205.9842755794525, 'accumulated_logging_time': 3.541409969329834, 'global_step': 92885, 'preemption_count': 0}), (93833, {'train/accuracy': 0.8225781321525574, 'train/loss': 0.6907076835632324, 'validation/accuracy': 0.736579954624176, 'validation/loss': 1.04587721824646, 'validation/num_examples': 50000, 'test/accuracy': 0.6124000549316406, 'test/loss': 1.6616320610046387, 'test/num_examples': 10000, 'score': 41637.26306915283, 'total_duration': 44887.69271564484, 'accumulated_submission_time': 41637.26306915283, 'accumulated_eval_time': 3241.694093942642, 'accumulated_logging_time': 3.575056791305542, 'global_step': 93833, 'preemption_count': 0}), (94778, {'train/accuracy': 0.8091992139816284, 'train/loss': 0.7314270734786987, 'validation/accuracy': 0.7390999794006348, 'validation/loss': 1.0349777936935425, 'validation/num_examples': 50000, 'test/accuracy': 0.6151000261306763, 'test/loss': 1.6441214084625244, 'test/num_examples': 10000, 'score': 42057.36578083038, 'total_duration': 45342.55961918831, 'accumulated_submission_time': 42057.36578083038, 'accumulated_eval_time': 3276.3718383312225, 'accumulated_logging_time': 3.6096181869506836, 'global_step': 94778, 'preemption_count': 0}), (95722, {'train/accuracy': 0.8138671517372131, 'train/loss': 0.7235919833183289, 'validation/accuracy': 0.736739993095398, 'validation/loss': 1.0535563230514526, 'validation/num_examples': 50000, 'test/accuracy': 0.6057000160217285, 'test/loss': 1.680138349533081, 'test/num_examples': 10000, 'score': 42477.49273610115, 'total_duration': 45797.50256180763, 'accumulated_submission_time': 42477.49273610115, 'accumulated_eval_time': 3311.101194858551, 'accumulated_logging_time': 3.6434314250946045, 'global_step': 95722, 'preemption_count': 0}), (96667, {'train/accuracy': 0.8196484446525574, 'train/loss': 0.704096257686615, 'validation/accuracy': 0.73853999376297, 'validation/loss': 1.0456427335739136, 'validation/num_examples': 50000, 'test/accuracy': 0.6146000027656555, 'test/loss': 1.6553770303726196, 'test/num_examples': 10000, 'score': 42897.63587832451, 'total_duration': 46249.7727265358, 'accumulated_submission_time': 42897.63587832451, 'accumulated_eval_time': 3343.1433713436127, 'accumulated_logging_time': 3.676774024963379, 'global_step': 96667, 'preemption_count': 0}), (97610, {'train/accuracy': 0.8161913752555847, 'train/loss': 0.7107599377632141, 'validation/accuracy': 0.7409999966621399, 'validation/loss': 1.0231674909591675, 'validation/num_examples': 50000, 'test/accuracy': 0.6165000200271606, 'test/loss': 1.6399441957473755, 'test/num_examples': 10000, 'score': 43318.00505113602, 'total_duration': 46704.69818735123, 'accumulated_submission_time': 43318.00505113602, 'accumulated_eval_time': 3377.6077132225037, 'accumulated_logging_time': 3.7166271209716797, 'global_step': 97610, 'preemption_count': 0}), (98556, {'train/accuracy': 0.8185741901397705, 'train/loss': 0.699514627456665, 'validation/accuracy': 0.7416399717330933, 'validation/loss': 1.0216460227966309, 'validation/num_examples': 50000, 'test/accuracy': 0.6168000102043152, 'test/loss': 1.6231310367584229, 'test/num_examples': 10000, 'score': 43738.30462694168, 'total_duration': 47160.798404455185, 'accumulated_submission_time': 43738.30462694168, 'accumulated_eval_time': 3413.3209006786346, 'accumulated_logging_time': 3.751324415206909, 'global_step': 98556, 'preemption_count': 0}), (99501, {'train/accuracy': 0.8238476514816284, 'train/loss': 0.6778075098991394, 'validation/accuracy': 0.7441200017929077, 'validation/loss': 1.0106030702590942, 'validation/num_examples': 50000, 'test/accuracy': 0.6188000440597534, 'test/loss': 1.6165797710418701, 'test/num_examples': 10000, 'score': 44158.91107749939, 'total_duration': 47614.98087024689, 'accumulated_submission_time': 44158.91107749939, 'accumulated_eval_time': 3446.814339160919, 'accumulated_logging_time': 3.7815587520599365, 'global_step': 99501, 'preemption_count': 0}), (100444, {'train/accuracy': 0.8323046565055847, 'train/loss': 0.6562907099723816, 'validation/accuracy': 0.7439799904823303, 'validation/loss': 1.0213578939437866, 'validation/num_examples': 50000, 'test/accuracy': 0.6168000102043152, 'test/loss': 1.6335022449493408, 'test/num_examples': 10000, 'score': 44578.8914835453, 'total_duration': 48070.29369139671, 'accumulated_submission_time': 44578.8914835453, 'accumulated_eval_time': 3482.0554757118225, 'accumulated_logging_time': 3.821136474609375, 'global_step': 100444, 'preemption_count': 0}), (101388, {'train/accuracy': 0.8255273103713989, 'train/loss': 0.6668426394462585, 'validation/accuracy': 0.7452600002288818, 'validation/loss': 1.003542184829712, 'validation/num_examples': 50000, 'test/accuracy': 0.6236000061035156, 'test/loss': 1.609777808189392, 'test/num_examples': 10000, 'score': 44998.959970235825, 'total_duration': 48523.312101364136, 'accumulated_submission_time': 44998.959970235825, 'accumulated_eval_time': 3514.9195449352264, 'accumulated_logging_time': 3.8547041416168213, 'global_step': 101388, 'preemption_count': 0}), (102330, {'train/accuracy': 0.8272460699081421, 'train/loss': 0.6679974794387817, 'validation/accuracy': 0.7484399676322937, 'validation/loss': 1.0021166801452637, 'validation/num_examples': 50000, 'test/accuracy': 0.6233000159263611, 'test/loss': 1.6095317602157593, 'test/num_examples': 10000, 'score': 45418.93943095207, 'total_duration': 48979.08910894394, 'accumulated_submission_time': 45418.93943095207, 'accumulated_eval_time': 3550.6198267936707, 'accumulated_logging_time': 3.8995537757873535, 'global_step': 102330, 'preemption_count': 0}), (103276, {'train/accuracy': 0.833789050579071, 'train/loss': 0.6367660164833069, 'validation/accuracy': 0.7475000023841858, 'validation/loss': 0.9865875244140625, 'validation/num_examples': 50000, 'test/accuracy': 0.6249000430107117, 'test/loss': 1.5951905250549316, 'test/num_examples': 10000, 'score': 45838.909757614136, 'total_duration': 49431.99482727051, 'accumulated_submission_time': 45838.909757614136, 'accumulated_eval_time': 3583.4697527885437, 'accumulated_logging_time': 3.932786464691162, 'global_step': 103276, 'preemption_count': 0}), (104218, {'train/accuracy': 0.8297656178474426, 'train/loss': 0.6642767786979675, 'validation/accuracy': 0.7516399621963501, 'validation/loss': 0.994663655757904, 'validation/num_examples': 50000, 'test/accuracy': 0.6238000392913818, 'test/loss': 1.6038514375686646, 'test/num_examples': 10000, 'score': 46258.91853380203, 'total_duration': 49883.67628288269, 'accumulated_submission_time': 46258.91853380203, 'accumulated_eval_time': 3615.0578157901764, 'accumulated_logging_time': 3.9654600620269775, 'global_step': 104218, 'preemption_count': 0}), (105160, {'train/accuracy': 0.8348437547683716, 'train/loss': 0.6299718618392944, 'validation/accuracy': 0.753059983253479, 'validation/loss': 0.9723790287971497, 'validation/num_examples': 50000, 'test/accuracy': 0.6304000020027161, 'test/loss': 1.5898592472076416, 'test/num_examples': 10000, 'score': 46679.14871048927, 'total_duration': 50336.998074769974, 'accumulated_submission_time': 46679.14871048927, 'accumulated_eval_time': 3648.033533334732, 'accumulated_logging_time': 4.029381513595581, 'global_step': 105160, 'preemption_count': 0}), (106106, {'train/accuracy': 0.8372851610183716, 'train/loss': 0.6215903759002686, 'validation/accuracy': 0.7533999681472778, 'validation/loss': 0.9754841327667236, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.5825921297073364, 'test/num_examples': 10000, 'score': 47099.167150735855, 'total_duration': 50790.82998538017, 'accumulated_submission_time': 47099.167150735855, 'accumulated_eval_time': 3681.750886440277, 'accumulated_logging_time': 4.073232889175415, 'global_step': 106106, 'preemption_count': 0}), (107051, {'train/accuracy': 0.8421874642372131, 'train/loss': 0.6038376688957214, 'validation/accuracy': 0.7533400058746338, 'validation/loss': 0.9784523844718933, 'validation/num_examples': 50000, 'test/accuracy': 0.6310000419616699, 'test/loss': 1.5913622379302979, 'test/num_examples': 10000, 'score': 47519.38187241554, 'total_duration': 51243.55078268051, 'accumulated_submission_time': 47519.38187241554, 'accumulated_eval_time': 3714.167423725128, 'accumulated_logging_time': 4.110680103302002, 'global_step': 107051, 'preemption_count': 0}), (107994, {'train/accuracy': 0.8350781202316284, 'train/loss': 0.6316884756088257, 'validation/accuracy': 0.7540199756622314, 'validation/loss': 0.968947172164917, 'validation/num_examples': 50000, 'test/accuracy': 0.6300000548362732, 'test/loss': 1.5743050575256348, 'test/num_examples': 10000, 'score': 47939.34608221054, 'total_duration': 51698.19714593887, 'accumulated_submission_time': 47939.34608221054, 'accumulated_eval_time': 3748.756111383438, 'accumulated_logging_time': 4.151872634887695, 'global_step': 107994, 'preemption_count': 0}), (108939, {'train/accuracy': 0.8401757478713989, 'train/loss': 0.6095958352088928, 'validation/accuracy': 0.7569599747657776, 'validation/loss': 0.9585469961166382, 'validation/num_examples': 50000, 'test/accuracy': 0.6322000026702881, 'test/loss': 1.5597306489944458, 'test/num_examples': 10000, 'score': 48359.519057273865, 'total_duration': 52151.403217315674, 'accumulated_submission_time': 48359.519057273865, 'accumulated_eval_time': 3781.701289653778, 'accumulated_logging_time': 4.187899827957153, 'global_step': 108939, 'preemption_count': 0}), (109884, {'train/accuracy': 0.8474804759025574, 'train/loss': 0.5809025168418884, 'validation/accuracy': 0.7572599649429321, 'validation/loss': 0.9565075039863586, 'validation/num_examples': 50000, 'test/accuracy': 0.6308000087738037, 'test/loss': 1.5641238689422607, 'test/num_examples': 10000, 'score': 48779.83942055702, 'total_duration': 52607.753846883774, 'accumulated_submission_time': 48779.83942055702, 'accumulated_eval_time': 3817.634386777878, 'accumulated_logging_time': 4.231295108795166, 'global_step': 109884, 'preemption_count': 0}), (110830, {'train/accuracy': 0.84130859375, 'train/loss': 0.611589789390564, 'validation/accuracy': 0.7575799822807312, 'validation/loss': 0.9555621147155762, 'validation/num_examples': 50000, 'test/accuracy': 0.6379000544548035, 'test/loss': 1.555673360824585, 'test/num_examples': 10000, 'score': 49199.886014938354, 'total_duration': 53061.86001467705, 'accumulated_submission_time': 49199.886014938354, 'accumulated_eval_time': 3851.6018323898315, 'accumulated_logging_time': 4.2699151039123535, 'global_step': 110830, 'preemption_count': 0}), (111776, {'train/accuracy': 0.8459570407867432, 'train/loss': 0.5894351005554199, 'validation/accuracy': 0.7598599791526794, 'validation/loss': 0.9470462799072266, 'validation/num_examples': 50000, 'test/accuracy': 0.6331000328063965, 'test/loss': 1.547625184059143, 'test/num_examples': 10000, 'score': 49619.927680015564, 'total_duration': 53516.78128504753, 'accumulated_submission_time': 49619.927680015564, 'accumulated_eval_time': 3886.3910517692566, 'accumulated_logging_time': 4.307658910751343, 'global_step': 111776, 'preemption_count': 0}), (112720, {'train/accuracy': 0.84619140625, 'train/loss': 0.5805347561836243, 'validation/accuracy': 0.7622799873352051, 'validation/loss': 0.9378506541252136, 'validation/num_examples': 50000, 'test/accuracy': 0.6384000182151794, 'test/loss': 1.5401344299316406, 'test/num_examples': 10000, 'score': 50039.9345574379, 'total_duration': 53969.43102359772, 'accumulated_submission_time': 50039.9345574379, 'accumulated_eval_time': 3918.946114063263, 'accumulated_logging_time': 4.342726469039917, 'global_step': 112720, 'preemption_count': 0}), (113662, {'train/accuracy': 0.8561522960662842, 'train/loss': 0.5643961429595947, 'validation/accuracy': 0.7628399729728699, 'validation/loss': 0.9491704702377319, 'validation/num_examples': 50000, 'test/accuracy': 0.6375000476837158, 'test/loss': 1.5496562719345093, 'test/num_examples': 10000, 'score': 50459.97273135185, 'total_duration': 54425.21489691734, 'accumulated_submission_time': 50459.97273135185, 'accumulated_eval_time': 3954.6028020381927, 'accumulated_logging_time': 4.378979921340942, 'global_step': 113662, 'preemption_count': 0}), (114604, {'train/accuracy': 0.8505468368530273, 'train/loss': 0.5697076320648193, 'validation/accuracy': 0.7631799578666687, 'validation/loss': 0.931150496006012, 'validation/num_examples': 50000, 'test/accuracy': 0.6397000551223755, 'test/loss': 1.5249947309494019, 'test/num_examples': 10000, 'score': 50879.94529294968, 'total_duration': 54879.10041451454, 'accumulated_submission_time': 50879.94529294968, 'accumulated_eval_time': 3988.4300713539124, 'accumulated_logging_time': 4.412188529968262, 'global_step': 114604, 'preemption_count': 0}), (115547, {'train/accuracy': 0.8536718487739563, 'train/loss': 0.5610446929931641, 'validation/accuracy': 0.7638999819755554, 'validation/loss': 0.9312052726745605, 'validation/num_examples': 50000, 'test/accuracy': 0.6373000144958496, 'test/loss': 1.5294908285140991, 'test/num_examples': 10000, 'score': 51300.09628677368, 'total_duration': 55331.65394306183, 'accumulated_submission_time': 51300.09628677368, 'accumulated_eval_time': 4020.7327842712402, 'accumulated_logging_time': 4.459543704986572, 'global_step': 115547, 'preemption_count': 0}), (116490, {'train/accuracy': 0.8540233969688416, 'train/loss': 0.5607977509498596, 'validation/accuracy': 0.7656799554824829, 'validation/loss': 0.9310572147369385, 'validation/num_examples': 50000, 'test/accuracy': 0.6445000171661377, 'test/loss': 1.5323371887207031, 'test/num_examples': 10000, 'score': 51720.394916534424, 'total_duration': 55785.432247400284, 'accumulated_submission_time': 51720.394916534424, 'accumulated_eval_time': 4054.1191594600677, 'accumulated_logging_time': 4.499362468719482, 'global_step': 116490, 'preemption_count': 0}), (117434, {'train/accuracy': 0.8561718463897705, 'train/loss': 0.5504412055015564, 'validation/accuracy': 0.7667399644851685, 'validation/loss': 0.9199657440185547, 'validation/num_examples': 50000, 'test/accuracy': 0.6425000429153442, 'test/loss': 1.5176986455917358, 'test/num_examples': 10000, 'score': 52140.364542007446, 'total_duration': 56241.737661123276, 'accumulated_submission_time': 52140.364542007446, 'accumulated_eval_time': 4090.3634123802185, 'accumulated_logging_time': 4.538177728652954, 'global_step': 117434, 'preemption_count': 0}), (118382, {'train/accuracy': 0.8539453148841858, 'train/loss': 0.5580064058303833, 'validation/accuracy': 0.7667799592018127, 'validation/loss': 0.9167547225952148, 'validation/num_examples': 50000, 'test/accuracy': 0.64410001039505, 'test/loss': 1.512929081916809, 'test/num_examples': 10000, 'score': 52560.621530056, 'total_duration': 56696.270032167435, 'accumulated_submission_time': 52560.621530056, 'accumulated_eval_time': 4124.5489621162415, 'accumulated_logging_time': 4.575566053390503, 'global_step': 118382, 'preemption_count': 0}), (119327, {'train/accuracy': 0.8578320145606995, 'train/loss': 0.5392902493476868, 'validation/accuracy': 0.7668399810791016, 'validation/loss': 0.9132672548294067, 'validation/num_examples': 50000, 'test/accuracy': 0.6463000178337097, 'test/loss': 1.503037691116333, 'test/num_examples': 10000, 'score': 52980.662798166275, 'total_duration': 57148.683334350586, 'accumulated_submission_time': 52980.662798166275, 'accumulated_eval_time': 4156.831968307495, 'accumulated_logging_time': 4.611612796783447, 'global_step': 119327, 'preemption_count': 0}), (120271, {'train/accuracy': 0.8631249666213989, 'train/loss': 0.5213625431060791, 'validation/accuracy': 0.769059956073761, 'validation/loss': 0.909471869468689, 'validation/num_examples': 50000, 'test/accuracy': 0.647100031375885, 'test/loss': 1.4938733577728271, 'test/num_examples': 10000, 'score': 53400.73462295532, 'total_duration': 57601.41824054718, 'accumulated_submission_time': 53400.73462295532, 'accumulated_eval_time': 4189.408996105194, 'accumulated_logging_time': 4.6450583934783936, 'global_step': 120271, 'preemption_count': 0}), (121213, {'train/accuracy': 0.8573827743530273, 'train/loss': 0.5495367050170898, 'validation/accuracy': 0.7687599658966064, 'validation/loss': 0.9154432415962219, 'validation/num_examples': 50000, 'test/accuracy': 0.6465000510215759, 'test/loss': 1.504189372062683, 'test/num_examples': 10000, 'score': 53820.65683197975, 'total_duration': 58054.6372487545, 'accumulated_submission_time': 53820.65683197975, 'accumulated_eval_time': 4222.604034662247, 'accumulated_logging_time': 4.694658279418945, 'global_step': 121213, 'preemption_count': 0}), (122156, {'train/accuracy': 0.8579882383346558, 'train/loss': 0.5272805094718933, 'validation/accuracy': 0.7706999778747559, 'validation/loss': 0.9024597406387329, 'validation/num_examples': 50000, 'test/accuracy': 0.65010005235672, 'test/loss': 1.487162470817566, 'test/num_examples': 10000, 'score': 54240.74327278137, 'total_duration': 58509.546602249146, 'accumulated_submission_time': 54240.74327278137, 'accumulated_eval_time': 4257.331519842148, 'accumulated_logging_time': 4.7378764152526855, 'global_step': 122156, 'preemption_count': 0}), (123102, {'train/accuracy': 0.8630273342132568, 'train/loss': 0.52430260181427, 'validation/accuracy': 0.769819974899292, 'validation/loss': 0.9018756747245789, 'validation/num_examples': 50000, 'test/accuracy': 0.6461000442504883, 'test/loss': 1.4945242404937744, 'test/num_examples': 10000, 'score': 54660.90355968475, 'total_duration': 58962.234115600586, 'accumulated_submission_time': 54660.90355968475, 'accumulated_eval_time': 4289.764947891235, 'accumulated_logging_time': 4.778675556182861, 'global_step': 123102, 'preemption_count': 0}), (124046, {'train/accuracy': 0.8626952767372131, 'train/loss': 0.5199557542800903, 'validation/accuracy': 0.7716799974441528, 'validation/loss': 0.8945387005805969, 'validation/num_examples': 50000, 'test/accuracy': 0.6510000228881836, 'test/loss': 1.4852551221847534, 'test/num_examples': 10000, 'score': 55081.20386981964, 'total_duration': 59417.379841566086, 'accumulated_submission_time': 55081.20386981964, 'accumulated_eval_time': 4324.514363765717, 'accumulated_logging_time': 4.8217689990997314, 'global_step': 124046, 'preemption_count': 0}), (124992, {'train/accuracy': 0.8640234470367432, 'train/loss': 0.5254991054534912, 'validation/accuracy': 0.7728999853134155, 'validation/loss': 0.8978889584541321, 'validation/num_examples': 50000, 'test/accuracy': 0.6508000493049622, 'test/loss': 1.4892643690109253, 'test/num_examples': 10000, 'score': 55501.52442550659, 'total_duration': 59872.0070066452, 'accumulated_submission_time': 55501.52442550659, 'accumulated_eval_time': 4358.733941078186, 'accumulated_logging_time': 4.85650110244751, 'global_step': 124992, 'preemption_count': 0}), (125937, {'train/accuracy': 0.86328125, 'train/loss': 0.5222283601760864, 'validation/accuracy': 0.7728399634361267, 'validation/loss': 0.8917573094367981, 'validation/num_examples': 50000, 'test/accuracy': 0.6516000032424927, 'test/loss': 1.4831252098083496, 'test/num_examples': 10000, 'score': 55921.4867773056, 'total_duration': 60326.21323823929, 'accumulated_submission_time': 55921.4867773056, 'accumulated_eval_time': 4392.890504360199, 'accumulated_logging_time': 4.890900135040283, 'global_step': 125937, 'preemption_count': 0}), (126882, {'train/accuracy': 0.8663085699081421, 'train/loss': 0.5123443007469177, 'validation/accuracy': 0.7719399929046631, 'validation/loss': 0.8921030163764954, 'validation/num_examples': 50000, 'test/accuracy': 0.6491000056266785, 'test/loss': 1.481019377708435, 'test/num_examples': 10000, 'score': 56341.7328619957, 'total_duration': 60780.02904462814, 'accumulated_submission_time': 56341.7328619957, 'accumulated_eval_time': 4426.36954665184, 'accumulated_logging_time': 4.929235935211182, 'global_step': 126882, 'preemption_count': 0}), (127826, {'train/accuracy': 0.8672655820846558, 'train/loss': 0.5014148354530334, 'validation/accuracy': 0.7742999792098999, 'validation/loss': 0.8846955299377441, 'validation/num_examples': 50000, 'test/accuracy': 0.6528000235557556, 'test/loss': 1.466226577758789, 'test/num_examples': 10000, 'score': 56761.648509025574, 'total_duration': 61234.93220591545, 'accumulated_submission_time': 56761.648509025574, 'accumulated_eval_time': 4461.260905742645, 'accumulated_logging_time': 4.972701072692871, 'global_step': 127826, 'preemption_count': 0})], 'global_step': 127826}
I0319 20:17:25.074724 139793440028480 submission_runner.py:596] Timing: 56761.648509025574
I0319 20:17:25.074798 139793440028480 submission_runner.py:598] Total number of evals: 136
I0319 20:17:25.074840 139793440028480 submission_runner.py:599] ====================
I0319 20:17:25.075083 139793440028480 submission_runner.py:683] Final imagenet_vit_map score: 0

python3 submission_runner.py --framework=jax --workload=ogbg_gelu --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/ogbg_gelu/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --num_tuning_trials=1 --rng_seed=3377931912 --max_global_steps=80000 2>&1 | tee -a /logs/ogbg_gelu_jax_02-15-2024-12-00-30.log
I0215 12:00:52.256848 140558855219008 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax.
I0215 12:00:53.245936 140558855219008 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter CUDA Host
I0215 12:00:53.247062 140558855219008 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0215 12:00:53.247250 140558855219008 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0215 12:00:53.254316 140558855219008 submission_runner.py:542] Using RNG seed 3377931912
I0215 12:00:54.300463 140558855219008 submission_runner.py:551] --- Tuning run 1/1 ---
I0215 12:00:54.300717 140558855219008 submission_runner.py:556] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1.
I0215 12:00:54.301209 140558855219008 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1/hparams.json.
I0215 12:00:54.481490 140558855219008 submission_runner.py:206] Initializing dataset.
I0215 12:00:54.596192 140558855219008 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:00:54.601834 140558855219008 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0215 12:00:54.863470 140558855219008 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0215 12:00:54.926610 140558855219008 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:00:55.008975 140558855219008 submission_runner.py:213] Initializing model.
I0215 12:00:59.443317 140558855219008 submission_runner.py:255] Initializing optimizer.
I0215 12:01:00.063202 140558855219008 submission_runner.py:262] Initializing metrics bundle.
I0215 12:01:00.063400 140558855219008 submission_runner.py:280] Initializing checkpoint and logger.
I0215 12:01:00.064346 140558855219008 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1 with prefix checkpoint_
I0215 12:01:00.064483 140558855219008 submission_runner.py:300] Saving meta data to /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1/meta_data_0.json.
I0215 12:01:00.064667 140558855219008 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0215 12:01:00.064728 140558855219008 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0215 12:01:00.361602 140558855219008 logger_utils.py:220] Unable to record git information. Continuing without it.
I0215 12:01:00.634649 140558855219008 submission_runner.py:304] Saving flags to /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1/flags_0.json.
I0215 12:01:00.643580 140558855219008 submission_runner.py:314] Starting training loop.
I0215 12:01:19.769035 140393681250048 logging_writer.py:48] [0] global_step=0, grad_norm=2.9782216548919678, loss=0.7441335320472717
I0215 12:01:19.784140 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:01:19.789999 140558855219008 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:01:19.794266 140558855219008 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:01:19.859050 140558855219008 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:03:09.918728 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:03:09.922274 140558855219008 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:03:09.926575 140558855219008 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:03:09.990852 140558855219008 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:04:40.580876 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:04:40.584071 140558855219008 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:04:40.588028 140558855219008 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:04:40.651647 140558855219008 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:06:14.459738 140558855219008 submission_runner.py:408] Time since start: 313.82s, 	Step: 1, 	{'train/accuracy': 0.5693638920783997, 'train/loss': 0.7166677117347717, 'train/mean_average_precision': 0.02251561318132391, 'validation/accuracy': 0.566946268081665, 'validation/loss': 0.7168007493019104, 'validation/mean_average_precision': 0.02615410617255163, 'validation/num_examples': 43793, 'test/accuracy': 0.5636456608772278, 'test/loss': 0.7183514833450317, 'test/mean_average_precision': 0.02845508046388855, 'test/num_examples': 43793, 'score': 19.140517473220825, 'total_duration': 313.81607389450073, 'accumulated_submission_time': 19.140517473220825, 'accumulated_eval_time': 294.67551445961, 'accumulated_logging_time': 0}
I0215 12:06:14.477857 140390115645184 logging_writer.py:48] [1] accumulated_eval_time=294.675514, accumulated_logging_time=0, accumulated_submission_time=19.140517, global_step=1, preemption_count=0, score=19.140517, test/accuracy=0.563646, test/loss=0.718351, test/mean_average_precision=0.028455, test/num_examples=43793, total_duration=313.816074, train/accuracy=0.569364, train/loss=0.716668, train/mean_average_precision=0.022516, validation/accuracy=0.566946, validation/loss=0.716801, validation/mean_average_precision=0.026154, validation/num_examples=43793
I0215 12:06:14.796419 140391499769600 logging_writer.py:48] [1] global_step=1, grad_norm=3.0520212650299072, loss=0.7453023791313171
I0215 12:06:15.127956 140390115645184 logging_writer.py:48] [2] global_step=2, grad_norm=2.8214941024780273, loss=0.7269859313964844
I0215 12:06:15.444124 140391499769600 logging_writer.py:48] [3] global_step=3, grad_norm=2.4331557750701904, loss=0.6961104869842529
I0215 12:06:15.750358 140390115645184 logging_writer.py:48] [4] global_step=4, grad_norm=1.9644283056259155, loss=0.6612958908081055
I0215 12:06:16.063984 140391499769600 logging_writer.py:48] [5] global_step=5, grad_norm=1.570272445678711, loss=0.631381630897522
I0215 12:06:16.385432 140390115645184 logging_writer.py:48] [6] global_step=6, grad_norm=1.3609601259231567, loss=0.6045153737068176
I0215 12:06:16.697897 140391499769600 logging_writer.py:48] [7] global_step=7, grad_norm=1.2089372873306274, loss=0.5811668634414673
I0215 12:06:17.014107 140390115645184 logging_writer.py:48] [8] global_step=8, grad_norm=1.0969566106796265, loss=0.5599226355552673
I0215 12:06:17.320170 140391499769600 logging_writer.py:48] [9] global_step=9, grad_norm=0.9853439927101135, loss=0.5425264835357666
I0215 12:06:17.629602 140390115645184 logging_writer.py:48] [10] global_step=10, grad_norm=0.8862019777297974, loss=0.5237690806388855
I0215 12:06:17.941271 140391499769600 logging_writer.py:48] [11] global_step=11, grad_norm=0.7955034375190735, loss=0.5072872042655945
I0215 12:06:18.266140 140390115645184 logging_writer.py:48] [12] global_step=12, grad_norm=0.7249506711959839, loss=0.4977859556674957
I0215 12:06:18.572443 140391499769600 logging_writer.py:48] [13] global_step=13, grad_norm=0.6658803224563599, loss=0.4829164743423462
I0215 12:06:18.884348 140390115645184 logging_writer.py:48] [14] global_step=14, grad_norm=0.6097846031188965, loss=0.4677920937538147
I0215 12:06:19.197738 140391499769600 logging_writer.py:48] [15] global_step=15, grad_norm=0.5640499591827393, loss=0.4575543999671936
I0215 12:06:19.504493 140390115645184 logging_writer.py:48] [16] global_step=16, grad_norm=0.5228390693664551, loss=0.4457971751689911
I0215 12:06:19.815895 140391499769600 logging_writer.py:48] [17] global_step=17, grad_norm=0.4945175349712372, loss=0.4386865198612213
I0215 12:06:20.117320 140390115645184 logging_writer.py:48] [18] global_step=18, grad_norm=0.47897619009017944, loss=0.42965176701545715
I0215 12:06:20.422569 140391499769600 logging_writer.py:48] [19] global_step=19, grad_norm=0.46923938393592834, loss=0.4235506057739258
I0215 12:06:20.743658 140390115645184 logging_writer.py:48] [20] global_step=20, grad_norm=0.45367640256881714, loss=0.4182954430580139
I0215 12:06:21.074169 140391499769600 logging_writer.py:48] [21] global_step=21, grad_norm=0.451228529214859, loss=0.4075424373149872
I0215 12:06:21.382380 140390115645184 logging_writer.py:48] [22] global_step=22, grad_norm=0.43716883659362793, loss=0.40304118394851685
I0215 12:06:21.690946 140391499769600 logging_writer.py:48] [23] global_step=23, grad_norm=0.4272197186946869, loss=0.3957194983959198
I0215 12:06:22.001253 140390115645184 logging_writer.py:48] [24] global_step=24, grad_norm=0.4183656573295593, loss=0.3877759873867035
I0215 12:06:22.328549 140391499769600 logging_writer.py:48] [25] global_step=25, grad_norm=0.4122423231601715, loss=0.38015493750572205
I0215 12:06:22.633175 140390115645184 logging_writer.py:48] [26] global_step=26, grad_norm=0.39741256833076477, loss=0.3743276298046112
I0215 12:06:22.935405 140391499769600 logging_writer.py:48] [27] global_step=27, grad_norm=0.39078232645988464, loss=0.36661040782928467
I0215 12:06:23.257345 140390115645184 logging_writer.py:48] [28] global_step=28, grad_norm=0.38492462038993835, loss=0.3601469397544861
I0215 12:06:23.562873 140391499769600 logging_writer.py:48] [29] global_step=29, grad_norm=0.3780726194381714, loss=0.3518407344818115
I0215 12:06:23.866313 140390115645184 logging_writer.py:48] [30] global_step=30, grad_norm=0.36628055572509766, loss=0.3478659987449646
I0215 12:06:24.192690 140391499769600 logging_writer.py:48] [31] global_step=31, grad_norm=0.36002078652381897, loss=0.3427211344242096
I0215 12:06:24.499223 140390115645184 logging_writer.py:48] [32] global_step=32, grad_norm=0.3526400029659271, loss=0.33317476511001587
I0215 12:06:24.801352 140391499769600 logging_writer.py:48] [33] global_step=33, grad_norm=0.3424259424209595, loss=0.33156147599220276
I0215 12:06:25.114463 140390115645184 logging_writer.py:48] [34] global_step=34, grad_norm=0.33855104446411133, loss=0.3209003210067749
I0215 12:06:25.421968 140391499769600 logging_writer.py:48] [35] global_step=35, grad_norm=0.33088505268096924, loss=0.3158605694770813
I0215 12:06:25.727336 140390115645184 logging_writer.py:48] [36] global_step=36, grad_norm=0.3210800886154175, loss=0.31051111221313477
I0215 12:06:26.036905 140391499769600 logging_writer.py:48] [37] global_step=37, grad_norm=0.3154591917991638, loss=0.3047410845756531
I0215 12:06:26.345986 140390115645184 logging_writer.py:48] [38] global_step=38, grad_norm=0.3112448453903198, loss=0.2973317503929138
I0215 12:06:26.656120 140391499769600 logging_writer.py:48] [39] global_step=39, grad_norm=0.30430135130882263, loss=0.29176148772239685
I0215 12:06:26.966929 140390115645184 logging_writer.py:48] [40] global_step=40, grad_norm=0.2956926226615906, loss=0.28793734312057495
I0215 12:06:27.267245 140391499769600 logging_writer.py:48] [41] global_step=41, grad_norm=0.29201069474220276, loss=0.2786099314689636
I0215 12:06:27.583891 140390115645184 logging_writer.py:48] [42] global_step=42, grad_norm=0.2855440676212311, loss=0.27264297008514404
I0215 12:06:27.894860 140391499769600 logging_writer.py:48] [43] global_step=43, grad_norm=0.27874618768692017, loss=0.2649596035480499
I0215 12:06:28.202255 140390115645184 logging_writer.py:48] [44] global_step=44, grad_norm=0.27155801653862, loss=0.2593161165714264
I0215 12:06:28.508699 140391499769600 logging_writer.py:48] [45] global_step=45, grad_norm=0.2624984681606293, loss=0.2580733299255371
I0215 12:06:28.809645 140390115645184 logging_writer.py:48] [46] global_step=46, grad_norm=0.2576267421245575, loss=0.24734137952327728
I0215 12:06:29.124670 140391499769600 logging_writer.py:48] [47] global_step=47, grad_norm=0.25168079137802124, loss=0.24135714769363403
I0215 12:06:29.424175 140390115645184 logging_writer.py:48] [48] global_step=48, grad_norm=0.2463056594133377, loss=0.2335404008626938
I0215 12:06:29.728323 140391499769600 logging_writer.py:48] [49] global_step=49, grad_norm=0.23852957785129547, loss=0.2304280549287796
I0215 12:06:30.028376 140390115645184 logging_writer.py:48] [50] global_step=50, grad_norm=0.2345154732465744, loss=0.22112500667572021
I0215 12:06:30.332689 140391499769600 logging_writer.py:48] [51] global_step=51, grad_norm=0.22600460052490234, loss=0.21503326296806335
I0215 12:06:30.632086 140390115645184 logging_writer.py:48] [52] global_step=52, grad_norm=0.21867793798446655, loss=0.21109244227409363
I0215 12:06:30.935480 140391499769600 logging_writer.py:48] [53] global_step=53, grad_norm=0.21294763684272766, loss=0.20316118001937866
I0215 12:06:31.273678 140390115645184 logging_writer.py:48] [54] global_step=54, grad_norm=0.20393401384353638, loss=0.20200219750404358
I0215 12:06:31.587020 140391499769600 logging_writer.py:48] [55] global_step=55, grad_norm=0.197624072432518, loss=0.19535966217517853
I0215 12:06:31.893273 140390115645184 logging_writer.py:48] [56] global_step=56, grad_norm=0.19334548711776733, loss=0.18544907867908478
I0215 12:06:32.201607 140391499769600 logging_writer.py:48] [57] global_step=57, grad_norm=0.18164584040641785, loss=0.18675006926059723
I0215 12:06:32.505362 140390115645184 logging_writer.py:48] [58] global_step=58, grad_norm=0.1806676983833313, loss=0.1747921109199524
I0215 12:06:32.805647 140391499769600 logging_writer.py:48] [59] global_step=59, grad_norm=0.17506709694862366, loss=0.16695432364940643
I0215 12:06:33.126719 140390115645184 logging_writer.py:48] [60] global_step=60, grad_norm=0.16566458344459534, loss=0.1676395833492279
I0215 12:06:33.432442 140391499769600 logging_writer.py:48] [61] global_step=61, grad_norm=0.1609581857919693, loss=0.1615261286497116
I0215 12:06:33.739630 140390115645184 logging_writer.py:48] [62] global_step=62, grad_norm=0.1524507701396942, loss=0.15963153541088104
I0215 12:06:34.052801 140391499769600 logging_writer.py:48] [63] global_step=63, grad_norm=0.14984852075576782, loss=0.1531878262758255
I0215 12:06:34.380985 140390115645184 logging_writer.py:48] [64] global_step=64, grad_norm=0.14146849513053894, loss=0.15160419046878815
I0215 12:06:34.686203 140391499769600 logging_writer.py:48] [65] global_step=65, grad_norm=0.13758555054664612, loss=0.14162100851535797
I0215 12:06:34.992061 140390115645184 logging_writer.py:48] [66] global_step=66, grad_norm=0.13271869719028473, loss=0.13665436208248138
I0215 12:06:35.304108 140391499769600 logging_writer.py:48] [67] global_step=67, grad_norm=0.12544463574886322, loss=0.13565154373645782
I0215 12:06:35.618159 140390115645184 logging_writer.py:48] [68] global_step=68, grad_norm=0.12026049941778183, loss=0.13206839561462402
I0215 12:06:35.936225 140391499769600 logging_writer.py:48] [69] global_step=69, grad_norm=0.11363354325294495, loss=0.12937401235103607
I0215 12:06:36.245956 140390115645184 logging_writer.py:48] [70] global_step=70, grad_norm=0.11330892890691757, loss=0.11872393637895584
I0215 12:06:36.553026 140391499769600 logging_writer.py:48] [71] global_step=71, grad_norm=0.10683420300483704, loss=0.11688174307346344
I0215 12:06:36.860097 140390115645184 logging_writer.py:48] [72] global_step=72, grad_norm=0.10082552582025528, loss=0.11775194853544235
I0215 12:06:37.179749 140391499769600 logging_writer.py:48] [73] global_step=73, grad_norm=0.09694427251815796, loss=0.12056617438793182
I0215 12:06:37.501697 140390115645184 logging_writer.py:48] [74] global_step=74, grad_norm=0.09132357686758041, loss=0.11338181793689728
I0215 12:06:37.812697 140391499769600 logging_writer.py:48] [75] global_step=75, grad_norm=0.08931204676628113, loss=0.1064799502491951
I0215 12:06:38.121756 140390115645184 logging_writer.py:48] [76] global_step=76, grad_norm=0.08581335842609406, loss=0.10047241300344467
I0215 12:06:38.414586 140391499769600 logging_writer.py:48] [77] global_step=77, grad_norm=0.08047747611999512, loss=0.10589902848005295
I0215 12:06:38.716712 140390115645184 logging_writer.py:48] [78] global_step=78, grad_norm=0.07873204350471497, loss=0.09479234367609024
I0215 12:06:39.019617 140391499769600 logging_writer.py:48] [79] global_step=79, grad_norm=0.07570984214544296, loss=0.09453414380550385
I0215 12:06:39.327542 140390115645184 logging_writer.py:48] [80] global_step=80, grad_norm=0.06978632509708405, loss=0.09872947633266449
I0215 12:06:39.637219 140391499769600 logging_writer.py:48] [81] global_step=81, grad_norm=0.06814219057559967, loss=0.09188571572303772
I0215 12:06:39.958240 140390115645184 logging_writer.py:48] [82] global_step=82, grad_norm=0.06364983320236206, loss=0.08792150020599365
I0215 12:06:40.286685 140391499769600 logging_writer.py:48] [83] global_step=83, grad_norm=0.06179943308234215, loss=0.08893509954214096
I0215 12:06:40.601255 140390115645184 logging_writer.py:48] [84] global_step=84, grad_norm=0.0589776411652565, loss=0.0841633677482605
I0215 12:06:40.914086 140391499769600 logging_writer.py:48] [85] global_step=85, grad_norm=0.05582265928387642, loss=0.08480054885149002
I0215 12:06:41.230544 140390115645184 logging_writer.py:48] [86] global_step=86, grad_norm=0.05157805606722832, loss=0.08270677924156189
I0215 12:06:41.541333 140391499769600 logging_writer.py:48] [87] global_step=87, grad_norm=0.05043390393257141, loss=0.07922083139419556
I0215 12:06:41.857932 140390115645184 logging_writer.py:48] [88] global_step=88, grad_norm=0.048159774392843246, loss=0.07851473242044449
I0215 12:06:42.191295 140391499769600 logging_writer.py:48] [89] global_step=89, grad_norm=0.04626152291893959, loss=0.07668881118297577
I0215 12:06:42.517922 140390115645184 logging_writer.py:48] [90] global_step=90, grad_norm=0.042469561100006104, loss=0.07634028792381287
I0215 12:06:42.839248 140391499769600 logging_writer.py:48] [91] global_step=91, grad_norm=0.040041323751211166, loss=0.07761237770318985
I0215 12:06:43.166280 140390115645184 logging_writer.py:48] [92] global_step=92, grad_norm=0.03987054154276848, loss=0.0750124603509903
I0215 12:06:43.486596 140391499769600 logging_writer.py:48] [93] global_step=93, grad_norm=0.03779050335288048, loss=0.07458554208278656
I0215 12:06:43.794091 140390115645184 logging_writer.py:48] [94] global_step=94, grad_norm=0.03454189375042915, loss=0.07792220264673233
I0215 12:06:44.116036 140391499769600 logging_writer.py:48] [95] global_step=95, grad_norm=0.033666424453258514, loss=0.06929349154233932
I0215 12:06:44.437538 140390115645184 logging_writer.py:48] [96] global_step=96, grad_norm=0.03288963809609413, loss=0.06947759538888931
I0215 12:06:44.752454 140391499769600 logging_writer.py:48] [97] global_step=97, grad_norm=0.030682647600769997, loss=0.06840155273675919
I0215 12:06:45.077630 140390115645184 logging_writer.py:48] [98] global_step=98, grad_norm=0.031926099210977554, loss=0.07426387071609497
I0215 12:06:45.414180 140391499769600 logging_writer.py:48] [99] global_step=99, grad_norm=0.028735622763633728, loss=0.06867416203022003
I0215 12:06:45.733074 140390115645184 logging_writer.py:48] [100] global_step=100, grad_norm=0.02663980983197689, loss=0.06797141581773758
I0215 12:08:47.254207 140391499769600 logging_writer.py:48] [500] global_step=500, grad_norm=0.011785106733441353, loss=0.05819942057132721
I0215 12:10:14.751679 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:12:04.802156 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:12:07.717094 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:12:10.554821 140558855219008 submission_runner.py:408] Time since start: 669.91s, 	Step: 784, 	{'train/accuracy': 0.9867364764213562, 'train/loss': 0.05376839265227318, 'train/mean_average_precision': 0.03944228519030182, 'validation/accuracy': 0.9840367436408997, 'validation/loss': 0.06404019147157669, 'validation/mean_average_precision': 0.03898960368019125, 'validation/num_examples': 43793, 'test/accuracy': 0.9830296039581299, 'test/loss': 0.06735099852085114, 'test/mean_average_precision': 0.03981701520095944, 'test/num_examples': 43793, 'score': 259.38515639305115, 'total_duration': 669.91117811203, 'accumulated_submission_time': 259.38515639305115, 'accumulated_eval_time': 410.4786365032196, 'accumulated_logging_time': 0.028557300567626953}
I0215 12:12:10.571021 140391516555008 logging_writer.py:48] [784] accumulated_eval_time=410.478637, accumulated_logging_time=0.028557, accumulated_submission_time=259.385156, global_step=784, preemption_count=0, score=259.385156, test/accuracy=0.983030, test/loss=0.067351, test/mean_average_precision=0.039817, test/num_examples=43793, total_duration=669.911178, train/accuracy=0.986736, train/loss=0.053768, train/mean_average_precision=0.039442, validation/accuracy=0.984037, validation/loss=0.064040, validation/mean_average_precision=0.038990, validation/num_examples=43793
I0215 12:13:16.478613 140391524947712 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.009132204577326775, loss=0.05530194938182831
I0215 12:15:50.702999 140391516555008 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.006123400758951902, loss=0.050983112305402756
I0215 12:16:10.734708 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:17:59.199695 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:18:02.131533 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:18:04.941065 140558855219008 submission_runner.py:408] Time since start: 1024.30s, 	Step: 1569, 	{'train/accuracy': 0.9869202375411987, 'train/loss': 0.0504998080432415, 'train/mean_average_precision': 0.06201516743381764, 'validation/accuracy': 0.9842185974121094, 'validation/loss': 0.06088742986321449, 'validation/mean_average_precision': 0.06648660536337875, 'validation/num_examples': 43793, 'test/accuracy': 0.983212411403656, 'test/loss': 0.0642148107290268, 'test/mean_average_precision': 0.0652801938168278, 'test/num_examples': 43793, 'score': 499.51279520988464, 'total_duration': 1024.2972824573517, 'accumulated_submission_time': 499.51279520988464, 'accumulated_eval_time': 524.6848311424255, 'accumulated_logging_time': 0.05793571472167969}
I0215 12:18:04.958871 140391499769600 logging_writer.py:48] [1569] accumulated_eval_time=524.684831, accumulated_logging_time=0.057936, accumulated_submission_time=499.512795, global_step=1569, preemption_count=0, score=499.512795, test/accuracy=0.983212, test/loss=0.064215, test/mean_average_precision=0.065280, test/num_examples=43793, total_duration=1024.297282, train/accuracy=0.986920, train/loss=0.050500, train/mean_average_precision=0.062015, validation/accuracy=0.984219, validation/loss=0.060887, validation/mean_average_precision=0.066487, validation/num_examples=43793
I0215 12:20:15.114527 140391508162304 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.004256558138877153, loss=0.044983867555856705
I0215 12:22:04.969716 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:23:56.189982 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:23:59.144007 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:24:02.148016 140558855219008 submission_runner.py:408] Time since start: 1381.50s, 	Step: 2364, 	{'train/accuracy': 0.9871264100074768, 'train/loss': 0.047555021941661835, 'train/mean_average_precision': 0.10512532192452656, 'validation/accuracy': 0.9845048189163208, 'validation/loss': 0.05712180212140083, 'validation/mean_average_precision': 0.09566470113648733, 'validation/num_examples': 43793, 'test/accuracy': 0.9835144281387329, 'test/loss': 0.06053604558110237, 'test/mean_average_precision': 0.0948612460114271, 'test/num_examples': 43793, 'score': 739.4934566020966, 'total_duration': 1381.5043685436249, 'accumulated_submission_time': 739.4934566020966, 'accumulated_eval_time': 641.8630967140198, 'accumulated_logging_time': 0.0860452651977539}
I0215 12:24:02.163671 140391127664384 logging_writer.py:48] [2364] accumulated_eval_time=641.863097, accumulated_logging_time=0.086045, accumulated_submission_time=739.493457, global_step=2364, preemption_count=0, score=739.493457, test/accuracy=0.983514, test/loss=0.060536, test/mean_average_precision=0.094861, test/num_examples=43793, total_duration=1381.504369, train/accuracy=0.987126, train/loss=0.047555, train/mean_average_precision=0.105125, validation/accuracy=0.984505, validation/loss=0.057122, validation/mean_average_precision=0.095665, validation/num_examples=43793
I0215 12:24:43.183191 140391524947712 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.006322508677840233, loss=0.05294719338417053
I0215 12:27:13.763407 140391127664384 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.004830872640013695, loss=0.04597664251923561
I0215 12:28:02.355046 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:29:54.604708 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:29:57.525419 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:30:00.368162 140558855219008 submission_runner.py:408] Time since start: 1739.72s, 	Step: 3164, 	{'train/accuracy': 0.9878024458885193, 'train/loss': 0.0436401441693306, 'train/mean_average_precision': 0.13012382310835782, 'validation/accuracy': 0.9849801659584045, 'validation/loss': 0.052965857088565826, 'validation/mean_average_precision': 0.13423313683812868, 'validation/num_examples': 43793, 'test/accuracy': 0.9840034246444702, 'test/loss': 0.05607813596725464, 'test/mean_average_precision': 0.1347402842878854, 'test/num_examples': 43793, 'score': 979.6541843414307, 'total_duration': 1739.7244699001312, 'accumulated_submission_time': 979.6541843414307, 'accumulated_eval_time': 759.8761308193207, 'accumulated_logging_time': 0.11197471618652344}
I0215 12:30:00.384293 140391508162304 logging_writer.py:48] [3164] accumulated_eval_time=759.876131, accumulated_logging_time=0.111975, accumulated_submission_time=979.654184, global_step=3164, preemption_count=0, score=979.654184, test/accuracy=0.984003, test/loss=0.056078, test/mean_average_precision=0.134740, test/num_examples=43793, total_duration=1739.724470, train/accuracy=0.987802, train/loss=0.043640, train/mean_average_precision=0.130124, validation/accuracy=0.984980, validation/loss=0.052966, validation/mean_average_precision=0.134233, validation/num_examples=43793
I0215 12:31:42.484779 140391516555008 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.004574704449623823, loss=0.041936226189136505
I0215 12:34:00.635030 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:35:51.008043 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:35:53.991307 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:35:56.918043 140558855219008 submission_runner.py:408] Time since start: 2096.27s, 	Step: 3965, 	{'train/accuracy': 0.9881826043128967, 'train/loss': 0.04131815582513809, 'train/mean_average_precision': 0.17441314763671695, 'validation/accuracy': 0.9853154420852661, 'validation/loss': 0.050839733332395554, 'validation/mean_average_precision': 0.1618505253433002, 'validation/num_examples': 43793, 'test/accuracy': 0.9843454360961914, 'test/loss': 0.053814951330423355, 'test/mean_average_precision': 0.15346176383838325, 'test/num_examples': 43793, 'score': 1219.8746342658997, 'total_duration': 2096.2743821144104, 'accumulated_submission_time': 1219.8746342658997, 'accumulated_eval_time': 876.1591114997864, 'accumulated_logging_time': 0.13838791847229004}
I0215 12:35:56.936444 140391261918976 logging_writer.py:48] [3965] accumulated_eval_time=876.159111, accumulated_logging_time=0.138388, accumulated_submission_time=1219.874634, global_step=3965, preemption_count=0, score=1219.874634, test/accuracy=0.984345, test/loss=0.053815, test/mean_average_precision=0.153462, test/num_examples=43793, total_duration=2096.274382, train/accuracy=0.988183, train/loss=0.041318, train/mean_average_precision=0.174413, validation/accuracy=0.985315, validation/loss=0.050840, validation/mean_average_precision=0.161851, validation/num_examples=43793
I0215 12:36:07.749928 140391499769600 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.00409473804756999, loss=0.043259840458631516
I0215 12:38:36.883490 140391261918976 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.009373975917696953, loss=0.048521578311920166
I0215 12:39:57.083931 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:41:49.964624 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:41:52.904264 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:41:55.774682 140558855219008 submission_runner.py:408] Time since start: 2455.13s, 	Step: 4777, 	{'train/accuracy': 0.9883701205253601, 'train/loss': 0.040291424840688705, 'train/mean_average_precision': 0.20075425532661081, 'validation/accuracy': 0.9855314493179321, 'validation/loss': 0.04998880997300148, 'validation/mean_average_precision': 0.18313837887554377, 'validation/num_examples': 43793, 'test/accuracy': 0.9846609234809875, 'test/loss': 0.052836447954177856, 'test/mean_average_precision': 0.17774275510360227, 'test/num_examples': 43793, 'score': 1459.9918675422668, 'total_duration': 2455.131016731262, 'accumulated_submission_time': 1459.9918675422668, 'accumulated_eval_time': 994.8498177528381, 'accumulated_logging_time': 0.16654562950134277}
I0215 12:41:55.790855 140391541733120 logging_writer.py:48] [4777] accumulated_eval_time=994.849818, accumulated_logging_time=0.166546, accumulated_submission_time=1459.991868, global_step=4777, preemption_count=0, score=1459.991868, test/accuracy=0.984661, test/loss=0.052836, test/mean_average_precision=0.177743, test/num_examples=43793, total_duration=2455.131017, train/accuracy=0.988370, train/loss=0.040291, train/mean_average_precision=0.200754, validation/accuracy=0.985531, validation/loss=0.049989, validation/mean_average_precision=0.183138, validation/num_examples=43793
I0215 12:43:03.001154 140496231986944 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.006714330054819584, loss=0.04044725000858307
I0215 12:45:30.941221 140391541733120 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.009052851237356663, loss=0.0433676615357399
I0215 12:45:56.021214 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:47:48.872488 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:47:51.757990 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:47:54.711321 140558855219008 submission_runner.py:408] Time since start: 2814.07s, 	Step: 5587, 	{'train/accuracy': 0.9884465932846069, 'train/loss': 0.03969131410121918, 'train/mean_average_precision': 0.22177069814333206, 'validation/accuracy': 0.9856182932853699, 'validation/loss': 0.04934554547071457, 'validation/mean_average_precision': 0.1869321901309273, 'validation/num_examples': 43793, 'test/accuracy': 0.9846992492675781, 'test/loss': 0.05211930349469185, 'test/mean_average_precision': 0.195391130551246, 'test/num_examples': 43793, 'score': 1700.1923978328705, 'total_duration': 2814.067674636841, 'accumulated_submission_time': 1700.1923978328705, 'accumulated_eval_time': 1113.539880514145, 'accumulated_logging_time': 0.19261860847473145}
I0215 12:47:54.727098 140397990151936 logging_writer.py:48] [5587] accumulated_eval_time=1113.539881, accumulated_logging_time=0.192619, accumulated_submission_time=1700.192398, global_step=5587, preemption_count=0, score=1700.192398, test/accuracy=0.984699, test/loss=0.052119, test/mean_average_precision=0.195391, test/num_examples=43793, total_duration=2814.067675, train/accuracy=0.988447, train/loss=0.039691, train/mean_average_precision=0.221771, validation/accuracy=0.985618, validation/loss=0.049346, validation/mean_average_precision=0.186932, validation/num_examples=43793
I0215 12:49:57.022600 140397998544640 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.00718848267570138, loss=0.040084242820739746
I0215 12:51:54.789285 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:53:49.161946 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:53:52.092040 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:53:55.067044 140558855219008 submission_runner.py:408] Time since start: 3174.42s, 	Step: 6398, 	{'train/accuracy': 0.9889736771583557, 'train/loss': 0.038123201578855515, 'train/mean_average_precision': 0.2349179301416333, 'validation/accuracy': 0.9858220815658569, 'validation/loss': 0.04804627224802971, 'validation/mean_average_precision': 0.1984774781926117, 'validation/num_examples': 43793, 'test/accuracy': 0.9849115014076233, 'test/loss': 0.05060332268476486, 'test/mean_average_precision': 0.20190277384964853, 'test/num_examples': 43793, 'score': 1940.2245869636536, 'total_duration': 3174.423397541046, 'accumulated_submission_time': 1940.2245869636536, 'accumulated_eval_time': 1233.8176052570343, 'accumulated_logging_time': 0.21876311302185059}
I0215 12:53:55.085094 140496231986944 logging_writer.py:48] [6398] accumulated_eval_time=1233.817605, accumulated_logging_time=0.218763, accumulated_submission_time=1940.224587, global_step=6398, preemption_count=0, score=1940.224587, test/accuracy=0.984912, test/loss=0.050603, test/mean_average_precision=0.201903, test/num_examples=43793, total_duration=3174.423398, train/accuracy=0.988974, train/loss=0.038123, train/mean_average_precision=0.234918, validation/accuracy=0.985822, validation/loss=0.048046, validation/mean_average_precision=0.198477, validation/num_examples=43793
I0215 12:54:25.780134 140496919828224 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.004593515302985907, loss=0.03654955327510834
I0215 12:56:53.610549 140496231986944 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.005897970404475927, loss=0.04317672550678253
I0215 12:57:55.165330 140558855219008 spec.py:321] Evaluating on the training split.
I0215 12:59:47.053269 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 12:59:49.972633 140558855219008 spec.py:349] Evaluating on the test split.
I0215 12:59:52.851825 140558855219008 submission_runner.py:408] Time since start: 3532.21s, 	Step: 7210, 	{'train/accuracy': 0.9890118837356567, 'train/loss': 0.03766995668411255, 'train/mean_average_precision': 0.2398642775243317, 'validation/accuracy': 0.9859276413917542, 'validation/loss': 0.047928184270858765, 'validation/mean_average_precision': 0.2053059024384642, 'validation/num_examples': 43793, 'test/accuracy': 0.9849966168403625, 'test/loss': 0.05060633644461632, 'test/mean_average_precision': 0.21350139491207332, 'test/num_examples': 43793, 'score': 2180.274940252304, 'total_duration': 3532.2081785202026, 'accumulated_submission_time': 2180.274940252304, 'accumulated_eval_time': 1351.5040628910065, 'accumulated_logging_time': 0.24683284759521484}
I0215 12:59:52.867991 140397990151936 logging_writer.py:48] [7210] accumulated_eval_time=1351.504063, accumulated_logging_time=0.246833, accumulated_submission_time=2180.274940, global_step=7210, preemption_count=0, score=2180.274940, test/accuracy=0.984997, test/loss=0.050606, test/mean_average_precision=0.213501, test/num_examples=43793, total_duration=3532.208179, train/accuracy=0.989012, train/loss=0.037670, train/mean_average_precision=0.239864, validation/accuracy=0.985928, validation/loss=0.047928, validation/mean_average_precision=0.205306, validation/num_examples=43793
I0215 13:01:19.015372 140397998544640 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.006992757320404053, loss=0.03994975984096527
I0215 13:03:48.927757 140397990151936 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.005002871155738831, loss=0.03535597026348114
I0215 13:03:53.060553 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:05:43.605607 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:05:46.501247 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:05:49.318434 140558855219008 submission_runner.py:408] Time since start: 3888.67s, 	Step: 8015, 	{'train/accuracy': 0.9890701174736023, 'train/loss': 0.03723662346601486, 'train/mean_average_precision': 0.26311847693002366, 'validation/accuracy': 0.9860911965370178, 'validation/loss': 0.04735775664448738, 'validation/mean_average_precision': 0.2088996544773056, 'validation/num_examples': 43793, 'test/accuracy': 0.9851566553115845, 'test/loss': 0.05012679845094681, 'test/mean_average_precision': 0.2101401705609189, 'test/num_examples': 43793, 'score': 2420.438141107559, 'total_duration': 3888.6747868061066, 'accumulated_submission_time': 2420.438141107559, 'accumulated_eval_time': 1467.7618923187256, 'accumulated_logging_time': 0.2729909420013428}
I0215 13:05:49.337168 140496231986944 logging_writer.py:48] [8015] accumulated_eval_time=1467.761892, accumulated_logging_time=0.272991, accumulated_submission_time=2420.438141, global_step=8015, preemption_count=0, score=2420.438141, test/accuracy=0.985157, test/loss=0.050127, test/mean_average_precision=0.210140, test/num_examples=43793, total_duration=3888.674787, train/accuracy=0.989070, train/loss=0.037237, train/mean_average_precision=0.263118, validation/accuracy=0.986091, validation/loss=0.047358, validation/mean_average_precision=0.208900, validation/num_examples=43793
I0215 13:08:13.429399 140496919828224 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.006388569716364145, loss=0.034102585166692734
I0215 13:09:49.561257 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:11:42.043790 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:11:44.958418 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:11:47.814343 140558855219008 submission_runner.py:408] Time since start: 4247.17s, 	Step: 8828, 	{'train/accuracy': 0.9891208410263062, 'train/loss': 0.03691388666629791, 'train/mean_average_precision': 0.26128539831433084, 'validation/accuracy': 0.9860575199127197, 'validation/loss': 0.04710816964507103, 'validation/mean_average_precision': 0.2148633769300631, 'validation/num_examples': 43793, 'test/accuracy': 0.9852033853530884, 'test/loss': 0.04990917444229126, 'test/mean_average_precision': 0.21433318563487957, 'test/num_examples': 43793, 'score': 2660.6300616264343, 'total_duration': 4247.170699596405, 'accumulated_submission_time': 2660.6300616264343, 'accumulated_eval_time': 1586.0149447917938, 'accumulated_logging_time': 0.3037986755371094}
I0215 13:11:47.830703 140391541733120 logging_writer.py:48] [8828] accumulated_eval_time=1586.014945, accumulated_logging_time=0.303799, accumulated_submission_time=2660.630062, global_step=8828, preemption_count=0, score=2660.630062, test/accuracy=0.985203, test/loss=0.049909, test/mean_average_precision=0.214333, test/num_examples=43793, total_duration=4247.170700, train/accuracy=0.989121, train/loss=0.036914, train/mean_average_precision=0.261285, validation/accuracy=0.986058, validation/loss=0.047108, validation/mean_average_precision=0.214863, validation/num_examples=43793
I0215 13:12:38.762354 140397998544640 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.005103777162730694, loss=0.03607860952615738
I0215 13:15:05.365310 140391541733120 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.007654616143554449, loss=0.04331580549478531
I0215 13:15:47.837174 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:17:39.267891 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:17:42.169877 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:17:45.003202 140558855219008 submission_runner.py:408] Time since start: 4604.36s, 	Step: 9646, 	{'train/accuracy': 0.9893123507499695, 'train/loss': 0.03648633137345314, 'train/mean_average_precision': 0.2645382724796011, 'validation/accuracy': 0.9861553311347961, 'validation/loss': 0.04697838053107262, 'validation/mean_average_precision': 0.2157253602313035, 'validation/num_examples': 43793, 'test/accuracy': 0.9852674007415771, 'test/loss': 0.049749329686164856, 'test/mean_average_precision': 0.21633157402381953, 'test/num_examples': 43793, 'score': 2900.6061305999756, 'total_duration': 4604.35955286026, 'accumulated_submission_time': 2900.6061305999756, 'accumulated_eval_time': 1703.1809272766113, 'accumulated_logging_time': 0.3312511444091797}
I0215 13:17:45.019848 140496231986944 logging_writer.py:48] [9646] accumulated_eval_time=1703.180927, accumulated_logging_time=0.331251, accumulated_submission_time=2900.606131, global_step=9646, preemption_count=0, score=2900.606131, test/accuracy=0.985267, test/loss=0.049749, test/mean_average_precision=0.216332, test/num_examples=43793, total_duration=4604.359553, train/accuracy=0.989312, train/loss=0.036486, train/mean_average_precision=0.264538, validation/accuracy=0.986155, validation/loss=0.046978, validation/mean_average_precision=0.215725, validation/num_examples=43793
I0215 13:19:31.070822 140496919828224 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.007775789592415094, loss=0.03794184699654579
I0215 13:21:45.175139 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:23:37.765494 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:23:40.693625 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:23:43.508392 140558855219008 submission_runner.py:408] Time since start: 4962.86s, 	Step: 10455, 	{'train/accuracy': 0.9894191026687622, 'train/loss': 0.03609400615096092, 'train/mean_average_precision': 0.2865384206324179, 'validation/accuracy': 0.9862256050109863, 'validation/loss': 0.04684554040431976, 'validation/mean_average_precision': 0.22356917604668142, 'validation/num_examples': 43793, 'test/accuracy': 0.985323429107666, 'test/loss': 0.04953790456056595, 'test/mean_average_precision': 0.22041907754365606, 'test/num_examples': 43793, 'score': 3140.7301058769226, 'total_duration': 4962.864740371704, 'accumulated_submission_time': 3140.7301058769226, 'accumulated_eval_time': 1821.5141458511353, 'accumulated_logging_time': 0.3597078323364258}
I0215 13:23:43.524770 140391541733120 logging_writer.py:48] [10455] accumulated_eval_time=1821.514146, accumulated_logging_time=0.359708, accumulated_submission_time=3140.730106, global_step=10455, preemption_count=0, score=3140.730106, test/accuracy=0.985323, test/loss=0.049538, test/mean_average_precision=0.220419, test/num_examples=43793, total_duration=4962.864740, train/accuracy=0.989419, train/loss=0.036094, train/mean_average_precision=0.286538, validation/accuracy=0.986226, validation/loss=0.046846, validation/mean_average_precision=0.223569, validation/num_examples=43793
I0215 13:23:57.154489 140397998544640 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.005316836293786764, loss=0.036091309040784836
I0215 13:26:24.382059 140391541733120 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.00599062442779541, loss=0.042336128652095795
I0215 13:27:43.671806 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:29:35.431146 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:29:38.379907 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:29:41.284211 140558855219008 submission_runner.py:408] Time since start: 5320.64s, 	Step: 11266, 	{'train/accuracy': 0.9895251989364624, 'train/loss': 0.03552322834730148, 'train/mean_average_precision': 0.2967167923105972, 'validation/accuracy': 0.986258864402771, 'validation/loss': 0.04618356376886368, 'validation/mean_average_precision': 0.23176290094448254, 'validation/num_examples': 43793, 'test/accuracy': 0.9854127168655396, 'test/loss': 0.04886827990412712, 'test/mean_average_precision': 0.22687608646803212, 'test/num_examples': 43793, 'score': 3380.84489774704, 'total_duration': 5320.640565872192, 'accumulated_submission_time': 3380.84489774704, 'accumulated_eval_time': 1939.126511335373, 'accumulated_logging_time': 0.3882114887237549}
I0215 13:29:41.301300 140397990151936 logging_writer.py:48] [11266] accumulated_eval_time=1939.126511, accumulated_logging_time=0.388211, accumulated_submission_time=3380.844898, global_step=11266, preemption_count=0, score=3380.844898, test/accuracy=0.985413, test/loss=0.048868, test/mean_average_precision=0.226876, test/num_examples=43793, total_duration=5320.640566, train/accuracy=0.989525, train/loss=0.035523, train/mean_average_precision=0.296717, validation/accuracy=0.986259, validation/loss=0.046184, validation/mean_average_precision=0.231763, validation/num_examples=43793
I0215 13:30:50.407235 140496919828224 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.0071879285387694836, loss=0.03560778498649597
I0215 13:33:17.191677 140397990151936 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.006785671226680279, loss=0.04042316973209381
I0215 13:33:41.296236 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:35:35.061485 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:35:37.953428 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:35:40.795693 140558855219008 submission_runner.py:408] Time since start: 5680.15s, 	Step: 12082, 	{'train/accuracy': 0.9895297288894653, 'train/loss': 0.03553763031959534, 'train/mean_average_precision': 0.29095703409640916, 'validation/accuracy': 0.9862949848175049, 'validation/loss': 0.046071235090494156, 'validation/mean_average_precision': 0.22722639295907104, 'validation/num_examples': 43793, 'test/accuracy': 0.9854207038879395, 'test/loss': 0.04879102110862732, 'test/mean_average_precision': 0.22654920477927487, 'test/num_examples': 43793, 'score': 3620.80961561203, 'total_duration': 5680.152049779892, 'accumulated_submission_time': 3620.80961561203, 'accumulated_eval_time': 2058.625925064087, 'accumulated_logging_time': 0.41527295112609863}
I0215 13:35:40.812934 140391541733120 logging_writer.py:48] [12082] accumulated_eval_time=2058.625925, accumulated_logging_time=0.415273, accumulated_submission_time=3620.809616, global_step=12082, preemption_count=0, score=3620.809616, test/accuracy=0.985421, test/loss=0.048791, test/mean_average_precision=0.226549, test/num_examples=43793, total_duration=5680.152050, train/accuracy=0.989530, train/loss=0.035538, train/mean_average_precision=0.290957, validation/accuracy=0.986295, validation/loss=0.046071, validation/mean_average_precision=0.227226, validation/num_examples=43793
I0215 13:37:48.340589 140397998544640 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.004655970726162195, loss=0.03228112310171127
I0215 13:39:41.069548 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:41:30.912948 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:41:33.778717 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:41:36.653464 140558855219008 submission_runner.py:408] Time since start: 6036.01s, 	Step: 12882, 	{'train/accuracy': 0.9894252419471741, 'train/loss': 0.03547088801860809, 'train/mean_average_precision': 0.3050775358934861, 'validation/accuracy': 0.9861180186271667, 'validation/loss': 0.0464729368686676, 'validation/mean_average_precision': 0.22479508294736614, 'validation/num_examples': 43793, 'test/accuracy': 0.9853373169898987, 'test/loss': 0.048980019986629486, 'test/mean_average_precision': 0.2260544465997763, 'test/num_examples': 43793, 'score': 3861.03609418869, 'total_duration': 6036.009812831879, 'accumulated_submission_time': 3861.03609418869, 'accumulated_eval_time': 2174.2098026275635, 'accumulated_logging_time': 0.442767858505249}
I0215 13:41:36.670231 140397990151936 logging_writer.py:48] [12882] accumulated_eval_time=2174.209803, accumulated_logging_time=0.442768, accumulated_submission_time=3861.036094, global_step=12882, preemption_count=0, score=3861.036094, test/accuracy=0.985337, test/loss=0.048980, test/mean_average_precision=0.226054, test/num_examples=43793, total_duration=6036.009813, train/accuracy=0.989425, train/loss=0.035471, train/mean_average_precision=0.305078, validation/accuracy=0.986118, validation/loss=0.046473, validation/mean_average_precision=0.224795, validation/num_examples=43793
I0215 13:42:12.209208 140496231986944 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.0054818689823150635, loss=0.03330658748745918
I0215 13:44:41.693092 140397990151936 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.007019168697297573, loss=0.036174874752759933
I0215 13:45:36.661270 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:47:28.716498 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:47:31.658547 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:47:34.503623 140558855219008 submission_runner.py:408] Time since start: 6393.86s, 	Step: 13686, 	{'train/accuracy': 0.9895843863487244, 'train/loss': 0.035197339951992035, 'train/mean_average_precision': 0.3040051887718651, 'validation/accuracy': 0.986271858215332, 'validation/loss': 0.04618595167994499, 'validation/mean_average_precision': 0.23340475222767337, 'validation/num_examples': 43793, 'test/accuracy': 0.9854274988174438, 'test/loss': 0.04894350469112396, 'test/mean_average_precision': 0.22977608416949577, 'test/num_examples': 43793, 'score': 4100.995650053024, 'total_duration': 6393.8599808216095, 'accumulated_submission_time': 4100.995650053024, 'accumulated_eval_time': 2292.0521154403687, 'accumulated_logging_time': 0.47088122367858887}
I0215 13:47:34.520367 140391533340416 logging_writer.py:48] [13686] accumulated_eval_time=2292.052115, accumulated_logging_time=0.470881, accumulated_submission_time=4100.995650, global_step=13686, preemption_count=0, score=4100.995650, test/accuracy=0.985427, test/loss=0.048944, test/mean_average_precision=0.229776, test/num_examples=43793, total_duration=6393.859981, train/accuracy=0.989584, train/loss=0.035197, train/mean_average_precision=0.304005, validation/accuracy=0.986272, validation/loss=0.046186, validation/mean_average_precision=0.233405, validation/num_examples=43793
I0215 13:49:08.518282 140397998544640 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.006871374323964119, loss=0.036249373108148575
I0215 13:51:34.756859 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:53:28.636421 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:53:31.537163 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:53:34.431800 140558855219008 submission_runner.py:408] Time since start: 6753.79s, 	Step: 14490, 	{'train/accuracy': 0.9896256923675537, 'train/loss': 0.03509758412837982, 'train/mean_average_precision': 0.31245645781840997, 'validation/accuracy': 0.9863173365592957, 'validation/loss': 0.046009767800569534, 'validation/mean_average_precision': 0.23576781840168118, 'validation/num_examples': 43793, 'test/accuracy': 0.98543381690979, 'test/loss': 0.04876386746764183, 'test/mean_average_precision': 0.22828556474929557, 'test/num_examples': 43793, 'score': 4341.20063662529, 'total_duration': 6753.788158655167, 'accumulated_submission_time': 4341.20063662529, 'accumulated_eval_time': 2411.727029323578, 'accumulated_logging_time': 0.4989173412322998}
I0215 13:53:34.448738 140391541733120 logging_writer.py:48] [14490] accumulated_eval_time=2411.727029, accumulated_logging_time=0.498917, accumulated_submission_time=4341.200637, global_step=14490, preemption_count=0, score=4341.200637, test/accuracy=0.985434, test/loss=0.048764, test/mean_average_precision=0.228286, test/num_examples=43793, total_duration=6753.788159, train/accuracy=0.989626, train/loss=0.035098, train/mean_average_precision=0.312456, validation/accuracy=0.986317, validation/loss=0.046010, validation/mean_average_precision=0.235768, validation/num_examples=43793
I0215 13:53:37.706361 140496231986944 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.006223634816706181, loss=0.037952620536088943
I0215 13:56:06.151392 140391541733120 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.007502484600991011, loss=0.03943398594856262
I0215 13:57:34.706755 140558855219008 spec.py:321] Evaluating on the training split.
I0215 13:59:29.257660 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 13:59:32.242697 140558855219008 spec.py:349] Evaluating on the test split.
I0215 13:59:35.141141 140558855219008 submission_runner.py:408] Time since start: 7114.50s, 	Step: 15299, 	{'train/accuracy': 0.9898055791854858, 'train/loss': 0.034368254244327545, 'train/mean_average_precision': 0.3225131338005006, 'validation/accuracy': 0.9864476323127747, 'validation/loss': 0.04557877406477928, 'validation/mean_average_precision': 0.24291223686864546, 'validation/num_examples': 43793, 'test/accuracy': 0.9855812191963196, 'test/loss': 0.04829447716474533, 'test/mean_average_precision': 0.24182538198083214, 'test/num_examples': 43793, 'score': 4581.42748093605, 'total_duration': 7114.497435808182, 'accumulated_submission_time': 4581.42748093605, 'accumulated_eval_time': 2532.16131734848, 'accumulated_logging_time': 0.5264565944671631}
I0215 13:59:35.158179 140391533340416 logging_writer.py:48] [15299] accumulated_eval_time=2532.161317, accumulated_logging_time=0.526457, accumulated_submission_time=4581.427481, global_step=15299, preemption_count=0, score=4581.427481, test/accuracy=0.985581, test/loss=0.048294, test/mean_average_precision=0.241825, test/num_examples=43793, total_duration=7114.497436, train/accuracy=0.989806, train/loss=0.034368, train/mean_average_precision=0.322513, validation/accuracy=0.986448, validation/loss=0.045579, validation/mean_average_precision=0.242912, validation/num_examples=43793
I0215 14:00:35.910976 140397998544640 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.008450382389128208, loss=0.035685617476701736
I0215 14:03:03.741345 140391533340416 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.005412045866250992, loss=0.038364313542842865
I0215 14:03:35.365505 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:05:29.612183 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:05:32.517413 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:05:35.378913 140558855219008 submission_runner.py:408] Time since start: 7474.74s, 	Step: 16108, 	{'train/accuracy': 0.9897297024726868, 'train/loss': 0.0345727801322937, 'train/mean_average_precision': 0.31502869400206335, 'validation/accuracy': 0.986379861831665, 'validation/loss': 0.04576767981052399, 'validation/mean_average_precision': 0.24187853646152457, 'validation/num_examples': 43793, 'test/accuracy': 0.9854687452316284, 'test/loss': 0.04844063147902489, 'test/mean_average_precision': 0.23342012889699956, 'test/num_examples': 43793, 'score': 4821.604562520981, 'total_duration': 7474.735268831253, 'accumulated_submission_time': 4821.604562520981, 'accumulated_eval_time': 2652.174682855606, 'accumulated_logging_time': 0.5535891056060791}
I0215 14:05:35.396002 140397990151936 logging_writer.py:48] [16108] accumulated_eval_time=2652.174683, accumulated_logging_time=0.553589, accumulated_submission_time=4821.604563, global_step=16108, preemption_count=0, score=4821.604563, test/accuracy=0.985469, test/loss=0.048441, test/mean_average_precision=0.233420, test/num_examples=43793, total_duration=7474.735269, train/accuracy=0.989730, train/loss=0.034573, train/mean_average_precision=0.315029, validation/accuracy=0.986380, validation/loss=0.045768, validation/mean_average_precision=0.241879, validation/num_examples=43793
I0215 14:07:33.997076 140496231986944 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.009643047116696835, loss=0.037760768085718155
I0215 14:09:35.562183 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:11:30.325951 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:11:33.277579 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:11:36.151966 140558855219008 submission_runner.py:408] Time since start: 7835.51s, 	Step: 16908, 	{'train/accuracy': 0.9896472096443176, 'train/loss': 0.03469448909163475, 'train/mean_average_precision': 0.3334875193006531, 'validation/accuracy': 0.986416757106781, 'validation/loss': 0.04654909297823906, 'validation/mean_average_precision': 0.237449798334552, 'validation/num_examples': 43793, 'test/accuracy': 0.9854261875152588, 'test/loss': 0.04952452331781387, 'test/mean_average_precision': 0.23467114236565567, 'test/num_examples': 43793, 'score': 5061.741016864777, 'total_duration': 7835.508245706558, 'accumulated_submission_time': 5061.741016864777, 'accumulated_eval_time': 2772.764359474182, 'accumulated_logging_time': 0.5806984901428223}
I0215 14:11:36.169940 140391533340416 logging_writer.py:48] [16908] accumulated_eval_time=2772.764359, accumulated_logging_time=0.580698, accumulated_submission_time=5061.741017, global_step=16908, preemption_count=0, score=5061.741017, test/accuracy=0.985426, test/loss=0.049525, test/mean_average_precision=0.234671, test/num_examples=43793, total_duration=7835.508246, train/accuracy=0.989647, train/loss=0.034694, train/mean_average_precision=0.333488, validation/accuracy=0.986417, validation/loss=0.046549, validation/mean_average_precision=0.237450, validation/num_examples=43793
I0215 14:12:04.230260 140397998544640 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.004894473124295473, loss=0.03313300386071205
I0215 14:14:34.211132 140391533340416 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.00643425015732646, loss=0.034233834594488144
I0215 14:15:36.430060 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:17:32.317496 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:17:35.253670 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:17:38.138152 140558855219008 submission_runner.py:408] Time since start: 8197.49s, 	Step: 17707, 	{'train/accuracy': 0.9898167848587036, 'train/loss': 0.03413078561425209, 'train/mean_average_precision': 0.33301643636648404, 'validation/accuracy': 0.9864492416381836, 'validation/loss': 0.04549198970198631, 'validation/mean_average_precision': 0.2416681358724859, 'validation/num_examples': 43793, 'test/accuracy': 0.9856346845626831, 'test/loss': 0.04810168221592903, 'test/mean_average_precision': 0.23992580592895876, 'test/num_examples': 43793, 'score': 5301.969636917114, 'total_duration': 8197.494507551193, 'accumulated_submission_time': 5301.969636917114, 'accumulated_eval_time': 2894.4724345207214, 'accumulated_logging_time': 0.6092581748962402}
I0215 14:17:38.156203 140391541733120 logging_writer.py:48] [17707] accumulated_eval_time=2894.472435, accumulated_logging_time=0.609258, accumulated_submission_time=5301.969637, global_step=17707, preemption_count=0, score=5301.969637, test/accuracy=0.985635, test/loss=0.048102, test/mean_average_precision=0.239926, test/num_examples=43793, total_duration=8197.494508, train/accuracy=0.989817, train/loss=0.034131, train/mean_average_precision=0.333016, validation/accuracy=0.986449, validation/loss=0.045492, validation/mean_average_precision=0.241668, validation/num_examples=43793
I0215 14:19:06.058290 140496231986944 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.006335578393191099, loss=0.037201568484306335
I0215 14:21:34.629102 140391541733120 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.005346318241208792, loss=0.03557245805859566
I0215 14:21:38.179113 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:23:29.727745 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:23:32.736337 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:23:35.583780 140558855219008 submission_runner.py:408] Time since start: 8554.94s, 	Step: 18513, 	{'train/accuracy': 0.9900407195091248, 'train/loss': 0.03361191973090172, 'train/mean_average_precision': 0.3292521840163297, 'validation/accuracy': 0.9864256978034973, 'validation/loss': 0.04545723274350166, 'validation/mean_average_precision': 0.24146475887560825, 'validation/num_examples': 43793, 'test/accuracy': 0.9855483770370483, 'test/loss': 0.048102300614118576, 'test/mean_average_precision': 0.23633133314839228, 'test/num_examples': 43793, 'score': 5541.96201634407, 'total_duration': 8554.940137147903, 'accumulated_submission_time': 5541.96201634407, 'accumulated_eval_time': 3011.877057790756, 'accumulated_logging_time': 0.6373209953308105}
I0215 14:23:35.601121 140397990151936 logging_writer.py:48] [18513] accumulated_eval_time=3011.877058, accumulated_logging_time=0.637321, accumulated_submission_time=5541.962016, global_step=18513, preemption_count=0, score=5541.962016, test/accuracy=0.985548, test/loss=0.048102, test/mean_average_precision=0.236331, test/num_examples=43793, total_duration=8554.940137, train/accuracy=0.990041, train/loss=0.033612, train/mean_average_precision=0.329252, validation/accuracy=0.986426, validation/loss=0.045457, validation/mean_average_precision=0.241465, validation/num_examples=43793
I0215 14:26:02.748039 140397998544640 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.008897495456039906, loss=0.03882313519716263
I0215 14:27:35.837430 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:29:34.337355 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:29:37.263609 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:29:40.203982 140558855219008 submission_runner.py:408] Time since start: 8919.56s, 	Step: 19315, 	{'train/accuracy': 0.9900639057159424, 'train/loss': 0.03348094969987869, 'train/mean_average_precision': 0.3457457087036121, 'validation/accuracy': 0.9864204525947571, 'validation/loss': 0.0455227792263031, 'validation/mean_average_precision': 0.2419592692715293, 'validation/num_examples': 43793, 'test/accuracy': 0.9855188727378845, 'test/loss': 0.04802831634879112, 'test/mean_average_precision': 0.23403043628169984, 'test/num_examples': 43793, 'score': 5782.166433095932, 'total_duration': 8919.560321807861, 'accumulated_submission_time': 5782.166433095932, 'accumulated_eval_time': 3136.2435569763184, 'accumulated_logging_time': 0.666022539138794}
I0215 14:29:40.221795 140391533340416 logging_writer.py:48] [19315] accumulated_eval_time=3136.243557, accumulated_logging_time=0.666023, accumulated_submission_time=5782.166433, global_step=19315, preemption_count=0, score=5782.166433, test/accuracy=0.985519, test/loss=0.048028, test/mean_average_precision=0.234030, test/num_examples=43793, total_duration=8919.560322, train/accuracy=0.990064, train/loss=0.033481, train/mean_average_precision=0.345746, validation/accuracy=0.986420, validation/loss=0.045523, validation/mean_average_precision=0.241959, validation/num_examples=43793
I0215 14:30:36.378996 140496231986944 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.007528405636548996, loss=0.03206507861614227
I0215 14:33:06.594980 140391533340416 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.005991128273308277, loss=0.030698442831635475
I0215 14:33:40.304821 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:35:33.695995 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:35:36.605179 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:35:39.456430 140558855219008 submission_runner.py:408] Time since start: 9278.81s, 	Step: 20114, 	{'train/accuracy': 0.9902040362358093, 'train/loss': 0.03292137756943703, 'train/mean_average_precision': 0.34107476389629626, 'validation/accuracy': 0.9865178465843201, 'validation/loss': 0.04509178176522255, 'validation/mean_average_precision': 0.2474738529253242, 'validation/num_examples': 43793, 'test/accuracy': 0.9855892062187195, 'test/loss': 0.04794633761048317, 'test/mean_average_precision': 0.2361131925923404, 'test/num_examples': 43793, 'score': 6022.218946695328, 'total_duration': 9278.812786579132, 'accumulated_submission_time': 6022.218946695328, 'accumulated_eval_time': 3255.395132303238, 'accumulated_logging_time': 0.6938948631286621}
I0215 14:35:39.473886 140391541733120 logging_writer.py:48] [20114] accumulated_eval_time=3255.395132, accumulated_logging_time=0.693895, accumulated_submission_time=6022.218947, global_step=20114, preemption_count=0, score=6022.218947, test/accuracy=0.985589, test/loss=0.047946, test/mean_average_precision=0.236113, test/num_examples=43793, total_duration=9278.812787, train/accuracy=0.990204, train/loss=0.032921, train/mean_average_precision=0.341075, validation/accuracy=0.986518, validation/loss=0.045092, validation/mean_average_precision=0.247474, validation/num_examples=43793
I0215 14:37:34.778346 140397998544640 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.008610736578702927, loss=0.03763607144355774
I0215 14:39:39.616509 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:41:32.479389 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:41:35.397533 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:41:38.246930 140558855219008 submission_runner.py:408] Time since start: 9637.60s, 	Step: 20915, 	{'train/accuracy': 0.9901921153068542, 'train/loss': 0.032833244651556015, 'train/mean_average_precision': 0.36167022996321013, 'validation/accuracy': 0.9866693019866943, 'validation/loss': 0.045052655041217804, 'validation/mean_average_precision': 0.24691223584681768, 'validation/num_examples': 43793, 'test/accuracy': 0.9858360290527344, 'test/loss': 0.047784652560949326, 'test/mean_average_precision': 0.24229247663631828, 'test/num_examples': 43793, 'score': 6262.329718351364, 'total_duration': 9637.603274822235, 'accumulated_submission_time': 6262.329718351364, 'accumulated_eval_time': 3374.0255103111267, 'accumulated_logging_time': 0.7228715419769287}
I0215 14:41:38.266331 140397990151936 logging_writer.py:48] [20915] accumulated_eval_time=3374.025510, accumulated_logging_time=0.722872, accumulated_submission_time=6262.329718, global_step=20915, preemption_count=0, score=6262.329718, test/accuracy=0.985836, test/loss=0.047785, test/mean_average_precision=0.242292, test/num_examples=43793, total_duration=9637.603275, train/accuracy=0.990192, train/loss=0.032833, train/mean_average_precision=0.361670, validation/accuracy=0.986669, validation/loss=0.045053, validation/mean_average_precision=0.246912, validation/num_examples=43793
I0215 14:42:06.396279 140496231986944 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.006481697782874107, loss=0.034357670694589615
I0215 14:44:41.675391 140397990151936 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.007095562294125557, loss=0.03575626760721207
I0215 14:45:38.427397 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:47:34.201799 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:47:37.357704 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:47:40.451450 140558855219008 submission_runner.py:408] Time since start: 9999.81s, 	Step: 21685, 	{'train/accuracy': 0.9902804493904114, 'train/loss': 0.03238203004002571, 'train/mean_average_precision': 0.36169987265257586, 'validation/accuracy': 0.9865775108337402, 'validation/loss': 0.045015059411525726, 'validation/mean_average_precision': 0.24800739676275738, 'validation/num_examples': 43793, 'test/accuracy': 0.9857075810432434, 'test/loss': 0.0476527065038681, 'test/mean_average_precision': 0.24525885014241705, 'test/num_examples': 43793, 'score': 6502.458470821381, 'total_duration': 9999.807790756226, 'accumulated_submission_time': 6502.458470821381, 'accumulated_eval_time': 3496.0495159626007, 'accumulated_logging_time': 0.7540431022644043}
I0215 14:47:40.471834 140391533340416 logging_writer.py:48] [21685] accumulated_eval_time=3496.049516, accumulated_logging_time=0.754043, accumulated_submission_time=6502.458471, global_step=21685, preemption_count=0, score=6502.458471, test/accuracy=0.985708, test/loss=0.047653, test/mean_average_precision=0.245259, test/num_examples=43793, total_duration=9999.807791, train/accuracy=0.990280, train/loss=0.032382, train/mean_average_precision=0.361700, validation/accuracy=0.986578, validation/loss=0.045015, validation/mean_average_precision=0.248007, validation/num_examples=43793
I0215 14:49:15.026488 140391541733120 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.009090127423405647, loss=0.03785288706421852
I0215 14:51:40.614350 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:53:37.546245 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:53:40.592956 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:53:43.493517 140558855219008 submission_runner.py:408] Time since start: 10362.85s, 	Step: 22487, 	{'train/accuracy': 0.9903327822685242, 'train/loss': 0.03214234486222267, 'train/mean_average_precision': 0.3777090384321131, 'validation/accuracy': 0.9865458607673645, 'validation/loss': 0.045063186436891556, 'validation/mean_average_precision': 0.24876764334666746, 'validation/num_examples': 43793, 'test/accuracy': 0.9856696724891663, 'test/loss': 0.047757964581251144, 'test/mean_average_precision': 0.2459056515754398, 'test/num_examples': 43793, 'score': 6742.568008184433, 'total_duration': 10362.849860668182, 'accumulated_submission_time': 6742.568008184433, 'accumulated_eval_time': 3618.9286420345306, 'accumulated_logging_time': 0.7853474617004395}
I0215 14:53:43.514447 140397990151936 logging_writer.py:48] [22487] accumulated_eval_time=3618.928642, accumulated_logging_time=0.785347, accumulated_submission_time=6742.568008, global_step=22487, preemption_count=0, score=6742.568008, test/accuracy=0.985670, test/loss=0.047758, test/mean_average_precision=0.245906, test/num_examples=43793, total_duration=10362.849861, train/accuracy=0.990333, train/loss=0.032142, train/mean_average_precision=0.377709, validation/accuracy=0.986546, validation/loss=0.045063, validation/mean_average_precision=0.248768, validation/num_examples=43793
I0215 14:53:47.631780 140496231986944 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.006452251225709915, loss=0.03471231088042259
I0215 14:56:16.347303 140397990151936 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.0069920988753438, loss=0.03472091257572174
I0215 14:57:43.749912 140558855219008 spec.py:321] Evaluating on the training split.
I0215 14:59:37.629871 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 14:59:40.528129 140558855219008 spec.py:349] Evaluating on the test split.
I0215 14:59:43.351977 140558855219008 submission_runner.py:408] Time since start: 10722.71s, 	Step: 23289, 	{'train/accuracy': 0.9904166460037231, 'train/loss': 0.03200071305036545, 'train/mean_average_precision': 0.3798967214932285, 'validation/accuracy': 0.9865365028381348, 'validation/loss': 0.045101284980773926, 'validation/mean_average_precision': 0.25290702655006436, 'validation/num_examples': 43793, 'test/accuracy': 0.9856052398681641, 'test/loss': 0.04792635142803192, 'test/mean_average_precision': 0.24114919698556977, 'test/num_examples': 43793, 'score': 6982.772907733917, 'total_duration': 10722.708332777023, 'accumulated_submission_time': 6982.772907733917, 'accumulated_eval_time': 3738.530680656433, 'accumulated_logging_time': 0.8162612915039062}
I0215 14:59:43.369354 140391541733120 logging_writer.py:48] [23289] accumulated_eval_time=3738.530681, accumulated_logging_time=0.816261, accumulated_submission_time=6982.772908, global_step=23289, preemption_count=0, score=6982.772908, test/accuracy=0.985605, test/loss=0.047926, test/mean_average_precision=0.241149, test/num_examples=43793, total_duration=10722.708333, train/accuracy=0.990417, train/loss=0.032001, train/mean_average_precision=0.379897, validation/accuracy=0.986537, validation/loss=0.045101, validation/mean_average_precision=0.252907, validation/num_examples=43793
I0215 15:00:47.209085 140397998544640 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.007391523569822311, loss=0.03043372742831707
I0215 15:03:16.518207 140391541733120 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.006558422464877367, loss=0.03521105647087097
I0215 15:03:43.439254 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:05:32.978456 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:05:35.860986 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:05:38.711075 140558855219008 submission_runner.py:408] Time since start: 11078.07s, 	Step: 24092, 	{'train/accuracy': 0.9904586672782898, 'train/loss': 0.0317632220685482, 'train/mean_average_precision': 0.3812432287274077, 'validation/accuracy': 0.9866761565208435, 'validation/loss': 0.04506000503897667, 'validation/mean_average_precision': 0.2522855819840074, 'validation/num_examples': 43793, 'test/accuracy': 0.9857593774795532, 'test/loss': 0.04781632497906685, 'test/mean_average_precision': 0.2474309985986365, 'test/num_examples': 43793, 'score': 7222.812620639801, 'total_duration': 11078.06734585762, 'accumulated_submission_time': 7222.812620639801, 'accumulated_eval_time': 3853.80237531662, 'accumulated_logging_time': 0.8436019420623779}
I0215 15:05:38.728931 140391533340416 logging_writer.py:48] [24092] accumulated_eval_time=3853.802375, accumulated_logging_time=0.843602, accumulated_submission_time=7222.812621, global_step=24092, preemption_count=0, score=7222.812621, test/accuracy=0.985759, test/loss=0.047816, test/mean_average_precision=0.247431, test/num_examples=43793, total_duration=11078.067346, train/accuracy=0.990459, train/loss=0.031763, train/mean_average_precision=0.381243, validation/accuracy=0.986676, validation/loss=0.045060, validation/mean_average_precision=0.252286, validation/num_examples=43793
I0215 15:07:41.289205 140496231986944 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.006605064962059259, loss=0.03544839471578598
I0215 15:09:38.816322 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:11:33.724946 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:11:36.658636 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:11:39.527913 140558855219008 submission_runner.py:408] Time since start: 11438.88s, 	Step: 24889, 	{'train/accuracy': 0.990593671798706, 'train/loss': 0.03128660470247269, 'train/mean_average_precision': 0.4036834877808288, 'validation/accuracy': 0.9866505861282349, 'validation/loss': 0.04494381323456764, 'validation/mean_average_precision': 0.2563426920614002, 'validation/num_examples': 43793, 'test/accuracy': 0.9856540560722351, 'test/loss': 0.047728996723890305, 'test/mean_average_precision': 0.2504933925253517, 'test/num_examples': 43793, 'score': 7462.8647129535675, 'total_duration': 11438.8841817379, 'accumulated_submission_time': 7462.8647129535675, 'accumulated_eval_time': 3974.5138549804688, 'accumulated_logging_time': 0.872492790222168}
I0215 15:11:39.546873 140391541733120 logging_writer.py:48] [24889] accumulated_eval_time=3974.513855, accumulated_logging_time=0.872493, accumulated_submission_time=7462.864713, global_step=24889, preemption_count=0, score=7462.864713, test/accuracy=0.985654, test/loss=0.047729, test/mean_average_precision=0.250493, test/num_examples=43793, total_duration=11438.884182, train/accuracy=0.990594, train/loss=0.031287, train/mean_average_precision=0.403683, validation/accuracy=0.986651, validation/loss=0.044944, validation/mean_average_precision=0.256343, validation/num_examples=43793
I0215 15:12:13.605495 140397998544640 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.007067793048918247, loss=0.03635771945118904
I0215 15:14:42.487098 140391541733120 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.006802740506827831, loss=0.03229418769478798
I0215 15:15:39.636770 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:17:30.942332 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:17:33.854017 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:17:36.711970 140558855219008 submission_runner.py:408] Time since start: 11796.07s, 	Step: 25691, 	{'train/accuracy': 0.9905317425727844, 'train/loss': 0.031591158360242844, 'train/mean_average_precision': 0.40582348287446796, 'validation/accuracy': 0.9864395260810852, 'validation/loss': 0.044990669935941696, 'validation/mean_average_precision': 0.25316924651499445, 'validation/num_examples': 43793, 'test/accuracy': 0.9856073260307312, 'test/loss': 0.04763708636164665, 'test/mean_average_precision': 0.24866514421990052, 'test/num_examples': 43793, 'score': 7702.922703742981, 'total_duration': 11796.068321228027, 'accumulated_submission_time': 7702.922703742981, 'accumulated_eval_time': 4091.589015483856, 'accumulated_logging_time': 0.9030063152313232}
I0215 15:17:36.731029 140397990151936 logging_writer.py:48] [25691] accumulated_eval_time=4091.589015, accumulated_logging_time=0.903006, accumulated_submission_time=7702.922704, global_step=25691, preemption_count=0, score=7702.922704, test/accuracy=0.985607, test/loss=0.047637, test/mean_average_precision=0.248665, test/num_examples=43793, total_duration=11796.068321, train/accuracy=0.990532, train/loss=0.031591, train/mean_average_precision=0.405823, validation/accuracy=0.986440, validation/loss=0.044991, validation/mean_average_precision=0.253169, validation/num_examples=43793
I0215 15:19:08.726778 140496231986944 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.006873948499560356, loss=0.03428314998745918
I0215 15:21:36.929790 140397990151936 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.006788343656808138, loss=0.032674986869096756
I0215 15:21:36.934705 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:23:30.446597 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:23:33.386475 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:23:36.244720 140558855219008 submission_runner.py:408] Time since start: 12155.60s, 	Step: 26501, 	{'train/accuracy': 0.9906776547431946, 'train/loss': 0.031160177662968636, 'train/mean_average_precision': 0.38478117823430885, 'validation/accuracy': 0.986697256565094, 'validation/loss': 0.04443108290433884, 'validation/mean_average_precision': 0.26084758401881364, 'validation/num_examples': 43793, 'test/accuracy': 0.9858174920082092, 'test/loss': 0.047003548592329025, 'test/mean_average_precision': 0.2522577493853196, 'test/num_examples': 43793, 'score': 7943.094611883163, 'total_duration': 12155.601073265076, 'accumulated_submission_time': 7943.094611883163, 'accumulated_eval_time': 4210.898966789246, 'accumulated_logging_time': 0.9333603382110596}
I0215 15:23:36.263023 140391533340416 logging_writer.py:48] [26501] accumulated_eval_time=4210.898967, accumulated_logging_time=0.933360, accumulated_submission_time=7943.094612, global_step=26501, preemption_count=0, score=7943.094612, test/accuracy=0.985817, test/loss=0.047004, test/mean_average_precision=0.252258, test/num_examples=43793, total_duration=12155.601073, train/accuracy=0.990678, train/loss=0.031160, train/mean_average_precision=0.384781, validation/accuracy=0.986697, validation/loss=0.044431, validation/mean_average_precision=0.260848, validation/num_examples=43793
I0215 15:26:05.627369 140391541733120 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.007857410237193108, loss=0.03498246148228645
I0215 15:27:36.468839 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:29:31.638422 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:29:34.555906 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:29:37.418434 140558855219008 submission_runner.py:408] Time since start: 12516.77s, 	Step: 27304, 	{'train/accuracy': 0.9906051158905029, 'train/loss': 0.031287405639886856, 'train/mean_average_precision': 0.39008280964440123, 'validation/accuracy': 0.9867220520973206, 'validation/loss': 0.0448036715388298, 'validation/mean_average_precision': 0.26013396483334067, 'validation/num_examples': 43793, 'test/accuracy': 0.9857977032661438, 'test/loss': 0.047631457448005676, 'test/mean_average_precision': 0.2584049320942328, 'test/num_examples': 43793, 'score': 8183.269677639008, 'total_duration': 12516.774696350098, 'accumulated_submission_time': 8183.269677639008, 'accumulated_eval_time': 4331.848429679871, 'accumulated_logging_time': 0.9616117477416992}
I0215 15:29:37.436502 140397990151936 logging_writer.py:48] [27304] accumulated_eval_time=4331.848430, accumulated_logging_time=0.961612, accumulated_submission_time=8183.269678, global_step=27304, preemption_count=0, score=8183.269678, test/accuracy=0.985798, test/loss=0.047631, test/mean_average_precision=0.258405, test/num_examples=43793, total_duration=12516.774696, train/accuracy=0.990605, train/loss=0.031287, train/mean_average_precision=0.390083, validation/accuracy=0.986722, validation/loss=0.044804, validation/mean_average_precision=0.260134, validation/num_examples=43793
I0215 15:30:36.712933 140397998544640 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.006995135452598333, loss=0.03189127519726753
I0215 15:33:06.294612 140397990151936 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.008091624826192856, loss=0.030826928094029427
I0215 15:33:37.469727 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:35:28.692318 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:35:31.586401 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:35:34.429309 140558855219008 submission_runner.py:408] Time since start: 12873.79s, 	Step: 28105, 	{'train/accuracy': 0.9906920790672302, 'train/loss': 0.03111342154443264, 'train/mean_average_precision': 0.39355989987326967, 'validation/accuracy': 0.9865706562995911, 'validation/loss': 0.04452333226799965, 'validation/mean_average_precision': 0.25944352835395085, 'validation/num_examples': 43793, 'test/accuracy': 0.9857614636421204, 'test/loss': 0.0472450815141201, 'test/mean_average_precision': 0.25979714903313816, 'test/num_examples': 43793, 'score': 8423.270768642426, 'total_duration': 12873.785564899445, 'accumulated_submission_time': 8423.270768642426, 'accumulated_eval_time': 4448.807866334915, 'accumulated_logging_time': 0.9911422729492188}
I0215 15:35:34.448316 140391533340416 logging_writer.py:48] [28105] accumulated_eval_time=4448.807866, accumulated_logging_time=0.991142, accumulated_submission_time=8423.270769, global_step=28105, preemption_count=0, score=8423.270769, test/accuracy=0.985761, test/loss=0.047245, test/mean_average_precision=0.259797, test/num_examples=43793, total_duration=12873.785565, train/accuracy=0.990692, train/loss=0.031113, train/mean_average_precision=0.393560, validation/accuracy=0.986571, validation/loss=0.044523, validation/mean_average_precision=0.259444, validation/num_examples=43793
I0215 15:37:33.487907 140391541733120 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.008717450313270092, loss=0.03350986912846565
I0215 15:39:34.515645 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:41:26.061841 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:41:28.922307 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:41:31.772099 140558855219008 submission_runner.py:408] Time since start: 13231.13s, 	Step: 28905, 	{'train/accuracy': 0.9906162023544312, 'train/loss': 0.031410664319992065, 'train/mean_average_precision': 0.3932863708234818, 'validation/accuracy': 0.9866136312484741, 'validation/loss': 0.04453418403863907, 'validation/mean_average_precision': 0.260449099808771, 'validation/num_examples': 43793, 'test/accuracy': 0.9856266975402832, 'test/loss': 0.04729403927922249, 'test/mean_average_precision': 0.25054739536132165, 'test/num_examples': 43793, 'score': 8663.30679178238, 'total_duration': 13231.128353595734, 'accumulated_submission_time': 8663.30679178238, 'accumulated_eval_time': 4566.064197063446, 'accumulated_logging_time': 1.0210652351379395}
I0215 15:41:31.790246 140397990151936 logging_writer.py:48] [28905] accumulated_eval_time=4566.064197, accumulated_logging_time=1.021065, accumulated_submission_time=8663.306792, global_step=28905, preemption_count=0, score=8663.306792, test/accuracy=0.985627, test/loss=0.047294, test/mean_average_precision=0.250547, test/num_examples=43793, total_duration=13231.128354, train/accuracy=0.990616, train/loss=0.031411, train/mean_average_precision=0.393286, validation/accuracy=0.986614, validation/loss=0.044534, validation/mean_average_precision=0.260449, validation/num_examples=43793
I0215 15:42:00.130220 140496231986944 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.0069495392963290215, loss=0.03628404811024666
I0215 15:44:29.033714 140397990151936 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.0061639416962862015, loss=0.03444403409957886
I0215 15:45:32.014879 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:47:25.720288 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:47:28.673650 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:47:31.602203 140558855219008 submission_runner.py:408] Time since start: 13590.96s, 	Step: 29712, 	{'train/accuracy': 0.9907676577568054, 'train/loss': 0.030899884179234505, 'train/mean_average_precision': 0.3986741024077358, 'validation/accuracy': 0.9867419600486755, 'validation/loss': 0.0443255789577961, 'validation/mean_average_precision': 0.2597302343281836, 'validation/num_examples': 43793, 'test/accuracy': 0.9858217239379883, 'test/loss': 0.047150321304798126, 'test/mean_average_precision': 0.2518995441702635, 'test/num_examples': 43793, 'score': 8903.500543117523, 'total_duration': 13590.958433151245, 'accumulated_submission_time': 8903.500543117523, 'accumulated_eval_time': 4685.651364326477, 'accumulated_logging_time': 1.0495333671569824}
I0215 15:47:31.620522 140391533340416 logging_writer.py:48] [29712] accumulated_eval_time=4685.651364, accumulated_logging_time=1.049533, accumulated_submission_time=8903.500543, global_step=29712, preemption_count=0, score=8903.500543, test/accuracy=0.985822, test/loss=0.047150, test/mean_average_precision=0.251900, test/num_examples=43793, total_duration=13590.958433, train/accuracy=0.990768, train/loss=0.030900, train/mean_average_precision=0.398674, validation/accuracy=0.986742, validation/loss=0.044326, validation/mean_average_precision=0.259730, validation/num_examples=43793
I0215 15:48:58.261780 140391541733120 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.006087598390877247, loss=0.03348585590720177
I0215 15:51:27.106347 140391533340416 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.007081419695168734, loss=0.03185373172163963
I0215 15:51:31.835519 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:53:26.282989 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:53:29.213213 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:53:32.103001 140558855219008 submission_runner.py:408] Time since start: 13951.46s, 	Step: 30517, 	{'train/accuracy': 0.9905664324760437, 'train/loss': 0.031198348850011826, 'train/mean_average_precision': 0.38783654051340644, 'validation/accuracy': 0.9867748022079468, 'validation/loss': 0.0439961738884449, 'validation/mean_average_precision': 0.2665757788639038, 'validation/num_examples': 43793, 'test/accuracy': 0.9860087037086487, 'test/loss': 0.046797990798950195, 'test/mean_average_precision': 0.25804127223452267, 'test/num_examples': 43793, 'score': 9143.683574199677, 'total_duration': 13951.459356546402, 'accumulated_submission_time': 9143.683574199677, 'accumulated_eval_time': 4805.918799638748, 'accumulated_logging_time': 1.0794861316680908}
I0215 15:53:32.122238 140397998544640 logging_writer.py:48] [30517] accumulated_eval_time=4805.918800, accumulated_logging_time=1.079486, accumulated_submission_time=9143.683574, global_step=30517, preemption_count=0, score=9143.683574, test/accuracy=0.986009, test/loss=0.046798, test/mean_average_precision=0.258041, test/num_examples=43793, total_duration=13951.459357, train/accuracy=0.990566, train/loss=0.031198, train/mean_average_precision=0.387837, validation/accuracy=0.986775, validation/loss=0.043996, validation/mean_average_precision=0.266576, validation/num_examples=43793
I0215 15:56:06.016542 140496231986944 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.007057553622871637, loss=0.033747974783182144
I0215 15:57:32.361639 140558855219008 spec.py:321] Evaluating on the training split.
I0215 15:59:25.025377 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 15:59:27.926464 140558855219008 spec.py:349] Evaluating on the test split.
I0215 15:59:30.771424 140558855219008 submission_runner.py:408] Time since start: 14310.13s, 	Step: 31282, 	{'train/accuracy': 0.9906517267227173, 'train/loss': 0.031064718961715698, 'train/mean_average_precision': 0.40025726768079206, 'validation/accuracy': 0.9868442416191101, 'validation/loss': 0.04441835358738899, 'validation/mean_average_precision': 0.26885799994850995, 'validation/num_examples': 43793, 'test/accuracy': 0.9859362840652466, 'test/loss': 0.04755548760294914, 'test/mean_average_precision': 0.25152940890160963, 'test/num_examples': 43793, 'score': 9383.892793655396, 'total_duration': 14310.127695083618, 'accumulated_submission_time': 9383.892793655396, 'accumulated_eval_time': 4924.328466176987, 'accumulated_logging_time': 1.1089887619018555}
I0215 15:59:30.789635 140391541733120 logging_writer.py:48] [31282] accumulated_eval_time=4924.328466, accumulated_logging_time=1.108989, accumulated_submission_time=9383.892794, global_step=31282, preemption_count=0, score=9383.892794, test/accuracy=0.985936, test/loss=0.047555, test/mean_average_precision=0.251529, test/num_examples=43793, total_duration=14310.127695, train/accuracy=0.990652, train/loss=0.031065, train/mean_average_precision=0.400257, validation/accuracy=0.986844, validation/loss=0.044418, validation/mean_average_precision=0.268858, validation/num_examples=43793
I0215 16:00:36.292604 140397990151936 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.005953325890004635, loss=0.03164646402001381
I0215 16:03:05.157533 140391541733120 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.009993646293878555, loss=0.03383925184607506
I0215 16:03:31.062836 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:05:22.406532 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:05:25.327091 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:05:28.290773 140558855219008 submission_runner.py:408] Time since start: 14667.65s, 	Step: 32088, 	{'train/accuracy': 0.9907066226005554, 'train/loss': 0.030870866030454636, 'train/mean_average_precision': 0.40536934801238705, 'validation/accuracy': 0.9868454337120056, 'validation/loss': 0.04414380341768265, 'validation/mean_average_precision': 0.266349913505409, 'validation/num_examples': 43793, 'test/accuracy': 0.9860078692436218, 'test/loss': 0.046979185193777084, 'test/mean_average_precision': 0.2602632506597743, 'test/num_examples': 43793, 'score': 9624.135488510132, 'total_duration': 14667.647130012512, 'accumulated_submission_time': 9624.135488510132, 'accumulated_eval_time': 5041.556356430054, 'accumulated_logging_time': 1.1372549533843994}
I0215 16:05:28.309346 140391533340416 logging_writer.py:48] [32088] accumulated_eval_time=5041.556356, accumulated_logging_time=1.137255, accumulated_submission_time=9624.135489, global_step=32088, preemption_count=0, score=9624.135489, test/accuracy=0.986008, test/loss=0.046979, test/mean_average_precision=0.260263, test/num_examples=43793, total_duration=14667.647130, train/accuracy=0.990707, train/loss=0.030871, train/mean_average_precision=0.405369, validation/accuracy=0.986845, validation/loss=0.044144, validation/mean_average_precision=0.266350, validation/num_examples=43793
I0215 16:07:31.578828 140496231986944 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.006452380679547787, loss=0.03364761546254158
I0215 16:09:28.344054 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:11:18.476447 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:11:21.383283 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:11:24.261713 140558855219008 submission_runner.py:408] Time since start: 15023.62s, 	Step: 32890, 	{'train/accuracy': 0.9908499717712402, 'train/loss': 0.030452154576778412, 'train/mean_average_precision': 0.41087146431963484, 'validation/accuracy': 0.9866591095924377, 'validation/loss': 0.04421091452240944, 'validation/mean_average_precision': 0.26975505060107274, 'validation/num_examples': 43793, 'test/accuracy': 0.9858633875846863, 'test/loss': 0.046740736812353134, 'test/mean_average_precision': 0.2641553066836875, 'test/num_examples': 43793, 'score': 9864.138288497925, 'total_duration': 15023.617991685867, 'accumulated_submission_time': 9864.138288497925, 'accumulated_eval_time': 5157.473906040192, 'accumulated_logging_time': 1.1674108505249023}
I0215 16:11:24.280476 140391541733120 logging_writer.py:48] [32890] accumulated_eval_time=5157.473906, accumulated_logging_time=1.167411, accumulated_submission_time=9864.138288, global_step=32890, preemption_count=0, score=9864.138288, test/accuracy=0.985863, test/loss=0.046741, test/mean_average_precision=0.264155, test/num_examples=43793, total_duration=15023.617992, train/accuracy=0.990850, train/loss=0.030452, train/mean_average_precision=0.410871, validation/accuracy=0.986659, validation/loss=0.044211, validation/mean_average_precision=0.269755, validation/num_examples=43793
I0215 16:11:58.209856 140397998544640 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.00689657311886549, loss=0.03194887563586235
I0215 16:14:27.719877 140391541733120 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.006952706258744001, loss=0.03533194959163666
I0215 16:15:24.539193 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:17:16.883971 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:17:19.799721 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:17:22.693267 140558855219008 submission_runner.py:408] Time since start: 15382.05s, 	Step: 33692, 	{'train/accuracy': 0.990959644317627, 'train/loss': 0.03008321300148964, 'train/mean_average_precision': 0.42591783386311277, 'validation/accuracy': 0.986894965171814, 'validation/loss': 0.04384702444076538, 'validation/mean_average_precision': 0.268862412040396, 'validation/num_examples': 43793, 'test/accuracy': 0.9860697984695435, 'test/loss': 0.04663802683353424, 'test/mean_average_precision': 0.26242280128963674, 'test/num_examples': 43793, 'score': 10104.366126537323, 'total_duration': 15382.049540758133, 'accumulated_submission_time': 10104.366126537323, 'accumulated_eval_time': 5275.627857923508, 'accumulated_logging_time': 1.1961736679077148}
I0215 16:17:22.712081 140391533340416 logging_writer.py:48] [33692] accumulated_eval_time=5275.627858, accumulated_logging_time=1.196174, accumulated_submission_time=10104.366127, global_step=33692, preemption_count=0, score=10104.366127, test/accuracy=0.986070, test/loss=0.046638, test/mean_average_precision=0.262423, test/num_examples=43793, total_duration=15382.049541, train/accuracy=0.990960, train/loss=0.030083, train/mean_average_precision=0.425918, validation/accuracy=0.986895, validation/loss=0.043847, validation/mean_average_precision=0.268862, validation/num_examples=43793
I0215 16:18:56.245685 140496231986944 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.009159817360341549, loss=0.030874453485012054
I0215 16:21:22.900355 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:23:15.170908 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:23:18.153860 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:23:21.050023 140558855219008 submission_runner.py:408] Time since start: 15740.41s, 	Step: 34491, 	{'train/accuracy': 0.9909486770629883, 'train/loss': 0.030090447515249252, 'train/mean_average_precision': 0.422063504416863, 'validation/accuracy': 0.9868669509887695, 'validation/loss': 0.044136032462120056, 'validation/mean_average_precision': 0.2717689440758293, 'validation/num_examples': 43793, 'test/accuracy': 0.9860184192657471, 'test/loss': 0.046802032738924026, 'test/mean_average_precision': 0.26549055706253527, 'test/num_examples': 43793, 'score': 10344.243387460709, 'total_duration': 15740.40635585785, 'accumulated_submission_time': 10344.243387460709, 'accumulated_eval_time': 5393.7774794101715, 'accumulated_logging_time': 1.5052134990692139}
I0215 16:23:21.069573 140391541733120 logging_writer.py:48] [34491] accumulated_eval_time=5393.777479, accumulated_logging_time=1.505213, accumulated_submission_time=10344.243387, global_step=34491, preemption_count=0, score=10344.243387, test/accuracy=0.986018, test/loss=0.046802, test/mean_average_precision=0.265491, test/num_examples=43793, total_duration=15740.406356, train/accuracy=0.990949, train/loss=0.030090, train/mean_average_precision=0.422064, validation/accuracy=0.986867, validation/loss=0.044136, validation/mean_average_precision=0.271769, validation/num_examples=43793
I0215 16:23:23.994345 140397990151936 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.00842463131994009, loss=0.02900814451277256
I0215 16:25:52.250250 140391541733120 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.006772961467504501, loss=0.031226009130477905
I0215 16:27:21.154803 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:29:10.650486 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:29:13.641371 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:29:16.512131 140558855219008 submission_runner.py:408] Time since start: 16095.87s, 	Step: 35301, 	{'train/accuracy': 0.9909507036209106, 'train/loss': 0.030007656663656235, 'train/mean_average_precision': 0.41621058367797076, 'validation/accuracy': 0.9868714213371277, 'validation/loss': 0.044038087129592896, 'validation/mean_average_precision': 0.26950994311060966, 'validation/num_examples': 43793, 'test/accuracy': 0.985953152179718, 'test/loss': 0.04704086109995842, 'test/mean_average_precision': 0.26186054097946704, 'test/num_examples': 43793, 'score': 10584.297667741776, 'total_duration': 16095.868485212326, 'accumulated_submission_time': 10584.297667741776, 'accumulated_eval_time': 5509.134773015976, 'accumulated_logging_time': 1.535217046737671}
I0215 16:29:16.531037 140391533340416 logging_writer.py:48] [35301] accumulated_eval_time=5509.134773, accumulated_logging_time=1.535217, accumulated_submission_time=10584.297668, global_step=35301, preemption_count=0, score=10584.297668, test/accuracy=0.985953, test/loss=0.047041, test/mean_average_precision=0.261861, test/num_examples=43793, total_duration=16095.868485, train/accuracy=0.990951, train/loss=0.030008, train/mean_average_precision=0.416211, validation/accuracy=0.986871, validation/loss=0.044038, validation/mean_average_precision=0.269510, validation/num_examples=43793
I0215 16:30:16.241237 140397998544640 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.00690703047439456, loss=0.03167710080742836
I0215 16:32:46.266982 140391533340416 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.007279864978045225, loss=0.03229595348238945
I0215 16:33:16.710265 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:35:09.070764 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:35:11.981334 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:35:14.865691 140558855219008 submission_runner.py:408] Time since start: 16454.22s, 	Step: 36102, 	{'train/accuracy': 0.9910622835159302, 'train/loss': 0.02962324768304825, 'train/mean_average_precision': 0.4420537200569223, 'validation/accuracy': 0.9867861866950989, 'validation/loss': 0.043832093477249146, 'validation/mean_average_precision': 0.2760404445839678, 'validation/num_examples': 43793, 'test/accuracy': 0.9859316349029541, 'test/loss': 0.046541858464479446, 'test/mean_average_precision': 0.2638355831556632, 'test/num_examples': 43793, 'score': 10824.44524049759, 'total_duration': 16454.22203207016, 'accumulated_submission_time': 10824.44524049759, 'accumulated_eval_time': 5627.290143966675, 'accumulated_logging_time': 1.5657312870025635}
I0215 16:35:14.885566 140397990151936 logging_writer.py:48] [36102] accumulated_eval_time=5627.290144, accumulated_logging_time=1.565731, accumulated_submission_time=10824.445240, global_step=36102, preemption_count=0, score=10824.445240, test/accuracy=0.985932, test/loss=0.046542, test/mean_average_precision=0.263836, test/num_examples=43793, total_duration=16454.222032, train/accuracy=0.991062, train/loss=0.029623, train/mean_average_precision=0.442054, validation/accuracy=0.986786, validation/loss=0.043832, validation/mean_average_precision=0.276040, validation/num_examples=43793
I0215 16:37:14.015713 140496231986944 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.007137296721339226, loss=0.033018529415130615
I0215 16:39:15.021499 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:41:04.235343 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:41:07.269432 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:41:10.174946 140558855219008 submission_runner.py:408] Time since start: 16809.53s, 	Step: 36905, 	{'train/accuracy': 0.9912161231040955, 'train/loss': 0.029131349176168442, 'train/mean_average_precision': 0.4341946078622406, 'validation/accuracy': 0.9868279695510864, 'validation/loss': 0.04388804733753204, 'validation/mean_average_precision': 0.27278300213550005, 'validation/num_examples': 43793, 'test/accuracy': 0.9860461950302124, 'test/loss': 0.046655405312776566, 'test/mean_average_precision': 0.2615703244886798, 'test/num_examples': 43793, 'score': 11064.55094218254, 'total_duration': 16809.531289100647, 'accumulated_submission_time': 11064.55094218254, 'accumulated_eval_time': 5742.443549633026, 'accumulated_logging_time': 1.5958011150360107}
I0215 16:41:10.200400 140391533340416 logging_writer.py:48] [36905] accumulated_eval_time=5742.443550, accumulated_logging_time=1.595801, accumulated_submission_time=11064.550942, global_step=36905, preemption_count=0, score=11064.550942, test/accuracy=0.986046, test/loss=0.046655, test/mean_average_precision=0.261570, test/num_examples=43793, total_duration=16809.531289, train/accuracy=0.991216, train/loss=0.029131, train/mean_average_precision=0.434195, validation/accuracy=0.986828, validation/loss=0.043888, validation/mean_average_precision=0.272783, validation/num_examples=43793
I0215 16:41:38.632924 140391541733120 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.006610378157347441, loss=0.027945924550294876
I0215 16:44:08.629607 140391533340416 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.00846310704946518, loss=0.03167325630784035
I0215 16:45:10.401218 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:47:02.624968 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:47:05.555829 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:47:08.448163 140558855219008 submission_runner.py:408] Time since start: 17167.80s, 	Step: 37708, 	{'train/accuracy': 0.9911729097366333, 'train/loss': 0.029126038774847984, 'train/mean_average_precision': 0.43465958796957527, 'validation/accuracy': 0.9869737029075623, 'validation/loss': 0.043982043862342834, 'validation/mean_average_precision': 0.27213364521255906, 'validation/num_examples': 43793, 'test/accuracy': 0.9862058162689209, 'test/loss': 0.046692799776792526, 'test/mean_average_precision': 0.2642213755927276, 'test/num_examples': 43793, 'score': 11304.71995639801, 'total_duration': 17167.80451154709, 'accumulated_submission_time': 11304.71995639801, 'accumulated_eval_time': 5860.490448236465, 'accumulated_logging_time': 1.6325039863586426}
I0215 16:47:08.467656 140397990151936 logging_writer.py:48] [37708] accumulated_eval_time=5860.490448, accumulated_logging_time=1.632504, accumulated_submission_time=11304.719956, global_step=37708, preemption_count=0, score=11304.719956, test/accuracy=0.986206, test/loss=0.046693, test/mean_average_precision=0.264221, test/num_examples=43793, total_duration=17167.804512, train/accuracy=0.991173, train/loss=0.029126, train/mean_average_precision=0.434660, validation/accuracy=0.986974, validation/loss=0.043982, validation/mean_average_precision=0.272134, validation/num_examples=43793
I0215 16:48:36.104422 140397998544640 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.007310626562684774, loss=0.0301005057990551
I0215 16:51:04.415970 140397990151936 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.008067004382610321, loss=0.034745730459690094
I0215 16:51:08.655061 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:52:59.388068 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:53:02.336311 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:53:05.223083 140558855219008 submission_runner.py:408] Time since start: 17524.58s, 	Step: 38515, 	{'train/accuracy': 0.9913110733032227, 'train/loss': 0.028675206005573273, 'train/mean_average_precision': 0.4532701397411206, 'validation/accuracy': 0.9870066046714783, 'validation/loss': 0.043889645487070084, 'validation/mean_average_precision': 0.27540190341426884, 'validation/num_examples': 43793, 'test/accuracy': 0.9861574172973633, 'test/loss': 0.04660233482718468, 'test/mean_average_precision': 0.2677591567196427, 'test/num_examples': 43793, 'score': 11544.876920700073, 'total_duration': 17524.579430818558, 'accumulated_submission_time': 11544.876920700073, 'accumulated_eval_time': 5977.058417797089, 'accumulated_logging_time': 1.662172794342041}
I0215 16:53:05.242248 140391533340416 logging_writer.py:48] [38515] accumulated_eval_time=5977.058418, accumulated_logging_time=1.662173, accumulated_submission_time=11544.876921, global_step=38515, preemption_count=0, score=11544.876921, test/accuracy=0.986157, test/loss=0.046602, test/mean_average_precision=0.267759, test/num_examples=43793, total_duration=17524.579431, train/accuracy=0.991311, train/loss=0.028675, train/mean_average_precision=0.453270, validation/accuracy=0.987007, validation/loss=0.043890, validation/mean_average_precision=0.275402, validation/num_examples=43793
I0215 16:55:30.025248 140496231986944 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.008468740619719028, loss=0.032183047384023666
I0215 16:57:05.416987 140558855219008 spec.py:321] Evaluating on the training split.
I0215 16:58:55.717718 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 16:58:58.668515 140558855219008 spec.py:349] Evaluating on the test split.
I0215 16:59:01.632003 140558855219008 submission_runner.py:408] Time since start: 17880.99s, 	Step: 39323, 	{'train/accuracy': 0.991313099861145, 'train/loss': 0.0285030547529459, 'train/mean_average_precision': 0.4603995903031187, 'validation/accuracy': 0.987025260925293, 'validation/loss': 0.043616004288196564, 'validation/mean_average_precision': 0.28006071241193264, 'validation/num_examples': 43793, 'test/accuracy': 0.9861207604408264, 'test/loss': 0.04663196951150894, 'test/mean_average_precision': 0.26565293580273447, 'test/num_examples': 43793, 'score': 11785.02121591568, 'total_duration': 17880.9883582592, 'accumulated_submission_time': 11785.02121591568, 'accumulated_eval_time': 6093.273400306702, 'accumulated_logging_time': 1.691354751586914}
I0215 16:59:01.651823 140391541733120 logging_writer.py:48] [39323] accumulated_eval_time=6093.273400, accumulated_logging_time=1.691355, accumulated_submission_time=11785.021216, global_step=39323, preemption_count=0, score=11785.021216, test/accuracy=0.986121, test/loss=0.046632, test/mean_average_precision=0.265653, test/num_examples=43793, total_duration=17880.988358, train/accuracy=0.991313, train/loss=0.028503, train/mean_average_precision=0.460400, validation/accuracy=0.987025, validation/loss=0.043616, validation/mean_average_precision=0.280061, validation/num_examples=43793
I0215 16:59:54.150022 140397990151936 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.008427934721112251, loss=0.030969759449362755
I0215 17:02:32.146980 140391541733120 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.009294983930885792, loss=0.03257810324430466
I0215 17:03:01.911373 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:04:51.775180 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:04:54.708029 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:04:57.581230 140558855219008 submission_runner.py:408] Time since start: 18236.94s, 	Step: 40100, 	{'train/accuracy': 0.9914779663085938, 'train/loss': 0.02809392847120762, 'train/mean_average_precision': 0.4666837057423398, 'validation/accuracy': 0.9870171546936035, 'validation/loss': 0.044153276830911636, 'validation/mean_average_precision': 0.27689153665500765, 'validation/num_examples': 43793, 'test/accuracy': 0.9861767888069153, 'test/loss': 0.04695762321352959, 'test/mean_average_precision': 0.27076288885568567, 'test/num_examples': 43793, 'score': 12025.25090932846, 'total_duration': 18236.93758249283, 'accumulated_submission_time': 12025.25090932846, 'accumulated_eval_time': 6208.943210840225, 'accumulated_logging_time': 1.7215301990509033}
I0215 17:04:57.601135 140391533340416 logging_writer.py:48] [40100] accumulated_eval_time=6208.943211, accumulated_logging_time=1.721530, accumulated_submission_time=12025.250909, global_step=40100, preemption_count=0, score=12025.250909, test/accuracy=0.986177, test/loss=0.046958, test/mean_average_precision=0.270763, test/num_examples=43793, total_duration=18236.937582, train/accuracy=0.991478, train/loss=0.028094, train/mean_average_precision=0.466684, validation/accuracy=0.987017, validation/loss=0.044153, validation/mean_average_precision=0.276892, validation/num_examples=43793
I0215 17:06:57.453051 140397998544640 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.006809529382735491, loss=0.02873235009610653
I0215 17:08:57.716243 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:10:46.062759 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:10:48.974044 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:10:51.822633 140558855219008 submission_runner.py:408] Time since start: 18591.18s, 	Step: 40905, 	{'train/accuracy': 0.99159175157547, 'train/loss': 0.027824023738503456, 'train/mean_average_precision': 0.4809402975676566, 'validation/accuracy': 0.9869733452796936, 'validation/loss': 0.04394612833857536, 'validation/mean_average_precision': 0.2773797747661502, 'validation/num_examples': 43793, 'test/accuracy': 0.9861670732498169, 'test/loss': 0.04684828594326973, 'test/mean_average_precision': 0.2682419940073253, 'test/num_examples': 43793, 'score': 12265.333916902542, 'total_duration': 18591.17898917198, 'accumulated_submission_time': 12265.333916902542, 'accumulated_eval_time': 6323.049568891525, 'accumulated_logging_time': 1.7531330585479736}
I0215 17:10:51.842357 140397990151936 logging_writer.py:48] [40905] accumulated_eval_time=6323.049569, accumulated_logging_time=1.753133, accumulated_submission_time=12265.333917, global_step=40905, preemption_count=0, score=12265.333917, test/accuracy=0.986167, test/loss=0.046848, test/mean_average_precision=0.268242, test/num_examples=43793, total_duration=18591.178989, train/accuracy=0.991592, train/loss=0.027824, train/mean_average_precision=0.480940, validation/accuracy=0.986973, validation/loss=0.043946, validation/mean_average_precision=0.277380, validation/num_examples=43793
I0215 17:11:20.835877 140496231986944 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.007819725200533867, loss=0.03245299309492111
I0215 17:13:51.695968 140397990151936 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.008259045891463757, loss=0.031808480620384216
I0215 17:14:52.033743 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:16:41.378752 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:16:44.441061 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:16:47.480210 140558855219008 submission_runner.py:408] Time since start: 18946.84s, 	Step: 41697, 	{'train/accuracy': 0.991690993309021, 'train/loss': 0.02746974676847458, 'train/mean_average_precision': 0.48252646377440706, 'validation/accuracy': 0.9869489669799805, 'validation/loss': 0.04386945068836212, 'validation/mean_average_precision': 0.276292395426865, 'validation/num_examples': 43793, 'test/accuracy': 0.9860900044441223, 'test/loss': 0.04675828665494919, 'test/mean_average_precision': 0.26951874910829016, 'test/num_examples': 43793, 'score': 12505.492862939835, 'total_duration': 18946.83656311035, 'accumulated_submission_time': 12505.492862939835, 'accumulated_eval_time': 6438.4959943294525, 'accumulated_logging_time': 1.783900499343872}
I0215 17:16:47.501271 140391533340416 logging_writer.py:48] [41697] accumulated_eval_time=6438.495994, accumulated_logging_time=1.783900, accumulated_submission_time=12505.492863, global_step=41697, preemption_count=0, score=12505.492863, test/accuracy=0.986090, test/loss=0.046758, test/mean_average_precision=0.269519, test/num_examples=43793, total_duration=18946.836563, train/accuracy=0.991691, train/loss=0.027470, train/mean_average_precision=0.482526, validation/accuracy=0.986949, validation/loss=0.043869, validation/mean_average_precision=0.276292, validation/num_examples=43793
I0215 17:18:19.576307 140391541733120 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.008682173676788807, loss=0.028196338564157486
I0215 17:20:47.517883 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:22:42.101720 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:22:45.040785 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:22:47.999520 140558855219008 submission_runner.py:408] Time since start: 19307.36s, 	Step: 42489, 	{'train/accuracy': 0.9918253421783447, 'train/loss': 0.02702687494456768, 'train/mean_average_precision': 0.5020348541304076, 'validation/accuracy': 0.9869607090950012, 'validation/loss': 0.043892014771699905, 'validation/mean_average_precision': 0.27548950655669785, 'validation/num_examples': 43793, 'test/accuracy': 0.9861548542976379, 'test/loss': 0.046674396842718124, 'test/mean_average_precision': 0.2707714665254074, 'test/num_examples': 43793, 'score': 12745.479783058167, 'total_duration': 19307.35587310791, 'accumulated_submission_time': 12745.479783058167, 'accumulated_eval_time': 6558.977596759796, 'accumulated_logging_time': 1.8147785663604736}
I0215 17:22:48.020232 140397990151936 logging_writer.py:48] [42489] accumulated_eval_time=6558.977597, accumulated_logging_time=1.814779, accumulated_submission_time=12745.479783, global_step=42489, preemption_count=0, score=12745.479783, test/accuracy=0.986155, test/loss=0.046674, test/mean_average_precision=0.270771, test/num_examples=43793, total_duration=19307.355873, train/accuracy=0.991825, train/loss=0.027027, train/mean_average_precision=0.502035, validation/accuracy=0.986961, validation/loss=0.043892, validation/mean_average_precision=0.275490, validation/num_examples=43793
I0215 17:22:51.687638 140496231986944 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.00869600661098957, loss=0.02809547446668148
I0215 17:25:21.298550 140397990151936 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.008850470185279846, loss=0.02842681296169758
I0215 17:26:48.264148 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:28:37.790122 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:28:40.835752 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:28:43.775295 140558855219008 submission_runner.py:408] Time since start: 19663.13s, 	Step: 43290, 	{'train/accuracy': 0.991926372051239, 'train/loss': 0.02652258425951004, 'train/mean_average_precision': 0.500133610940606, 'validation/accuracy': 0.9871036410331726, 'validation/loss': 0.04388105869293213, 'validation/mean_average_precision': 0.2817920888343989, 'validation/num_examples': 43793, 'test/accuracy': 0.9862323999404907, 'test/loss': 0.04668118804693222, 'test/mean_average_precision': 0.27378587329587795, 'test/num_examples': 43793, 'score': 12985.692975997925, 'total_duration': 19663.1316511631, 'accumulated_submission_time': 12985.692975997925, 'accumulated_eval_time': 6674.488714456558, 'accumulated_logging_time': 1.845799207687378}
I0215 17:28:43.795395 140391533340416 logging_writer.py:48] [43290] accumulated_eval_time=6674.488714, accumulated_logging_time=1.845799, accumulated_submission_time=12985.692976, global_step=43290, preemption_count=0, score=12985.692976, test/accuracy=0.986232, test/loss=0.046681, test/mean_average_precision=0.273786, test/num_examples=43793, total_duration=19663.131651, train/accuracy=0.991926, train/loss=0.026523, train/mean_average_precision=0.500134, validation/accuracy=0.987104, validation/loss=0.043881, validation/mean_average_precision=0.281792, validation/num_examples=43793
I0215 17:29:46.158242 140391541733120 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.009116418659687042, loss=0.027542678639292717
I0215 17:32:15.739718 140391533340416 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.01015186682343483, loss=0.033985573798418045
I0215 17:32:43.821248 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:34:35.236806 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:34:38.167036 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:34:41.088519 140558855219008 submission_runner.py:408] Time since start: 20020.44s, 	Step: 44095, 	{'train/accuracy': 0.9919463396072388, 'train/loss': 0.026412740349769592, 'train/mean_average_precision': 0.5125865507853793, 'validation/accuracy': 0.9869989156723022, 'validation/loss': 0.04396924749016762, 'validation/mean_average_precision': 0.28133133965131774, 'validation/num_examples': 43793, 'test/accuracy': 0.9861599206924438, 'test/loss': 0.04687561094760895, 'test/mean_average_precision': 0.2723896809814793, 'test/num_examples': 43793, 'score': 13225.688195943832, 'total_duration': 20020.444877386093, 'accumulated_submission_time': 13225.688195943832, 'accumulated_eval_time': 6791.755942583084, 'accumulated_logging_time': 1.8759524822235107}
I0215 17:34:41.108734 140397990151936 logging_writer.py:48] [44095] accumulated_eval_time=6791.755943, accumulated_logging_time=1.875952, accumulated_submission_time=13225.688196, global_step=44095, preemption_count=0, score=13225.688196, test/accuracy=0.986160, test/loss=0.046876, test/mean_average_precision=0.272390, test/num_examples=43793, total_duration=20020.444877, train/accuracy=0.991946, train/loss=0.026413, train/mean_average_precision=0.512587, validation/accuracy=0.986999, validation/loss=0.043969, validation/mean_average_precision=0.281331, validation/num_examples=43793
I0215 17:36:42.515126 140496231986944 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.011697315610945225, loss=0.03226371482014656
I0215 17:38:41.268261 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:40:31.530545 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:40:34.571344 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:40:37.618361 140558855219008 submission_runner.py:408] Time since start: 20376.97s, 	Step: 44894, 	{'train/accuracy': 0.9921253323554993, 'train/loss': 0.0258957389742136, 'train/mean_average_precision': 0.5274417351894362, 'validation/accuracy': 0.986997663974762, 'validation/loss': 0.04408834129571915, 'validation/mean_average_precision': 0.2798952488124757, 'validation/num_examples': 43793, 'test/accuracy': 0.9861388802528381, 'test/loss': 0.04690347611904144, 'test/mean_average_precision': 0.27196203256157236, 'test/num_examples': 43793, 'score': 13465.81727361679, 'total_duration': 20376.97470331192, 'accumulated_submission_time': 13465.81727361679, 'accumulated_eval_time': 6908.105998754501, 'accumulated_logging_time': 1.9063105583190918}
I0215 17:40:37.639101 140391533340416 logging_writer.py:48] [44894] accumulated_eval_time=6908.105999, accumulated_logging_time=1.906311, accumulated_submission_time=13465.817274, global_step=44894, preemption_count=0, score=13465.817274, test/accuracy=0.986139, test/loss=0.046903, test/mean_average_precision=0.271962, test/num_examples=43793, total_duration=20376.974703, train/accuracy=0.992125, train/loss=0.025896, train/mean_average_precision=0.527442, validation/accuracy=0.986998, validation/loss=0.044088, validation/mean_average_precision=0.279895, validation/num_examples=43793
I0215 17:41:09.703816 140397998544640 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.009068834595382214, loss=0.025778742507100105
I0215 17:43:38.232370 140391533340416 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.009811915457248688, loss=0.02843298390507698
I0215 17:44:37.836910 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:46:25.002743 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:46:27.930035 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:46:30.816873 140558855219008 submission_runner.py:408] Time since start: 20730.17s, 	Step: 45701, 	{'train/accuracy': 0.9923860430717468, 'train/loss': 0.025061296299099922, 'train/mean_average_precision': 0.544396729755047, 'validation/accuracy': 0.9871178269386292, 'validation/loss': 0.04403109848499298, 'validation/mean_average_precision': 0.2788353045437888, 'validation/num_examples': 43793, 'test/accuracy': 0.9862593412399292, 'test/loss': 0.04694725573062897, 'test/mean_average_precision': 0.2771417963157735, 'test/num_examples': 43793, 'score': 13705.983646392822, 'total_duration': 20730.17310166359, 'accumulated_submission_time': 13705.983646392822, 'accumulated_eval_time': 7021.08579492569, 'accumulated_logging_time': 1.9382295608520508}
I0215 17:46:30.837089 140397990151936 logging_writer.py:48] [45701] accumulated_eval_time=7021.085795, accumulated_logging_time=1.938230, accumulated_submission_time=13705.983646, global_step=45701, preemption_count=0, score=13705.983646, test/accuracy=0.986259, test/loss=0.046947, test/mean_average_precision=0.277142, test/num_examples=43793, total_duration=20730.173102, train/accuracy=0.992386, train/loss=0.025061, train/mean_average_precision=0.544397, validation/accuracy=0.987118, validation/loss=0.044031, validation/mean_average_precision=0.278835, validation/num_examples=43793
I0215 17:48:02.568758 140496231986944 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.009038271382451057, loss=0.029397359117865562
I0215 17:50:31.100221 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:52:24.208474 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:52:27.208781 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:52:30.110616 140558855219008 submission_runner.py:408] Time since start: 21089.47s, 	Step: 46493, 	{'train/accuracy': 0.9923943281173706, 'train/loss': 0.025010382756590843, 'train/mean_average_precision': 0.5558541752889394, 'validation/accuracy': 0.9869339466094971, 'validation/loss': 0.04429585486650467, 'validation/mean_average_precision': 0.28067874416990524, 'validation/num_examples': 43793, 'test/accuracy': 0.9861578345298767, 'test/loss': 0.04711482673883438, 'test/mean_average_precision': 0.27500759447516127, 'test/num_examples': 43793, 'score': 13946.215344667435, 'total_duration': 21089.466974258423, 'accumulated_submission_time': 13946.215344667435, 'accumulated_eval_time': 7140.096159934998, 'accumulated_logging_time': 1.9698936939239502}
I0215 17:52:30.131158 140391533340416 logging_writer.py:48] [46493] accumulated_eval_time=7140.096160, accumulated_logging_time=1.969894, accumulated_submission_time=13946.215345, global_step=46493, preemption_count=0, score=13946.215345, test/accuracy=0.986158, test/loss=0.047115, test/mean_average_precision=0.275008, test/num_examples=43793, total_duration=21089.466974, train/accuracy=0.992394, train/loss=0.025010, train/mean_average_precision=0.555854, validation/accuracy=0.986934, validation/loss=0.044296, validation/mean_average_precision=0.280679, validation/num_examples=43793
I0215 17:52:32.575853 140397998544640 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.008877419866621494, loss=0.02358556166291237
I0215 17:55:03.249034 140391533340416 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.009811925701797009, loss=0.02840029075741768
I0215 17:56:30.232958 140558855219008 spec.py:321] Evaluating on the training split.
I0215 17:58:21.653075 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 17:58:24.665982 140558855219008 spec.py:349] Evaluating on the test split.
I0215 17:58:27.630021 140558855219008 submission_runner.py:408] Time since start: 21446.99s, 	Step: 47289, 	{'train/accuracy': 0.9925546050071716, 'train/loss': 0.02443597838282585, 'train/mean_average_precision': 0.5603245341514393, 'validation/accuracy': 0.9870212078094482, 'validation/loss': 0.04425477609038353, 'validation/mean_average_precision': 0.27881796437874984, 'validation/num_examples': 43793, 'test/accuracy': 0.986214280128479, 'test/loss': 0.047055650502443314, 'test/mean_average_precision': 0.2745095251535885, 'test/num_examples': 43793, 'score': 14186.285210132599, 'total_duration': 21446.986362457275, 'accumulated_submission_time': 14186.285210132599, 'accumulated_eval_time': 7257.493173122406, 'accumulated_logging_time': 2.0020265579223633}
I0215 17:58:27.650253 140391541733120 logging_writer.py:48] [47289] accumulated_eval_time=7257.493173, accumulated_logging_time=2.002027, accumulated_submission_time=14186.285210, global_step=47289, preemption_count=0, score=14186.285210, test/accuracy=0.986214, test/loss=0.047056, test/mean_average_precision=0.274510, test/num_examples=43793, total_duration=21446.986362, train/accuracy=0.992555, train/loss=0.024436, train/mean_average_precision=0.560325, validation/accuracy=0.987021, validation/loss=0.044255, validation/mean_average_precision=0.278818, validation/num_examples=43793
I0215 17:59:30.553917 140397990151936 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.009562165476381779, loss=0.029523523524403572
I0215 18:02:00.799731 140391541733120 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.010755451396107674, loss=0.029772356152534485
I0215 18:02:27.806616 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:04:19.414963 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:04:22.388295 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:04:25.262511 140558855219008 submission_runner.py:408] Time since start: 21804.62s, 	Step: 48092, 	{'train/accuracy': 0.9926342368125916, 'train/loss': 0.02426978573203087, 'train/mean_average_precision': 0.5552311478682642, 'validation/accuracy': 0.987153947353363, 'validation/loss': 0.044016726315021515, 'validation/mean_average_precision': 0.2843239468740543, 'validation/num_examples': 43793, 'test/accuracy': 0.9862285852432251, 'test/loss': 0.046874240040779114, 'test/mean_average_precision': 0.2762326809136221, 'test/num_examples': 43793, 'score': 14426.411679029465, 'total_duration': 21804.61886739731, 'accumulated_submission_time': 14426.411679029465, 'accumulated_eval_time': 7374.949022531509, 'accumulated_logging_time': 2.032355546951294}
I0215 18:04:25.283098 140397998544640 logging_writer.py:48] [48092] accumulated_eval_time=7374.949023, accumulated_logging_time=2.032356, accumulated_submission_time=14426.411679, global_step=48092, preemption_count=0, score=14426.411679, test/accuracy=0.986229, test/loss=0.046874, test/mean_average_precision=0.276233, test/num_examples=43793, total_duration=21804.618867, train/accuracy=0.992634, train/loss=0.024270, train/mean_average_precision=0.555231, validation/accuracy=0.987154, validation/loss=0.044017, validation/mean_average_precision=0.284324, validation/num_examples=43793
I0215 18:06:27.686850 140496231986944 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.00871784333139658, loss=0.026032108813524246
I0215 18:08:25.569886 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:10:09.032479 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:10:12.121816 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:10:14.998548 140558855219008 submission_runner.py:408] Time since start: 22154.35s, 	Step: 48896, 	{'train/accuracy': 0.9927313327789307, 'train/loss': 0.023883545771241188, 'train/mean_average_precision': 0.5718605383754497, 'validation/accuracy': 0.9871352910995483, 'validation/loss': 0.04433589428663254, 'validation/mean_average_precision': 0.2819300844568879, 'validation/num_examples': 43793, 'test/accuracy': 0.986268162727356, 'test/loss': 0.04721706733107567, 'test/mean_average_precision': 0.2796114318798893, 'test/num_examples': 43793, 'score': 14666.668749570847, 'total_duration': 22154.354904174805, 'accumulated_submission_time': 14666.668749570847, 'accumulated_eval_time': 7484.377660512924, 'accumulated_logging_time': 2.0628912448883057}
I0215 18:10:15.019196 140391541733120 logging_writer.py:48] [48896] accumulated_eval_time=7484.377661, accumulated_logging_time=2.062891, accumulated_submission_time=14666.668750, global_step=48896, preemption_count=0, score=14666.668750, test/accuracy=0.986268, test/loss=0.047217, test/mean_average_precision=0.279611, test/num_examples=43793, total_duration=22154.354904, train/accuracy=0.992731, train/loss=0.023884, train/mean_average_precision=0.571861, validation/accuracy=0.987135, validation/loss=0.044336, validation/mean_average_precision=0.281930, validation/num_examples=43793
I0215 18:10:45.997839 140397990151936 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.00793035700917244, loss=0.026024257764220238
I0215 18:13:14.417471 140391541733120 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.008578486740589142, loss=0.027968434616923332
I0215 18:14:15.245280 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:16:04.844575 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:16:07.750826 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:16:10.618657 140558855219008 submission_runner.py:408] Time since start: 22509.98s, 	Step: 49706, 	{'train/accuracy': 0.9928947687149048, 'train/loss': 0.023473793640732765, 'train/mean_average_precision': 0.5778326863214858, 'validation/accuracy': 0.9870362281799316, 'validation/loss': 0.04449714347720146, 'validation/mean_average_precision': 0.2845194402876295, 'validation/num_examples': 43793, 'test/accuracy': 0.9861615896224976, 'test/loss': 0.04741447791457176, 'test/mean_average_precision': 0.27202136972686014, 'test/num_examples': 43793, 'score': 14906.865149497986, 'total_duration': 22509.97501564026, 'accumulated_submission_time': 14906.865149497986, 'accumulated_eval_time': 7599.751002073288, 'accumulated_logging_time': 2.093366861343384}
I0215 18:16:10.639995 140391533340416 logging_writer.py:48] [49706] accumulated_eval_time=7599.751002, accumulated_logging_time=2.093367, accumulated_submission_time=14906.865149, global_step=49706, preemption_count=0, score=14906.865149, test/accuracy=0.986162, test/loss=0.047414, test/mean_average_precision=0.272021, test/num_examples=43793, total_duration=22509.975016, train/accuracy=0.992895, train/loss=0.023474, train/mean_average_precision=0.577833, validation/accuracy=0.987036, validation/loss=0.044497, validation/mean_average_precision=0.284519, validation/num_examples=43793
I0215 18:17:38.252144 140397998544640 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.009632990695536137, loss=0.029518790543079376
I0215 18:20:06.710896 140391533340416 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.008909832686185837, loss=0.027288777753710747
I0215 18:20:10.889488 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:21:59.257375 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:22:02.179273 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:22:05.104976 140558855219008 submission_runner.py:408] Time since start: 22864.46s, 	Step: 50515, 	{'train/accuracy': 0.9929825663566589, 'train/loss': 0.02328301966190338, 'train/mean_average_precision': 0.593450051311089, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04429353401064873, 'validation/mean_average_precision': 0.2846719079451756, 'validation/num_examples': 43793, 'test/accuracy': 0.9863090515136719, 'test/loss': 0.04722001776099205, 'test/mean_average_precision': 0.27595725081776806, 'test/num_examples': 43793, 'score': 15147.084553956985, 'total_duration': 22864.46127462387, 'accumulated_submission_time': 15147.084553956985, 'accumulated_eval_time': 7713.966383218765, 'accumulated_logging_time': 2.124816417694092}
I0215 18:22:05.126489 140391541733120 logging_writer.py:48] [50515] accumulated_eval_time=7713.966383, accumulated_logging_time=2.124816, accumulated_submission_time=15147.084554, global_step=50515, preemption_count=0, score=15147.084554, test/accuracy=0.986309, test/loss=0.047220, test/mean_average_precision=0.275957, test/num_examples=43793, total_duration=22864.461275, train/accuracy=0.992983, train/loss=0.023283, train/mean_average_precision=0.593450, validation/accuracy=0.987154, validation/loss=0.044294, validation/mean_average_precision=0.284672, validation/num_examples=43793
I0215 18:24:29.881569 140496231986944 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.010122551582753658, loss=0.027638055384159088
I0215 18:26:05.245372 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:27:55.873504 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:27:58.855710 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:28:01.827994 140558855219008 submission_runner.py:408] Time since start: 23221.18s, 	Step: 51318, 	{'train/accuracy': 0.9929440021514893, 'train/loss': 0.023267265409231186, 'train/mean_average_precision': 0.5915164042765131, 'validation/accuracy': 0.9870508313179016, 'validation/loss': 0.04445941001176834, 'validation/mean_average_precision': 0.28038965042115216, 'validation/num_examples': 43793, 'test/accuracy': 0.9862285852432251, 'test/loss': 0.047378383576869965, 'test/mean_average_precision': 0.2771135049515942, 'test/num_examples': 43793, 'score': 15387.17203593254, 'total_duration': 23221.18435025215, 'accumulated_submission_time': 15387.17203593254, 'accumulated_eval_time': 7830.548970460892, 'accumulated_logging_time': 2.157545566558838}
I0215 18:28:01.848885 140391533340416 logging_writer.py:48] [51318] accumulated_eval_time=7830.548970, accumulated_logging_time=2.157546, accumulated_submission_time=15387.172036, global_step=51318, preemption_count=0, score=15387.172036, test/accuracy=0.986229, test/loss=0.047378, test/mean_average_precision=0.277114, test/num_examples=43793, total_duration=23221.184350, train/accuracy=0.992944, train/loss=0.023267, train/mean_average_precision=0.591516, validation/accuracy=0.987051, validation/loss=0.044459, validation/mean_average_precision=0.280390, validation/num_examples=43793
I0215 18:28:56.609537 140397998544640 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.009884245693683624, loss=0.02367520146071911
I0215 18:31:27.281085 140391533340416 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.009979809634387493, loss=0.026518501341342926
I0215 18:32:02.030036 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:33:54.951569 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:33:57.921176 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:34:00.842422 140558855219008 submission_runner.py:408] Time since start: 23580.20s, 	Step: 52116, 	{'train/accuracy': 0.9929519891738892, 'train/loss': 0.02312520146369934, 'train/mean_average_precision': 0.5874984056136354, 'validation/accuracy': 0.9871340990066528, 'validation/loss': 0.04432467743754387, 'validation/mean_average_precision': 0.28806774429424764, 'validation/num_examples': 43793, 'test/accuracy': 0.9862744808197021, 'test/loss': 0.04726393148303032, 'test/mean_average_precision': 0.2797398962344857, 'test/num_examples': 43793, 'score': 15627.323832988739, 'total_duration': 23580.198765039444, 'accumulated_submission_time': 15627.323832988739, 'accumulated_eval_time': 7949.361320257187, 'accumulated_logging_time': 2.1882736682891846}
I0215 18:34:00.863385 140391541733120 logging_writer.py:48] [52116] accumulated_eval_time=7949.361320, accumulated_logging_time=2.188274, accumulated_submission_time=15627.323833, global_step=52116, preemption_count=0, score=15627.323833, test/accuracy=0.986274, test/loss=0.047264, test/mean_average_precision=0.279740, test/num_examples=43793, total_duration=23580.198765, train/accuracy=0.992952, train/loss=0.023125, train/mean_average_precision=0.587498, validation/accuracy=0.987134, validation/loss=0.044325, validation/mean_average_precision=0.288068, validation/num_examples=43793
I0215 18:35:55.927203 140397990151936 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.009811954572796822, loss=0.02839144505560398
I0215 18:38:00.887406 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:39:51.559349 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:39:54.496197 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:39:57.404869 140558855219008 submission_runner.py:408] Time since start: 23936.76s, 	Step: 52918, 	{'train/accuracy': 0.9930144548416138, 'train/loss': 0.023031149059534073, 'train/mean_average_precision': 0.5870615159635201, 'validation/accuracy': 0.987106442451477, 'validation/loss': 0.04474416375160217, 'validation/mean_average_precision': 0.2841183988113131, 'validation/num_examples': 43793, 'test/accuracy': 0.9862787127494812, 'test/loss': 0.04757234454154968, 'test/mean_average_precision': 0.27971161989533533, 'test/num_examples': 43793, 'score': 15867.316489696503, 'total_duration': 23936.761212348938, 'accumulated_submission_time': 15867.316489696503, 'accumulated_eval_time': 8065.878739833832, 'accumulated_logging_time': 2.220555067062378}
I0215 18:39:57.426803 140391533340416 logging_writer.py:48] [52918] accumulated_eval_time=8065.878740, accumulated_logging_time=2.220555, accumulated_submission_time=15867.316490, global_step=52918, preemption_count=0, score=15867.316490, test/accuracy=0.986279, test/loss=0.047572, test/mean_average_precision=0.279712, test/num_examples=43793, total_duration=23936.761212, train/accuracy=0.993014, train/loss=0.023031, train/mean_average_precision=0.587062, validation/accuracy=0.987106, validation/loss=0.044744, validation/mean_average_precision=0.284118, validation/num_examples=43793
I0215 18:40:22.186506 140496231986944 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.01149365771561861, loss=0.02898501604795456
I0215 18:42:50.728633 140391533340416 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.013612276874482632, loss=0.024877190589904785
I0215 18:43:57.651817 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:45:45.996115 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:45:48.956318 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:45:51.836516 140558855219008 submission_runner.py:408] Time since start: 24291.19s, 	Step: 53725, 	{'train/accuracy': 0.9931383728981018, 'train/loss': 0.02272367663681507, 'train/mean_average_precision': 0.6022293814190338, 'validation/accuracy': 0.9871269464492798, 'validation/loss': 0.04455486312508583, 'validation/mean_average_precision': 0.285360844400321, 'validation/num_examples': 43793, 'test/accuracy': 0.9862610101699829, 'test/loss': 0.047440215945243835, 'test/mean_average_precision': 0.27731181284116074, 'test/num_examples': 43793, 'score': 16107.51065826416, 'total_duration': 24291.192872285843, 'accumulated_submission_time': 16107.51065826416, 'accumulated_eval_time': 8180.06339931488, 'accumulated_logging_time': 2.252974271774292}
I0215 18:45:51.857970 140391541733120 logging_writer.py:48] [53725] accumulated_eval_time=8180.063399, accumulated_logging_time=2.252974, accumulated_submission_time=16107.510658, global_step=53725, preemption_count=0, score=16107.510658, test/accuracy=0.986261, test/loss=0.047440, test/mean_average_precision=0.277312, test/num_examples=43793, total_duration=24291.192872, train/accuracy=0.993138, train/loss=0.022724, train/mean_average_precision=0.602229, validation/accuracy=0.987127, validation/loss=0.044555, validation/mean_average_precision=0.285361, validation/num_examples=43793
I0215 18:47:14.659289 140397990151936 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.009786254726350307, loss=0.025518517941236496
I0215 18:49:44.308640 140391541733120 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.009410744532942772, loss=0.023930486291646957
I0215 18:49:52.135093 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:51:37.234787 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:51:40.204649 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:51:43.083436 140558855219008 submission_runner.py:408] Time since start: 24642.44s, 	Step: 54527, 	{'train/accuracy': 0.9931251406669617, 'train/loss': 0.022641677409410477, 'train/mean_average_precision': 0.6076571028786262, 'validation/accuracy': 0.9871287941932678, 'validation/loss': 0.044688351452350616, 'validation/mean_average_precision': 0.2884000268612941, 'validation/num_examples': 43793, 'test/accuracy': 0.9862395524978638, 'test/loss': 0.04768885672092438, 'test/mean_average_precision': 0.27851998307997644, 'test/num_examples': 43793, 'score': 16347.757538318634, 'total_duration': 24642.439792633057, 'accumulated_submission_time': 16347.757538318634, 'accumulated_eval_time': 8291.01169705391, 'accumulated_logging_time': 2.284498453140259}
I0215 18:51:43.105020 140391533340416 logging_writer.py:48] [54527] accumulated_eval_time=8291.011697, accumulated_logging_time=2.284498, accumulated_submission_time=16347.757538, global_step=54527, preemption_count=0, score=16347.757538, test/accuracy=0.986240, test/loss=0.047689, test/mean_average_precision=0.278520, test/num_examples=43793, total_duration=24642.439793, train/accuracy=0.993125, train/loss=0.022642, train/mean_average_precision=0.607657, validation/accuracy=0.987129, validation/loss=0.044688, validation/mean_average_precision=0.288400, validation/num_examples=43793
I0215 18:54:03.922862 140397998544640 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.008697264827787876, loss=0.025191744789481163
I0215 18:55:43.311178 140558855219008 spec.py:321] Evaluating on the training split.
I0215 18:57:35.801624 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 18:57:38.698210 140558855219008 spec.py:349] Evaluating on the test split.
I0215 18:57:41.616624 140558855219008 submission_runner.py:408] Time since start: 25000.97s, 	Step: 55337, 	{'train/accuracy': 0.9931420087814331, 'train/loss': 0.022613918408751488, 'train/mean_average_precision': 0.6031121853587724, 'validation/accuracy': 0.9871211051940918, 'validation/loss': 0.04463699460029602, 'validation/mean_average_precision': 0.2870607012805973, 'validation/num_examples': 43793, 'test/accuracy': 0.9862585067749023, 'test/loss': 0.04758983105421066, 'test/mean_average_precision': 0.2787665003113842, 'test/num_examples': 43793, 'score': 16587.9323387146, 'total_duration': 25000.97297644615, 'accumulated_submission_time': 16587.9323387146, 'accumulated_eval_time': 8409.317105770111, 'accumulated_logging_time': 2.317509412765503}
I0215 18:57:41.640180 140376781825792 logging_writer.py:48] [55337] accumulated_eval_time=8409.317106, accumulated_logging_time=2.317509, accumulated_submission_time=16587.932339, global_step=55337, preemption_count=0, score=16587.932339, test/accuracy=0.986259, test/loss=0.047590, test/mean_average_precision=0.278767, test/num_examples=43793, total_duration=25000.972976, train/accuracy=0.993142, train/loss=0.022614, train/mean_average_precision=0.603112, validation/accuracy=0.987121, validation/loss=0.044637, validation/mean_average_precision=0.287061, validation/num_examples=43793
I0215 18:58:31.064885 140391541733120 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.01085114199668169, loss=0.025952553376555443
I0215 19:01:00.832947 140376781825792 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.010559792630374432, loss=0.022254355251789093
I0215 19:01:41.832784 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:03:29.149117 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:03:32.088865 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:03:34.979486 140558855219008 submission_runner.py:408] Time since start: 25354.34s, 	Step: 56138, 	{'train/accuracy': 0.9931641817092896, 'train/loss': 0.022553671151399612, 'train/mean_average_precision': 0.5970061701388318, 'validation/accuracy': 0.9871296286582947, 'validation/loss': 0.044749077409505844, 'validation/mean_average_precision': 0.2870641637165094, 'validation/num_examples': 43793, 'test/accuracy': 0.9862576723098755, 'test/loss': 0.04776632413268089, 'test/mean_average_precision': 0.28008036900261646, 'test/num_examples': 43793, 'score': 16828.094554424286, 'total_duration': 25354.335829734802, 'accumulated_submission_time': 16828.094554424286, 'accumulated_eval_time': 8522.463761806488, 'accumulated_logging_time': 2.351247549057007}
I0215 19:03:35.001703 140391533340416 logging_writer.py:48] [56138] accumulated_eval_time=8522.463762, accumulated_logging_time=2.351248, accumulated_submission_time=16828.094554, global_step=56138, preemption_count=0, score=16828.094554, test/accuracy=0.986258, test/loss=0.047766, test/mean_average_precision=0.280080, test/num_examples=43793, total_duration=25354.335830, train/accuracy=0.993164, train/loss=0.022554, train/mean_average_precision=0.597006, validation/accuracy=0.987130, validation/loss=0.044749, validation/mean_average_precision=0.287064, validation/num_examples=43793
I0215 19:05:23.389216 140397990151936 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.00985810998827219, loss=0.02537762001156807
I0215 19:07:35.259354 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:09:21.767949 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:09:24.657299 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:09:27.554254 140558855219008 submission_runner.py:408] Time since start: 25706.91s, 	Step: 56939, 	{'train/accuracy': 0.9931225180625916, 'train/loss': 0.02266804315149784, 'train/mean_average_precision': 0.6018605240359625, 'validation/accuracy': 0.9871299862861633, 'validation/loss': 0.04467529058456421, 'validation/mean_average_precision': 0.2872979678903459, 'validation/num_examples': 43793, 'test/accuracy': 0.986282467842102, 'test/loss': 0.047671858221292496, 'test/mean_average_precision': 0.28036413821063483, 'test/num_examples': 43793, 'score': 17068.321801185608, 'total_duration': 25706.910608768463, 'accumulated_submission_time': 17068.321801185608, 'accumulated_eval_time': 8634.758631944656, 'accumulated_logging_time': 2.3836841583251953}
I0215 19:09:27.575484 140376781825792 logging_writer.py:48] [56939] accumulated_eval_time=8634.758632, accumulated_logging_time=2.383684, accumulated_submission_time=17068.321801, global_step=56939, preemption_count=0, score=17068.321801, test/accuracy=0.986282, test/loss=0.047672, test/mean_average_precision=0.280364, test/num_examples=43793, total_duration=25706.910609, train/accuracy=0.993123, train/loss=0.022668, train/mean_average_precision=0.601861, validation/accuracy=0.987130, validation/loss=0.044675, validation/mean_average_precision=0.287298, validation/num_examples=43793
I0215 19:09:46.017347 140397998544640 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.009914782829582691, loss=0.02568376250565052
I0215 19:12:14.466994 140376781825792 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.01039243582636118, loss=0.025248542428016663
I0215 19:13:27.595841 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:15:14.401038 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:15:17.775622 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:15:21.010661 140558855219008 submission_runner.py:408] Time since start: 26060.37s, 	Step: 57748, 	{'train/accuracy': 0.9932647943496704, 'train/loss': 0.022245002910494804, 'train/mean_average_precision': 0.6067731179136278, 'validation/accuracy': 0.9871702194213867, 'validation/loss': 0.04471084102988243, 'validation/mean_average_precision': 0.2871020006283302, 'validation/num_examples': 43793, 'test/accuracy': 0.9863107204437256, 'test/loss': 0.04770280048251152, 'test/mean_average_precision': 0.28026811313528477, 'test/num_examples': 43793, 'score': 17308.312358617783, 'total_duration': 26060.3670027256, 'accumulated_submission_time': 17308.312358617783, 'accumulated_eval_time': 8748.173397064209, 'accumulated_logging_time': 2.4148707389831543}
I0215 19:15:21.034440 140391541733120 logging_writer.py:48] [57748] accumulated_eval_time=8748.173397, accumulated_logging_time=2.414871, accumulated_submission_time=17308.312359, global_step=57748, preemption_count=0, score=17308.312359, test/accuracy=0.986311, test/loss=0.047703, test/mean_average_precision=0.280268, test/num_examples=43793, total_duration=26060.367003, train/accuracy=0.993265, train/loss=0.022245, train/mean_average_precision=0.606773, validation/accuracy=0.987170, validation/loss=0.044711, validation/mean_average_precision=0.287102, validation/num_examples=43793
I0215 19:16:38.158354 140397990151936 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.009319868870079517, loss=0.023365790024399757
I0215 19:19:10.890084 140391541733120 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.011975474655628204, loss=0.02283608913421631
I0215 19:19:21.020705 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:21:11.266728 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:21:14.150901 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:21:17.118562 140558855219008 submission_runner.py:408] Time since start: 26416.47s, 	Step: 58534, 	{'train/accuracy': 0.9932355880737305, 'train/loss': 0.022261090576648712, 'train/mean_average_precision': 0.6178622360076718, 'validation/accuracy': 0.987131655216217, 'validation/loss': 0.044713929295539856, 'validation/mean_average_precision': 0.28784321534360646, 'validation/num_examples': 43793, 'test/accuracy': 0.9863073229789734, 'test/loss': 0.04769863188266754, 'test/mean_average_precision': 0.2802668372362473, 'test/num_examples': 43793, 'score': 17548.26337003708, 'total_duration': 26416.47491788864, 'accumulated_submission_time': 17548.26337003708, 'accumulated_eval_time': 8864.271213769913, 'accumulated_logging_time': 2.449326515197754}
I0215 19:21:17.140278 140376781825792 logging_writer.py:48] [58534] accumulated_eval_time=8864.271214, accumulated_logging_time=2.449327, accumulated_submission_time=17548.263370, global_step=58534, preemption_count=0, score=17548.263370, test/accuracy=0.986307, test/loss=0.047699, test/mean_average_precision=0.280267, test/num_examples=43793, total_duration=26416.474918, train/accuracy=0.993236, train/loss=0.022261, train/mean_average_precision=0.617862, validation/accuracy=0.987132, validation/loss=0.044714, validation/mean_average_precision=0.287843, validation/num_examples=43793
I0215 19:23:35.638451 140397998544640 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.00997175369411707, loss=0.027169296517968178
I0215 19:25:17.232758 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:27:07.512106 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:27:10.452969 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:27:13.346083 140558855219008 submission_runner.py:408] Time since start: 26772.70s, 	Step: 59341, 	{'train/accuracy': 0.993293285369873, 'train/loss': 0.022195057943463326, 'train/mean_average_precision': 0.601180504078912, 'validation/accuracy': 0.9871352910995483, 'validation/loss': 0.04474446177482605, 'validation/mean_average_precision': 0.28794393499347676, 'validation/num_examples': 43793, 'test/accuracy': 0.9863098859786987, 'test/loss': 0.04773981124162674, 'test/mean_average_precision': 0.2803615214382558, 'test/num_examples': 43793, 'score': 17788.325407505035, 'total_duration': 26772.70242524147, 'accumulated_submission_time': 17788.325407505035, 'accumulated_eval_time': 8980.384490013123, 'accumulated_logging_time': 2.4813530445098877}
I0215 19:27:13.367440 140391533340416 logging_writer.py:48] [59341] accumulated_eval_time=8980.384490, accumulated_logging_time=2.481353, accumulated_submission_time=17788.325408, global_step=59341, preemption_count=0, score=17788.325408, test/accuracy=0.986310, test/loss=0.047740, test/mean_average_precision=0.280362, test/num_examples=43793, total_duration=26772.702425, train/accuracy=0.993293, train/loss=0.022195, train/mean_average_precision=0.601181, validation/accuracy=0.987135, validation/loss=0.044744, validation/mean_average_precision=0.287944, validation/num_examples=43793
I0215 19:28:01.514772 140397990151936 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.011289536952972412, loss=0.02817477285861969
I0215 19:30:29.816672 140391533340416 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.009821858257055283, loss=0.02603246085345745
I0215 19:31:13.414834 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:32:58.062865 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:33:00.984877 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:33:03.891631 140558855219008 submission_runner.py:408] Time since start: 27123.25s, 	Step: 60146, 	{'train/accuracy': 0.9932788014411926, 'train/loss': 0.022192470729351044, 'train/mean_average_precision': 0.6098885446263707, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04474251717329025, 'validation/mean_average_precision': 0.28814181325092886, 'validation/num_examples': 43793, 'test/accuracy': 0.9862951040267944, 'test/loss': 0.04773058369755745, 'test/mean_average_precision': 0.2804849067881474, 'test/num_examples': 43793, 'score': 18028.340656995773, 'total_duration': 27123.247985363007, 'accumulated_submission_time': 18028.340656995773, 'accumulated_eval_time': 9090.861245632172, 'accumulated_logging_time': 2.5141851902008057}
I0215 19:33:03.913985 140376781825792 logging_writer.py:48] [60146] accumulated_eval_time=9090.861246, accumulated_logging_time=2.514185, accumulated_submission_time=18028.340657, global_step=60146, preemption_count=0, score=18028.340657, test/accuracy=0.986295, test/loss=0.047731, test/mean_average_precision=0.280485, test/num_examples=43793, total_duration=27123.247985, train/accuracy=0.993279, train/loss=0.022192, train/mean_average_precision=0.609889, validation/accuracy=0.987136, validation/loss=0.044743, validation/mean_average_precision=0.288142, validation/num_examples=43793
I0215 19:34:49.749761 140391541733120 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.009791245684027672, loss=0.024117400869727135
I0215 19:37:04.018102 140558855219008 spec.py:321] Evaluating on the training split.
I0215 19:38:51.826799 140558855219008 spec.py:333] Evaluating on the validation split.
I0215 19:38:54.783718 140558855219008 spec.py:349] Evaluating on the test split.
I0215 19:38:57.692785 140558855219008 submission_runner.py:408] Time since start: 27477.05s, 	Step: 60947, 	{'train/accuracy': 0.9931958913803101, 'train/loss': 0.022368598729372025, 'train/mean_average_precision': 0.6026620392714828, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04474251717329025, 'validation/mean_average_precision': 0.2881028970050903, 'validation/num_examples': 43793, 'test/accuracy': 0.9862951040267944, 'test/loss': 0.04773058369755745, 'test/mean_average_precision': 0.28056115923477914, 'test/num_examples': 43793, 'score': 18268.41448521614, 'total_duration': 27477.049141407013, 'accumulated_submission_time': 18268.41448521614, 'accumulated_eval_time': 9204.535899400711, 'accumulated_logging_time': 2.5469765663146973}
I0215 19:38:57.714943 140391533340416 logging_writer.py:48] [60947] accumulated_eval_time=9204.535899, accumulated_logging_time=2.546977, accumulated_submission_time=18268.414485, global_step=60947, preemption_count=0, score=18268.414485, test/accuracy=0.986295, test/loss=0.047731, test/mean_average_precision=0.280561, test/num_examples=43793, total_duration=27477.049141, train/accuracy=0.993196, train/loss=0.022369, train/mean_average_precision=0.602662, validation/accuracy=0.987136, validation/loss=0.044743, validation/mean_average_precision=0.288103, validation/num_examples=43793
I0215 19:39:14.058119 140397990151936 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.010288061574101448, loss=0.026545988395810127
I0215 19:41:43.712061 140391533340416 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.010337093845009804, loss=0.02663969062268734
I0215 19:42:26.496709 140397990151936 logging_writer.py:48] [61644] global_step=61644, preemption_count=0, score=18477.156199
I0215 19:42:26.546000 140558855219008 checkpoints.py:490] Saving checkpoint at step: 61644
I0215 19:42:26.655560 140558855219008 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1/checkpoint_61644
I0215 19:42:26.656683 140558855219008 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/ogbg_gelu_jax/trial_1/checkpoint_61644.
I0215 19:42:26.808233 140558855219008 submission_runner.py:583] Tuning trial 1/1
I0215 19:42:26.808461 140558855219008 submission_runner.py:584] Hyperparameters: Hyperparameters(learning_rate=0.01897755400372091, beta1=0.9666072782043229, beta2=0.99681600289198, warmup_steps=3000, weight_decay=0.015653883841116094)
I0215 19:42:26.812378 140558855219008 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/accuracy': 0.5693638920783997, 'train/loss': 0.7166677117347717, 'train/mean_average_precision': 0.02251561318132391, 'validation/accuracy': 0.566946268081665, 'validation/loss': 0.7168007493019104, 'validation/mean_average_precision': 0.02615410617255163, 'validation/num_examples': 43793, 'test/accuracy': 0.5636456608772278, 'test/loss': 0.7183514833450317, 'test/mean_average_precision': 0.02845508046388855, 'test/num_examples': 43793, 'score': 19.140517473220825, 'total_duration': 313.81607389450073, 'accumulated_submission_time': 19.140517473220825, 'accumulated_eval_time': 294.67551445961, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (784, {'train/accuracy': 0.9867364764213562, 'train/loss': 0.05376839265227318, 'train/mean_average_precision': 0.03944228519030182, 'validation/accuracy': 0.9840367436408997, 'validation/loss': 0.06404019147157669, 'validation/mean_average_precision': 0.03898960368019125, 'validation/num_examples': 43793, 'test/accuracy': 0.9830296039581299, 'test/loss': 0.06735099852085114, 'test/mean_average_precision': 0.03981701520095944, 'test/num_examples': 43793, 'score': 259.38515639305115, 'total_duration': 669.91117811203, 'accumulated_submission_time': 259.38515639305115, 'accumulated_eval_time': 410.4786365032196, 'accumulated_logging_time': 0.028557300567626953, 'global_step': 784, 'preemption_count': 0}), (1569, {'train/accuracy': 0.9869202375411987, 'train/loss': 0.0504998080432415, 'train/mean_average_precision': 0.06201516743381764, 'validation/accuracy': 0.9842185974121094, 'validation/loss': 0.06088742986321449, 'validation/mean_average_precision': 0.06648660536337875, 'validation/num_examples': 43793, 'test/accuracy': 0.983212411403656, 'test/loss': 0.0642148107290268, 'test/mean_average_precision': 0.0652801938168278, 'test/num_examples': 43793, 'score': 499.51279520988464, 'total_duration': 1024.2972824573517, 'accumulated_submission_time': 499.51279520988464, 'accumulated_eval_time': 524.6848311424255, 'accumulated_logging_time': 0.05793571472167969, 'global_step': 1569, 'preemption_count': 0}), (2364, {'train/accuracy': 0.9871264100074768, 'train/loss': 0.047555021941661835, 'train/mean_average_precision': 0.10512532192452656, 'validation/accuracy': 0.9845048189163208, 'validation/loss': 0.05712180212140083, 'validation/mean_average_precision': 0.09566470113648733, 'validation/num_examples': 43793, 'test/accuracy': 0.9835144281387329, 'test/loss': 0.06053604558110237, 'test/mean_average_precision': 0.0948612460114271, 'test/num_examples': 43793, 'score': 739.4934566020966, 'total_duration': 1381.5043685436249, 'accumulated_submission_time': 739.4934566020966, 'accumulated_eval_time': 641.8630967140198, 'accumulated_logging_time': 0.0860452651977539, 'global_step': 2364, 'preemption_count': 0}), (3164, {'train/accuracy': 0.9878024458885193, 'train/loss': 0.0436401441693306, 'train/mean_average_precision': 0.13012382310835782, 'validation/accuracy': 0.9849801659584045, 'validation/loss': 0.052965857088565826, 'validation/mean_average_precision': 0.13423313683812868, 'validation/num_examples': 43793, 'test/accuracy': 0.9840034246444702, 'test/loss': 0.05607813596725464, 'test/mean_average_precision': 0.1347402842878854, 'test/num_examples': 43793, 'score': 979.6541843414307, 'total_duration': 1739.7244699001312, 'accumulated_submission_time': 979.6541843414307, 'accumulated_eval_time': 759.8761308193207, 'accumulated_logging_time': 0.11197471618652344, 'global_step': 3164, 'preemption_count': 0}), (3965, {'train/accuracy': 0.9881826043128967, 'train/loss': 0.04131815582513809, 'train/mean_average_precision': 0.17441314763671695, 'validation/accuracy': 0.9853154420852661, 'validation/loss': 0.050839733332395554, 'validation/mean_average_precision': 0.1618505253433002, 'validation/num_examples': 43793, 'test/accuracy': 0.9843454360961914, 'test/loss': 0.053814951330423355, 'test/mean_average_precision': 0.15346176383838325, 'test/num_examples': 43793, 'score': 1219.8746342658997, 'total_duration': 2096.2743821144104, 'accumulated_submission_time': 1219.8746342658997, 'accumulated_eval_time': 876.1591114997864, 'accumulated_logging_time': 0.13838791847229004, 'global_step': 3965, 'preemption_count': 0}), (4777, {'train/accuracy': 0.9883701205253601, 'train/loss': 0.040291424840688705, 'train/mean_average_precision': 0.20075425532661081, 'validation/accuracy': 0.9855314493179321, 'validation/loss': 0.04998880997300148, 'validation/mean_average_precision': 0.18313837887554377, 'validation/num_examples': 43793, 'test/accuracy': 0.9846609234809875, 'test/loss': 0.052836447954177856, 'test/mean_average_precision': 0.17774275510360227, 'test/num_examples': 43793, 'score': 1459.9918675422668, 'total_duration': 2455.131016731262, 'accumulated_submission_time': 1459.9918675422668, 'accumulated_eval_time': 994.8498177528381, 'accumulated_logging_time': 0.16654562950134277, 'global_step': 4777, 'preemption_count': 0}), (5587, {'train/accuracy': 0.9884465932846069, 'train/loss': 0.03969131410121918, 'train/mean_average_precision': 0.22177069814333206, 'validation/accuracy': 0.9856182932853699, 'validation/loss': 0.04934554547071457, 'validation/mean_average_precision': 0.1869321901309273, 'validation/num_examples': 43793, 'test/accuracy': 0.9846992492675781, 'test/loss': 0.05211930349469185, 'test/mean_average_precision': 0.195391130551246, 'test/num_examples': 43793, 'score': 1700.1923978328705, 'total_duration': 2814.067674636841, 'accumulated_submission_time': 1700.1923978328705, 'accumulated_eval_time': 1113.539880514145, 'accumulated_logging_time': 0.19261860847473145, 'global_step': 5587, 'preemption_count': 0}), (6398, {'train/accuracy': 0.9889736771583557, 'train/loss': 0.038123201578855515, 'train/mean_average_precision': 0.2349179301416333, 'validation/accuracy': 0.9858220815658569, 'validation/loss': 0.04804627224802971, 'validation/mean_average_precision': 0.1984774781926117, 'validation/num_examples': 43793, 'test/accuracy': 0.9849115014076233, 'test/loss': 0.05060332268476486, 'test/mean_average_precision': 0.20190277384964853, 'test/num_examples': 43793, 'score': 1940.2245869636536, 'total_duration': 3174.423397541046, 'accumulated_submission_time': 1940.2245869636536, 'accumulated_eval_time': 1233.8176052570343, 'accumulated_logging_time': 0.21876311302185059, 'global_step': 6398, 'preemption_count': 0}), (7210, {'train/accuracy': 0.9890118837356567, 'train/loss': 0.03766995668411255, 'train/mean_average_precision': 0.2398642775243317, 'validation/accuracy': 0.9859276413917542, 'validation/loss': 0.047928184270858765, 'validation/mean_average_precision': 0.2053059024384642, 'validation/num_examples': 43793, 'test/accuracy': 0.9849966168403625, 'test/loss': 0.05060633644461632, 'test/mean_average_precision': 0.21350139491207332, 'test/num_examples': 43793, 'score': 2180.274940252304, 'total_duration': 3532.2081785202026, 'accumulated_submission_time': 2180.274940252304, 'accumulated_eval_time': 1351.5040628910065, 'accumulated_logging_time': 0.24683284759521484, 'global_step': 7210, 'preemption_count': 0}), (8015, {'train/accuracy': 0.9890701174736023, 'train/loss': 0.03723662346601486, 'train/mean_average_precision': 0.26311847693002366, 'validation/accuracy': 0.9860911965370178, 'validation/loss': 0.04735775664448738, 'validation/mean_average_precision': 0.2088996544773056, 'validation/num_examples': 43793, 'test/accuracy': 0.9851566553115845, 'test/loss': 0.05012679845094681, 'test/mean_average_precision': 0.2101401705609189, 'test/num_examples': 43793, 'score': 2420.438141107559, 'total_duration': 3888.6747868061066, 'accumulated_submission_time': 2420.438141107559, 'accumulated_eval_time': 1467.7618923187256, 'accumulated_logging_time': 0.2729909420013428, 'global_step': 8015, 'preemption_count': 0}), (8828, {'train/accuracy': 0.9891208410263062, 'train/loss': 0.03691388666629791, 'train/mean_average_precision': 0.26128539831433084, 'validation/accuracy': 0.9860575199127197, 'validation/loss': 0.04710816964507103, 'validation/mean_average_precision': 0.2148633769300631, 'validation/num_examples': 43793, 'test/accuracy': 0.9852033853530884, 'test/loss': 0.04990917444229126, 'test/mean_average_precision': 0.21433318563487957, 'test/num_examples': 43793, 'score': 2660.6300616264343, 'total_duration': 4247.170699596405, 'accumulated_submission_time': 2660.6300616264343, 'accumulated_eval_time': 1586.0149447917938, 'accumulated_logging_time': 0.3037986755371094, 'global_step': 8828, 'preemption_count': 0}), (9646, {'train/accuracy': 0.9893123507499695, 'train/loss': 0.03648633137345314, 'train/mean_average_precision': 0.2645382724796011, 'validation/accuracy': 0.9861553311347961, 'validation/loss': 0.04697838053107262, 'validation/mean_average_precision': 0.2157253602313035, 'validation/num_examples': 43793, 'test/accuracy': 0.9852674007415771, 'test/loss': 0.049749329686164856, 'test/mean_average_precision': 0.21633157402381953, 'test/num_examples': 43793, 'score': 2900.6061305999756, 'total_duration': 4604.35955286026, 'accumulated_submission_time': 2900.6061305999756, 'accumulated_eval_time': 1703.1809272766113, 'accumulated_logging_time': 0.3312511444091797, 'global_step': 9646, 'preemption_count': 0}), (10455, {'train/accuracy': 0.9894191026687622, 'train/loss': 0.03609400615096092, 'train/mean_average_precision': 0.2865384206324179, 'validation/accuracy': 0.9862256050109863, 'validation/loss': 0.04684554040431976, 'validation/mean_average_precision': 0.22356917604668142, 'validation/num_examples': 43793, 'test/accuracy': 0.985323429107666, 'test/loss': 0.04953790456056595, 'test/mean_average_precision': 0.22041907754365606, 'test/num_examples': 43793, 'score': 3140.7301058769226, 'total_duration': 4962.864740371704, 'accumulated_submission_time': 3140.7301058769226, 'accumulated_eval_time': 1821.5141458511353, 'accumulated_logging_time': 0.3597078323364258, 'global_step': 10455, 'preemption_count': 0}), (11266, {'train/accuracy': 0.9895251989364624, 'train/loss': 0.03552322834730148, 'train/mean_average_precision': 0.2967167923105972, 'validation/accuracy': 0.986258864402771, 'validation/loss': 0.04618356376886368, 'validation/mean_average_precision': 0.23176290094448254, 'validation/num_examples': 43793, 'test/accuracy': 0.9854127168655396, 'test/loss': 0.04886827990412712, 'test/mean_average_precision': 0.22687608646803212, 'test/num_examples': 43793, 'score': 3380.84489774704, 'total_duration': 5320.640565872192, 'accumulated_submission_time': 3380.84489774704, 'accumulated_eval_time': 1939.126511335373, 'accumulated_logging_time': 0.3882114887237549, 'global_step': 11266, 'preemption_count': 0}), (12082, {'train/accuracy': 0.9895297288894653, 'train/loss': 0.03553763031959534, 'train/mean_average_precision': 0.29095703409640916, 'validation/accuracy': 0.9862949848175049, 'validation/loss': 0.046071235090494156, 'validation/mean_average_precision': 0.22722639295907104, 'validation/num_examples': 43793, 'test/accuracy': 0.9854207038879395, 'test/loss': 0.04879102110862732, 'test/mean_average_precision': 0.22654920477927487, 'test/num_examples': 43793, 'score': 3620.80961561203, 'total_duration': 5680.152049779892, 'accumulated_submission_time': 3620.80961561203, 'accumulated_eval_time': 2058.625925064087, 'accumulated_logging_time': 0.41527295112609863, 'global_step': 12082, 'preemption_count': 0}), (12882, {'train/accuracy': 0.9894252419471741, 'train/loss': 0.03547088801860809, 'train/mean_average_precision': 0.3050775358934861, 'validation/accuracy': 0.9861180186271667, 'validation/loss': 0.0464729368686676, 'validation/mean_average_precision': 0.22479508294736614, 'validation/num_examples': 43793, 'test/accuracy': 0.9853373169898987, 'test/loss': 0.048980019986629486, 'test/mean_average_precision': 0.2260544465997763, 'test/num_examples': 43793, 'score': 3861.03609418869, 'total_duration': 6036.009812831879, 'accumulated_submission_time': 3861.03609418869, 'accumulated_eval_time': 2174.2098026275635, 'accumulated_logging_time': 0.442767858505249, 'global_step': 12882, 'preemption_count': 0}), (13686, {'train/accuracy': 0.9895843863487244, 'train/loss': 0.035197339951992035, 'train/mean_average_precision': 0.3040051887718651, 'validation/accuracy': 0.986271858215332, 'validation/loss': 0.04618595167994499, 'validation/mean_average_precision': 0.23340475222767337, 'validation/num_examples': 43793, 'test/accuracy': 0.9854274988174438, 'test/loss': 0.04894350469112396, 'test/mean_average_precision': 0.22977608416949577, 'test/num_examples': 43793, 'score': 4100.995650053024, 'total_duration': 6393.8599808216095, 'accumulated_submission_time': 4100.995650053024, 'accumulated_eval_time': 2292.0521154403687, 'accumulated_logging_time': 0.47088122367858887, 'global_step': 13686, 'preemption_count': 0}), (14490, {'train/accuracy': 0.9896256923675537, 'train/loss': 0.03509758412837982, 'train/mean_average_precision': 0.31245645781840997, 'validation/accuracy': 0.9863173365592957, 'validation/loss': 0.046009767800569534, 'validation/mean_average_precision': 0.23576781840168118, 'validation/num_examples': 43793, 'test/accuracy': 0.98543381690979, 'test/loss': 0.04876386746764183, 'test/mean_average_precision': 0.22828556474929557, 'test/num_examples': 43793, 'score': 4341.20063662529, 'total_duration': 6753.788158655167, 'accumulated_submission_time': 4341.20063662529, 'accumulated_eval_time': 2411.727029323578, 'accumulated_logging_time': 0.4989173412322998, 'global_step': 14490, 'preemption_count': 0}), (15299, {'train/accuracy': 0.9898055791854858, 'train/loss': 0.034368254244327545, 'train/mean_average_precision': 0.3225131338005006, 'validation/accuracy': 0.9864476323127747, 'validation/loss': 0.04557877406477928, 'validation/mean_average_precision': 0.24291223686864546, 'validation/num_examples': 43793, 'test/accuracy': 0.9855812191963196, 'test/loss': 0.04829447716474533, 'test/mean_average_precision': 0.24182538198083214, 'test/num_examples': 43793, 'score': 4581.42748093605, 'total_duration': 7114.497435808182, 'accumulated_submission_time': 4581.42748093605, 'accumulated_eval_time': 2532.16131734848, 'accumulated_logging_time': 0.5264565944671631, 'global_step': 15299, 'preemption_count': 0}), (16108, {'train/accuracy': 0.9897297024726868, 'train/loss': 0.0345727801322937, 'train/mean_average_precision': 0.31502869400206335, 'validation/accuracy': 0.986379861831665, 'validation/loss': 0.04576767981052399, 'validation/mean_average_precision': 0.24187853646152457, 'validation/num_examples': 43793, 'test/accuracy': 0.9854687452316284, 'test/loss': 0.04844063147902489, 'test/mean_average_precision': 0.23342012889699956, 'test/num_examples': 43793, 'score': 4821.604562520981, 'total_duration': 7474.735268831253, 'accumulated_submission_time': 4821.604562520981, 'accumulated_eval_time': 2652.174682855606, 'accumulated_logging_time': 0.5535891056060791, 'global_step': 16108, 'preemption_count': 0}), (16908, {'train/accuracy': 0.9896472096443176, 'train/loss': 0.03469448909163475, 'train/mean_average_precision': 0.3334875193006531, 'validation/accuracy': 0.986416757106781, 'validation/loss': 0.04654909297823906, 'validation/mean_average_precision': 0.237449798334552, 'validation/num_examples': 43793, 'test/accuracy': 0.9854261875152588, 'test/loss': 0.04952452331781387, 'test/mean_average_precision': 0.23467114236565567, 'test/num_examples': 43793, 'score': 5061.741016864777, 'total_duration': 7835.508245706558, 'accumulated_submission_time': 5061.741016864777, 'accumulated_eval_time': 2772.764359474182, 'accumulated_logging_time': 0.5806984901428223, 'global_step': 16908, 'preemption_count': 0}), (17707, {'train/accuracy': 0.9898167848587036, 'train/loss': 0.03413078561425209, 'train/mean_average_precision': 0.33301643636648404, 'validation/accuracy': 0.9864492416381836, 'validation/loss': 0.04549198970198631, 'validation/mean_average_precision': 0.2416681358724859, 'validation/num_examples': 43793, 'test/accuracy': 0.9856346845626831, 'test/loss': 0.04810168221592903, 'test/mean_average_precision': 0.23992580592895876, 'test/num_examples': 43793, 'score': 5301.969636917114, 'total_duration': 8197.494507551193, 'accumulated_submission_time': 5301.969636917114, 'accumulated_eval_time': 2894.4724345207214, 'accumulated_logging_time': 0.6092581748962402, 'global_step': 17707, 'preemption_count': 0}), (18513, {'train/accuracy': 0.9900407195091248, 'train/loss': 0.03361191973090172, 'train/mean_average_precision': 0.3292521840163297, 'validation/accuracy': 0.9864256978034973, 'validation/loss': 0.04545723274350166, 'validation/mean_average_precision': 0.24146475887560825, 'validation/num_examples': 43793, 'test/accuracy': 0.9855483770370483, 'test/loss': 0.048102300614118576, 'test/mean_average_precision': 0.23633133314839228, 'test/num_examples': 43793, 'score': 5541.96201634407, 'total_duration': 8554.940137147903, 'accumulated_submission_time': 5541.96201634407, 'accumulated_eval_time': 3011.877057790756, 'accumulated_logging_time': 0.6373209953308105, 'global_step': 18513, 'preemption_count': 0}), (19315, {'train/accuracy': 0.9900639057159424, 'train/loss': 0.03348094969987869, 'train/mean_average_precision': 0.3457457087036121, 'validation/accuracy': 0.9864204525947571, 'validation/loss': 0.0455227792263031, 'validation/mean_average_precision': 0.2419592692715293, 'validation/num_examples': 43793, 'test/accuracy': 0.9855188727378845, 'test/loss': 0.04802831634879112, 'test/mean_average_precision': 0.23403043628169984, 'test/num_examples': 43793, 'score': 5782.166433095932, 'total_duration': 8919.560321807861, 'accumulated_submission_time': 5782.166433095932, 'accumulated_eval_time': 3136.2435569763184, 'accumulated_logging_time': 0.666022539138794, 'global_step': 19315, 'preemption_count': 0}), (20114, {'train/accuracy': 0.9902040362358093, 'train/loss': 0.03292137756943703, 'train/mean_average_precision': 0.34107476389629626, 'validation/accuracy': 0.9865178465843201, 'validation/loss': 0.04509178176522255, 'validation/mean_average_precision': 0.2474738529253242, 'validation/num_examples': 43793, 'test/accuracy': 0.9855892062187195, 'test/loss': 0.04794633761048317, 'test/mean_average_precision': 0.2361131925923404, 'test/num_examples': 43793, 'score': 6022.218946695328, 'total_duration': 9278.812786579132, 'accumulated_submission_time': 6022.218946695328, 'accumulated_eval_time': 3255.395132303238, 'accumulated_logging_time': 0.6938948631286621, 'global_step': 20114, 'preemption_count': 0}), (20915, {'train/accuracy': 0.9901921153068542, 'train/loss': 0.032833244651556015, 'train/mean_average_precision': 0.36167022996321013, 'validation/accuracy': 0.9866693019866943, 'validation/loss': 0.045052655041217804, 'validation/mean_average_precision': 0.24691223584681768, 'validation/num_examples': 43793, 'test/accuracy': 0.9858360290527344, 'test/loss': 0.047784652560949326, 'test/mean_average_precision': 0.24229247663631828, 'test/num_examples': 43793, 'score': 6262.329718351364, 'total_duration': 9637.603274822235, 'accumulated_submission_time': 6262.329718351364, 'accumulated_eval_time': 3374.0255103111267, 'accumulated_logging_time': 0.7228715419769287, 'global_step': 20915, 'preemption_count': 0}), (21685, {'train/accuracy': 0.9902804493904114, 'train/loss': 0.03238203004002571, 'train/mean_average_precision': 0.36169987265257586, 'validation/accuracy': 0.9865775108337402, 'validation/loss': 0.045015059411525726, 'validation/mean_average_precision': 0.24800739676275738, 'validation/num_examples': 43793, 'test/accuracy': 0.9857075810432434, 'test/loss': 0.0476527065038681, 'test/mean_average_precision': 0.24525885014241705, 'test/num_examples': 43793, 'score': 6502.458470821381, 'total_duration': 9999.807790756226, 'accumulated_submission_time': 6502.458470821381, 'accumulated_eval_time': 3496.0495159626007, 'accumulated_logging_time': 0.7540431022644043, 'global_step': 21685, 'preemption_count': 0}), (22487, {'train/accuracy': 0.9903327822685242, 'train/loss': 0.03214234486222267, 'train/mean_average_precision': 0.3777090384321131, 'validation/accuracy': 0.9865458607673645, 'validation/loss': 0.045063186436891556, 'validation/mean_average_precision': 0.24876764334666746, 'validation/num_examples': 43793, 'test/accuracy': 0.9856696724891663, 'test/loss': 0.047757964581251144, 'test/mean_average_precision': 0.2459056515754398, 'test/num_examples': 43793, 'score': 6742.568008184433, 'total_duration': 10362.849860668182, 'accumulated_submission_time': 6742.568008184433, 'accumulated_eval_time': 3618.9286420345306, 'accumulated_logging_time': 0.7853474617004395, 'global_step': 22487, 'preemption_count': 0}), (23289, {'train/accuracy': 0.9904166460037231, 'train/loss': 0.03200071305036545, 'train/mean_average_precision': 0.3798967214932285, 'validation/accuracy': 0.9865365028381348, 'validation/loss': 0.045101284980773926, 'validation/mean_average_precision': 0.25290702655006436, 'validation/num_examples': 43793, 'test/accuracy': 0.9856052398681641, 'test/loss': 0.04792635142803192, 'test/mean_average_precision': 0.24114919698556977, 'test/num_examples': 43793, 'score': 6982.772907733917, 'total_duration': 10722.708332777023, 'accumulated_submission_time': 6982.772907733917, 'accumulated_eval_time': 3738.530680656433, 'accumulated_logging_time': 0.8162612915039062, 'global_step': 23289, 'preemption_count': 0}), (24092, {'train/accuracy': 0.9904586672782898, 'train/loss': 0.0317632220685482, 'train/mean_average_precision': 0.3812432287274077, 'validation/accuracy': 0.9866761565208435, 'validation/loss': 0.04506000503897667, 'validation/mean_average_precision': 0.2522855819840074, 'validation/num_examples': 43793, 'test/accuracy': 0.9857593774795532, 'test/loss': 0.04781632497906685, 'test/mean_average_precision': 0.2474309985986365, 'test/num_examples': 43793, 'score': 7222.812620639801, 'total_duration': 11078.06734585762, 'accumulated_submission_time': 7222.812620639801, 'accumulated_eval_time': 3853.80237531662, 'accumulated_logging_time': 0.8436019420623779, 'global_step': 24092, 'preemption_count': 0}), (24889, {'train/accuracy': 0.990593671798706, 'train/loss': 0.03128660470247269, 'train/mean_average_precision': 0.4036834877808288, 'validation/accuracy': 0.9866505861282349, 'validation/loss': 0.04494381323456764, 'validation/mean_average_precision': 0.2563426920614002, 'validation/num_examples': 43793, 'test/accuracy': 0.9856540560722351, 'test/loss': 0.047728996723890305, 'test/mean_average_precision': 0.2504933925253517, 'test/num_examples': 43793, 'score': 7462.8647129535675, 'total_duration': 11438.8841817379, 'accumulated_submission_time': 7462.8647129535675, 'accumulated_eval_time': 3974.5138549804688, 'accumulated_logging_time': 0.872492790222168, 'global_step': 24889, 'preemption_count': 0}), (25691, {'train/accuracy': 0.9905317425727844, 'train/loss': 0.031591158360242844, 'train/mean_average_precision': 0.40582348287446796, 'validation/accuracy': 0.9864395260810852, 'validation/loss': 0.044990669935941696, 'validation/mean_average_precision': 0.25316924651499445, 'validation/num_examples': 43793, 'test/accuracy': 0.9856073260307312, 'test/loss': 0.04763708636164665, 'test/mean_average_precision': 0.24866514421990052, 'test/num_examples': 43793, 'score': 7702.922703742981, 'total_duration': 11796.068321228027, 'accumulated_submission_time': 7702.922703742981, 'accumulated_eval_time': 4091.589015483856, 'accumulated_logging_time': 0.9030063152313232, 'global_step': 25691, 'preemption_count': 0}), (26501, {'train/accuracy': 0.9906776547431946, 'train/loss': 0.031160177662968636, 'train/mean_average_precision': 0.38478117823430885, 'validation/accuracy': 0.986697256565094, 'validation/loss': 0.04443108290433884, 'validation/mean_average_precision': 0.26084758401881364, 'validation/num_examples': 43793, 'test/accuracy': 0.9858174920082092, 'test/loss': 0.047003548592329025, 'test/mean_average_precision': 0.2522577493853196, 'test/num_examples': 43793, 'score': 7943.094611883163, 'total_duration': 12155.601073265076, 'accumulated_submission_time': 7943.094611883163, 'accumulated_eval_time': 4210.898966789246, 'accumulated_logging_time': 0.9333603382110596, 'global_step': 26501, 'preemption_count': 0}), (27304, {'train/accuracy': 0.9906051158905029, 'train/loss': 0.031287405639886856, 'train/mean_average_precision': 0.39008280964440123, 'validation/accuracy': 0.9867220520973206, 'validation/loss': 0.0448036715388298, 'validation/mean_average_precision': 0.26013396483334067, 'validation/num_examples': 43793, 'test/accuracy': 0.9857977032661438, 'test/loss': 0.047631457448005676, 'test/mean_average_precision': 0.2584049320942328, 'test/num_examples': 43793, 'score': 8183.269677639008, 'total_duration': 12516.774696350098, 'accumulated_submission_time': 8183.269677639008, 'accumulated_eval_time': 4331.848429679871, 'accumulated_logging_time': 0.9616117477416992, 'global_step': 27304, 'preemption_count': 0}), (28105, {'train/accuracy': 0.9906920790672302, 'train/loss': 0.03111342154443264, 'train/mean_average_precision': 0.39355989987326967, 'validation/accuracy': 0.9865706562995911, 'validation/loss': 0.04452333226799965, 'validation/mean_average_precision': 0.25944352835395085, 'validation/num_examples': 43793, 'test/accuracy': 0.9857614636421204, 'test/loss': 0.0472450815141201, 'test/mean_average_precision': 0.25979714903313816, 'test/num_examples': 43793, 'score': 8423.270768642426, 'total_duration': 12873.785564899445, 'accumulated_submission_time': 8423.270768642426, 'accumulated_eval_time': 4448.807866334915, 'accumulated_logging_time': 0.9911422729492188, 'global_step': 28105, 'preemption_count': 0}), (28905, {'train/accuracy': 0.9906162023544312, 'train/loss': 0.031410664319992065, 'train/mean_average_precision': 0.3932863708234818, 'validation/accuracy': 0.9866136312484741, 'validation/loss': 0.04453418403863907, 'validation/mean_average_precision': 0.260449099808771, 'validation/num_examples': 43793, 'test/accuracy': 0.9856266975402832, 'test/loss': 0.04729403927922249, 'test/mean_average_precision': 0.25054739536132165, 'test/num_examples': 43793, 'score': 8663.30679178238, 'total_duration': 13231.128353595734, 'accumulated_submission_time': 8663.30679178238, 'accumulated_eval_time': 4566.064197063446, 'accumulated_logging_time': 1.0210652351379395, 'global_step': 28905, 'preemption_count': 0}), (29712, {'train/accuracy': 0.9907676577568054, 'train/loss': 0.030899884179234505, 'train/mean_average_precision': 0.3986741024077358, 'validation/accuracy': 0.9867419600486755, 'validation/loss': 0.0443255789577961, 'validation/mean_average_precision': 0.2597302343281836, 'validation/num_examples': 43793, 'test/accuracy': 0.9858217239379883, 'test/loss': 0.047150321304798126, 'test/mean_average_precision': 0.2518995441702635, 'test/num_examples': 43793, 'score': 8903.500543117523, 'total_duration': 13590.958433151245, 'accumulated_submission_time': 8903.500543117523, 'accumulated_eval_time': 4685.651364326477, 'accumulated_logging_time': 1.0495333671569824, 'global_step': 29712, 'preemption_count': 0}), (30517, {'train/accuracy': 0.9905664324760437, 'train/loss': 0.031198348850011826, 'train/mean_average_precision': 0.38783654051340644, 'validation/accuracy': 0.9867748022079468, 'validation/loss': 0.0439961738884449, 'validation/mean_average_precision': 0.2665757788639038, 'validation/num_examples': 43793, 'test/accuracy': 0.9860087037086487, 'test/loss': 0.046797990798950195, 'test/mean_average_precision': 0.25804127223452267, 'test/num_examples': 43793, 'score': 9143.683574199677, 'total_duration': 13951.459356546402, 'accumulated_submission_time': 9143.683574199677, 'accumulated_eval_time': 4805.918799638748, 'accumulated_logging_time': 1.0794861316680908, 'global_step': 30517, 'preemption_count': 0}), (31282, {'train/accuracy': 0.9906517267227173, 'train/loss': 0.031064718961715698, 'train/mean_average_precision': 0.40025726768079206, 'validation/accuracy': 0.9868442416191101, 'validation/loss': 0.04441835358738899, 'validation/mean_average_precision': 0.26885799994850995, 'validation/num_examples': 43793, 'test/accuracy': 0.9859362840652466, 'test/loss': 0.04755548760294914, 'test/mean_average_precision': 0.25152940890160963, 'test/num_examples': 43793, 'score': 9383.892793655396, 'total_duration': 14310.127695083618, 'accumulated_submission_time': 9383.892793655396, 'accumulated_eval_time': 4924.328466176987, 'accumulated_logging_time': 1.1089887619018555, 'global_step': 31282, 'preemption_count': 0}), (32088, {'train/accuracy': 0.9907066226005554, 'train/loss': 0.030870866030454636, 'train/mean_average_precision': 0.40536934801238705, 'validation/accuracy': 0.9868454337120056, 'validation/loss': 0.04414380341768265, 'validation/mean_average_precision': 0.266349913505409, 'validation/num_examples': 43793, 'test/accuracy': 0.9860078692436218, 'test/loss': 0.046979185193777084, 'test/mean_average_precision': 0.2602632506597743, 'test/num_examples': 43793, 'score': 9624.135488510132, 'total_duration': 14667.647130012512, 'accumulated_submission_time': 9624.135488510132, 'accumulated_eval_time': 5041.556356430054, 'accumulated_logging_time': 1.1372549533843994, 'global_step': 32088, 'preemption_count': 0}), (32890, {'train/accuracy': 0.9908499717712402, 'train/loss': 0.030452154576778412, 'train/mean_average_precision': 0.41087146431963484, 'validation/accuracy': 0.9866591095924377, 'validation/loss': 0.04421091452240944, 'validation/mean_average_precision': 0.26975505060107274, 'validation/num_examples': 43793, 'test/accuracy': 0.9858633875846863, 'test/loss': 0.046740736812353134, 'test/mean_average_precision': 0.2641553066836875, 'test/num_examples': 43793, 'score': 9864.138288497925, 'total_duration': 15023.617991685867, 'accumulated_submission_time': 9864.138288497925, 'accumulated_eval_time': 5157.473906040192, 'accumulated_logging_time': 1.1674108505249023, 'global_step': 32890, 'preemption_count': 0}), (33692, {'train/accuracy': 0.990959644317627, 'train/loss': 0.03008321300148964, 'train/mean_average_precision': 0.42591783386311277, 'validation/accuracy': 0.986894965171814, 'validation/loss': 0.04384702444076538, 'validation/mean_average_precision': 0.268862412040396, 'validation/num_examples': 43793, 'test/accuracy': 0.9860697984695435, 'test/loss': 0.04663802683353424, 'test/mean_average_precision': 0.26242280128963674, 'test/num_examples': 43793, 'score': 10104.366126537323, 'total_duration': 15382.049540758133, 'accumulated_submission_time': 10104.366126537323, 'accumulated_eval_time': 5275.627857923508, 'accumulated_logging_time': 1.1961736679077148, 'global_step': 33692, 'preemption_count': 0}), (34491, {'train/accuracy': 0.9909486770629883, 'train/loss': 0.030090447515249252, 'train/mean_average_precision': 0.422063504416863, 'validation/accuracy': 0.9868669509887695, 'validation/loss': 0.044136032462120056, 'validation/mean_average_precision': 0.2717689440758293, 'validation/num_examples': 43793, 'test/accuracy': 0.9860184192657471, 'test/loss': 0.046802032738924026, 'test/mean_average_precision': 0.26549055706253527, 'test/num_examples': 43793, 'score': 10344.243387460709, 'total_duration': 15740.40635585785, 'accumulated_submission_time': 10344.243387460709, 'accumulated_eval_time': 5393.7774794101715, 'accumulated_logging_time': 1.5052134990692139, 'global_step': 34491, 'preemption_count': 0}), (35301, {'train/accuracy': 0.9909507036209106, 'train/loss': 0.030007656663656235, 'train/mean_average_precision': 0.41621058367797076, 'validation/accuracy': 0.9868714213371277, 'validation/loss': 0.044038087129592896, 'validation/mean_average_precision': 0.26950994311060966, 'validation/num_examples': 43793, 'test/accuracy': 0.985953152179718, 'test/loss': 0.04704086109995842, 'test/mean_average_precision': 0.26186054097946704, 'test/num_examples': 43793, 'score': 10584.297667741776, 'total_duration': 16095.868485212326, 'accumulated_submission_time': 10584.297667741776, 'accumulated_eval_time': 5509.134773015976, 'accumulated_logging_time': 1.535217046737671, 'global_step': 35301, 'preemption_count': 0}), (36102, {'train/accuracy': 0.9910622835159302, 'train/loss': 0.02962324768304825, 'train/mean_average_precision': 0.4420537200569223, 'validation/accuracy': 0.9867861866950989, 'validation/loss': 0.043832093477249146, 'validation/mean_average_precision': 0.2760404445839678, 'validation/num_examples': 43793, 'test/accuracy': 0.9859316349029541, 'test/loss': 0.046541858464479446, 'test/mean_average_precision': 0.2638355831556632, 'test/num_examples': 43793, 'score': 10824.44524049759, 'total_duration': 16454.22203207016, 'accumulated_submission_time': 10824.44524049759, 'accumulated_eval_time': 5627.290143966675, 'accumulated_logging_time': 1.5657312870025635, 'global_step': 36102, 'preemption_count': 0}), (36905, {'train/accuracy': 0.9912161231040955, 'train/loss': 0.029131349176168442, 'train/mean_average_precision': 0.4341946078622406, 'validation/accuracy': 0.9868279695510864, 'validation/loss': 0.04388804733753204, 'validation/mean_average_precision': 0.27278300213550005, 'validation/num_examples': 43793, 'test/accuracy': 0.9860461950302124, 'test/loss': 0.046655405312776566, 'test/mean_average_precision': 0.2615703244886798, 'test/num_examples': 43793, 'score': 11064.55094218254, 'total_duration': 16809.531289100647, 'accumulated_submission_time': 11064.55094218254, 'accumulated_eval_time': 5742.443549633026, 'accumulated_logging_time': 1.5958011150360107, 'global_step': 36905, 'preemption_count': 0}), (37708, {'train/accuracy': 0.9911729097366333, 'train/loss': 0.029126038774847984, 'train/mean_average_precision': 0.43465958796957527, 'validation/accuracy': 0.9869737029075623, 'validation/loss': 0.043982043862342834, 'validation/mean_average_precision': 0.27213364521255906, 'validation/num_examples': 43793, 'test/accuracy': 0.9862058162689209, 'test/loss': 0.046692799776792526, 'test/mean_average_precision': 0.2642213755927276, 'test/num_examples': 43793, 'score': 11304.71995639801, 'total_duration': 17167.80451154709, 'accumulated_submission_time': 11304.71995639801, 'accumulated_eval_time': 5860.490448236465, 'accumulated_logging_time': 1.6325039863586426, 'global_step': 37708, 'preemption_count': 0}), (38515, {'train/accuracy': 0.9913110733032227, 'train/loss': 0.028675206005573273, 'train/mean_average_precision': 0.4532701397411206, 'validation/accuracy': 0.9870066046714783, 'validation/loss': 0.043889645487070084, 'validation/mean_average_precision': 0.27540190341426884, 'validation/num_examples': 43793, 'test/accuracy': 0.9861574172973633, 'test/loss': 0.04660233482718468, 'test/mean_average_precision': 0.2677591567196427, 'test/num_examples': 43793, 'score': 11544.876920700073, 'total_duration': 17524.579430818558, 'accumulated_submission_time': 11544.876920700073, 'accumulated_eval_time': 5977.058417797089, 'accumulated_logging_time': 1.662172794342041, 'global_step': 38515, 'preemption_count': 0}), (39323, {'train/accuracy': 0.991313099861145, 'train/loss': 0.0285030547529459, 'train/mean_average_precision': 0.4603995903031187, 'validation/accuracy': 0.987025260925293, 'validation/loss': 0.043616004288196564, 'validation/mean_average_precision': 0.28006071241193264, 'validation/num_examples': 43793, 'test/accuracy': 0.9861207604408264, 'test/loss': 0.04663196951150894, 'test/mean_average_precision': 0.26565293580273447, 'test/num_examples': 43793, 'score': 11785.02121591568, 'total_duration': 17880.9883582592, 'accumulated_submission_time': 11785.02121591568, 'accumulated_eval_time': 6093.273400306702, 'accumulated_logging_time': 1.691354751586914, 'global_step': 39323, 'preemption_count': 0}), (40100, {'train/accuracy': 0.9914779663085938, 'train/loss': 0.02809392847120762, 'train/mean_average_precision': 0.4666837057423398, 'validation/accuracy': 0.9870171546936035, 'validation/loss': 0.044153276830911636, 'validation/mean_average_precision': 0.27689153665500765, 'validation/num_examples': 43793, 'test/accuracy': 0.9861767888069153, 'test/loss': 0.04695762321352959, 'test/mean_average_precision': 0.27076288885568567, 'test/num_examples': 43793, 'score': 12025.25090932846, 'total_duration': 18236.93758249283, 'accumulated_submission_time': 12025.25090932846, 'accumulated_eval_time': 6208.943210840225, 'accumulated_logging_time': 1.7215301990509033, 'global_step': 40100, 'preemption_count': 0}), (40905, {'train/accuracy': 0.99159175157547, 'train/loss': 0.027824023738503456, 'train/mean_average_precision': 0.4809402975676566, 'validation/accuracy': 0.9869733452796936, 'validation/loss': 0.04394612833857536, 'validation/mean_average_precision': 0.2773797747661502, 'validation/num_examples': 43793, 'test/accuracy': 0.9861670732498169, 'test/loss': 0.04684828594326973, 'test/mean_average_precision': 0.2682419940073253, 'test/num_examples': 43793, 'score': 12265.333916902542, 'total_duration': 18591.17898917198, 'accumulated_submission_time': 12265.333916902542, 'accumulated_eval_time': 6323.049568891525, 'accumulated_logging_time': 1.7531330585479736, 'global_step': 40905, 'preemption_count': 0}), (41697, {'train/accuracy': 0.991690993309021, 'train/loss': 0.02746974676847458, 'train/mean_average_precision': 0.48252646377440706, 'validation/accuracy': 0.9869489669799805, 'validation/loss': 0.04386945068836212, 'validation/mean_average_precision': 0.276292395426865, 'validation/num_examples': 43793, 'test/accuracy': 0.9860900044441223, 'test/loss': 0.04675828665494919, 'test/mean_average_precision': 0.26951874910829016, 'test/num_examples': 43793, 'score': 12505.492862939835, 'total_duration': 18946.83656311035, 'accumulated_submission_time': 12505.492862939835, 'accumulated_eval_time': 6438.4959943294525, 'accumulated_logging_time': 1.783900499343872, 'global_step': 41697, 'preemption_count': 0}), (42489, {'train/accuracy': 0.9918253421783447, 'train/loss': 0.02702687494456768, 'train/mean_average_precision': 0.5020348541304076, 'validation/accuracy': 0.9869607090950012, 'validation/loss': 0.043892014771699905, 'validation/mean_average_precision': 0.27548950655669785, 'validation/num_examples': 43793, 'test/accuracy': 0.9861548542976379, 'test/loss': 0.046674396842718124, 'test/mean_average_precision': 0.2707714665254074, 'test/num_examples': 43793, 'score': 12745.479783058167, 'total_duration': 19307.35587310791, 'accumulated_submission_time': 12745.479783058167, 'accumulated_eval_time': 6558.977596759796, 'accumulated_logging_time': 1.8147785663604736, 'global_step': 42489, 'preemption_count': 0}), (43290, {'train/accuracy': 0.991926372051239, 'train/loss': 0.02652258425951004, 'train/mean_average_precision': 0.500133610940606, 'validation/accuracy': 0.9871036410331726, 'validation/loss': 0.04388105869293213, 'validation/mean_average_precision': 0.2817920888343989, 'validation/num_examples': 43793, 'test/accuracy': 0.9862323999404907, 'test/loss': 0.04668118804693222, 'test/mean_average_precision': 0.27378587329587795, 'test/num_examples': 43793, 'score': 12985.692975997925, 'total_duration': 19663.1316511631, 'accumulated_submission_time': 12985.692975997925, 'accumulated_eval_time': 6674.488714456558, 'accumulated_logging_time': 1.845799207687378, 'global_step': 43290, 'preemption_count': 0}), (44095, {'train/accuracy': 0.9919463396072388, 'train/loss': 0.026412740349769592, 'train/mean_average_precision': 0.5125865507853793, 'validation/accuracy': 0.9869989156723022, 'validation/loss': 0.04396924749016762, 'validation/mean_average_precision': 0.28133133965131774, 'validation/num_examples': 43793, 'test/accuracy': 0.9861599206924438, 'test/loss': 0.04687561094760895, 'test/mean_average_precision': 0.2723896809814793, 'test/num_examples': 43793, 'score': 13225.688195943832, 'total_duration': 20020.444877386093, 'accumulated_submission_time': 13225.688195943832, 'accumulated_eval_time': 6791.755942583084, 'accumulated_logging_time': 1.8759524822235107, 'global_step': 44095, 'preemption_count': 0}), (44894, {'train/accuracy': 0.9921253323554993, 'train/loss': 0.0258957389742136, 'train/mean_average_precision': 0.5274417351894362, 'validation/accuracy': 0.986997663974762, 'validation/loss': 0.04408834129571915, 'validation/mean_average_precision': 0.2798952488124757, 'validation/num_examples': 43793, 'test/accuracy': 0.9861388802528381, 'test/loss': 0.04690347611904144, 'test/mean_average_precision': 0.27196203256157236, 'test/num_examples': 43793, 'score': 13465.81727361679, 'total_duration': 20376.97470331192, 'accumulated_submission_time': 13465.81727361679, 'accumulated_eval_time': 6908.105998754501, 'accumulated_logging_time': 1.9063105583190918, 'global_step': 44894, 'preemption_count': 0}), (45701, {'train/accuracy': 0.9923860430717468, 'train/loss': 0.025061296299099922, 'train/mean_average_precision': 0.544396729755047, 'validation/accuracy': 0.9871178269386292, 'validation/loss': 0.04403109848499298, 'validation/mean_average_precision': 0.2788353045437888, 'validation/num_examples': 43793, 'test/accuracy': 0.9862593412399292, 'test/loss': 0.04694725573062897, 'test/mean_average_precision': 0.2771417963157735, 'test/num_examples': 43793, 'score': 13705.983646392822, 'total_duration': 20730.17310166359, 'accumulated_submission_time': 13705.983646392822, 'accumulated_eval_time': 7021.08579492569, 'accumulated_logging_time': 1.9382295608520508, 'global_step': 45701, 'preemption_count': 0}), (46493, {'train/accuracy': 0.9923943281173706, 'train/loss': 0.025010382756590843, 'train/mean_average_precision': 0.5558541752889394, 'validation/accuracy': 0.9869339466094971, 'validation/loss': 0.04429585486650467, 'validation/mean_average_precision': 0.28067874416990524, 'validation/num_examples': 43793, 'test/accuracy': 0.9861578345298767, 'test/loss': 0.04711482673883438, 'test/mean_average_precision': 0.27500759447516127, 'test/num_examples': 43793, 'score': 13946.215344667435, 'total_duration': 21089.466974258423, 'accumulated_submission_time': 13946.215344667435, 'accumulated_eval_time': 7140.096159934998, 'accumulated_logging_time': 1.9698936939239502, 'global_step': 46493, 'preemption_count': 0}), (47289, {'train/accuracy': 0.9925546050071716, 'train/loss': 0.02443597838282585, 'train/mean_average_precision': 0.5603245341514393, 'validation/accuracy': 0.9870212078094482, 'validation/loss': 0.04425477609038353, 'validation/mean_average_precision': 0.27881796437874984, 'validation/num_examples': 43793, 'test/accuracy': 0.986214280128479, 'test/loss': 0.047055650502443314, 'test/mean_average_precision': 0.2745095251535885, 'test/num_examples': 43793, 'score': 14186.285210132599, 'total_duration': 21446.986362457275, 'accumulated_submission_time': 14186.285210132599, 'accumulated_eval_time': 7257.493173122406, 'accumulated_logging_time': 2.0020265579223633, 'global_step': 47289, 'preemption_count': 0}), (48092, {'train/accuracy': 0.9926342368125916, 'train/loss': 0.02426978573203087, 'train/mean_average_precision': 0.5552311478682642, 'validation/accuracy': 0.987153947353363, 'validation/loss': 0.044016726315021515, 'validation/mean_average_precision': 0.2843239468740543, 'validation/num_examples': 43793, 'test/accuracy': 0.9862285852432251, 'test/loss': 0.046874240040779114, 'test/mean_average_precision': 0.2762326809136221, 'test/num_examples': 43793, 'score': 14426.411679029465, 'total_duration': 21804.61886739731, 'accumulated_submission_time': 14426.411679029465, 'accumulated_eval_time': 7374.949022531509, 'accumulated_logging_time': 2.032355546951294, 'global_step': 48092, 'preemption_count': 0}), (48896, {'train/accuracy': 0.9927313327789307, 'train/loss': 0.023883545771241188, 'train/mean_average_precision': 0.5718605383754497, 'validation/accuracy': 0.9871352910995483, 'validation/loss': 0.04433589428663254, 'validation/mean_average_precision': 0.2819300844568879, 'validation/num_examples': 43793, 'test/accuracy': 0.986268162727356, 'test/loss': 0.04721706733107567, 'test/mean_average_precision': 0.2796114318798893, 'test/num_examples': 43793, 'score': 14666.668749570847, 'total_duration': 22154.354904174805, 'accumulated_submission_time': 14666.668749570847, 'accumulated_eval_time': 7484.377660512924, 'accumulated_logging_time': 2.0628912448883057, 'global_step': 48896, 'preemption_count': 0}), (49706, {'train/accuracy': 0.9928947687149048, 'train/loss': 0.023473793640732765, 'train/mean_average_precision': 0.5778326863214858, 'validation/accuracy': 0.9870362281799316, 'validation/loss': 0.04449714347720146, 'validation/mean_average_precision': 0.2845194402876295, 'validation/num_examples': 43793, 'test/accuracy': 0.9861615896224976, 'test/loss': 0.04741447791457176, 'test/mean_average_precision': 0.27202136972686014, 'test/num_examples': 43793, 'score': 14906.865149497986, 'total_duration': 22509.97501564026, 'accumulated_submission_time': 14906.865149497986, 'accumulated_eval_time': 7599.751002073288, 'accumulated_logging_time': 2.093366861343384, 'global_step': 49706, 'preemption_count': 0}), (50515, {'train/accuracy': 0.9929825663566589, 'train/loss': 0.02328301966190338, 'train/mean_average_precision': 0.593450051311089, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04429353401064873, 'validation/mean_average_precision': 0.2846719079451756, 'validation/num_examples': 43793, 'test/accuracy': 0.9863090515136719, 'test/loss': 0.04722001776099205, 'test/mean_average_precision': 0.27595725081776806, 'test/num_examples': 43793, 'score': 15147.084553956985, 'total_duration': 22864.46127462387, 'accumulated_submission_time': 15147.084553956985, 'accumulated_eval_time': 7713.966383218765, 'accumulated_logging_time': 2.124816417694092, 'global_step': 50515, 'preemption_count': 0}), (51318, {'train/accuracy': 0.9929440021514893, 'train/loss': 0.023267265409231186, 'train/mean_average_precision': 0.5915164042765131, 'validation/accuracy': 0.9870508313179016, 'validation/loss': 0.04445941001176834, 'validation/mean_average_precision': 0.28038965042115216, 'validation/num_examples': 43793, 'test/accuracy': 0.9862285852432251, 'test/loss': 0.047378383576869965, 'test/mean_average_precision': 0.2771135049515942, 'test/num_examples': 43793, 'score': 15387.17203593254, 'total_duration': 23221.18435025215, 'accumulated_submission_time': 15387.17203593254, 'accumulated_eval_time': 7830.548970460892, 'accumulated_logging_time': 2.157545566558838, 'global_step': 51318, 'preemption_count': 0}), (52116, {'train/accuracy': 0.9929519891738892, 'train/loss': 0.02312520146369934, 'train/mean_average_precision': 0.5874984056136354, 'validation/accuracy': 0.9871340990066528, 'validation/loss': 0.04432467743754387, 'validation/mean_average_precision': 0.28806774429424764, 'validation/num_examples': 43793, 'test/accuracy': 0.9862744808197021, 'test/loss': 0.04726393148303032, 'test/mean_average_precision': 0.2797398962344857, 'test/num_examples': 43793, 'score': 15627.323832988739, 'total_duration': 23580.198765039444, 'accumulated_submission_time': 15627.323832988739, 'accumulated_eval_time': 7949.361320257187, 'accumulated_logging_time': 2.1882736682891846, 'global_step': 52116, 'preemption_count': 0}), (52918, {'train/accuracy': 0.9930144548416138, 'train/loss': 0.023031149059534073, 'train/mean_average_precision': 0.5870615159635201, 'validation/accuracy': 0.987106442451477, 'validation/loss': 0.04474416375160217, 'validation/mean_average_precision': 0.2841183988113131, 'validation/num_examples': 43793, 'test/accuracy': 0.9862787127494812, 'test/loss': 0.04757234454154968, 'test/mean_average_precision': 0.27971161989533533, 'test/num_examples': 43793, 'score': 15867.316489696503, 'total_duration': 23936.761212348938, 'accumulated_submission_time': 15867.316489696503, 'accumulated_eval_time': 8065.878739833832, 'accumulated_logging_time': 2.220555067062378, 'global_step': 52918, 'preemption_count': 0}), (53725, {'train/accuracy': 0.9931383728981018, 'train/loss': 0.02272367663681507, 'train/mean_average_precision': 0.6022293814190338, 'validation/accuracy': 0.9871269464492798, 'validation/loss': 0.04455486312508583, 'validation/mean_average_precision': 0.285360844400321, 'validation/num_examples': 43793, 'test/accuracy': 0.9862610101699829, 'test/loss': 0.047440215945243835, 'test/mean_average_precision': 0.27731181284116074, 'test/num_examples': 43793, 'score': 16107.51065826416, 'total_duration': 24291.192872285843, 'accumulated_submission_time': 16107.51065826416, 'accumulated_eval_time': 8180.06339931488, 'accumulated_logging_time': 2.252974271774292, 'global_step': 53725, 'preemption_count': 0}), (54527, {'train/accuracy': 0.9931251406669617, 'train/loss': 0.022641677409410477, 'train/mean_average_precision': 0.6076571028786262, 'validation/accuracy': 0.9871287941932678, 'validation/loss': 0.044688351452350616, 'validation/mean_average_precision': 0.2884000268612941, 'validation/num_examples': 43793, 'test/accuracy': 0.9862395524978638, 'test/loss': 0.04768885672092438, 'test/mean_average_precision': 0.27851998307997644, 'test/num_examples': 43793, 'score': 16347.757538318634, 'total_duration': 24642.439792633057, 'accumulated_submission_time': 16347.757538318634, 'accumulated_eval_time': 8291.01169705391, 'accumulated_logging_time': 2.284498453140259, 'global_step': 54527, 'preemption_count': 0}), (55337, {'train/accuracy': 0.9931420087814331, 'train/loss': 0.022613918408751488, 'train/mean_average_precision': 0.6031121853587724, 'validation/accuracy': 0.9871211051940918, 'validation/loss': 0.04463699460029602, 'validation/mean_average_precision': 0.2870607012805973, 'validation/num_examples': 43793, 'test/accuracy': 0.9862585067749023, 'test/loss': 0.04758983105421066, 'test/mean_average_precision': 0.2787665003113842, 'test/num_examples': 43793, 'score': 16587.9323387146, 'total_duration': 25000.97297644615, 'accumulated_submission_time': 16587.9323387146, 'accumulated_eval_time': 8409.317105770111, 'accumulated_logging_time': 2.317509412765503, 'global_step': 55337, 'preemption_count': 0}), (56138, {'train/accuracy': 0.9931641817092896, 'train/loss': 0.022553671151399612, 'train/mean_average_precision': 0.5970061701388318, 'validation/accuracy': 0.9871296286582947, 'validation/loss': 0.044749077409505844, 'validation/mean_average_precision': 0.2870641637165094, 'validation/num_examples': 43793, 'test/accuracy': 0.9862576723098755, 'test/loss': 0.04776632413268089, 'test/mean_average_precision': 0.28008036900261646, 'test/num_examples': 43793, 'score': 16828.094554424286, 'total_duration': 25354.335829734802, 'accumulated_submission_time': 16828.094554424286, 'accumulated_eval_time': 8522.463761806488, 'accumulated_logging_time': 2.351247549057007, 'global_step': 56138, 'preemption_count': 0}), (56939, {'train/accuracy': 0.9931225180625916, 'train/loss': 0.02266804315149784, 'train/mean_average_precision': 0.6018605240359625, 'validation/accuracy': 0.9871299862861633, 'validation/loss': 0.04467529058456421, 'validation/mean_average_precision': 0.2872979678903459, 'validation/num_examples': 43793, 'test/accuracy': 0.986282467842102, 'test/loss': 0.047671858221292496, 'test/mean_average_precision': 0.28036413821063483, 'test/num_examples': 43793, 'score': 17068.321801185608, 'total_duration': 25706.910608768463, 'accumulated_submission_time': 17068.321801185608, 'accumulated_eval_time': 8634.758631944656, 'accumulated_logging_time': 2.3836841583251953, 'global_step': 56939, 'preemption_count': 0}), (57748, {'train/accuracy': 0.9932647943496704, 'train/loss': 0.022245002910494804, 'train/mean_average_precision': 0.6067731179136278, 'validation/accuracy': 0.9871702194213867, 'validation/loss': 0.04471084102988243, 'validation/mean_average_precision': 0.2871020006283302, 'validation/num_examples': 43793, 'test/accuracy': 0.9863107204437256, 'test/loss': 0.04770280048251152, 'test/mean_average_precision': 0.28026811313528477, 'test/num_examples': 43793, 'score': 17308.312358617783, 'total_duration': 26060.3670027256, 'accumulated_submission_time': 17308.312358617783, 'accumulated_eval_time': 8748.173397064209, 'accumulated_logging_time': 2.4148707389831543, 'global_step': 57748, 'preemption_count': 0}), (58534, {'train/accuracy': 0.9932355880737305, 'train/loss': 0.022261090576648712, 'train/mean_average_precision': 0.6178622360076718, 'validation/accuracy': 0.987131655216217, 'validation/loss': 0.044713929295539856, 'validation/mean_average_precision': 0.28784321534360646, 'validation/num_examples': 43793, 'test/accuracy': 0.9863073229789734, 'test/loss': 0.04769863188266754, 'test/mean_average_precision': 0.2802668372362473, 'test/num_examples': 43793, 'score': 17548.26337003708, 'total_duration': 26416.47491788864, 'accumulated_submission_time': 17548.26337003708, 'accumulated_eval_time': 8864.271213769913, 'accumulated_logging_time': 2.449326515197754, 'global_step': 58534, 'preemption_count': 0}), (59341, {'train/accuracy': 0.993293285369873, 'train/loss': 0.022195057943463326, 'train/mean_average_precision': 0.601180504078912, 'validation/accuracy': 0.9871352910995483, 'validation/loss': 0.04474446177482605, 'validation/mean_average_precision': 0.28794393499347676, 'validation/num_examples': 43793, 'test/accuracy': 0.9863098859786987, 'test/loss': 0.04773981124162674, 'test/mean_average_precision': 0.2803615214382558, 'test/num_examples': 43793, 'score': 17788.325407505035, 'total_duration': 26772.70242524147, 'accumulated_submission_time': 17788.325407505035, 'accumulated_eval_time': 8980.384490013123, 'accumulated_logging_time': 2.4813530445098877, 'global_step': 59341, 'preemption_count': 0}), (60146, {'train/accuracy': 0.9932788014411926, 'train/loss': 0.022192470729351044, 'train/mean_average_precision': 0.6098885446263707, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04474251717329025, 'validation/mean_average_precision': 0.28814181325092886, 'validation/num_examples': 43793, 'test/accuracy': 0.9862951040267944, 'test/loss': 0.04773058369755745, 'test/mean_average_precision': 0.2804849067881474, 'test/num_examples': 43793, 'score': 18028.340656995773, 'total_duration': 27123.247985363007, 'accumulated_submission_time': 18028.340656995773, 'accumulated_eval_time': 9090.861245632172, 'accumulated_logging_time': 2.5141851902008057, 'global_step': 60146, 'preemption_count': 0}), (60947, {'train/accuracy': 0.9931958913803101, 'train/loss': 0.022368598729372025, 'train/mean_average_precision': 0.6026620392714828, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04474251717329025, 'validation/mean_average_precision': 0.2881028970050903, 'validation/num_examples': 43793, 'test/accuracy': 0.9862951040267944, 'test/loss': 0.04773058369755745, 'test/mean_average_precision': 0.28056115923477914, 'test/num_examples': 43793, 'score': 18268.41448521614, 'total_duration': 27477.049141407013, 'accumulated_submission_time': 18268.41448521614, 'accumulated_eval_time': 9204.535899400711, 'accumulated_logging_time': 2.5469765663146973, 'global_step': 60947, 'preemption_count': 0})], 'global_step': 61644}
I0215 19:42:26.812608 140558855219008 submission_runner.py:586] Timing: 18477.156198740005
I0215 19:42:26.812668 140558855219008 submission_runner.py:588] Total number of evals: 77
I0215 19:42:26.812709 140558855219008 submission_runner.py:589] ====================
I0215 19:42:26.813124 140558855219008 submission_runner.py:673] Final ogbg_gelu score: 18477.156198740005

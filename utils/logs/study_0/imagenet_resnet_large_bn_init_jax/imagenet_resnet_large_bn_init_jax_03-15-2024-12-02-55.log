python3 submission_runner.py --framework=jax --workload=imagenet_resnet_large_bn_init --submission_path=reference_algorithms/target_setting_algorithms/jax_momentum.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=2511472366 --max_global_steps=186666 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_resnet_large_bn_init/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/imagenet_resnet_large_bn_init_jax_03-15-2024-12-02-55.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0315 12:03:17.390809 140219736737600 logger_utils.py:61] Removing existing experiment directory /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax because --overwrite was set.
I0315 12:03:17.400762 140219736737600 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax.
I0315 12:03:18.486286 140219736737600 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0315 12:03:18.487922 140219736737600 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0315 12:03:18.488139 140219736737600 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0315 12:03:18.495402 140219736737600 submission_runner.py:554] Using RNG seed 2511472366
I0315 12:03:19.625845 140219736737600 submission_runner.py:563] --- Tuning run 1/1 ---
I0315 12:03:19.626086 140219736737600 submission_runner.py:568] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1.
I0315 12:03:19.626317 140219736737600 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1/hparams.json.
I0315 12:03:19.814865 140219736737600 submission_runner.py:209] Initializing dataset.
I0315 12:03:19.832631 140219736737600 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:03:19.843896 140219736737600 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 12:03:20.253274 140219736737600 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:03:21.520813 140219736737600 submission_runner.py:220] Initializing model.
I0315 12:03:32.978362 140219736737600 submission_runner.py:262] Initializing optimizer.
I0315 12:03:34.565910 140219736737600 submission_runner.py:269] Initializing metrics bundle.
I0315 12:03:34.566173 140219736737600 submission_runner.py:287] Initializing checkpoint and logger.
I0315 12:03:34.567790 140219736737600 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1 with prefix checkpoint_
I0315 12:03:34.567978 140219736737600 submission_runner.py:307] Saving meta data to /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0315 12:03:34.903231 140219736737600 logger_utils.py:220] Unable to record git information. Continuing without it.
I0315 12:03:35.227361 140219736737600 submission_runner.py:311] Saving flags to /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1/flags_0.json.
I0315 12:03:35.237580 140219736737600 submission_runner.py:321] Starting training loop.
I0315 12:04:22.522588 140056153007872 logging_writer.py:48] [0] global_step=0, grad_norm=110.12958526611328, loss=10.539152145385742
I0315 12:04:22.540508 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:04:23.550409 140219736737600 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:04:23.560553 140219736737600 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 12:04:23.651898 140219736737600 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:04:36.989386 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:04:38.387104 140219736737600 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:04:38.408387 140219736737600 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 12:04:38.471377 140219736737600 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 12:04:54.443399 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:04:55.229847 140219736737600 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0315 12:04:55.234920 140219736737600 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0315 12:04:55.273695 140219736737600 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0315 12:04:59.328634 140219736737600 submission_runner.py:420] Time since start: 84.09s, 	Step: 1, 	{'train/accuracy': 0.0009566326625645161, 'train/loss': 681.6714477539062, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 691.8001708984375, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 681.23779296875, 'test/num_examples': 10000, 'score': 47.302772998809814, 'total_duration': 84.09100985527039, 'accumulated_submission_time': 47.302772998809814, 'accumulated_eval_time': 36.78810667991638, 'accumulated_logging_time': 0}
I0315 12:04:59.345942 140034044847872 logging_writer.py:48] [1] accumulated_eval_time=36.788107, accumulated_logging_time=0, accumulated_submission_time=47.302773, global_step=1, preemption_count=0, score=47.302773, test/accuracy=0.001000, test/loss=681.237793, test/num_examples=10000, total_duration=84.091010, train/accuracy=0.000957, train/loss=681.671448, validation/accuracy=0.001000, validation/loss=691.800171, validation/num_examples=50000
I0315 12:04:59.690367 140034036455168 logging_writer.py:48] [1] global_step=1, grad_norm=109.14598846435547, loss=10.500322341918945
I0315 12:05:00.031319 140034044847872 logging_writer.py:48] [2] global_step=2, grad_norm=106.09832763671875, loss=9.68880844116211
I0315 12:05:00.378532 140034036455168 logging_writer.py:48] [3] global_step=3, grad_norm=98.64964294433594, loss=9.099207878112793
I0315 12:05:00.717729 140034044847872 logging_writer.py:48] [4] global_step=4, grad_norm=87.7542724609375, loss=8.648146629333496
I0315 12:05:01.055947 140034036455168 logging_writer.py:48] [5] global_step=5, grad_norm=79.14735412597656, loss=8.725980758666992
I0315 12:05:01.393926 140034044847872 logging_writer.py:48] [6] global_step=6, grad_norm=84.28401184082031, loss=8.915140151977539
I0315 12:05:01.731438 140034036455168 logging_writer.py:48] [7] global_step=7, grad_norm=86.15602111816406, loss=9.809996604919434
I0315 12:05:02.067526 140034044847872 logging_writer.py:48] [8] global_step=8, grad_norm=54.924781799316406, loss=10.81582260131836
I0315 12:05:02.404326 140034036455168 logging_writer.py:48] [9] global_step=9, grad_norm=58.62532043457031, loss=11.342966079711914
I0315 12:05:02.741715 140034044847872 logging_writer.py:48] [10] global_step=10, grad_norm=46.203102111816406, loss=11.096624374389648
I0315 12:05:03.080032 140034036455168 logging_writer.py:48] [11] global_step=11, grad_norm=46.36651611328125, loss=11.114083290100098
I0315 12:05:03.419092 140034044847872 logging_writer.py:48] [12] global_step=12, grad_norm=58.43056869506836, loss=11.146648406982422
I0315 12:05:03.757677 140034036455168 logging_writer.py:48] [13] global_step=13, grad_norm=46.928470611572266, loss=11.633235931396484
I0315 12:05:04.096088 140034044847872 logging_writer.py:48] [14] global_step=14, grad_norm=49.35122299194336, loss=11.86830997467041
I0315 12:05:04.432774 140034036455168 logging_writer.py:48] [15] global_step=15, grad_norm=37.932926177978516, loss=12.141894340515137
I0315 12:05:04.770970 140034044847872 logging_writer.py:48] [16] global_step=16, grad_norm=37.06816864013672, loss=14.519274711608887
I0315 12:05:05.115408 140034036455168 logging_writer.py:48] [17] global_step=17, grad_norm=50.03487014770508, loss=12.113905906677246
I0315 12:05:05.453115 140034044847872 logging_writer.py:48] [18] global_step=18, grad_norm=24.38686752319336, loss=11.81525707244873
I0315 12:05:05.791330 140034036455168 logging_writer.py:48] [19] global_step=19, grad_norm=52.744441986083984, loss=14.146544456481934
I0315 12:05:06.132490 140034044847872 logging_writer.py:48] [20] global_step=20, grad_norm=137.15402221679688, loss=17.06582260131836
I0315 12:05:06.468347 140034036455168 logging_writer.py:48] [21] global_step=21, grad_norm=120.84618377685547, loss=13.397282600402832
I0315 12:05:06.814448 140034044847872 logging_writer.py:48] [22] global_step=22, grad_norm=35.256587982177734, loss=14.542657852172852
I0315 12:05:07.155519 140034036455168 logging_writer.py:48] [23] global_step=23, grad_norm=267.1908874511719, loss=14.82182502746582
I0315 12:05:07.496866 140034044847872 logging_writer.py:48] [24] global_step=24, grad_norm=34.476806640625, loss=15.624079704284668
I0315 12:05:07.835118 140034036455168 logging_writer.py:48] [25] global_step=25, grad_norm=28.071670532226562, loss=18.112836837768555
I0315 12:05:08.174762 140034044847872 logging_writer.py:48] [26] global_step=26, grad_norm=30.933679580688477, loss=14.651890754699707
I0315 12:05:08.510863 140034036455168 logging_writer.py:48] [27] global_step=27, grad_norm=28.293333053588867, loss=12.851248741149902
I0315 12:05:08.845539 140034044847872 logging_writer.py:48] [28] global_step=28, grad_norm=21.20677375793457, loss=12.862667083740234
I0315 12:05:09.183304 140034036455168 logging_writer.py:48] [29] global_step=29, grad_norm=32.242408752441406, loss=12.82274055480957
I0315 12:05:09.520155 140034044847872 logging_writer.py:48] [30] global_step=30, grad_norm=40.84721374511719, loss=13.706700325012207
I0315 12:05:09.857470 140034036455168 logging_writer.py:48] [31] global_step=31, grad_norm=67.43601989746094, loss=13.915628433227539
I0315 12:05:10.201544 140034044847872 logging_writer.py:48] [32] global_step=32, grad_norm=33.63737106323242, loss=14.731132507324219
I0315 12:05:10.541099 140034036455168 logging_writer.py:48] [33] global_step=33, grad_norm=20.789371490478516, loss=12.875202178955078
I0315 12:05:10.877514 140034044847872 logging_writer.py:48] [34] global_step=34, grad_norm=19.914695739746094, loss=16.693897247314453
I0315 12:05:11.215525 140034036455168 logging_writer.py:48] [35] global_step=35, grad_norm=16.192461013793945, loss=13.260231971740723
I0315 12:05:11.552358 140034044847872 logging_writer.py:48] [36] global_step=36, grad_norm=13.60159683227539, loss=12.810141563415527
I0315 12:05:11.885739 140034036455168 logging_writer.py:48] [37] global_step=37, grad_norm=22.35137176513672, loss=14.753697395324707
I0315 12:05:12.224066 140034044847872 logging_writer.py:48] [38] global_step=38, grad_norm=16.344411849975586, loss=11.095258712768555
I0315 12:05:12.561234 140034036455168 logging_writer.py:48] [39] global_step=39, grad_norm=20.02068519592285, loss=11.079163551330566
I0315 12:05:12.903390 140034044847872 logging_writer.py:48] [40] global_step=40, grad_norm=17.59893035888672, loss=11.295836448669434
I0315 12:05:13.238153 140034036455168 logging_writer.py:48] [41] global_step=41, grad_norm=11.16663646697998, loss=13.764284133911133
I0315 12:05:13.576217 140034044847872 logging_writer.py:48] [42] global_step=42, grad_norm=10.253331184387207, loss=11.109880447387695
I0315 12:05:13.912853 140034036455168 logging_writer.py:48] [43] global_step=43, grad_norm=6.947107315063477, loss=11.37785816192627
I0315 12:05:14.254937 140034044847872 logging_writer.py:48] [44] global_step=44, grad_norm=9.636163711547852, loss=12.843873023986816
I0315 12:05:14.592051 140034036455168 logging_writer.py:48] [45] global_step=45, grad_norm=7.7955780029296875, loss=10.874824523925781
I0315 12:05:14.928812 140034044847872 logging_writer.py:48] [46] global_step=46, grad_norm=9.097387313842773, loss=9.895076751708984
I0315 12:05:15.266664 140034036455168 logging_writer.py:48] [47] global_step=47, grad_norm=7.520582675933838, loss=10.902931213378906
I0315 12:05:15.606058 140034044847872 logging_writer.py:48] [48] global_step=48, grad_norm=18.262615203857422, loss=12.171943664550781
I0315 12:05:15.944355 140034036455168 logging_writer.py:48] [49] global_step=49, grad_norm=9.287121772766113, loss=10.724518775939941
I0315 12:05:16.282277 140034044847872 logging_writer.py:48] [50] global_step=50, grad_norm=36.39653778076172, loss=11.93966007232666
I0315 12:05:16.620802 140034036455168 logging_writer.py:48] [51] global_step=51, grad_norm=9.160849571228027, loss=12.964371681213379
I0315 12:05:16.955419 140034044847872 logging_writer.py:48] [52] global_step=52, grad_norm=13.697916030883789, loss=13.507074356079102
I0315 12:05:17.301815 140034036455168 logging_writer.py:48] [53] global_step=53, grad_norm=17.393552780151367, loss=14.979143142700195
I0315 12:05:17.643753 140034044847872 logging_writer.py:48] [54] global_step=54, grad_norm=43.104190826416016, loss=16.63349151611328
I0315 12:05:17.981471 140034036455168 logging_writer.py:48] [55] global_step=55, grad_norm=10.7920560836792, loss=11.939886093139648
I0315 12:05:18.321492 140034044847872 logging_writer.py:48] [56] global_step=56, grad_norm=20.662277221679688, loss=16.413360595703125
I0315 12:05:18.660744 140034036455168 logging_writer.py:48] [57] global_step=57, grad_norm=13.244574546813965, loss=14.344196319580078
I0315 12:05:18.997795 140034044847872 logging_writer.py:48] [58] global_step=58, grad_norm=6.325756072998047, loss=12.757261276245117
I0315 12:05:19.336388 140034036455168 logging_writer.py:48] [59] global_step=59, grad_norm=15.575645446777344, loss=12.448738098144531
I0315 12:05:19.671672 140034044847872 logging_writer.py:48] [60] global_step=60, grad_norm=9.59711742401123, loss=12.620474815368652
I0315 12:05:20.006019 140034036455168 logging_writer.py:48] [61] global_step=61, grad_norm=142.58804321289062, loss=15.695125579833984
I0315 12:05:20.342806 140034044847872 logging_writer.py:48] [62] global_step=62, grad_norm=12.879083633422852, loss=13.440568923950195
I0315 12:05:20.677399 140034036455168 logging_writer.py:48] [63] global_step=63, grad_norm=12.24068832397461, loss=13.57370662689209
I0315 12:05:21.015444 140034044847872 logging_writer.py:48] [64] global_step=64, grad_norm=13.962638854980469, loss=15.87292194366455
I0315 12:05:21.353326 140034036455168 logging_writer.py:48] [65] global_step=65, grad_norm=11.116621017456055, loss=12.725030899047852
I0315 12:05:21.693210 140034044847872 logging_writer.py:48] [66] global_step=66, grad_norm=10.740110397338867, loss=11.45545482635498
I0315 12:05:22.030279 140034036455168 logging_writer.py:48] [67] global_step=67, grad_norm=7.146587371826172, loss=11.980447769165039
I0315 12:05:22.369024 140034044847872 logging_writer.py:48] [68] global_step=68, grad_norm=10.503283500671387, loss=14.732037544250488
I0315 12:05:22.711776 140034036455168 logging_writer.py:48] [69] global_step=69, grad_norm=10.637333869934082, loss=11.011001586914062
I0315 12:05:23.048524 140034044847872 logging_writer.py:48] [70] global_step=70, grad_norm=7.483164310455322, loss=9.63176155090332
I0315 12:05:23.393460 140034036455168 logging_writer.py:48] [71] global_step=71, grad_norm=5.9607038497924805, loss=10.175662994384766
I0315 12:05:23.730982 140034044847872 logging_writer.py:48] [72] global_step=72, grad_norm=7.3518452644348145, loss=10.059867858886719
I0315 12:05:24.064607 140034036455168 logging_writer.py:48] [73] global_step=73, grad_norm=5.307065010070801, loss=10.310733795166016
I0315 12:05:24.400460 140034044847872 logging_writer.py:48] [74] global_step=74, grad_norm=6.51250696182251, loss=10.760031700134277
I0315 12:05:24.734249 140034036455168 logging_writer.py:48] [75] global_step=75, grad_norm=8.078030586242676, loss=9.348711013793945
I0315 12:05:25.073311 140034044847872 logging_writer.py:48] [76] global_step=76, grad_norm=5.165748596191406, loss=8.994239807128906
I0315 12:05:25.410505 140034036455168 logging_writer.py:48] [77] global_step=77, grad_norm=20.984310150146484, loss=9.900328636169434
I0315 12:05:25.745400 140034044847872 logging_writer.py:48] [78] global_step=78, grad_norm=4.126133918762207, loss=11.557352066040039
I0315 12:05:26.085945 140034036455168 logging_writer.py:48] [79] global_step=79, grad_norm=5.77516508102417, loss=9.989340782165527
I0315 12:05:26.424299 140034044847872 logging_writer.py:48] [80] global_step=80, grad_norm=5.719943046569824, loss=10.403562545776367
I0315 12:05:26.762073 140034036455168 logging_writer.py:48] [81] global_step=81, grad_norm=7.1996049880981445, loss=8.954561233520508
I0315 12:05:27.101440 140034044847872 logging_writer.py:48] [82] global_step=82, grad_norm=9.838777542114258, loss=10.698938369750977
I0315 12:05:27.437528 140034036455168 logging_writer.py:48] [83] global_step=83, grad_norm=12.155797958374023, loss=10.478828430175781
I0315 12:05:27.772572 140034044847872 logging_writer.py:48] [84] global_step=84, grad_norm=5.200182914733887, loss=9.833966255187988
I0315 12:05:28.106950 140034036455168 logging_writer.py:48] [85] global_step=85, grad_norm=6.6966118812561035, loss=10.118941307067871
I0315 12:05:28.442195 140034044847872 logging_writer.py:48] [86] global_step=86, grad_norm=4.389678955078125, loss=8.557486534118652
I0315 12:05:28.781002 140034036455168 logging_writer.py:48] [87] global_step=87, grad_norm=3.8295068740844727, loss=9.797286987304688
I0315 12:05:29.123763 140034044847872 logging_writer.py:48] [88] global_step=88, grad_norm=4.55867862701416, loss=10.453962326049805
I0315 12:05:29.460149 140034036455168 logging_writer.py:48] [89] global_step=89, grad_norm=6.928930282592773, loss=8.75635051727295
I0315 12:05:29.795628 140034044847872 logging_writer.py:48] [90] global_step=90, grad_norm=7.349679946899414, loss=8.7987060546875
I0315 12:05:30.136568 140034036455168 logging_writer.py:48] [91] global_step=91, grad_norm=6.944575309753418, loss=10.479866981506348
I0315 12:05:30.471288 140034044847872 logging_writer.py:48] [92] global_step=92, grad_norm=2.9174325466156006, loss=8.333946228027344
I0315 12:05:30.804556 140034036455168 logging_writer.py:48] [93] global_step=93, grad_norm=54.876243591308594, loss=11.400583267211914
I0315 12:05:31.147219 140034044847872 logging_writer.py:48] [94] global_step=94, grad_norm=9.668374061584473, loss=13.733450889587402
I0315 12:05:31.491202 140034036455168 logging_writer.py:48] [95] global_step=95, grad_norm=5.050967216491699, loss=10.750531196594238
I0315 12:05:31.832218 140034044847872 logging_writer.py:48] [96] global_step=96, grad_norm=7.204216003417969, loss=12.407392501831055
I0315 12:05:32.170936 140034036455168 logging_writer.py:48] [97] global_step=97, grad_norm=5.894471645355225, loss=13.484489440917969
I0315 12:05:32.508487 140034044847872 logging_writer.py:48] [98] global_step=98, grad_norm=6.5771379470825195, loss=10.865981101989746
I0315 12:05:32.846762 140034036455168 logging_writer.py:48] [99] global_step=99, grad_norm=13.574149131774902, loss=11.097068786621094
I0315 12:05:33.184784 140034044847872 logging_writer.py:48] [100] global_step=100, grad_norm=5.289648056030273, loss=9.485614776611328
I0315 12:07:47.601764 140034036455168 logging_writer.py:48] [500] global_step=500, grad_norm=0.09095031023025513, loss=6.8853759765625
I0315 12:10:35.696578 140034044847872 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.17281439900398254, loss=6.665286064147949
I0315 12:13:23.811015 140034036455168 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.11068132519721985, loss=6.789914608001709
I0315 12:13:29.589927 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:13:37.049891 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:13:45.292866 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:13:47.639272 140219736737600 submission_runner.py:420] Time since start: 612.40s, 	Step: 1519, 	{'train/accuracy': 0.004544004797935486, 'train/loss': 6.69061803817749, 'validation/accuracy': 0.004540000110864639, 'validation/loss': 6.6995415687561035, 'validation/num_examples': 50000, 'test/accuracy': 0.0034000002779066563, 'test/loss': 6.734652042388916, 'test/num_examples': 10000, 'score': 557.4852783679962, 'total_duration': 612.4016373157501, 'accumulated_submission_time': 557.4852783679962, 'accumulated_eval_time': 54.83740997314453, 'accumulated_logging_time': 0.026354551315307617}
I0315 12:13:47.657456 140034053240576 logging_writer.py:48] [1519] accumulated_eval_time=54.837410, accumulated_logging_time=0.026355, accumulated_submission_time=557.485278, global_step=1519, preemption_count=0, score=557.485278, test/accuracy=0.003400, test/loss=6.734652, test/num_examples=10000, total_duration=612.401637, train/accuracy=0.004544, train/loss=6.690618, validation/accuracy=0.004540, validation/loss=6.699542, validation/num_examples=50000
I0315 12:16:29.569423 140034137102080 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.15966853499412537, loss=6.562318801879883
I0315 12:19:17.500039 140034053240576 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.17811749875545502, loss=6.366059303283691
I0315 12:22:05.439843 140034137102080 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.1764429807662964, loss=6.137608528137207
I0315 12:22:17.970755 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:22:25.325224 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:22:33.760574 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:22:36.180300 140219736737600 submission_runner.py:420] Time since start: 1140.94s, 	Step: 3039, 	{'train/accuracy': 0.049605388194322586, 'train/loss': 5.57780122756958, 'validation/accuracy': 0.04690000042319298, 'validation/loss': 5.608048439025879, 'validation/num_examples': 50000, 'test/accuracy': 0.03580000251531601, 'test/loss': 5.819831848144531, 'test/num_examples': 10000, 'score': 1067.7323660850525, 'total_duration': 1140.9426672458649, 'accumulated_submission_time': 1067.7323660850525, 'accumulated_eval_time': 73.04691457748413, 'accumulated_logging_time': 0.05607151985168457}
I0315 12:22:36.198001 140057935603456 logging_writer.py:48] [3039] accumulated_eval_time=73.046915, accumulated_logging_time=0.056072, accumulated_submission_time=1067.732366, global_step=3039, preemption_count=0, score=1067.732366, test/accuracy=0.035800, test/loss=5.819832, test/num_examples=10000, total_duration=1140.942667, train/accuracy=0.049605, train/loss=5.577801, validation/accuracy=0.046900, validation/loss=5.608048, validation/num_examples=50000
I0315 12:25:11.439629 140057943996160 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.21809399127960205, loss=5.959885597229004
I0315 12:27:59.514734 140057935603456 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.2082669585943222, loss=5.780999660491943
I0315 12:30:47.768704 140057943996160 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.21238727867603302, loss=5.594147682189941
I0315 12:31:06.401478 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:31:13.676523 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:31:22.147756 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:31:24.797665 140219736737600 submission_runner.py:420] Time since start: 1669.56s, 	Step: 4557, 	{'train/accuracy': 0.1287667453289032, 'train/loss': 4.847797870635986, 'validation/accuracy': 0.1207599937915802, 'validation/loss': 4.9104180335998535, 'validation/num_examples': 50000, 'test/accuracy': 0.09220000356435776, 'test/loss': 5.2158074378967285, 'test/num_examples': 10000, 'score': 1577.8691699504852, 'total_duration': 1669.5600199699402, 'accumulated_submission_time': 1577.8691699504852, 'accumulated_eval_time': 91.44304966926575, 'accumulated_logging_time': 0.0863194465637207}
I0315 12:31:24.815263 140057994286848 logging_writer.py:48] [4557] accumulated_eval_time=91.443050, accumulated_logging_time=0.086319, accumulated_submission_time=1577.869170, global_step=4557, preemption_count=0, score=1577.869170, test/accuracy=0.092200, test/loss=5.215807, test/num_examples=10000, total_duration=1669.560020, train/accuracy=0.128767, train/loss=4.847798, validation/accuracy=0.120760, validation/loss=4.910418, validation/num_examples=50000
I0315 12:33:54.403702 140058002679552 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.20012721419334412, loss=5.286404132843018
I0315 12:36:42.439409 140057994286848 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.2112395018339157, loss=5.122471809387207
I0315 12:39:30.766728 140058002679552 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.21401122212409973, loss=4.945760250091553
I0315 12:39:55.021584 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:40:02.328109 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:40:10.832710 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:40:13.174637 140219736737600 submission_runner.py:420] Time since start: 2197.94s, 	Step: 6074, 	{'train/accuracy': 0.26281487941741943, 'train/loss': 3.9351720809936523, 'validation/accuracy': 0.2464199960231781, 'validation/loss': 4.055335998535156, 'validation/num_examples': 50000, 'test/accuracy': 0.18310001492500305, 'test/loss': 4.493728160858154, 'test/num_examples': 10000, 'score': 2088.0122191905975, 'total_duration': 2197.9370057582855, 'accumulated_submission_time': 2088.0122191905975, 'accumulated_eval_time': 109.59606838226318, 'accumulated_logging_time': 0.11431169509887695}
I0315 12:40:13.192273 140058002679552 logging_writer.py:48] [6074] accumulated_eval_time=109.596068, accumulated_logging_time=0.114312, accumulated_submission_time=2088.012219, global_step=6074, preemption_count=0, score=2088.012219, test/accuracy=0.183100, test/loss=4.493728, test/num_examples=10000, total_duration=2197.937006, train/accuracy=0.262815, train/loss=3.935172, validation/accuracy=0.246420, validation/loss=4.055336, validation/num_examples=50000
I0315 12:42:36.726648 140058027857664 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.2251814603805542, loss=4.811916828155518
I0315 12:45:25.080601 140058002679552 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.21016140282154083, loss=4.813287258148193
I0315 12:48:13.138888 140058027857664 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.20939725637435913, loss=4.571137428283691
I0315 12:48:43.183620 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:48:50.579766 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:48:58.942919 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:49:01.264769 140219736737600 submission_runner.py:420] Time since start: 2726.03s, 	Step: 7591, 	{'train/accuracy': 0.22765864431858063, 'train/loss': 4.142884731292725, 'validation/accuracy': 0.21345999836921692, 'validation/loss': 4.234279155731201, 'validation/num_examples': 50000, 'test/accuracy': 0.16130000352859497, 'test/loss': 4.688904285430908, 'test/num_examples': 10000, 'score': 2597.9389073848724, 'total_duration': 2726.0270931720734, 'accumulated_submission_time': 2597.9389073848724, 'accumulated_eval_time': 127.67713642120361, 'accumulated_logging_time': 0.14261126518249512}
I0315 12:49:01.289829 140057985926912 logging_writer.py:48] [7591] accumulated_eval_time=127.677136, accumulated_logging_time=0.142611, accumulated_submission_time=2597.938907, global_step=7591, preemption_count=0, score=2597.938907, test/accuracy=0.161300, test/loss=4.688904, test/num_examples=10000, total_duration=2726.027093, train/accuracy=0.227659, train/loss=4.142885, validation/accuracy=0.213460, validation/loss=4.234279, validation/num_examples=50000
I0315 12:51:19.315830 140057994319616 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.20669180154800415, loss=4.543895244598389
I0315 12:54:07.604352 140057985926912 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.2113162726163864, loss=4.3932905197143555
I0315 12:56:55.872678 140057994319616 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.21758365631103516, loss=4.303689479827881
I0315 12:57:31.520430 140219736737600 spec.py:321] Evaluating on the training split.
I0315 12:57:38.933889 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 12:57:47.396176 140219736737600 spec.py:349] Evaluating on the test split.
I0315 12:57:49.693126 140219736737600 submission_runner.py:420] Time since start: 3254.46s, 	Step: 9108, 	{'train/accuracy': 0.4121691584587097, 'train/loss': 2.926903247833252, 'validation/accuracy': 0.3558200001716614, 'validation/loss': 3.2475132942199707, 'validation/num_examples': 50000, 'test/accuracy': 0.2686000168323517, 'test/loss': 3.8534505367279053, 'test/num_examples': 10000, 'score': 3108.1007058620453, 'total_duration': 3254.4554920196533, 'accumulated_submission_time': 3108.1007058620453, 'accumulated_eval_time': 145.84979248046875, 'accumulated_logging_time': 0.18162846565246582}
I0315 12:57:49.710803 140057977534208 logging_writer.py:48] [9108] accumulated_eval_time=145.849792, accumulated_logging_time=0.181628, accumulated_submission_time=3108.100706, global_step=9108, preemption_count=0, score=3108.100706, test/accuracy=0.268600, test/loss=3.853451, test/num_examples=10000, total_duration=3254.455492, train/accuracy=0.412169, train/loss=2.926903, validation/accuracy=0.355820, validation/loss=3.247513, validation/num_examples=50000
I0315 13:00:01.908116 140057985926912 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.20993031561374664, loss=4.2781219482421875
I0315 13:02:50.329347 140057977534208 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.2091866284608841, loss=4.200893402099609
I0315 13:05:38.372307 140057985926912 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.21385736763477325, loss=4.15245246887207
I0315 13:06:19.905385 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:06:27.295238 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:06:35.912472 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:06:38.227513 140219736737600 submission_runner.py:420] Time since start: 3782.99s, 	Step: 10625, 	{'train/accuracy': 0.4539620578289032, 'train/loss': 2.6911368370056152, 'validation/accuracy': 0.41251999139785767, 'validation/loss': 2.916543960571289, 'validation/num_examples': 50000, 'test/accuracy': 0.3144000172615051, 'test/loss': 3.545785427093506, 'test/num_examples': 10000, 'score': 3618.2318530082703, 'total_duration': 3782.9898648262024, 'accumulated_submission_time': 3618.2318530082703, 'accumulated_eval_time': 164.17187094688416, 'accumulated_logging_time': 0.20866155624389648}
I0315 13:06:38.248342 140058090739456 logging_writer.py:48] [10625] accumulated_eval_time=164.171871, accumulated_logging_time=0.208662, accumulated_submission_time=3618.231853, global_step=10625, preemption_count=0, score=3618.231853, test/accuracy=0.314400, test/loss=3.545785, test/num_examples=10000, total_duration=3782.989865, train/accuracy=0.453962, train/loss=2.691137, validation/accuracy=0.412520, validation/loss=2.916544, validation/num_examples=50000
I0315 13:08:44.615221 140058099132160 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.22389592230319977, loss=4.16765022277832
I0315 13:11:32.790421 140058090739456 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.21934936940670013, loss=4.053544998168945
I0315 13:14:21.111037 140058099132160 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.21242403984069824, loss=4.15990686416626
I0315 13:15:08.274865 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:15:15.650791 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:15:24.358089 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:15:26.624845 140219736737600 submission_runner.py:420] Time since start: 4311.39s, 	Step: 12142, 	{'train/accuracy': 0.4854113459587097, 'train/loss': 2.5034611225128174, 'validation/accuracy': 0.4456999897956848, 'validation/loss': 2.707832098007202, 'validation/num_examples': 50000, 'test/accuracy': 0.33230000734329224, 'test/loss': 3.3627805709838867, 'test/num_examples': 10000, 'score': 4128.188938140869, 'total_duration': 4311.387203454971, 'accumulated_submission_time': 4128.188938140869, 'accumulated_eval_time': 182.52180695533752, 'accumulated_logging_time': 0.24398541450500488}
I0315 13:15:26.645133 140057994319616 logging_writer.py:48] [12142] accumulated_eval_time=182.521807, accumulated_logging_time=0.243985, accumulated_submission_time=4128.188938, global_step=12142, preemption_count=0, score=4128.188938, test/accuracy=0.332300, test/loss=3.362781, test/num_examples=10000, total_duration=4311.387203, train/accuracy=0.485411, train/loss=2.503461, validation/accuracy=0.445700, validation/loss=2.707832, validation/num_examples=50000
I0315 13:17:27.366850 140058002712320 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.22062280774116516, loss=4.018548965454102
I0315 13:20:15.579033 140057994319616 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.2306557148694992, loss=4.0537190437316895
I0315 13:23:03.736196 140058002712320 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.22491857409477234, loss=4.068603515625
I0315 13:23:56.671675 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:24:04.134228 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:24:12.651828 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:24:14.978963 140219736737600 submission_runner.py:420] Time since start: 4839.74s, 	Step: 13659, 	{'train/accuracy': 0.5143295526504517, 'train/loss': 2.328718900680542, 'validation/accuracy': 0.47585999965667725, 'validation/loss': 2.517012119293213, 'validation/num_examples': 50000, 'test/accuracy': 0.3653000295162201, 'test/loss': 3.148709535598755, 'test/num_examples': 10000, 'score': 4638.151408672333, 'total_duration': 4839.741317749023, 'accumulated_submission_time': 4638.151408672333, 'accumulated_eval_time': 200.82904863357544, 'accumulated_logging_time': 0.27428460121154785}
I0315 13:24:14.998035 140058011105024 logging_writer.py:48] [13659] accumulated_eval_time=200.829049, accumulated_logging_time=0.274285, accumulated_submission_time=4638.151409, global_step=13659, preemption_count=0, score=4638.151409, test/accuracy=0.365300, test/loss=3.148710, test/num_examples=10000, total_duration=4839.741318, train/accuracy=0.514330, train/loss=2.328719, validation/accuracy=0.475860, validation/loss=2.517012, validation/num_examples=50000
I0315 13:26:10.016998 140058090739456 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.23066987097263336, loss=3.9336445331573486
I0315 13:28:57.988121 140058011105024 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.23010964691638947, loss=3.9536585807800293
I0315 13:31:46.143357 140058090739456 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.2315738946199417, loss=3.91827392578125
I0315 13:32:45.162455 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:32:52.493827 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:33:01.097742 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:33:03.446873 140219736737600 submission_runner.py:420] Time since start: 5368.21s, 	Step: 15177, 	{'train/accuracy': 0.5061184763908386, 'train/loss': 2.377655267715454, 'validation/accuracy': 0.47453999519348145, 'validation/loss': 2.5379393100738525, 'validation/num_examples': 50000, 'test/accuracy': 0.35590001940727234, 'test/loss': 3.2392184734344482, 'test/num_examples': 10000, 'score': 5148.252074241638, 'total_duration': 5368.209239721298, 'accumulated_submission_time': 5148.252074241638, 'accumulated_eval_time': 219.11343455314636, 'accumulated_logging_time': 0.30254626274108887}
I0315 13:33:03.467992 140057985926912 logging_writer.py:48] [15177] accumulated_eval_time=219.113435, accumulated_logging_time=0.302546, accumulated_submission_time=5148.252074, global_step=15177, preemption_count=0, score=5148.252074, test/accuracy=0.355900, test/loss=3.239218, test/num_examples=10000, total_duration=5368.209240, train/accuracy=0.506118, train/loss=2.377655, validation/accuracy=0.474540, validation/loss=2.537939, validation/num_examples=50000
I0315 13:34:52.464803 140057994319616 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.22495293617248535, loss=3.8072829246520996
I0315 13:37:40.574064 140057985926912 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.227989062666893, loss=3.941958427429199
I0315 13:40:28.537708 140057994319616 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.23353198170661926, loss=3.93045711517334
I0315 13:41:33.579735 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:41:40.943960 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:41:53.694073 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:41:55.993842 140219736737600 submission_runner.py:420] Time since start: 5900.76s, 	Step: 16695, 	{'train/accuracy': 0.5298947691917419, 'train/loss': 2.262759208679199, 'validation/accuracy': 0.49925997853279114, 'validation/loss': 2.423909902572632, 'validation/num_examples': 50000, 'test/accuracy': 0.382500022649765, 'test/loss': 3.0907649993896484, 'test/num_examples': 10000, 'score': 5658.297363042831, 'total_duration': 5900.756187438965, 'accumulated_submission_time': 5658.297363042831, 'accumulated_eval_time': 241.52748775482178, 'accumulated_logging_time': 0.33531689643859863}
I0315 13:41:56.017920 140057994319616 logging_writer.py:48] [16695] accumulated_eval_time=241.527488, accumulated_logging_time=0.335317, accumulated_submission_time=5658.297363, global_step=16695, preemption_count=0, score=5658.297363, test/accuracy=0.382500, test/loss=3.090765, test/num_examples=10000, total_duration=5900.756187, train/accuracy=0.529895, train/loss=2.262759, validation/accuracy=0.499260, validation/loss=2.423910, validation/num_examples=50000
I0315 13:43:38.854115 140058090739456 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.23371532559394836, loss=3.933694362640381
I0315 13:46:26.844058 140057994319616 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.2202114462852478, loss=3.6776351928710938
I0315 13:49:14.717310 140058090739456 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.2307048738002777, loss=3.7787742614746094
I0315 13:50:26.126521 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:50:33.487143 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:50:44.886615 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:50:47.202982 140219736737600 submission_runner.py:420] Time since start: 6431.97s, 	Step: 18214, 	{'train/accuracy': 0.5557836294174194, 'train/loss': 2.1994197368621826, 'validation/accuracy': 0.4882600009441376, 'validation/loss': 2.52398419380188, 'validation/num_examples': 50000, 'test/accuracy': 0.3822000324726105, 'test/loss': 3.1456823348999023, 'test/num_examples': 10000, 'score': 6168.3401889801025, 'total_duration': 6431.965350389481, 'accumulated_submission_time': 6168.3401889801025, 'accumulated_eval_time': 262.6039364337921, 'accumulated_logging_time': 0.3696572780609131}
I0315 13:50:47.222799 140057994319616 logging_writer.py:48] [18214] accumulated_eval_time=262.603936, accumulated_logging_time=0.369657, accumulated_submission_time=6168.340189, global_step=18214, preemption_count=0, score=6168.340189, test/accuracy=0.382200, test/loss=3.145682, test/num_examples=10000, total_duration=6431.965350, train/accuracy=0.555784, train/loss=2.199420, validation/accuracy=0.488260, validation/loss=2.523984, validation/num_examples=50000
I0315 13:52:23.697254 140058002712320 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.23588746786117554, loss=3.7535593509674072
I0315 13:55:11.764020 140057994319616 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.23941363394260406, loss=3.789639949798584
I0315 13:57:59.693892 140058002712320 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.23324403166770935, loss=3.805047035217285
I0315 13:59:17.363518 140219736737600 spec.py:321] Evaluating on the training split.
I0315 13:59:24.952476 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 13:59:43.805689 140219736737600 spec.py:349] Evaluating on the test split.
I0315 13:59:46.103640 140219736737600 submission_runner.py:420] Time since start: 6970.87s, 	Step: 19733, 	{'train/accuracy': 0.5789421200752258, 'train/loss': 2.03883957862854, 'validation/accuracy': 0.5265399813652039, 'validation/loss': 2.2987494468688965, 'validation/num_examples': 50000, 'test/accuracy': 0.41370001435279846, 'test/loss': 2.9405357837677, 'test/num_examples': 10000, 'score': 6678.416119337082, 'total_duration': 6970.8660089969635, 'accumulated_submission_time': 6678.416119337082, 'accumulated_eval_time': 291.3440418243408, 'accumulated_logging_time': 0.40018391609191895}
I0315 13:59:46.124253 140057985926912 logging_writer.py:48] [19733] accumulated_eval_time=291.344042, accumulated_logging_time=0.400184, accumulated_submission_time=6678.416119, global_step=19733, preemption_count=0, score=6678.416119, test/accuracy=0.413700, test/loss=2.940536, test/num_examples=10000, total_duration=6970.866009, train/accuracy=0.578942, train/loss=2.038840, validation/accuracy=0.526540, validation/loss=2.298749, validation/num_examples=50000
I0315 14:01:16.222236 140058099132160 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.24273714423179626, loss=3.858854293823242
I0315 14:04:04.552047 140057985926912 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.2318241149187088, loss=3.6636760234832764
I0315 14:06:52.620375 140058099132160 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.2496711164712906, loss=3.896960735321045
I0315 14:08:16.361441 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:08:23.839437 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:08:37.942994 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:08:40.100040 140219736737600 submission_runner.py:420] Time since start: 7504.86s, 	Step: 21251, 	{'train/accuracy': 0.5830078125, 'train/loss': 2.0310115814208984, 'validation/accuracy': 0.5385800004005432, 'validation/loss': 2.2524328231811523, 'validation/num_examples': 50000, 'test/accuracy': 0.41540002822875977, 'test/loss': 2.9097514152526855, 'test/num_examples': 10000, 'score': 7188.590972185135, 'total_duration': 7504.862423181534, 'accumulated_submission_time': 7188.590972185135, 'accumulated_eval_time': 315.0826277732849, 'accumulated_logging_time': 0.43010997772216797}
I0315 14:08:40.116255 140058002712320 logging_writer.py:48] [21251] accumulated_eval_time=315.082628, accumulated_logging_time=0.430110, accumulated_submission_time=7188.590972, global_step=21251, preemption_count=0, score=7188.590972, test/accuracy=0.415400, test/loss=2.909751, test/num_examples=10000, total_duration=7504.862423, train/accuracy=0.583008, train/loss=2.031012, validation/accuracy=0.538580, validation/loss=2.252433, validation/num_examples=50000
I0315 14:10:03.952734 140058011105024 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.24247364699840546, loss=3.722465991973877
I0315 14:12:52.147509 140058002712320 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.2346680462360382, loss=3.7513375282287598
I0315 14:15:40.146610 140058011105024 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.24520418047904968, loss=3.677234411239624
I0315 14:17:10.409790 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:17:17.906379 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:17:34.662949 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:17:36.973264 140219736737600 submission_runner.py:420] Time since start: 8041.73s, 	Step: 22770, 	{'train/accuracy': 0.5297154188156128, 'train/loss': 2.2742745876312256, 'validation/accuracy': 0.4883599877357483, 'validation/loss': 2.461336851119995, 'validation/num_examples': 50000, 'test/accuracy': 0.37470000982284546, 'test/loss': 3.1011805534362793, 'test/num_examples': 10000, 'score': 7698.823069572449, 'total_duration': 8041.734592437744, 'accumulated_submission_time': 7698.823069572449, 'accumulated_eval_time': 341.64503598213196, 'accumulated_logging_time': 0.45485639572143555}
I0315 14:17:36.993614 140057994319616 logging_writer.py:48] [22770] accumulated_eval_time=341.645036, accumulated_logging_time=0.454856, accumulated_submission_time=7698.823070, global_step=22770, preemption_count=0, score=7698.823070, test/accuracy=0.374700, test/loss=3.101181, test/num_examples=10000, total_duration=8041.734592, train/accuracy=0.529715, train/loss=2.274275, validation/accuracy=0.488360, validation/loss=2.461337, validation/num_examples=50000
I0315 14:18:54.504958 140058002712320 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.23634861409664154, loss=3.665217399597168
I0315 14:21:42.654951 140057994319616 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.23590412735939026, loss=3.646002769470215
I0315 14:24:30.898259 140058002712320 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.2553800940513611, loss=3.7992680072784424
I0315 14:26:07.066507 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:26:14.692111 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:26:26.761399 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:26:29.020611 140219736737600 submission_runner.py:420] Time since start: 8573.78s, 	Step: 24288, 	{'train/accuracy': 0.57421875, 'train/loss': 2.068537712097168, 'validation/accuracy': 0.5332800149917603, 'validation/loss': 2.2714669704437256, 'validation/num_examples': 50000, 'test/accuracy': 0.4066000282764435, 'test/loss': 2.944248676300049, 'test/num_examples': 10000, 'score': 8208.831599235535, 'total_duration': 8573.782970666885, 'accumulated_submission_time': 8208.831599235535, 'accumulated_eval_time': 363.5991675853729, 'accumulated_logging_time': 0.48555660247802734}
I0315 14:26:29.043216 140058002712320 logging_writer.py:48] [24288] accumulated_eval_time=363.599168, accumulated_logging_time=0.485557, accumulated_submission_time=8208.831599, global_step=24288, preemption_count=0, score=8208.831599, test/accuracy=0.406600, test/loss=2.944249, test/num_examples=10000, total_duration=8573.782971, train/accuracy=0.574219, train/loss=2.068538, validation/accuracy=0.533280, validation/loss=2.271467, validation/num_examples=50000
I0315 14:27:40.531460 140058011105024 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.2461877465248108, loss=3.644672155380249
I0315 14:30:28.764925 140058002712320 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.23644907772541046, loss=3.595038414001465
I0315 14:33:16.841254 140058011105024 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.24326278269290924, loss=3.7227509021759033
I0315 14:34:59.256501 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:35:07.397077 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:35:18.944628 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:35:21.268083 140219736737600 submission_runner.py:420] Time since start: 9106.03s, 	Step: 25806, 	{'train/accuracy': 0.5788823366165161, 'train/loss': 2.0605785846710205, 'validation/accuracy': 0.545520007610321, 'validation/loss': 2.218935012817383, 'validation/num_examples': 50000, 'test/accuracy': 0.42500001192092896, 'test/loss': 2.9056777954101562, 'test/num_examples': 10000, 'score': 8718.980939388275, 'total_duration': 9106.030410051346, 'accumulated_submission_time': 8718.980939388275, 'accumulated_eval_time': 385.61068415641785, 'accumulated_logging_time': 0.5188980102539062}
I0315 14:35:21.289616 140058099132160 logging_writer.py:48] [25806] accumulated_eval_time=385.610684, accumulated_logging_time=0.518898, accumulated_submission_time=8718.980939, global_step=25806, preemption_count=0, score=8718.980939, test/accuracy=0.425000, test/loss=2.905678, test/num_examples=10000, total_duration=9106.030410, train/accuracy=0.578882, train/loss=2.060579, validation/accuracy=0.545520, validation/loss=2.218935, validation/num_examples=50000
I0315 14:36:26.947662 140058107524864 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.24222728610038757, loss=3.662506103515625
I0315 14:39:14.907172 140058099132160 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.24730823934078217, loss=3.70328426361084
I0315 14:42:02.802068 140058107524864 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.23922717571258545, loss=3.608698844909668
I0315 14:43:51.330648 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:43:59.613668 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:44:09.850129 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:44:12.142108 140219736737600 submission_runner.py:420] Time since start: 9636.90s, 	Step: 27325, 	{'train/accuracy': 0.625019907951355, 'train/loss': 1.7657756805419922, 'validation/accuracy': 0.5603199601173401, 'validation/loss': 2.084496259689331, 'validation/num_examples': 50000, 'test/accuracy': 0.4336000084877014, 'test/loss': 2.7859420776367188, 'test/num_examples': 10000, 'score': 9228.958266496658, 'total_duration': 9636.904457569122, 'accumulated_submission_time': 9228.958266496658, 'accumulated_eval_time': 406.4220998287201, 'accumulated_logging_time': 0.5506694316864014}
I0315 14:44:12.164102 140057977534208 logging_writer.py:48] [27325] accumulated_eval_time=406.422100, accumulated_logging_time=0.550669, accumulated_submission_time=9228.958266, global_step=27325, preemption_count=0, score=9228.958266, test/accuracy=0.433600, test/loss=2.785942, test/num_examples=10000, total_duration=9636.904458, train/accuracy=0.625020, train/loss=1.765776, validation/accuracy=0.560320, validation/loss=2.084496, validation/num_examples=50000
I0315 14:45:11.402797 140057985926912 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.23337869346141815, loss=3.516881227493286
I0315 14:47:59.415630 140057977534208 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.25062695145606995, loss=3.648594379425049
I0315 14:50:47.546082 140057985926912 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.24498994648456573, loss=3.600493907928467
I0315 14:52:42.195527 140219736737600 spec.py:321] Evaluating on the training split.
I0315 14:52:50.292624 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 14:53:03.473671 140219736737600 spec.py:349] Evaluating on the test split.
I0315 14:53:05.746203 140219736737600 submission_runner.py:420] Time since start: 10170.51s, 	Step: 28843, 	{'train/accuracy': 0.6181241869926453, 'train/loss': 1.8749414682388306, 'validation/accuracy': 0.5651400089263916, 'validation/loss': 2.1131842136383057, 'validation/num_examples': 50000, 'test/accuracy': 0.44510000944137573, 'test/loss': 2.7610645294189453, 'test/num_examples': 10000, 'score': 9738.925782680511, 'total_duration': 10170.508566141129, 'accumulated_submission_time': 9738.925782680511, 'accumulated_eval_time': 429.9727506637573, 'accumulated_logging_time': 0.5825750827789307}
I0315 14:53:05.765750 140058099132160 logging_writer.py:48] [28843] accumulated_eval_time=429.972751, accumulated_logging_time=0.582575, accumulated_submission_time=9738.925783, global_step=28843, preemption_count=0, score=9738.925783, test/accuracy=0.445100, test/loss=2.761065, test/num_examples=10000, total_duration=10170.508566, train/accuracy=0.618124, train/loss=1.874941, validation/accuracy=0.565140, validation/loss=2.113184, validation/num_examples=50000
I0315 14:53:58.926503 140058107524864 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.2442076951265335, loss=3.710418462753296
I0315 14:56:46.878399 140058099132160 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.25159159302711487, loss=3.622251033782959
I0315 14:59:34.912855 140058107524864 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.257890522480011, loss=3.5865230560302734
I0315 15:01:35.868307 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:01:43.889216 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:01:57.878855 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:02:00.092117 140219736737600 submission_runner.py:420] Time since start: 10704.85s, 	Step: 30362, 	{'train/accuracy': 0.6094347834587097, 'train/loss': 1.8473330736160278, 'validation/accuracy': 0.5592799782752991, 'validation/loss': 2.0749523639678955, 'validation/num_examples': 50000, 'test/accuracy': 0.42990002036094666, 'test/loss': 2.7951090335845947, 'test/num_examples': 10000, 'score': 10248.96442580223, 'total_duration': 10704.854495763779, 'accumulated_submission_time': 10248.96442580223, 'accumulated_eval_time': 454.19654631614685, 'accumulated_logging_time': 0.6118781566619873}
I0315 15:02:00.112185 140055997822720 logging_writer.py:48] [30362] accumulated_eval_time=454.196546, accumulated_logging_time=0.611878, accumulated_submission_time=10248.964426, global_step=30362, preemption_count=0, score=10248.964426, test/accuracy=0.429900, test/loss=2.795109, test/num_examples=10000, total_duration=10704.854496, train/accuracy=0.609435, train/loss=1.847333, validation/accuracy=0.559280, validation/loss=2.074952, validation/num_examples=50000
I0315 15:02:46.714657 140056006215424 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.25177890062332153, loss=3.6158642768859863
I0315 15:05:34.639669 140055997822720 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.24785371124744415, loss=3.5917437076568604
I0315 15:08:22.612557 140056006215424 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.250838041305542, loss=3.6181437969207764
I0315 15:10:30.147381 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:10:38.387898 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:10:50.515365 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:10:52.794216 140219736737600 submission_runner.py:420] Time since start: 11237.56s, 	Step: 31881, 	{'train/accuracy': 0.6079798936843872, 'train/loss': 1.8682525157928467, 'validation/accuracy': 0.5659999847412109, 'validation/loss': 2.0625662803649902, 'validation/num_examples': 50000, 'test/accuracy': 0.44380003213882446, 'test/loss': 2.7409098148345947, 'test/num_examples': 10000, 'score': 10758.935925245285, 'total_duration': 11237.556566238403, 'accumulated_submission_time': 10758.935925245285, 'accumulated_eval_time': 476.8433427810669, 'accumulated_logging_time': 0.6411774158477783}
I0315 15:10:52.817891 140056006215424 logging_writer.py:48] [31881] accumulated_eval_time=476.843343, accumulated_logging_time=0.641177, accumulated_submission_time=10758.935925, global_step=31881, preemption_count=0, score=10758.935925, test/accuracy=0.443800, test/loss=2.740910, test/num_examples=10000, total_duration=11237.556566, train/accuracy=0.607980, train/loss=1.868253, validation/accuracy=0.566000, validation/loss=2.062566, validation/num_examples=50000
I0315 15:11:33.138288 140056199165696 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.2598602771759033, loss=3.5776939392089844
I0315 15:14:21.182074 140056006215424 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.2555027902126312, loss=3.534928798675537
I0315 15:17:08.974139 140056199165696 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.2571500837802887, loss=3.606520175933838
I0315 15:19:23.069883 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:19:31.394728 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:19:43.365517 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:19:45.704057 140219736737600 submission_runner.py:420] Time since start: 11770.47s, 	Step: 33401, 	{'train/accuracy': 0.5858976244926453, 'train/loss': 1.987179160118103, 'validation/accuracy': 0.5421599745750427, 'validation/loss': 2.1853582859039307, 'validation/num_examples': 50000, 'test/accuracy': 0.42510002851486206, 'test/loss': 2.8899283409118652, 'test/num_examples': 10000, 'score': 11269.121939182281, 'total_duration': 11770.466438055038, 'accumulated_submission_time': 11269.121939182281, 'accumulated_eval_time': 499.4775059223175, 'accumulated_logging_time': 0.6751701831817627}
I0315 15:19:45.723137 140056006215424 logging_writer.py:48] [33401] accumulated_eval_time=499.477506, accumulated_logging_time=0.675170, accumulated_submission_time=11269.121939, global_step=33401, preemption_count=0, score=11269.121939, test/accuracy=0.425100, test/loss=2.889928, test/num_examples=10000, total_duration=11770.466438, train/accuracy=0.585898, train/loss=1.987179, validation/accuracy=0.542160, validation/loss=2.185358, validation/num_examples=50000
I0315 15:20:19.258924 140056199165696 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.2513575851917267, loss=3.6502890586853027
I0315 15:23:07.197058 140056006215424 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.2595389187335968, loss=3.6589279174804688
I0315 15:25:55.077366 140056199165696 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.2630566656589508, loss=3.597635269165039
I0315 15:28:15.871035 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:28:24.271591 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:28:37.385954 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:28:39.692540 140219736737600 submission_runner.py:420] Time since start: 12304.45s, 	Step: 34921, 	{'train/accuracy': 0.6458665132522583, 'train/loss': 1.7214691638946533, 'validation/accuracy': 0.5810399651527405, 'validation/loss': 1.9938098192214966, 'validation/num_examples': 50000, 'test/accuracy': 0.4595000147819519, 'test/loss': 2.6522984504699707, 'test/num_examples': 10000, 'score': 11779.20444560051, 'total_duration': 12304.454917669296, 'accumulated_submission_time': 11779.20444560051, 'accumulated_eval_time': 523.2989957332611, 'accumulated_logging_time': 0.7066562175750732}
I0315 15:28:39.711044 140057969141504 logging_writer.py:48] [34921] accumulated_eval_time=523.298996, accumulated_logging_time=0.706656, accumulated_submission_time=11779.204446, global_step=34921, preemption_count=0, score=11779.204446, test/accuracy=0.459500, test/loss=2.652298, test/num_examples=10000, total_duration=12304.454918, train/accuracy=0.645867, train/loss=1.721469, validation/accuracy=0.581040, validation/loss=1.993810, validation/num_examples=50000
I0315 15:29:06.635280 140057977534208 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.24666988849639893, loss=3.4750468730926514
I0315 15:31:54.442174 140057969141504 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.26453426480293274, loss=3.6085352897644043
I0315 15:34:42.359476 140057977534208 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.24964329600334167, loss=3.5536582469940186
I0315 15:37:09.778943 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:37:18.149066 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:37:33.173221 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:37:35.367757 140219736737600 submission_runner.py:420] Time since start: 12840.13s, 	Step: 36441, 	{'train/accuracy': 0.6417410373687744, 'train/loss': 1.8034937381744385, 'validation/accuracy': 0.5738599896430969, 'validation/loss': 2.0951340198516846, 'validation/num_examples': 50000, 'test/accuracy': 0.4464000165462494, 'test/loss': 2.7790067195892334, 'test/num_examples': 10000, 'score': 12289.209927797318, 'total_duration': 12840.130129814148, 'accumulated_submission_time': 12289.209927797318, 'accumulated_eval_time': 548.8877904415131, 'accumulated_logging_time': 0.7343935966491699}
I0315 15:37:35.386159 140055947466496 logging_writer.py:48] [36441] accumulated_eval_time=548.887790, accumulated_logging_time=0.734394, accumulated_submission_time=12289.209928, global_step=36441, preemption_count=0, score=12289.209928, test/accuracy=0.446400, test/loss=2.779007, test/num_examples=10000, total_duration=12840.130130, train/accuracy=0.641741, train/loss=1.803494, validation/accuracy=0.573860, validation/loss=2.095134, validation/num_examples=50000
I0315 15:37:55.562006 140055955859200 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.27190741896629333, loss=3.5798051357269287
I0315 15:40:43.429069 140055947466496 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.26315099000930786, loss=3.5207204818725586
I0315 15:43:31.203146 140055955859200 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.25510019063949585, loss=3.458477020263672
I0315 15:46:05.452919 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:46:12.787005 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:46:26.756534 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:46:28.924636 140219736737600 submission_runner.py:420] Time since start: 13373.69s, 	Step: 37961, 	{'train/accuracy': 0.6412029266357422, 'train/loss': 1.6708378791809082, 'validation/accuracy': 0.5851199626922607, 'validation/loss': 1.9359171390533447, 'validation/num_examples': 50000, 'test/accuracy': 0.46320003271102905, 'test/loss': 2.608592987060547, 'test/num_examples': 10000, 'score': 12799.21282839775, 'total_duration': 13373.687015533447, 'accumulated_submission_time': 12799.21282839775, 'accumulated_eval_time': 572.3594927787781, 'accumulated_logging_time': 0.762136697769165}
I0315 15:46:28.942899 140055947466496 logging_writer.py:48] [37961] accumulated_eval_time=572.359493, accumulated_logging_time=0.762137, accumulated_submission_time=12799.212828, global_step=37961, preemption_count=0, score=12799.212828, test/accuracy=0.463200, test/loss=2.608593, test/num_examples=10000, total_duration=13373.687016, train/accuracy=0.641203, train/loss=1.670838, validation/accuracy=0.585120, validation/loss=1.935917, validation/num_examples=50000
I0315 15:46:42.359080 140055955859200 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.2621116638183594, loss=3.516779899597168
I0315 15:49:30.169443 140055947466496 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.2646571695804596, loss=3.551027774810791
I0315 15:52:18.091792 140055955859200 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.25500208139419556, loss=3.5390870571136475
I0315 15:54:59.219680 140219736737600 spec.py:321] Evaluating on the training split.
I0315 15:55:06.530345 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 15:55:18.843182 140219736737600 spec.py:349] Evaluating on the test split.
I0315 15:55:21.143626 140219736737600 submission_runner.py:420] Time since start: 13905.91s, 	Step: 39482, 	{'train/accuracy': 0.6242027878761292, 'train/loss': 1.796441674232483, 'validation/accuracy': 0.5740799903869629, 'validation/loss': 2.023730754852295, 'validation/num_examples': 50000, 'test/accuracy': 0.4482000172138214, 'test/loss': 2.696899175643921, 'test/num_examples': 10000, 'score': 13309.426300764084, 'total_duration': 13905.905908823013, 'accumulated_submission_time': 13309.426300764084, 'accumulated_eval_time': 594.2833342552185, 'accumulated_logging_time': 0.789865255355835}
I0315 15:55:21.164419 140055796512512 logging_writer.py:48] [39482] accumulated_eval_time=594.283334, accumulated_logging_time=0.789865, accumulated_submission_time=13309.426301, global_step=39482, preemption_count=0, score=13309.426301, test/accuracy=0.448200, test/loss=2.696899, test/num_examples=10000, total_duration=13905.905909, train/accuracy=0.624203, train/loss=1.796442, validation/accuracy=0.574080, validation/loss=2.023731, validation/num_examples=50000
I0315 15:55:27.524026 140055947466496 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.26649361848831177, loss=3.5090787410736084
I0315 15:58:15.369529 140055796512512 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.2555880546569824, loss=3.492600440979004
I0315 16:01:03.095918 140055947466496 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.27599313855171204, loss=3.5701730251312256
I0315 16:03:50.990345 140055796512512 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.2680436372756958, loss=3.501777172088623
I0315 16:03:51.411892 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:03:58.804168 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:04:12.030797 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:04:14.318207 140219736737600 submission_runner.py:420] Time since start: 14439.08s, 	Step: 41003, 	{'train/accuracy': 0.5903419852256775, 'train/loss': 1.9976814985275269, 'validation/accuracy': 0.5457000136375427, 'validation/loss': 2.2147979736328125, 'validation/num_examples': 50000, 'test/accuracy': 0.40960001945495605, 'test/loss': 2.966240644454956, 'test/num_examples': 10000, 'score': 13819.610492706299, 'total_duration': 14439.08058643341, 'accumulated_submission_time': 13819.610492706299, 'accumulated_eval_time': 617.1896386146545, 'accumulated_logging_time': 0.8200054168701172}
I0315 16:04:14.338338 140055981037312 logging_writer.py:48] [41003] accumulated_eval_time=617.189639, accumulated_logging_time=0.820005, accumulated_submission_time=13819.610493, global_step=41003, preemption_count=0, score=13819.610493, test/accuracy=0.409600, test/loss=2.966241, test/num_examples=10000, total_duration=14439.080586, train/accuracy=0.590342, train/loss=1.997681, validation/accuracy=0.545700, validation/loss=2.214798, validation/num_examples=50000
I0315 16:07:01.739719 140055989430016 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.2651054859161377, loss=3.5095906257629395
I0315 16:09:49.650056 140055981037312 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.26505157351493835, loss=3.5220344066619873
I0315 16:12:37.498062 140055989430016 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.26123538613319397, loss=3.5676488876342773
I0315 16:12:44.323708 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:12:51.325824 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:13:05.492793 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:13:07.808373 140219736737600 submission_runner.py:420] Time since start: 14972.57s, 	Step: 42522, 	{'train/accuracy': 0.6168885231018066, 'train/loss': 1.8260935544967651, 'validation/accuracy': 0.5760799646377563, 'validation/loss': 2.0149435997009277, 'validation/num_examples': 50000, 'test/accuracy': 0.4488000273704529, 'test/loss': 2.704561948776245, 'test/num_examples': 10000, 'score': 14329.532070875168, 'total_duration': 14972.570736169815, 'accumulated_submission_time': 14329.532070875168, 'accumulated_eval_time': 640.67427110672, 'accumulated_logging_time': 0.8497834205627441}
I0315 16:13:07.831443 140055955859200 logging_writer.py:48] [42522] accumulated_eval_time=640.674271, accumulated_logging_time=0.849783, accumulated_submission_time=14329.532071, global_step=42522, preemption_count=0, score=14329.532071, test/accuracy=0.448800, test/loss=2.704562, test/num_examples=10000, total_duration=14972.570736, train/accuracy=0.616889, train/loss=1.826094, validation/accuracy=0.576080, validation/loss=2.014944, validation/num_examples=50000
I0315 16:15:48.664418 140055964251904 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.26855096220970154, loss=3.5304718017578125
I0315 16:18:36.453070 140055955859200 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.2665937542915344, loss=3.43713641166687
I0315 16:21:24.391346 140055964251904 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.2630925178527832, loss=3.4050536155700684
I0315 16:21:37.930241 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:21:44.981410 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:21:55.131111 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:21:57.429236 140219736737600 submission_runner.py:420] Time since start: 15502.19s, 	Step: 44042, 	{'train/accuracy': 0.6665935516357422, 'train/loss': 1.6319551467895508, 'validation/accuracy': 0.579259991645813, 'validation/loss': 2.0244803428649902, 'validation/num_examples': 50000, 'test/accuracy': 0.45000001788139343, 'test/loss': 2.6779887676239014, 'test/num_examples': 10000, 'score': 14839.568438529968, 'total_duration': 15502.191601276398, 'accumulated_submission_time': 14839.568438529968, 'accumulated_eval_time': 660.1732244491577, 'accumulated_logging_time': 0.8819336891174316}
I0315 16:21:57.451019 140055947466496 logging_writer.py:48] [44042] accumulated_eval_time=660.173224, accumulated_logging_time=0.881934, accumulated_submission_time=14839.568439, global_step=44042, preemption_count=0, score=14839.568439, test/accuracy=0.450000, test/loss=2.677989, test/num_examples=10000, total_duration=15502.191601, train/accuracy=0.666594, train/loss=1.631955, validation/accuracy=0.579260, validation/loss=2.024480, validation/num_examples=50000
I0315 16:24:31.742725 140055955859200 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.261179119348526, loss=3.395740032196045
I0315 16:27:19.722669 140055947466496 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.26474323868751526, loss=3.432126522064209
I0315 16:30:07.458205 140055955859200 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.27597758173942566, loss=3.5140275955200195
I0315 16:30:27.631750 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:30:34.699159 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:30:45.334054 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:30:47.652926 140219736737600 submission_runner.py:420] Time since start: 16032.42s, 	Step: 45562, 	{'train/accuracy': 0.6618502736091614, 'train/loss': 1.621239185333252, 'validation/accuracy': 0.6011599898338318, 'validation/loss': 1.8938428163528442, 'validation/num_examples': 50000, 'test/accuracy': 0.47280001640319824, 'test/loss': 2.5572855472564697, 'test/num_examples': 10000, 'score': 15349.6850771904, 'total_duration': 16032.415295362473, 'accumulated_submission_time': 15349.6850771904, 'accumulated_eval_time': 680.1943652629852, 'accumulated_logging_time': 0.9130690097808838}
I0315 16:30:47.671041 140055989430016 logging_writer.py:48] [45562] accumulated_eval_time=680.194365, accumulated_logging_time=0.913069, accumulated_submission_time=15349.685077, global_step=45562, preemption_count=0, score=15349.685077, test/accuracy=0.472800, test/loss=2.557286, test/num_examples=10000, total_duration=16032.415295, train/accuracy=0.661850, train/loss=1.621239, validation/accuracy=0.601160, validation/loss=1.893843, validation/num_examples=50000
I0315 16:33:15.120751 140055997822720 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.27906882762908936, loss=3.455368995666504
I0315 16:36:02.872342 140055989430016 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.26759815216064453, loss=3.5501856803894043
I0315 16:38:50.724038 140055997822720 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.26817095279693604, loss=3.489870548248291
I0315 16:39:17.658552 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:39:24.612982 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:39:38.923284 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:39:41.116249 140219736737600 submission_runner.py:420] Time since start: 16565.88s, 	Step: 47082, 	{'train/accuracy': 0.6599968075752258, 'train/loss': 1.6365338563919067, 'validation/accuracy': 0.6035400032997131, 'validation/loss': 1.8902983665466309, 'validation/num_examples': 50000, 'test/accuracy': 0.4853000342845917, 'test/loss': 2.5268380641937256, 'test/num_examples': 10000, 'score': 15859.610484600067, 'total_duration': 16565.878612041473, 'accumulated_submission_time': 15859.610484600067, 'accumulated_eval_time': 703.6520206928253, 'accumulated_logging_time': 0.9391820430755615}
I0315 16:39:41.136306 140055972644608 logging_writer.py:48] [47082] accumulated_eval_time=703.652021, accumulated_logging_time=0.939182, accumulated_submission_time=15859.610485, global_step=47082, preemption_count=0, score=15859.610485, test/accuracy=0.485300, test/loss=2.526838, test/num_examples=10000, total_duration=16565.878612, train/accuracy=0.659997, train/loss=1.636534, validation/accuracy=0.603540, validation/loss=1.890298, validation/num_examples=50000
I0315 16:42:01.951963 140055981037312 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.26318860054016113, loss=3.4227566719055176
I0315 16:44:49.714241 140055972644608 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.26951321959495544, loss=3.486307382583618
I0315 16:47:37.497951 140055981037312 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.26572421193122864, loss=3.480210304260254
I0315 16:48:11.419501 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:48:18.129159 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:48:30.737286 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:48:33.050829 140219736737600 submission_runner.py:420] Time since start: 17097.81s, 	Step: 48603, 	{'train/accuracy': 0.6563097834587097, 'train/loss': 1.7036696672439575, 'validation/accuracy': 0.6042799949645996, 'validation/loss': 1.9504328966140747, 'validation/num_examples': 50000, 'test/accuracy': 0.47700002789497375, 'test/loss': 2.6092634201049805, 'test/num_examples': 10000, 'score': 16369.831721305847, 'total_duration': 17097.813205957413, 'accumulated_submission_time': 16369.831721305847, 'accumulated_eval_time': 725.2833213806152, 'accumulated_logging_time': 0.9682011604309082}
I0315 16:48:33.068455 140055989430016 logging_writer.py:48] [48603] accumulated_eval_time=725.283321, accumulated_logging_time=0.968201, accumulated_submission_time=16369.831721, global_step=48603, preemption_count=0, score=16369.831721, test/accuracy=0.477000, test/loss=2.609263, test/num_examples=10000, total_duration=17097.813206, train/accuracy=0.656310, train/loss=1.703670, validation/accuracy=0.604280, validation/loss=1.950433, validation/num_examples=50000
I0315 16:50:47.027073 140056006215424 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.26541730761528015, loss=3.402975082397461
I0315 16:53:34.923934 140055989430016 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.2747665047645569, loss=3.4792227745056152
I0315 16:56:22.910538 140056006215424 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.2643752992153168, loss=3.323768138885498
I0315 16:57:03.218947 140219736737600 spec.py:321] Evaluating on the training split.
I0315 16:57:09.876411 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 16:57:21.498063 140219736737600 spec.py:349] Evaluating on the test split.
I0315 16:57:23.784283 140219736737600 submission_runner.py:420] Time since start: 17628.55s, 	Step: 50122, 	{'train/accuracy': 0.6453284025192261, 'train/loss': 1.7350159883499146, 'validation/accuracy': 0.6012200117111206, 'validation/loss': 1.9408735036849976, 'validation/num_examples': 50000, 'test/accuracy': 0.47360002994537354, 'test/loss': 2.606318235397339, 'test/num_examples': 10000, 'score': 16879.687109470367, 'total_duration': 17628.546664476395, 'accumulated_submission_time': 16879.687109470367, 'accumulated_eval_time': 745.848637342453, 'accumulated_logging_time': 1.2274518013000488}
I0315 16:57:23.803659 140055955859200 logging_writer.py:48] [50122] accumulated_eval_time=745.848637, accumulated_logging_time=1.227452, accumulated_submission_time=16879.687109, global_step=50122, preemption_count=0, score=16879.687109, test/accuracy=0.473600, test/loss=2.606318, test/num_examples=10000, total_duration=17628.546664, train/accuracy=0.645328, train/loss=1.735016, validation/accuracy=0.601220, validation/loss=1.940874, validation/num_examples=50000
I0315 16:59:31.011523 140055964251904 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.272536963224411, loss=3.4274115562438965
I0315 17:02:18.844833 140055955859200 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.2799617350101471, loss=3.4544780254364014
I0315 17:05:06.761677 140055964251904 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.2695937752723694, loss=3.340606689453125
I0315 17:05:53.826678 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:06:00.472075 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:06:10.562993 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:06:12.859624 140219736737600 submission_runner.py:420] Time since start: 18157.62s, 	Step: 51642, 	{'train/accuracy': 0.6628268361091614, 'train/loss': 1.6016414165496826, 'validation/accuracy': 0.6155799627304077, 'validation/loss': 1.818173885345459, 'validation/num_examples': 50000, 'test/accuracy': 0.49010002613067627, 'test/loss': 2.4969828128814697, 'test/num_examples': 10000, 'score': 17389.647258281708, 'total_duration': 18157.621995925903, 'accumulated_submission_time': 17389.647258281708, 'accumulated_eval_time': 764.8815550804138, 'accumulated_logging_time': 1.2552120685577393}
I0315 17:06:12.880935 140055955859200 logging_writer.py:48] [51642] accumulated_eval_time=764.881555, accumulated_logging_time=1.255212, accumulated_submission_time=17389.647258, global_step=51642, preemption_count=0, score=17389.647258, test/accuracy=0.490100, test/loss=2.496983, test/num_examples=10000, total_duration=18157.621996, train/accuracy=0.662827, train/loss=1.601641, validation/accuracy=0.615580, validation/loss=1.818174, validation/num_examples=50000
I0315 17:08:13.541485 140055964251904 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.2769777774810791, loss=3.3452811241149902
I0315 17:11:01.410160 140055955859200 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.28094345331192017, loss=3.4988369941711426
I0315 17:13:49.469931 140055964251904 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.2736169993877411, loss=3.4446494579315186
I0315 17:14:43.037002 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:14:49.753661 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:15:00.208890 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:15:02.610489 140219736737600 submission_runner.py:420] Time since start: 18687.37s, 	Step: 53161, 	{'train/accuracy': 0.6622289419174194, 'train/loss': 1.545854926109314, 'validation/accuracy': 0.5879799723625183, 'validation/loss': 1.8984012603759766, 'validation/num_examples': 50000, 'test/accuracy': 0.4563000202178955, 'test/loss': 2.6356890201568604, 'test/num_examples': 10000, 'score': 17899.738733530045, 'total_duration': 18687.372856378555, 'accumulated_submission_time': 17899.738733530045, 'accumulated_eval_time': 784.4550273418427, 'accumulated_logging_time': 1.286726713180542}
I0315 17:15:02.629065 140055997822720 logging_writer.py:48] [53161] accumulated_eval_time=784.455027, accumulated_logging_time=1.286727, accumulated_submission_time=17899.738734, global_step=53161, preemption_count=0, score=17899.738734, test/accuracy=0.456300, test/loss=2.635689, test/num_examples=10000, total_duration=18687.372856, train/accuracy=0.662229, train/loss=1.545855, validation/accuracy=0.587980, validation/loss=1.898401, validation/num_examples=50000
I0315 17:16:56.838848 140056006215424 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.2750410735607147, loss=3.3685593605041504
I0315 17:19:44.833248 140055997822720 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.2603968381881714, loss=3.3250794410705566
I0315 17:22:32.620609 140056006215424 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.27811169624328613, loss=3.4579310417175293
I0315 17:23:32.815504 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:23:39.391924 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:23:49.958627 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:23:52.276804 140219736737600 submission_runner.py:420] Time since start: 19217.04s, 	Step: 54681, 	{'train/accuracy': 0.6690449714660645, 'train/loss': 1.6354987621307373, 'validation/accuracy': 0.6118800044059753, 'validation/loss': 1.8964757919311523, 'validation/num_examples': 50000, 'test/accuracy': 0.4807000160217285, 'test/loss': 2.59613299369812, 'test/num_examples': 10000, 'score': 18409.862342119217, 'total_duration': 19217.039174079895, 'accumulated_submission_time': 18409.862342119217, 'accumulated_eval_time': 803.9163081645966, 'accumulated_logging_time': 1.3136131763458252}
I0315 17:23:52.299134 140055947466496 logging_writer.py:48] [54681] accumulated_eval_time=803.916308, accumulated_logging_time=1.313613, accumulated_submission_time=18409.862342, global_step=54681, preemption_count=0, score=18409.862342, test/accuracy=0.480700, test/loss=2.596133, test/num_examples=10000, total_duration=19217.039174, train/accuracy=0.669045, train/loss=1.635499, validation/accuracy=0.611880, validation/loss=1.896476, validation/num_examples=50000
I0315 17:25:39.889865 140055955859200 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.2839406728744507, loss=3.4447038173675537
I0315 17:28:27.973783 140055947466496 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.26270994544029236, loss=3.3683576583862305
I0315 17:31:15.775188 140055955859200 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.2842969298362732, loss=3.396521806716919
I0315 17:32:22.466079 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:32:29.013157 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:32:38.396582 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:32:40.749168 140219736737600 submission_runner.py:420] Time since start: 19745.51s, 	Step: 56200, 	{'train/accuracy': 0.6720344424247742, 'train/loss': 1.566835641860962, 'validation/accuracy': 0.6166200041770935, 'validation/loss': 1.810349464416504, 'validation/num_examples': 50000, 'test/accuracy': 0.4829000234603882, 'test/loss': 2.4869861602783203, 'test/num_examples': 10000, 'score': 18919.96532702446, 'total_duration': 19745.5115172863, 'accumulated_submission_time': 18919.96532702446, 'accumulated_eval_time': 822.1993520259857, 'accumulated_logging_time': 1.345710277557373}
I0315 17:32:40.771373 140055947466496 logging_writer.py:48] [56200] accumulated_eval_time=822.199352, accumulated_logging_time=1.345710, accumulated_submission_time=18919.965327, global_step=56200, preemption_count=0, score=18919.965327, test/accuracy=0.482900, test/loss=2.486986, test/num_examples=10000, total_duration=19745.511517, train/accuracy=0.672034, train/loss=1.566836, validation/accuracy=0.616620, validation/loss=1.810349, validation/num_examples=50000
I0315 17:34:21.987474 140055989430016 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.27438655495643616, loss=3.384976387023926
I0315 17:37:10.036137 140055947466496 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.2841499149799347, loss=3.347766637802124
I0315 17:39:58.058384 140055989430016 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.2933298349380493, loss=3.4199776649475098
I0315 17:41:10.968196 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:41:17.437415 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:41:27.389195 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:41:29.700907 140219736737600 submission_runner.py:420] Time since start: 20274.46s, 	Step: 57719, 	{'train/accuracy': 0.6335498690605164, 'train/loss': 1.7657365798950195, 'validation/accuracy': 0.5821200013160706, 'validation/loss': 2.0033061504364014, 'validation/num_examples': 50000, 'test/accuracy': 0.4556000232696533, 'test/loss': 2.6878976821899414, 'test/num_examples': 10000, 'score': 19430.09889483452, 'total_duration': 20274.463276147842, 'accumulated_submission_time': 19430.09889483452, 'accumulated_eval_time': 840.9320335388184, 'accumulated_logging_time': 1.3773596286773682}
I0315 17:41:29.722961 140055955859200 logging_writer.py:48] [57719] accumulated_eval_time=840.932034, accumulated_logging_time=1.377360, accumulated_submission_time=19430.098895, global_step=57719, preemption_count=0, score=19430.098895, test/accuracy=0.455600, test/loss=2.687898, test/num_examples=10000, total_duration=20274.463276, train/accuracy=0.633550, train/loss=1.765737, validation/accuracy=0.582120, validation/loss=2.003306, validation/num_examples=50000
I0315 17:43:04.592793 140055964251904 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.2819989025592804, loss=3.4251866340637207
I0315 17:45:52.572838 140055955859200 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.27825939655303955, loss=3.3300347328186035
I0315 17:48:40.837475 140055964251904 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.287461519241333, loss=3.4174742698669434
I0315 17:50:00.009531 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:50:06.490786 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:50:15.886767 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:50:18.203339 140219736737600 submission_runner.py:420] Time since start: 20802.97s, 	Step: 59237, 	{'train/accuracy': 0.662129282951355, 'train/loss': 1.6116786003112793, 'validation/accuracy': 0.6101199984550476, 'validation/loss': 1.8550580739974976, 'validation/num_examples': 50000, 'test/accuracy': 0.4830000102519989, 'test/loss': 2.505258560180664, 'test/num_examples': 10000, 'score': 19940.321910619736, 'total_duration': 20802.96570944786, 'accumulated_submission_time': 19940.321910619736, 'accumulated_eval_time': 859.1258161067963, 'accumulated_logging_time': 1.4092257022857666}
I0315 17:50:18.225477 140055796512512 logging_writer.py:48] [59237] accumulated_eval_time=859.125816, accumulated_logging_time=1.409226, accumulated_submission_time=19940.321911, global_step=59237, preemption_count=0, score=19940.321911, test/accuracy=0.483000, test/loss=2.505259, test/num_examples=10000, total_duration=20802.965709, train/accuracy=0.662129, train/loss=1.611679, validation/accuracy=0.610120, validation/loss=1.855058, validation/num_examples=50000
I0315 17:51:46.801391 140055947466496 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.2860054075717926, loss=3.396270275115967
I0315 17:54:34.785608 140055796512512 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.2773153483867645, loss=3.374206304550171
I0315 17:57:22.750383 140055947466496 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.28085780143737793, loss=3.393315076828003
I0315 17:58:48.482831 140219736737600 spec.py:321] Evaluating on the training split.
I0315 17:58:54.858084 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 17:59:03.780514 140219736737600 spec.py:349] Evaluating on the test split.
I0315 17:59:06.123124 140219736737600 submission_runner.py:420] Time since start: 21330.89s, 	Step: 60757, 	{'train/accuracy': 0.6338488459587097, 'train/loss': 1.764035701751709, 'validation/accuracy': 0.5829200148582458, 'validation/loss': 2.0148353576660156, 'validation/num_examples': 50000, 'test/accuracy': 0.45110002160072327, 'test/loss': 2.714724063873291, 'test/num_examples': 10000, 'score': 20450.511591672897, 'total_duration': 21330.88549399376, 'accumulated_submission_time': 20450.511591672897, 'accumulated_eval_time': 876.7660822868347, 'accumulated_logging_time': 1.4434089660644531}
I0315 17:59:06.145490 140055981037312 logging_writer.py:48] [60757] accumulated_eval_time=876.766082, accumulated_logging_time=1.443409, accumulated_submission_time=20450.511592, global_step=60757, preemption_count=0, score=20450.511592, test/accuracy=0.451100, test/loss=2.714724, test/num_examples=10000, total_duration=21330.885494, train/accuracy=0.633849, train/loss=1.764036, validation/accuracy=0.582920, validation/loss=2.014835, validation/num_examples=50000
I0315 18:00:28.224100 140055989430016 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.2863498330116272, loss=3.4012179374694824
I0315 18:03:16.124897 140055981037312 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.26922252774238586, loss=3.2859580516815186
I0315 18:06:04.197657 140055989430016 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.28746092319488525, loss=3.349177360534668
I0315 18:07:36.315240 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:07:42.763503 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:07:51.537162 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:07:53.849007 140219736737600 submission_runner.py:420] Time since start: 21858.61s, 	Step: 62276, 	{'train/accuracy': 0.6950533986091614, 'train/loss': 1.5297223329544067, 'validation/accuracy': 0.6177799701690674, 'validation/loss': 1.8755176067352295, 'validation/num_examples': 50000, 'test/accuracy': 0.4914000332355499, 'test/loss': 2.526862144470215, 'test/num_examples': 10000, 'score': 20960.61719608307, 'total_duration': 21858.611336946487, 'accumulated_submission_time': 20960.61719608307, 'accumulated_eval_time': 894.2997860908508, 'accumulated_logging_time': 1.4753570556640625}
I0315 18:07:53.872392 140055955859200 logging_writer.py:48] [62276] accumulated_eval_time=894.299786, accumulated_logging_time=1.475357, accumulated_submission_time=20960.617196, global_step=62276, preemption_count=0, score=20960.617196, test/accuracy=0.491400, test/loss=2.526862, test/num_examples=10000, total_duration=21858.611337, train/accuracy=0.695053, train/loss=1.529722, validation/accuracy=0.617780, validation/loss=1.875518, validation/num_examples=50000
I0315 18:09:09.485026 140055964251904 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.2893483638763428, loss=3.3272411823272705
I0315 18:11:57.464288 140055955859200 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.29252609610557556, loss=3.3520915508270264
I0315 18:14:45.535493 140055964251904 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.2875930070877075, loss=3.323725938796997
I0315 18:16:23.881289 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:16:30.298094 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:16:39.161366 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:16:41.459299 140219736737600 submission_runner.py:420] Time since start: 22386.22s, 	Step: 63794, 	{'train/accuracy': 0.6825574040412903, 'train/loss': 1.5783780813217163, 'validation/accuracy': 0.617579996585846, 'validation/loss': 1.8705898523330688, 'validation/num_examples': 50000, 'test/accuracy': 0.4853000342845917, 'test/loss': 2.554471492767334, 'test/num_examples': 10000, 'score': 21470.559576272964, 'total_duration': 22386.221648454666, 'accumulated_submission_time': 21470.559576272964, 'accumulated_eval_time': 911.877756357193, 'accumulated_logging_time': 1.509612798690796}
I0315 18:16:41.483463 140055989430016 logging_writer.py:48] [63794] accumulated_eval_time=911.877756, accumulated_logging_time=1.509613, accumulated_submission_time=21470.559576, global_step=63794, preemption_count=0, score=21470.559576, test/accuracy=0.485300, test/loss=2.554471, test/num_examples=10000, total_duration=22386.221648, train/accuracy=0.682557, train/loss=1.578378, validation/accuracy=0.617580, validation/loss=1.870590, validation/num_examples=50000
I0315 18:17:51.075179 140055997822720 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.29106390476226807, loss=3.413860559463501
I0315 18:20:39.294627 140055989430016 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.2857026159763336, loss=3.2393903732299805
I0315 18:23:27.144395 140055997822720 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.28955912590026855, loss=3.3386640548706055
I0315 18:25:11.651081 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:25:18.020630 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:25:26.897652 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:25:29.289559 140219736737600 submission_runner.py:420] Time since start: 22914.05s, 	Step: 65313, 	{'train/accuracy': 0.6825574040412903, 'train/loss': 1.5256329774856567, 'validation/accuracy': 0.625059962272644, 'validation/loss': 1.7955353260040283, 'validation/num_examples': 50000, 'test/accuracy': 0.4974000155925751, 'test/loss': 2.433189868927002, 'test/num_examples': 10000, 'score': 21980.664748430252, 'total_duration': 22914.051850557327, 'accumulated_submission_time': 21980.664748430252, 'accumulated_eval_time': 929.5161347389221, 'accumulated_logging_time': 1.543241024017334}
I0315 18:25:29.317076 140055955859200 logging_writer.py:48] [65313] accumulated_eval_time=929.516135, accumulated_logging_time=1.543241, accumulated_submission_time=21980.664748, global_step=65313, preemption_count=0, score=21980.664748, test/accuracy=0.497400, test/loss=2.433190, test/num_examples=10000, total_duration=22914.051851, train/accuracy=0.682557, train/loss=1.525633, validation/accuracy=0.625060, validation/loss=1.795535, validation/num_examples=50000
I0315 18:26:32.442371 140055964251904 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.304850310087204, loss=3.333625316619873
I0315 18:29:20.461859 140055955859200 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.2977868616580963, loss=3.3201241493225098
I0315 18:32:08.245744 140055964251904 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.296898752450943, loss=3.3076798915863037
I0315 18:33:59.455225 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:34:05.896550 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:34:14.862992 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:34:17.195675 140219736737600 submission_runner.py:420] Time since start: 23441.96s, 	Step: 66833, 	{'train/accuracy': 0.6800063848495483, 'train/loss': 1.5886160135269165, 'validation/accuracy': 0.6231799721717834, 'validation/loss': 1.831006646156311, 'validation/num_examples': 50000, 'test/accuracy': 0.5015000104904175, 'test/loss': 2.474353313446045, 'test/num_examples': 10000, 'score': 22490.73743534088, 'total_duration': 23441.95782518387, 'accumulated_submission_time': 22490.73743534088, 'accumulated_eval_time': 947.2563452720642, 'accumulated_logging_time': 1.5833804607391357}
I0315 18:34:17.217480 140055947466496 logging_writer.py:48] [66833] accumulated_eval_time=947.256345, accumulated_logging_time=1.583380, accumulated_submission_time=22490.737435, global_step=66833, preemption_count=0, score=22490.737435, test/accuracy=0.501500, test/loss=2.474353, test/num_examples=10000, total_duration=23441.957825, train/accuracy=0.680006, train/loss=1.588616, validation/accuracy=0.623180, validation/loss=1.831007, validation/num_examples=50000
I0315 18:35:13.677070 140055989430016 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.30248892307281494, loss=3.3839783668518066
I0315 18:38:01.608335 140055947466496 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.30434107780456543, loss=3.3773958683013916
I0315 18:40:49.620511 140055989430016 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.291748583316803, loss=3.318031072616577
I0315 18:42:47.405881 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:42:53.812919 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:43:02.763733 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:43:05.130677 140219736737600 submission_runner.py:420] Time since start: 23969.89s, 	Step: 68352, 	{'train/accuracy': 0.6900709271430969, 'train/loss': 1.4819682836532593, 'validation/accuracy': 0.6340999603271484, 'validation/loss': 1.7323555946350098, 'validation/num_examples': 50000, 'test/accuracy': 0.503600001335144, 'test/loss': 2.4148378372192383, 'test/num_examples': 10000, 'score': 23000.860374689102, 'total_duration': 23969.89304113388, 'accumulated_submission_time': 23000.860374689102, 'accumulated_eval_time': 964.9811155796051, 'accumulated_logging_time': 1.6150639057159424}
I0315 18:43:05.154869 140055997822720 logging_writer.py:48] [68352] accumulated_eval_time=964.981116, accumulated_logging_time=1.615064, accumulated_submission_time=23000.860375, global_step=68352, preemption_count=0, score=23000.860375, test/accuracy=0.503600, test/loss=2.414838, test/num_examples=10000, total_duration=23969.893041, train/accuracy=0.690071, train/loss=1.481968, validation/accuracy=0.634100, validation/loss=1.732356, validation/num_examples=50000
I0315 18:43:55.282133 140056006215424 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.3045399785041809, loss=3.3530046939849854
I0315 18:46:43.288487 140055997822720 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.30220213532447815, loss=3.391969919204712
I0315 18:49:31.189572 140056006215424 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.2911539077758789, loss=3.316213607788086
I0315 18:51:35.353971 140219736737600 spec.py:321] Evaluating on the training split.
I0315 18:51:41.700428 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 18:51:50.805179 140219736737600 spec.py:349] Evaluating on the test split.
I0315 18:51:53.157674 140219736737600 submission_runner.py:420] Time since start: 24497.92s, 	Step: 69872, 	{'train/accuracy': 0.735750138759613, 'train/loss': 1.310245394706726, 'validation/accuracy': 0.6309799551963806, 'validation/loss': 1.761465072631836, 'validation/num_examples': 50000, 'test/accuracy': 0.49720001220703125, 'test/loss': 2.425360679626465, 'test/num_examples': 10000, 'score': 23510.993293762207, 'total_duration': 24497.920041322708, 'accumulated_submission_time': 23510.993293762207, 'accumulated_eval_time': 982.7848091125488, 'accumulated_logging_time': 1.651102066040039}
I0315 18:51:53.181139 140055981037312 logging_writer.py:48] [69872] accumulated_eval_time=982.784809, accumulated_logging_time=1.651102, accumulated_submission_time=23510.993294, global_step=69872, preemption_count=0, score=23510.993294, test/accuracy=0.497200, test/loss=2.425361, test/num_examples=10000, total_duration=24497.920041, train/accuracy=0.735750, train/loss=1.310245, validation/accuracy=0.630980, validation/loss=1.761465, validation/num_examples=50000
I0315 18:52:36.611491 140055989430016 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.31659334897994995, loss=3.3902506828308105
I0315 18:55:24.503368 140055981037312 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.2945871353149414, loss=3.2433724403381348
I0315 18:58:12.398326 140055989430016 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.29998481273651123, loss=3.325251579284668
I0315 19:00:23.229886 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:00:29.383052 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:00:38.306568 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:00:40.626472 140219736737600 submission_runner.py:420] Time since start: 25025.39s, 	Step: 71392, 	{'train/accuracy': 0.6983617544174194, 'train/loss': 1.4776744842529297, 'validation/accuracy': 0.6286599636077881, 'validation/loss': 1.800763726234436, 'validation/num_examples': 50000, 'test/accuracy': 0.49400001764297485, 'test/loss': 2.4847891330718994, 'test/num_examples': 10000, 'score': 24020.97679042816, 'total_duration': 25025.388818740845, 'accumulated_submission_time': 24020.97679042816, 'accumulated_eval_time': 1000.1813578605652, 'accumulated_logging_time': 1.6846182346343994}
I0315 19:00:40.653646 140055972644608 logging_writer.py:48] [71392] accumulated_eval_time=1000.181358, accumulated_logging_time=1.684618, accumulated_submission_time=24020.976790, global_step=71392, preemption_count=0, score=24020.976790, test/accuracy=0.494000, test/loss=2.484789, test/num_examples=10000, total_duration=25025.388819, train/accuracy=0.698362, train/loss=1.477674, validation/accuracy=0.628660, validation/loss=1.800764, validation/num_examples=50000
I0315 19:01:17.306613 140055997822720 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.29047754406929016, loss=3.350308895111084
I0315 19:04:05.124283 140055972644608 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.3088361620903015, loss=3.3426544666290283
I0315 19:06:52.831907 140055997822720 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.294636070728302, loss=3.2721850872039795
I0315 19:09:10.832045 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:09:17.010018 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:09:26.038253 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:09:28.357930 140219736737600 submission_runner.py:420] Time since start: 25553.12s, 	Step: 72913, 	{'train/accuracy': 0.6980229616165161, 'train/loss': 1.427905797958374, 'validation/accuracy': 0.637499988079071, 'validation/loss': 1.7069525718688965, 'validation/num_examples': 50000, 'test/accuracy': 0.5054000020027161, 'test/loss': 2.4028196334838867, 'test/num_examples': 10000, 'score': 24531.09007692337, 'total_duration': 25553.120299100876, 'accumulated_submission_time': 24531.09007692337, 'accumulated_eval_time': 1017.7072203159332, 'accumulated_logging_time': 1.7220878601074219}
I0315 19:09:28.383444 140055955859200 logging_writer.py:48] [72913] accumulated_eval_time=1017.707220, accumulated_logging_time=1.722088, accumulated_submission_time=24531.090077, global_step=72913, preemption_count=0, score=24531.090077, test/accuracy=0.505400, test/loss=2.402820, test/num_examples=10000, total_duration=25553.120299, train/accuracy=0.698023, train/loss=1.427906, validation/accuracy=0.637500, validation/loss=1.706953, validation/num_examples=50000
I0315 19:09:57.988287 140055964251904 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.3056458830833435, loss=3.3044803142547607
I0315 19:12:45.723977 140055955859200 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.31336215138435364, loss=3.2870917320251465
I0315 19:15:33.503829 140055964251904 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.317495197057724, loss=3.3441996574401855
I0315 19:17:58.395650 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:18:04.650704 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:18:13.730285 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:18:16.029830 140219736737600 submission_runner.py:420] Time since start: 26080.79s, 	Step: 74433, 	{'train/accuracy': 0.6910873651504517, 'train/loss': 1.5273631811141968, 'validation/accuracy': 0.6297399997711182, 'validation/loss': 1.8042446374893188, 'validation/num_examples': 50000, 'test/accuracy': 0.5105000138282776, 'test/loss': 2.4476895332336426, 'test/num_examples': 10000, 'score': 25041.03431081772, 'total_duration': 26080.79218506813, 'accumulated_submission_time': 25041.03431081772, 'accumulated_eval_time': 1035.3413667678833, 'accumulated_logging_time': 1.7609531879425049}
I0315 19:18:16.053989 140055981037312 logging_writer.py:48] [74433] accumulated_eval_time=1035.341367, accumulated_logging_time=1.760953, accumulated_submission_time=25041.034311, global_step=74433, preemption_count=0, score=25041.034311, test/accuracy=0.510500, test/loss=2.447690, test/num_examples=10000, total_duration=26080.792185, train/accuracy=0.691087, train/loss=1.527363, validation/accuracy=0.629740, validation/loss=1.804245, validation/num_examples=50000
I0315 19:18:38.829177 140055989430016 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.30378615856170654, loss=3.308110475540161
I0315 19:21:26.801592 140055981037312 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.3074056804180145, loss=3.2996256351470947
I0315 19:24:14.844906 140055989430016 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.30571097135543823, loss=3.337918281555176
I0315 19:26:46.264159 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:26:53.109118 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:27:02.254087 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:27:04.561512 140219736737600 submission_runner.py:420] Time since start: 26609.32s, 	Step: 75952, 	{'train/accuracy': 0.6999362111091614, 'train/loss': 1.4965587854385376, 'validation/accuracy': 0.6417199969291687, 'validation/loss': 1.754271149635315, 'validation/num_examples': 50000, 'test/accuracy': 0.5117000341415405, 'test/loss': 2.413970708847046, 'test/num_examples': 10000, 'score': 25551.18010687828, 'total_duration': 26609.32388329506, 'accumulated_submission_time': 25551.18010687828, 'accumulated_eval_time': 1053.638699054718, 'accumulated_logging_time': 1.796116828918457}
I0315 19:27:04.588228 140055989430016 logging_writer.py:48] [75952] accumulated_eval_time=1053.638699, accumulated_logging_time=1.796117, accumulated_submission_time=25551.180107, global_step=75952, preemption_count=0, score=25551.180107, test/accuracy=0.511700, test/loss=2.413971, test/num_examples=10000, total_duration=26609.323883, train/accuracy=0.699936, train/loss=1.496559, validation/accuracy=0.641720, validation/loss=1.754271, validation/num_examples=50000
I0315 19:27:21.028768 140055997822720 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.30956873297691345, loss=3.292612314224243
I0315 19:30:08.768121 140055989430016 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.3187239468097687, loss=3.324985980987549
I0315 19:32:56.791615 140055997822720 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.3084867000579834, loss=3.227806806564331
I0315 19:35:34.797687 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:35:41.068914 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:35:49.851766 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:35:52.154103 140219736737600 submission_runner.py:420] Time since start: 27136.92s, 	Step: 77472, 	{'train/accuracy': 0.6788105964660645, 'train/loss': 1.539688229560852, 'validation/accuracy': 0.6212799549102783, 'validation/loss': 1.79335618019104, 'validation/num_examples': 50000, 'test/accuracy': 0.4953000247478485, 'test/loss': 2.4778523445129395, 'test/num_examples': 10000, 'score': 26061.325164079666, 'total_duration': 27136.916464805603, 'accumulated_submission_time': 26061.325164079666, 'accumulated_eval_time': 1070.9950873851776, 'accumulated_logging_time': 1.8330702781677246}
I0315 19:35:52.182448 140055981037312 logging_writer.py:48] [77472] accumulated_eval_time=1070.995087, accumulated_logging_time=1.833070, accumulated_submission_time=26061.325164, global_step=77472, preemption_count=0, score=26061.325164, test/accuracy=0.495300, test/loss=2.477852, test/num_examples=10000, total_duration=27136.916465, train/accuracy=0.678811, train/loss=1.539688, validation/accuracy=0.621280, validation/loss=1.793356, validation/num_examples=50000
I0315 19:36:01.944878 140056006215424 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.2993867099285126, loss=3.271099090576172
I0315 19:38:49.872666 140055981037312 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.31751933693885803, loss=3.26655650138855
I0315 19:41:37.777055 140056006215424 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.3040945827960968, loss=3.157090425491333
I0315 19:44:22.200053 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:44:28.353509 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:44:37.262074 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:44:39.654588 140219736737600 submission_runner.py:420] Time since start: 27664.42s, 	Step: 78991, 	{'train/accuracy': 0.7440808415412903, 'train/loss': 1.304325819015503, 'validation/accuracy': 0.6543999910354614, 'validation/loss': 1.688109040260315, 'validation/num_examples': 50000, 'test/accuracy': 0.5197000503540039, 'test/loss': 2.376405954360962, 'test/num_examples': 10000, 'score': 26571.27771782875, 'total_duration': 27664.416957378387, 'accumulated_submission_time': 26571.27771782875, 'accumulated_eval_time': 1088.4496076107025, 'accumulated_logging_time': 1.8720881938934326}
I0315 19:44:39.681030 140055947466496 logging_writer.py:48] [78991] accumulated_eval_time=1088.449608, accumulated_logging_time=1.872088, accumulated_submission_time=26571.277718, global_step=78991, preemption_count=0, score=26571.277718, test/accuracy=0.519700, test/loss=2.376406, test/num_examples=10000, total_duration=27664.416957, train/accuracy=0.744081, train/loss=1.304326, validation/accuracy=0.654400, validation/loss=1.688109, validation/num_examples=50000
I0315 19:44:43.034733 140055955859200 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.31561145186424255, loss=3.2818126678466797
I0315 19:47:30.958951 140055947466496 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.30857884883880615, loss=3.30289363861084
I0315 19:50:18.797221 140055955859200 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.30601364374160767, loss=3.1615071296691895
I0315 19:53:06.804285 140055947466496 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.3177923262119293, loss=3.2168498039245605
I0315 19:53:09.922187 140219736737600 spec.py:321] Evaluating on the training split.
I0315 19:53:16.087280 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 19:53:25.136325 140219736737600 spec.py:349] Evaluating on the test split.
I0315 19:53:27.486231 140219736737600 submission_runner.py:420] Time since start: 28192.25s, 	Step: 80511, 	{'train/accuracy': 0.7175741195678711, 'train/loss': 1.402329921722412, 'validation/accuracy': 0.6451599597930908, 'validation/loss': 1.7160725593566895, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.3861660957336426, 'test/num_examples': 10000, 'score': 27081.45338320732, 'total_duration': 28192.248603582382, 'accumulated_submission_time': 27081.45338320732, 'accumulated_eval_time': 1106.0136144161224, 'accumulated_logging_time': 1.9104361534118652}
I0315 19:53:27.509381 140055796512512 logging_writer.py:48] [80511] accumulated_eval_time=1106.013614, accumulated_logging_time=1.910436, accumulated_submission_time=27081.453383, global_step=80511, preemption_count=0, score=27081.453383, test/accuracy=0.515100, test/loss=2.386166, test/num_examples=10000, total_duration=28192.248604, train/accuracy=0.717574, train/loss=1.402330, validation/accuracy=0.645160, validation/loss=1.716073, validation/num_examples=50000
I0315 19:56:12.236731 140055947466496 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.3157069981098175, loss=3.203551769256592
I0315 19:59:00.073740 140055796512512 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.3218734562397003, loss=3.3161144256591797
I0315 20:01:48.341762 140055947466496 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.31464868783950806, loss=3.186725378036499
I0315 20:01:57.525852 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:02:03.774426 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:02:12.904710 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:02:15.202482 140219736737600 submission_runner.py:420] Time since start: 28719.96s, 	Step: 82029, 	{'train/accuracy': 0.7053172588348389, 'train/loss': 1.4680125713348389, 'validation/accuracy': 0.6407600045204163, 'validation/loss': 1.7571892738342285, 'validation/num_examples': 50000, 'test/accuracy': 0.5166000127792358, 'test/loss': 2.390846014022827, 'test/num_examples': 10000, 'score': 27591.40394973755, 'total_duration': 28719.964844942093, 'accumulated_submission_time': 27591.40394973755, 'accumulated_eval_time': 1123.690217256546, 'accumulated_logging_time': 1.9442918300628662}
I0315 20:02:15.228914 140055972644608 logging_writer.py:48] [82029] accumulated_eval_time=1123.690217, accumulated_logging_time=1.944292, accumulated_submission_time=27591.403950, global_step=82029, preemption_count=0, score=27591.403950, test/accuracy=0.516600, test/loss=2.390846, test/num_examples=10000, total_duration=28719.964845, train/accuracy=0.705317, train/loss=1.468013, validation/accuracy=0.640760, validation/loss=1.757189, validation/num_examples=50000
I0315 20:04:53.564981 140055997822720 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.3235110342502594, loss=3.2324137687683105
I0315 20:07:41.567126 140055972644608 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.31886059045791626, loss=3.252277374267578
I0315 20:10:29.271641 140055997822720 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.32629796862602234, loss=3.2156152725219727
I0315 20:10:45.445927 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:10:51.599620 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:11:00.664006 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:11:03.139564 140219736737600 submission_runner.py:420] Time since start: 29247.90s, 	Step: 83550, 	{'train/accuracy': 0.7248684763908386, 'train/loss': 1.3496756553649902, 'validation/accuracy': 0.6628199815750122, 'validation/loss': 1.6300710439682007, 'validation/num_examples': 50000, 'test/accuracy': 0.5449000000953674, 'test/loss': 2.249837636947632, 'test/num_examples': 10000, 'score': 28101.55716228485, 'total_duration': 29247.901939868927, 'accumulated_submission_time': 28101.55716228485, 'accumulated_eval_time': 1141.383838891983, 'accumulated_logging_time': 1.9798212051391602}
I0315 20:11:03.159548 140055947466496 logging_writer.py:48] [83550] accumulated_eval_time=1141.383839, accumulated_logging_time=1.979821, accumulated_submission_time=28101.557162, global_step=83550, preemption_count=0, score=28101.557162, test/accuracy=0.544900, test/loss=2.249838, test/num_examples=10000, total_duration=29247.901940, train/accuracy=0.724868, train/loss=1.349676, validation/accuracy=0.662820, validation/loss=1.630071, validation/num_examples=50000
I0315 20:13:34.658638 140055955859200 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.32619768381118774, loss=3.2288177013397217
I0315 20:16:22.655715 140055947466496 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.3283294141292572, loss=3.208707809448242
I0315 20:19:10.659180 140055955859200 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.3269162178039551, loss=3.1419522762298584
I0315 20:19:33.204094 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:19:39.447148 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:19:48.529004 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:19:50.838463 140219736737600 submission_runner.py:420] Time since start: 29775.60s, 	Step: 85069, 	{'train/accuracy': 0.7144650816917419, 'train/loss': 1.433240532875061, 'validation/accuracy': 0.6558799743652344, 'validation/loss': 1.6867034435272217, 'validation/num_examples': 50000, 'test/accuracy': 0.5259000062942505, 'test/loss': 2.3334290981292725, 'test/num_examples': 10000, 'score': 28611.537837028503, 'total_duration': 29775.600833654404, 'accumulated_submission_time': 28611.537837028503, 'accumulated_eval_time': 1159.0181767940521, 'accumulated_logging_time': 2.008910655975342}
I0315 20:19:50.861939 140055989430016 logging_writer.py:48] [85069] accumulated_eval_time=1159.018177, accumulated_logging_time=2.008911, accumulated_submission_time=28611.537837, global_step=85069, preemption_count=0, score=28611.537837, test/accuracy=0.525900, test/loss=2.333429, test/num_examples=10000, total_duration=29775.600834, train/accuracy=0.714465, train/loss=1.433241, validation/accuracy=0.655880, validation/loss=1.686703, validation/num_examples=50000
I0315 20:22:16.136173 140055997822720 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.3212464451789856, loss=3.1893057823181152
I0315 20:25:04.136510 140055989430016 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.33748313784599304, loss=3.204298734664917
I0315 20:27:52.367590 140055997822720 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.32818564772605896, loss=3.167051315307617
I0315 20:28:21.053937 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:28:27.236135 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:28:36.124755 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:28:38.442202 140219736737600 submission_runner.py:420] Time since start: 30303.20s, 	Step: 86587, 	{'train/accuracy': 0.7221779227256775, 'train/loss': 1.3290126323699951, 'validation/accuracy': 0.6613399982452393, 'validation/loss': 1.6058188676834106, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.271061420440674, 'test/num_examples': 10000, 'score': 29121.66387820244, 'total_duration': 30303.2045712471, 'accumulated_submission_time': 29121.66387820244, 'accumulated_eval_time': 1176.4064183235168, 'accumulated_logging_time': 2.043738842010498}
I0315 20:28:38.466349 140055955859200 logging_writer.py:48] [86587] accumulated_eval_time=1176.406418, accumulated_logging_time=2.043739, accumulated_submission_time=29121.663878, global_step=86587, preemption_count=0, score=29121.663878, test/accuracy=0.531200, test/loss=2.271061, test/num_examples=10000, total_duration=30303.204571, train/accuracy=0.722178, train/loss=1.329013, validation/accuracy=0.661340, validation/loss=1.605819, validation/num_examples=50000
I0315 20:30:57.609829 140055964251904 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.33755776286125183, loss=3.24589204788208
I0315 20:33:45.826564 140055955859200 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.34088394045829773, loss=3.239398241043091
I0315 20:36:34.012295 140055964251904 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.34061893820762634, loss=3.1874935626983643
I0315 20:37:08.741456 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:37:14.885944 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:37:23.955359 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:37:26.319494 140219736737600 submission_runner.py:420] Time since start: 30831.08s, 	Step: 88105, 	{'train/accuracy': 0.7548230290412903, 'train/loss': 1.264643669128418, 'validation/accuracy': 0.6629599928855896, 'validation/loss': 1.6557101011276245, 'validation/num_examples': 50000, 'test/accuracy': 0.5333000421524048, 'test/loss': 2.3110227584838867, 'test/num_examples': 10000, 'score': 29631.87465071678, 'total_duration': 30831.08186531067, 'accumulated_submission_time': 29631.87465071678, 'accumulated_eval_time': 1193.9844272136688, 'accumulated_logging_time': 2.0784449577331543}
I0315 20:37:26.343565 140055955859200 logging_writer.py:48] [88105] accumulated_eval_time=1193.984427, accumulated_logging_time=2.078445, accumulated_submission_time=29631.874651, global_step=88105, preemption_count=0, score=29631.874651, test/accuracy=0.533300, test/loss=2.311023, test/num_examples=10000, total_duration=30831.081865, train/accuracy=0.754823, train/loss=1.264644, validation/accuracy=0.662960, validation/loss=1.655710, validation/num_examples=50000
I0315 20:39:39.418113 140055989430016 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.335306316614151, loss=3.1345484256744385
I0315 20:42:27.244513 140055955859200 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.3367983102798462, loss=3.225385904312134
I0315 20:45:15.220510 140055989430016 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.3299357295036316, loss=3.1635756492614746
I0315 20:45:56.372220 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:46:02.633197 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:46:11.395243 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:46:13.696710 140219736737600 submission_runner.py:420] Time since start: 31358.46s, 	Step: 89624, 	{'train/accuracy': 0.7227559089660645, 'train/loss': 1.3492029905319214, 'validation/accuracy': 0.649179995059967, 'validation/loss': 1.6802361011505127, 'validation/num_examples': 50000, 'test/accuracy': 0.5248000025749207, 'test/loss': 2.3291525840759277, 'test/num_examples': 10000, 'score': 30141.839609861374, 'total_duration': 31358.45908021927, 'accumulated_submission_time': 30141.839609861374, 'accumulated_eval_time': 1211.308886051178, 'accumulated_logging_time': 2.1126153469085693}
I0315 20:46:13.722009 140055964251904 logging_writer.py:48] [89624] accumulated_eval_time=1211.308886, accumulated_logging_time=2.112615, accumulated_submission_time=30141.839610, global_step=89624, preemption_count=0, score=30141.839610, test/accuracy=0.524800, test/loss=2.329153, test/num_examples=10000, total_duration=31358.459080, train/accuracy=0.722756, train/loss=1.349203, validation/accuracy=0.649180, validation/loss=1.680236, validation/num_examples=50000
I0315 20:48:20.176215 140055972644608 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.3442670404911041, loss=3.190072774887085
I0315 20:51:08.492489 140055964251904 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.3397553265094757, loss=3.2505412101745605
I0315 20:53:56.746788 140055972644608 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.34363168478012085, loss=3.226222276687622
I0315 20:54:43.939129 140219736737600 spec.py:321] Evaluating on the training split.
I0315 20:54:50.076686 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 20:54:58.876418 140219736737600 spec.py:349] Evaluating on the test split.
I0315 20:55:01.176745 140219736737600 submission_runner.py:420] Time since start: 31885.94s, 	Step: 91142, 	{'train/accuracy': 0.7321228981018066, 'train/loss': 1.2703503370285034, 'validation/accuracy': 0.6629199981689453, 'validation/loss': 1.5804736614227295, 'validation/num_examples': 50000, 'test/accuracy': 0.5315999984741211, 'test/loss': 2.240797281265259, 'test/num_examples': 10000, 'score': 30651.993514060974, 'total_duration': 31885.939094781876, 'accumulated_submission_time': 30651.993514060974, 'accumulated_eval_time': 1228.546450138092, 'accumulated_logging_time': 2.147599458694458}
I0315 20:55:01.200826 140055955859200 logging_writer.py:48] [91142] accumulated_eval_time=1228.546450, accumulated_logging_time=2.147599, accumulated_submission_time=30651.993514, global_step=91142, preemption_count=0, score=30651.993514, test/accuracy=0.531600, test/loss=2.240797, test/num_examples=10000, total_duration=31885.939095, train/accuracy=0.732123, train/loss=1.270350, validation/accuracy=0.662920, validation/loss=1.580474, validation/num_examples=50000
I0315 20:57:01.790035 140055989430016 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.3474283218383789, loss=3.1626555919647217
I0315 20:59:50.018755 140055955859200 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.3457391858100891, loss=3.1325621604919434
I0315 21:02:38.310970 140055989430016 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.34509533643722534, loss=3.200040340423584
I0315 21:03:31.236510 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:03:37.486295 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:03:46.279750 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:03:48.616525 140219736737600 submission_runner.py:420] Time since start: 32413.38s, 	Step: 92659, 	{'train/accuracy': 0.7361088991165161, 'train/loss': 1.2528094053268433, 'validation/accuracy': 0.6668999791145325, 'validation/loss': 1.5570307970046997, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 2.1921234130859375, 'test/num_examples': 10000, 'score': 31161.964614391327, 'total_duration': 32413.378881692886, 'accumulated_submission_time': 31161.964614391327, 'accumulated_eval_time': 1245.9264180660248, 'accumulated_logging_time': 2.181300640106201}
I0315 21:03:48.641821 140055972644608 logging_writer.py:48] [92659] accumulated_eval_time=1245.926418, accumulated_logging_time=2.181301, accumulated_submission_time=31161.964614, global_step=92659, preemption_count=0, score=31161.964614, test/accuracy=0.544400, test/loss=2.192123, test/num_examples=10000, total_duration=32413.378882, train/accuracy=0.736109, train/loss=1.252809, validation/accuracy=0.666900, validation/loss=1.557031, validation/num_examples=50000
I0315 21:05:43.763846 140056006215424 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.3499143421649933, loss=3.151614189147949
I0315 21:08:31.580531 140055972644608 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.3440127968788147, loss=3.124237060546875
I0315 21:11:19.817645 140056006215424 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.34190163016319275, loss=3.1178970336914062
I0315 21:12:18.780689 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:12:24.956853 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:12:33.732182 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:12:36.093913 140219736737600 submission_runner.py:420] Time since start: 32940.86s, 	Step: 94177, 	{'train/accuracy': 0.7242506146430969, 'train/loss': 1.2950704097747803, 'validation/accuracy': 0.6656999588012695, 'validation/loss': 1.572513222694397, 'validation/num_examples': 50000, 'test/accuracy': 0.5347000360488892, 'test/loss': 2.2459769248962402, 'test/num_examples': 10000, 'score': 31672.038009881973, 'total_duration': 32940.856270074844, 'accumulated_submission_time': 31672.038009881973, 'accumulated_eval_time': 1263.2396013736725, 'accumulated_logging_time': 2.2167887687683105}
I0315 21:12:36.120594 140055796512512 logging_writer.py:48] [94177] accumulated_eval_time=1263.239601, accumulated_logging_time=2.216789, accumulated_submission_time=31672.038010, global_step=94177, preemption_count=0, score=31672.038010, test/accuracy=0.534700, test/loss=2.245977, test/num_examples=10000, total_duration=32940.856270, train/accuracy=0.724251, train/loss=1.295070, validation/accuracy=0.665700, validation/loss=1.572513, validation/num_examples=50000
I0315 21:14:24.913972 140055947466496 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.34374842047691345, loss=3.1218619346618652
I0315 21:17:13.053886 140055796512512 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.35382816195487976, loss=3.1485188007354736
I0315 21:20:01.136636 140055947466496 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.3478386402130127, loss=3.1464614868164062
I0315 21:21:06.425559 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:21:12.549604 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:21:21.520933 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:21:23.844428 140219736737600 submission_runner.py:420] Time since start: 33468.61s, 	Step: 95696, 	{'train/accuracy': 0.7590082883834839, 'train/loss': 1.2098000049591064, 'validation/accuracy': 0.6653800010681152, 'validation/loss': 1.604893445968628, 'validation/num_examples': 50000, 'test/accuracy': 0.5419000387191772, 'test/loss': 2.2530221939086914, 'test/num_examples': 10000, 'score': 32182.27980208397, 'total_duration': 33468.606795072556, 'accumulated_submission_time': 32182.27980208397, 'accumulated_eval_time': 1280.6584432125092, 'accumulated_logging_time': 2.2529103755950928}
I0315 21:21:23.868691 140055947466496 logging_writer.py:48] [95696] accumulated_eval_time=1280.658443, accumulated_logging_time=2.252910, accumulated_submission_time=32182.279802, global_step=95696, preemption_count=0, score=32182.279802, test/accuracy=0.541900, test/loss=2.253022, test/num_examples=10000, total_duration=33468.606795, train/accuracy=0.759008, train/loss=1.209800, validation/accuracy=0.665380, validation/loss=1.604893, validation/num_examples=50000
I0315 21:23:06.349896 140055955859200 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.3509196937084198, loss=3.086987018585205
I0315 21:25:54.567853 140055947466496 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.35668763518333435, loss=3.146717071533203
I0315 21:28:42.602262 140055955859200 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.3562934696674347, loss=3.129368782043457
I0315 21:29:53.871090 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:29:59.991248 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:30:08.866986 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:30:11.523605 140219736737600 submission_runner.py:420] Time since start: 33996.29s, 	Step: 97214, 	{'train/accuracy': 0.7708864808082581, 'train/loss': 1.1475695371627808, 'validation/accuracy': 0.6789000034332275, 'validation/loss': 1.5367943048477173, 'validation/num_examples': 50000, 'test/accuracy': 0.5506000518798828, 'test/loss': 2.176283597946167, 'test/num_examples': 10000, 'score': 32692.21554327011, 'total_duration': 33996.285942554474, 'accumulated_submission_time': 32692.21554327011, 'accumulated_eval_time': 1298.3109073638916, 'accumulated_logging_time': 2.28875470161438}
I0315 21:30:11.549452 140055796512512 logging_writer.py:48] [97214] accumulated_eval_time=1298.310907, accumulated_logging_time=2.288755, accumulated_submission_time=32692.215543, global_step=97214, preemption_count=0, score=32692.215543, test/accuracy=0.550600, test/loss=2.176284, test/num_examples=10000, total_duration=33996.285943, train/accuracy=0.770886, train/loss=1.147570, validation/accuracy=0.678900, validation/loss=1.536794, validation/num_examples=50000
I0315 21:31:47.858080 140055981037312 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.36680868268013, loss=3.182288646697998
I0315 21:34:35.769123 140055796512512 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.34846970438957214, loss=3.117032527923584
I0315 21:37:23.734114 140055981037312 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.3598170280456543, loss=3.159660816192627
I0315 21:38:41.833032 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:38:47.959232 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:38:56.933585 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:38:59.257570 140219736737600 submission_runner.py:420] Time since start: 34524.02s, 	Step: 98734, 	{'train/accuracy': 0.7511160373687744, 'train/loss': 1.2191133499145508, 'validation/accuracy': 0.6734200119972229, 'validation/loss': 1.5681793689727783, 'validation/num_examples': 50000, 'test/accuracy': 0.5435000061988831, 'test/loss': 2.2351646423339844, 'test/num_examples': 10000, 'score': 33202.435888290405, 'total_duration': 34524.019939661026, 'accumulated_submission_time': 33202.435888290405, 'accumulated_eval_time': 1315.7354176044464, 'accumulated_logging_time': 2.324050188064575}
I0315 21:38:59.281627 140055972644608 logging_writer.py:48] [98734] accumulated_eval_time=1315.735418, accumulated_logging_time=2.324050, accumulated_submission_time=33202.435888, global_step=98734, preemption_count=0, score=33202.435888, test/accuracy=0.543500, test/loss=2.235165, test/num_examples=10000, total_duration=34524.019940, train/accuracy=0.751116, train/loss=1.219113, validation/accuracy=0.673420, validation/loss=1.568179, validation/num_examples=50000
I0315 21:40:28.909640 140055997822720 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.3729466199874878, loss=3.101775646209717
I0315 21:43:16.583490 140055972644608 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.3623583912849426, loss=3.0562164783477783
I0315 21:46:04.326427 140055997822720 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.3599046766757965, loss=3.079967498779297
I0315 21:47:29.320966 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:47:35.416034 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:47:44.452192 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:47:46.780985 140219736737600 submission_runner.py:420] Time since start: 35051.54s, 	Step: 100255, 	{'train/accuracy': 0.7205038070678711, 'train/loss': 1.3478683233261108, 'validation/accuracy': 0.6510199904441833, 'validation/loss': 1.662100076675415, 'validation/num_examples': 50000, 'test/accuracy': 0.5278000235557556, 'test/loss': 2.3079800605773926, 'test/num_examples': 10000, 'score': 33712.410767793655, 'total_duration': 35051.54335141182, 'accumulated_submission_time': 33712.410767793655, 'accumulated_eval_time': 1333.1954073905945, 'accumulated_logging_time': 2.357520341873169}
I0315 21:47:46.807101 140055947466496 logging_writer.py:48] [100255] accumulated_eval_time=1333.195407, accumulated_logging_time=2.357520, accumulated_submission_time=33712.410768, global_step=100255, preemption_count=0, score=33712.410768, test/accuracy=0.527800, test/loss=2.307980, test/num_examples=10000, total_duration=35051.543351, train/accuracy=0.720504, train/loss=1.347868, validation/accuracy=0.651020, validation/loss=1.662100, validation/num_examples=50000
I0315 21:49:09.381035 140055955859200 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.35651931166648865, loss=3.0552287101745605
I0315 21:51:57.246277 140055947466496 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.3691258430480957, loss=3.0596508979797363
I0315 21:54:45.023958 140055955859200 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.3702825605869293, loss=3.0692949295043945
I0315 21:56:16.792578 140219736737600 spec.py:321] Evaluating on the training split.
I0315 21:56:22.988782 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 21:56:31.847143 140219736737600 spec.py:349] Evaluating on the test split.
I0315 21:56:34.094786 140219736737600 submission_runner.py:420] Time since start: 35578.86s, 	Step: 101775, 	{'train/accuracy': 0.7612404227256775, 'train/loss': 1.21299147605896, 'validation/accuracy': 0.684719979763031, 'validation/loss': 1.5416755676269531, 'validation/num_examples': 50000, 'test/accuracy': 0.5610000491142273, 'test/loss': 2.1778295040130615, 'test/num_examples': 10000, 'score': 34222.33161020279, 'total_duration': 35578.85714626312, 'accumulated_submission_time': 34222.33161020279, 'accumulated_eval_time': 1350.4975800514221, 'accumulated_logging_time': 2.3934168815612793}
I0315 21:56:34.125921 140055997822720 logging_writer.py:48] [101775] accumulated_eval_time=1350.497580, accumulated_logging_time=2.393417, accumulated_submission_time=34222.331610, global_step=101775, preemption_count=0, score=34222.331610, test/accuracy=0.561000, test/loss=2.177830, test/num_examples=10000, total_duration=35578.857146, train/accuracy=0.761240, train/loss=1.212991, validation/accuracy=0.684720, validation/loss=1.541676, validation/num_examples=50000
I0315 21:57:50.184555 140056006215424 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.3807586133480072, loss=3.1423420906066895
I0315 22:00:38.110978 140055997822720 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.36985379457473755, loss=3.087158679962158
I0315 22:03:26.121537 140056006215424 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.3649992048740387, loss=3.054931163787842
I0315 22:05:04.400893 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:05:10.642773 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:05:19.531203 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:05:21.812734 140219736737600 submission_runner.py:420] Time since start: 36106.58s, 	Step: 103295, 	{'train/accuracy': 0.7264229655265808, 'train/loss': 1.3491491079330444, 'validation/accuracy': 0.6582599878311157, 'validation/loss': 1.6586755514144897, 'validation/num_examples': 50000, 'test/accuracy': 0.5309000015258789, 'test/loss': 2.3244988918304443, 'test/num_examples': 10000, 'score': 34732.541697740555, 'total_duration': 36106.57509183884, 'accumulated_submission_time': 34732.541697740555, 'accumulated_eval_time': 1367.9093880653381, 'accumulated_logging_time': 2.435002088546753}
I0315 22:05:21.837581 140055796512512 logging_writer.py:48] [103295] accumulated_eval_time=1367.909388, accumulated_logging_time=2.435002, accumulated_submission_time=34732.541698, global_step=103295, preemption_count=0, score=34732.541698, test/accuracy=0.530900, test/loss=2.324499, test/num_examples=10000, total_duration=36106.575092, train/accuracy=0.726423, train/loss=1.349149, validation/accuracy=0.658260, validation/loss=1.658676, validation/num_examples=50000
I0315 22:06:31.114941 140055947466496 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.37742701172828674, loss=3.1081037521362305
I0315 22:09:18.923048 140055796512512 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.38714879751205444, loss=3.10813307762146
I0315 22:12:07.205537 140055947466496 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.37516143918037415, loss=3.0124034881591797
I0315 22:13:52.145096 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:13:58.321941 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:14:07.093520 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:14:09.414360 140219736737600 submission_runner.py:420] Time since start: 36634.18s, 	Step: 104814, 	{'train/accuracy': 0.8017378449440002, 'train/loss': 1.0380462408065796, 'validation/accuracy': 0.6862599849700928, 'validation/loss': 1.51997709274292, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 2.1280741691589355, 'test/num_examples': 10000, 'score': 35242.78598356247, 'total_duration': 36634.17669773102, 'accumulated_submission_time': 35242.78598356247, 'accumulated_eval_time': 1385.1785988807678, 'accumulated_logging_time': 2.470041275024414}
I0315 22:14:09.444122 140055947466496 logging_writer.py:48] [104814] accumulated_eval_time=1385.178599, accumulated_logging_time=2.470041, accumulated_submission_time=35242.785984, global_step=104814, preemption_count=0, score=35242.785984, test/accuracy=0.566600, test/loss=2.128074, test/num_examples=10000, total_duration=36634.176698, train/accuracy=0.801738, train/loss=1.038046, validation/accuracy=0.686260, validation/loss=1.519977, validation/num_examples=50000
I0315 22:15:12.367945 140055989430016 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.3840140998363495, loss=3.0306849479675293
I0315 22:18:00.365793 140055947466496 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.40410366654396057, loss=3.1059858798980713
I0315 22:20:48.280369 140055989430016 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.3848782181739807, loss=3.041640520095825
I0315 22:22:39.460959 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:22:45.661772 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:22:54.590674 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:22:56.920538 140219736737600 submission_runner.py:420] Time since start: 37161.68s, 	Step: 106333, 	{'train/accuracy': 0.7935466766357422, 'train/loss': 1.0361019372940063, 'validation/accuracy': 0.7030400037765503, 'validation/loss': 1.425618052482605, 'validation/num_examples': 50000, 'test/accuracy': 0.572100043296814, 'test/loss': 2.0632615089416504, 'test/num_examples': 10000, 'score': 35752.73928594589, 'total_duration': 37161.68286848068, 'accumulated_submission_time': 35752.73928594589, 'accumulated_eval_time': 1402.6381130218506, 'accumulated_logging_time': 2.509903907775879}
I0315 22:22:56.945518 140055955859200 logging_writer.py:48] [106333] accumulated_eval_time=1402.638113, accumulated_logging_time=2.509904, accumulated_submission_time=35752.739286, global_step=106333, preemption_count=0, score=35752.739286, test/accuracy=0.572100, test/loss=2.063262, test/num_examples=10000, total_duration=37161.682868, train/accuracy=0.793547, train/loss=1.036102, validation/accuracy=0.703040, validation/loss=1.425618, validation/num_examples=50000
I0315 22:23:53.414633 140055964251904 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.4030221700668335, loss=3.0681419372558594
I0315 22:26:41.283428 140055955859200 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.38016030192375183, loss=2.914287805557251
I0315 22:29:29.327187 140055964251904 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.3785259425640106, loss=2.948184013366699
I0315 22:31:27.168093 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:31:33.449619 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:31:42.363271 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:31:44.706030 140219736737600 submission_runner.py:420] Time since start: 37689.47s, 	Step: 107852, 	{'train/accuracy': 0.7864317297935486, 'train/loss': 1.0807485580444336, 'validation/accuracy': 0.6959599852561951, 'validation/loss': 1.46254563331604, 'validation/num_examples': 50000, 'test/accuracy': 0.5665000081062317, 'test/loss': 2.091984510421753, 'test/num_examples': 10000, 'score': 36262.89731884003, 'total_duration': 37689.46839976311, 'accumulated_submission_time': 36262.89731884003, 'accumulated_eval_time': 1420.1760292053223, 'accumulated_logging_time': 2.5443718433380127}
I0315 22:31:44.733017 140055947466496 logging_writer.py:48] [107852] accumulated_eval_time=1420.176029, accumulated_logging_time=2.544372, accumulated_submission_time=36262.897319, global_step=107852, preemption_count=0, score=36262.897319, test/accuracy=0.566500, test/loss=2.091985, test/num_examples=10000, total_duration=37689.468400, train/accuracy=0.786432, train/loss=1.080749, validation/accuracy=0.695960, validation/loss=1.462546, validation/num_examples=50000
I0315 22:32:34.855550 140055981037312 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.39125001430511475, loss=3.0478224754333496
I0315 22:35:22.868391 140055947466496 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.39421287178993225, loss=2.995102643966675
I0315 22:38:11.031488 140055981037312 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.4090076982975006, loss=2.9992825984954834
I0315 22:40:15.036694 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:40:21.180653 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:40:30.224832 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:40:32.550494 140219736737600 submission_runner.py:420] Time since start: 38217.31s, 	Step: 109371, 	{'train/accuracy': 0.7962173223495483, 'train/loss': 1.031316876411438, 'validation/accuracy': 0.7085999846458435, 'validation/loss': 1.4009512662887573, 'validation/num_examples': 50000, 'test/accuracy': 0.5795000195503235, 'test/loss': 2.0282557010650635, 'test/num_examples': 10000, 'score': 36773.13652920723, 'total_duration': 38217.31284785271, 'accumulated_submission_time': 36773.13652920723, 'accumulated_eval_time': 1437.689792394638, 'accumulated_logging_time': 2.581874370574951}
I0315 22:40:32.575791 140055947466496 logging_writer.py:48] [109371] accumulated_eval_time=1437.689792, accumulated_logging_time=2.581874, accumulated_submission_time=36773.136529, global_step=109371, preemption_count=0, score=36773.136529, test/accuracy=0.579500, test/loss=2.028256, test/num_examples=10000, total_duration=38217.312848, train/accuracy=0.796217, train/loss=1.031317, validation/accuracy=0.708600, validation/loss=1.400951, validation/num_examples=50000
I0315 22:41:16.285844 140055955859200 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.40566837787628174, loss=2.966411590576172
I0315 22:44:04.407560 140055947466496 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.40027379989624023, loss=2.923591375350952
I0315 22:46:52.521910 140055955859200 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.4089774191379547, loss=2.9696578979492188
I0315 22:49:02.822765 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:49:08.933255 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:49:17.831283 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:49:20.111193 140219736737600 submission_runner.py:420] Time since start: 38744.87s, 	Step: 110889, 	{'train/accuracy': 0.7971739172935486, 'train/loss': 1.009020447731018, 'validation/accuracy': 0.7094599604606628, 'validation/loss': 1.375060796737671, 'validation/num_examples': 50000, 'test/accuracy': 0.5776000022888184, 'test/loss': 2.030421257019043, 'test/num_examples': 10000, 'score': 37283.3183465004, 'total_duration': 38744.87355494499, 'accumulated_submission_time': 37283.3183465004, 'accumulated_eval_time': 1454.9782001972198, 'accumulated_logging_time': 2.618157148361206}
I0315 22:49:20.136733 140055997822720 logging_writer.py:48] [110889] accumulated_eval_time=1454.978200, accumulated_logging_time=2.618157, accumulated_submission_time=37283.318347, global_step=110889, preemption_count=0, score=37283.318347, test/accuracy=0.577600, test/loss=2.030421, test/num_examples=10000, total_duration=38744.873555, train/accuracy=0.797174, train/loss=1.009020, validation/accuracy=0.709460, validation/loss=1.375061, validation/num_examples=50000
I0315 22:49:57.772788 140056006215424 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.39820870757102966, loss=2.871438503265381
I0315 22:52:45.614445 140055997822720 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.4099450707435608, loss=2.9229495525360107
I0315 22:55:33.431146 140056006215424 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.42254361510276794, loss=2.9573135375976562
I0315 22:57:50.204000 140219736737600 spec.py:321] Evaluating on the training split.
I0315 22:57:56.347261 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 22:58:05.300626 140219736737600 spec.py:349] Evaluating on the test split.
I0315 22:58:07.655853 140219736737600 submission_runner.py:420] Time since start: 39272.42s, 	Step: 112409, 	{'train/accuracy': 0.7902383208274841, 'train/loss': 1.040706753730774, 'validation/accuracy': 0.7038999795913696, 'validation/loss': 1.4087190628051758, 'validation/num_examples': 50000, 'test/accuracy': 0.5773000121116638, 'test/loss': 2.0421769618988037, 'test/num_examples': 10000, 'score': 37793.321729660034, 'total_duration': 39272.41820645332, 'accumulated_submission_time': 37793.321729660034, 'accumulated_eval_time': 1472.4300179481506, 'accumulated_logging_time': 2.6541287899017334}
I0315 22:58:07.691088 140055964251904 logging_writer.py:48] [112409] accumulated_eval_time=1472.430018, accumulated_logging_time=2.654129, accumulated_submission_time=37793.321730, global_step=112409, preemption_count=0, score=37793.321730, test/accuracy=0.577300, test/loss=2.042177, test/num_examples=10000, total_duration=39272.418206, train/accuracy=0.790238, train/loss=1.040707, validation/accuracy=0.703900, validation/loss=1.408719, validation/num_examples=50000
I0315 22:58:38.554355 140055972644608 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.4209364354610443, loss=2.9723877906799316
I0315 23:01:26.790149 140055964251904 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.4394509196281433, loss=3.003261089324951
I0315 23:04:14.984142 140055972644608 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.4235284626483917, loss=2.9173617362976074
I0315 23:06:37.728259 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:06:43.931701 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:06:52.703742 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:06:55.033104 140219736737600 submission_runner.py:420] Time since start: 39799.80s, 	Step: 113926, 	{'train/accuracy': 0.8326291441917419, 'train/loss': 0.8875695466995239, 'validation/accuracy': 0.7185800075531006, 'validation/loss': 1.3616238832473755, 'validation/num_examples': 50000, 'test/accuracy': 0.5887000560760498, 'test/loss': 2.000600814819336, 'test/num_examples': 10000, 'score': 38303.29452633858, 'total_duration': 39799.795472860336, 'accumulated_submission_time': 38303.29452633858, 'accumulated_eval_time': 1489.7348415851593, 'accumulated_logging_time': 2.700051784515381}
I0315 23:06:55.062061 140055947466496 logging_writer.py:48] [113926] accumulated_eval_time=1489.734842, accumulated_logging_time=2.700052, accumulated_submission_time=38303.294526, global_step=113926, preemption_count=0, score=38303.294526, test/accuracy=0.588700, test/loss=2.000601, test/num_examples=10000, total_duration=39799.795473, train/accuracy=0.832629, train/loss=0.887570, validation/accuracy=0.718580, validation/loss=1.361624, validation/num_examples=50000
I0315 23:07:20.237584 140055955859200 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.4229608178138733, loss=2.9714910984039307
I0315 23:10:08.179789 140055947466496 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.4072933793067932, loss=2.898390769958496
I0315 23:12:56.397143 140055955859200 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.45024222135543823, loss=3.017772912979126
I0315 23:15:25.330043 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:15:31.515082 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:15:40.512986 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:15:42.826555 140219736737600 submission_runner.py:420] Time since start: 40327.59s, 	Step: 115445, 	{'train/accuracy': 0.8215879797935486, 'train/loss': 0.9264942407608032, 'validation/accuracy': 0.7172200083732605, 'validation/loss': 1.3684145212173462, 'validation/num_examples': 50000, 'test/accuracy': 0.5905000567436218, 'test/loss': 2.016941785812378, 'test/num_examples': 10000, 'score': 38813.49972128868, 'total_duration': 40327.58888578415, 'accumulated_submission_time': 38813.49972128868, 'accumulated_eval_time': 1507.2312965393066, 'accumulated_logging_time': 2.7389280796051025}
I0315 23:15:42.853620 140055972644608 logging_writer.py:48] [115445] accumulated_eval_time=1507.231297, accumulated_logging_time=2.738928, accumulated_submission_time=38813.499721, global_step=115445, preemption_count=0, score=38813.499721, test/accuracy=0.590500, test/loss=2.016942, test/num_examples=10000, total_duration=40327.588886, train/accuracy=0.821588, train/loss=0.926494, validation/accuracy=0.717220, validation/loss=1.368415, validation/num_examples=50000
I0315 23:16:01.667852 140055981037312 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.43240630626678467, loss=2.8604984283447266
I0315 23:18:49.701583 140055972644608 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.4300919771194458, loss=2.8995392322540283
I0315 23:21:37.724509 140055981037312 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.4380470812320709, loss=2.87492299079895
I0315 23:24:12.868555 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:24:18.994439 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:24:27.774484 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:24:30.070500 140219736737600 submission_runner.py:420] Time since start: 40854.83s, 	Step: 116963, 	{'train/accuracy': 0.828543484210968, 'train/loss': 0.883918046951294, 'validation/accuracy': 0.7252999544143677, 'validation/loss': 1.309679388999939, 'validation/num_examples': 50000, 'test/accuracy': 0.5981000065803528, 'test/loss': 1.936470627784729, 'test/num_examples': 10000, 'score': 39323.45069527626, 'total_duration': 40854.83286714554, 'accumulated_submission_time': 39323.45069527626, 'accumulated_eval_time': 1524.433219909668, 'accumulated_logging_time': 2.777219772338867}
I0315 23:24:30.097109 140055955859200 logging_writer.py:48] [116963] accumulated_eval_time=1524.433220, accumulated_logging_time=2.777220, accumulated_submission_time=39323.450695, global_step=116963, preemption_count=0, score=39323.450695, test/accuracy=0.598100, test/loss=1.936471, test/num_examples=10000, total_duration=40854.832867, train/accuracy=0.828543, train/loss=0.883918, validation/accuracy=0.725300, validation/loss=1.309679, validation/num_examples=50000
I0315 23:24:42.842619 140055964251904 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.44032156467437744, loss=2.840771198272705
I0315 23:27:30.555691 140055955859200 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.45342254638671875, loss=2.9546730518341064
I0315 23:30:18.550266 140055964251904 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.4689348340034485, loss=2.9740936756134033
I0315 23:33:00.294928 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:33:06.578911 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:33:15.340457 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:33:17.662024 140219736737600 submission_runner.py:420] Time since start: 41382.42s, 	Step: 118483, 	{'train/accuracy': 0.8358976244926453, 'train/loss': 0.8649929165840149, 'validation/accuracy': 0.733299970626831, 'validation/loss': 1.2923582792282104, 'validation/num_examples': 50000, 'test/accuracy': 0.6100000143051147, 'test/loss': 1.9099456071853638, 'test/num_examples': 10000, 'score': 39833.584914684296, 'total_duration': 41382.424394607544, 'accumulated_submission_time': 39833.584914684296, 'accumulated_eval_time': 1541.8003342151642, 'accumulated_logging_time': 2.8139991760253906}
I0315 23:33:17.691385 140055955859200 logging_writer.py:48] [118483] accumulated_eval_time=1541.800334, accumulated_logging_time=2.813999, accumulated_submission_time=39833.584915, global_step=118483, preemption_count=0, score=39833.584915, test/accuracy=0.610000, test/loss=1.909946, test/num_examples=10000, total_duration=41382.424395, train/accuracy=0.835898, train/loss=0.864993, validation/accuracy=0.733300, validation/loss=1.292358, validation/num_examples=50000
I0315 23:33:23.755122 140055981037312 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.4727628827095032, loss=2.929663896560669
I0315 23:36:11.803021 140055955859200 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.48848670721054077, loss=2.9244863986968994
I0315 23:38:59.619335 140055981037312 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.4767868220806122, loss=2.864959716796875
I0315 23:41:47.573676 140055955859200 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.45222732424736023, loss=2.832092761993408
I0315 23:41:47.671455 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:41:53.810224 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:42:02.789781 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:42:05.106650 140219736737600 submission_runner.py:420] Time since start: 41909.87s, 	Step: 120002, 	{'train/accuracy': 0.8349409699440002, 'train/loss': 0.8720414042472839, 'validation/accuracy': 0.7340399622917175, 'validation/loss': 1.2941697835922241, 'validation/num_examples': 50000, 'test/accuracy': 0.6096000075340271, 'test/loss': 1.9135819673538208, 'test/num_examples': 10000, 'score': 40343.50025868416, 'total_duration': 41909.86901688576, 'accumulated_submission_time': 40343.50025868416, 'accumulated_eval_time': 1559.2355153560638, 'accumulated_logging_time': 2.853339195251465}
I0315 23:42:05.132716 140055947466496 logging_writer.py:48] [120002] accumulated_eval_time=1559.235515, accumulated_logging_time=2.853339, accumulated_submission_time=40343.500259, global_step=120002, preemption_count=0, score=40343.500259, test/accuracy=0.609600, test/loss=1.913582, test/num_examples=10000, total_duration=41909.869017, train/accuracy=0.834941, train/loss=0.872041, validation/accuracy=0.734040, validation/loss=1.294170, validation/num_examples=50000
I0315 23:44:52.762196 140055972644608 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.4396427571773529, loss=2.8109984397888184
I0315 23:47:40.754616 140055947466496 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.48223769664764404, loss=2.8494014739990234
I0315 23:50:28.621751 140055972644608 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.46737778186798096, loss=2.794072151184082
I0315 23:50:35.433427 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:50:41.747766 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:50:50.475198 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:50:52.772644 140219736737600 submission_runner.py:420] Time since start: 42437.54s, 	Step: 121522, 	{'train/accuracy': 0.8537348508834839, 'train/loss': 0.781994640827179, 'validation/accuracy': 0.7448599934577942, 'validation/loss': 1.2308391332626343, 'validation/num_examples': 50000, 'test/accuracy': 0.617900013923645, 'test/loss': 1.8550323247909546, 'test/num_examples': 10000, 'score': 40853.73813080788, 'total_duration': 42437.535009622574, 'accumulated_submission_time': 40853.73813080788, 'accumulated_eval_time': 1576.574713230133, 'accumulated_logging_time': 2.889094352722168}
I0315 23:50:52.798060 140055964251904 logging_writer.py:48] [121522] accumulated_eval_time=1576.574713, accumulated_logging_time=2.889094, accumulated_submission_time=40853.738131, global_step=121522, preemption_count=0, score=40853.738131, test/accuracy=0.617900, test/loss=1.855032, test/num_examples=10000, total_duration=42437.535010, train/accuracy=0.853735, train/loss=0.781995, validation/accuracy=0.744860, validation/loss=1.230839, validation/num_examples=50000
I0315 23:53:33.558035 140055981037312 logging_writer.py:48] [122000] global_step=122000, grad_norm=0.4887479543685913, loss=2.772813320159912
I0315 23:56:21.411606 140055964251904 logging_writer.py:48] [122500] global_step=122500, grad_norm=0.4782872796058655, loss=2.766831636428833
I0315 23:59:09.127628 140055981037312 logging_writer.py:48] [123000] global_step=123000, grad_norm=0.48018208146095276, loss=2.714674472808838
I0315 23:59:22.935129 140219736737600 spec.py:321] Evaluating on the training split.
I0315 23:59:29.198440 140219736737600 spec.py:333] Evaluating on the validation split.
I0315 23:59:38.116663 140219736737600 spec.py:349] Evaluating on the test split.
I0315 23:59:40.406098 140219736737600 submission_runner.py:420] Time since start: 42965.17s, 	Step: 123043, 	{'train/accuracy': 0.8741031289100647, 'train/loss': 0.7374966740608215, 'validation/accuracy': 0.7486199736595154, 'validation/loss': 1.2402164936065674, 'validation/num_examples': 50000, 'test/accuracy': 0.6232000589370728, 'test/loss': 1.8539561033248901, 'test/num_examples': 10000, 'score': 41363.81107091904, 'total_duration': 42965.16845846176, 'accumulated_submission_time': 41363.81107091904, 'accumulated_eval_time': 1594.0456488132477, 'accumulated_logging_time': 2.924650192260742}
I0315 23:59:40.434463 140055955859200 logging_writer.py:48] [123043] accumulated_eval_time=1594.045649, accumulated_logging_time=2.924650, accumulated_submission_time=41363.811071, global_step=123043, preemption_count=0, score=41363.811071, test/accuracy=0.623200, test/loss=1.853956, test/num_examples=10000, total_duration=42965.168458, train/accuracy=0.874103, train/loss=0.737497, validation/accuracy=0.748620, validation/loss=1.240216, validation/num_examples=50000
I0316 00:02:14.174908 140055972644608 logging_writer.py:48] [123500] global_step=123500, grad_norm=0.4859829545021057, loss=2.735807418823242
I0316 00:05:02.201337 140055955859200 logging_writer.py:48] [124000] global_step=124000, grad_norm=0.49433526396751404, loss=2.764796257019043
I0316 00:07:50.215301 140055972644608 logging_writer.py:48] [124500] global_step=124500, grad_norm=0.4947696924209595, loss=2.6868677139282227
I0316 00:08:10.437449 140219736737600 spec.py:321] Evaluating on the training split.
I0316 00:08:16.925316 140219736737600 spec.py:333] Evaluating on the validation split.
I0316 00:08:25.840397 140219736737600 spec.py:349] Evaluating on the test split.
I0316 00:08:28.153397 140219736737600 submission_runner.py:420] Time since start: 43492.92s, 	Step: 124562, 	{'train/accuracy': 0.8776506781578064, 'train/loss': 0.7061590552330017, 'validation/accuracy': 0.7564399838447571, 'validation/loss': 1.199823021888733, 'validation/num_examples': 50000, 'test/accuracy': 0.6358000040054321, 'test/loss': 1.8023020029067993, 'test/num_examples': 10000, 'score': 41873.749415159225, 'total_duration': 43492.91576004028, 'accumulated_submission_time': 41873.749415159225, 'accumulated_eval_time': 1611.7615554332733, 'accumulated_logging_time': 2.9650187492370605}
I0316 00:08:28.179954 140055981037312 logging_writer.py:48] [124562] accumulated_eval_time=1611.761555, accumulated_logging_time=2.965019, accumulated_submission_time=41873.749415, global_step=124562, preemption_count=0, score=41873.749415, test/accuracy=0.635800, test/loss=1.802302, test/num_examples=10000, total_duration=43492.915760, train/accuracy=0.877651, train/loss=0.706159, validation/accuracy=0.756440, validation/loss=1.199823, validation/num_examples=50000
I0316 00:10:55.774147 140055997822720 logging_writer.py:48] [125000] global_step=125000, grad_norm=0.5062375068664551, loss=2.7591824531555176
I0316 00:13:43.760581 140055981037312 logging_writer.py:48] [125500] global_step=125500, grad_norm=0.48518106341362, loss=2.7161169052124023
I0316 00:16:31.660762 140055997822720 logging_writer.py:48] [126000] global_step=126000, grad_norm=0.48333683609962463, loss=2.6456475257873535
I0316 00:16:58.266580 140219736737600 spec.py:321] Evaluating on the training split.
I0316 00:17:04.404758 140219736737600 spec.py:333] Evaluating on the validation split.
I0316 00:17:13.311300 140219736737600 spec.py:349] Evaluating on the test split.
I0316 00:17:15.668685 140219736737600 submission_runner.py:420] Time since start: 44020.43s, 	Step: 126081, 	{'train/accuracy': 0.8871572017669678, 'train/loss': 0.663292407989502, 'validation/accuracy': 0.7620999813079834, 'validation/loss': 1.1754844188690186, 'validation/num_examples': 50000, 'test/accuracy': 0.641800045967102, 'test/loss': 1.7703522443771362, 'test/num_examples': 10000, 'score': 42383.772540807724, 'total_duration': 44020.43105649948, 'accumulated_submission_time': 42383.772540807724, 'accumulated_eval_time': 1629.1636288166046, 'accumulated_logging_time': 3.0010507106781006}
I0316 00:17:15.694705 140055955859200 logging_writer.py:48] [126081] accumulated_eval_time=1629.163629, accumulated_logging_time=3.001051, accumulated_submission_time=42383.772541, global_step=126081, preemption_count=0, score=42383.772541, test/accuracy=0.641800, test/loss=1.770352, test/num_examples=10000, total_duration=44020.431056, train/accuracy=0.887157, train/loss=0.663292, validation/accuracy=0.762100, validation/loss=1.175484, validation/num_examples=50000
I0316 00:19:36.860778 140055964251904 logging_writer.py:48] [126500] global_step=126500, grad_norm=0.4803941249847412, loss=2.6498332023620605
I0316 00:22:25.095767 140055955859200 logging_writer.py:48] [127000] global_step=127000, grad_norm=0.5046389698982239, loss=2.695258378982544
I0316 00:25:12.955044 140055964251904 logging_writer.py:48] [127500] global_step=127500, grad_norm=0.5038124918937683, loss=2.6589884757995605
I0316 00:25:45.977171 140219736737600 spec.py:321] Evaluating on the training split.
I0316 00:25:52.171354 140219736737600 spec.py:333] Evaluating on the validation split.
I0316 00:26:01.081725 140219736737600 spec.py:349] Evaluating on the test split.
I0316 00:26:03.486284 140219736737600 submission_runner.py:420] Time since start: 44548.25s, 	Step: 127600, 	{'train/accuracy': 0.8903459906578064, 'train/loss': 0.6631816625595093, 'validation/accuracy': 0.7636799812316895, 'validation/loss': 1.1692726612091064, 'validation/num_examples': 50000, 'test/accuracy': 0.6455000042915344, 'test/loss': 1.7630950212478638, 'test/num_examples': 10000, 'score': 42893.9892706871, 'total_duration': 44548.24864816666, 'accumulated_submission_time': 42893.9892706871, 'accumulated_eval_time': 1646.6727030277252, 'accumulated_logging_time': 3.037792444229126}
I0316 00:26:03.511845 140055947466496 logging_writer.py:48] [127600] accumulated_eval_time=1646.672703, accumulated_logging_time=3.037792, accumulated_submission_time=42893.989271, global_step=127600, preemption_count=0, score=42893.989271, test/accuracy=0.645500, test/loss=1.763095, test/num_examples=10000, total_duration=44548.248648, train/accuracy=0.890346, train/loss=0.663182, validation/accuracy=0.763680, validation/loss=1.169273, validation/num_examples=50000
I0316 00:28:18.211305 140055955859200 logging_writer.py:48] [128000] global_step=128000, grad_norm=0.5038163661956787, loss=2.751400947570801
I0316 00:31:06.227268 140055947466496 logging_writer.py:48] [128500] global_step=128500, grad_norm=0.4998007118701935, loss=2.6369740962982178
I0316 00:33:54.223094 140055955859200 logging_writer.py:48] [129000] global_step=129000, grad_norm=0.5175036787986755, loss=2.6921095848083496
I0316 00:34:33.694481 140219736737600 spec.py:321] Evaluating on the training split.
I0316 00:34:40.091865 140219736737600 spec.py:333] Evaluating on the validation split.
I0316 00:34:48.919143 140219736737600 spec.py:349] Evaluating on the test split.
I0316 00:34:51.223183 140219736737600 submission_runner.py:420] Time since start: 45075.99s, 	Step: 129119, 	{'train/accuracy': 0.8921396732330322, 'train/loss': 0.6511744260787964, 'validation/accuracy': 0.7664600014686584, 'validation/loss': 1.1603405475616455, 'validation/num_examples': 50000, 'test/accuracy': 0.6430000066757202, 'test/loss': 1.7546344995498657, 'test/num_examples': 10000, 'score': 43404.10743713379, 'total_duration': 45075.9855389595, 'accumulated_submission_time': 43404.10743713379, 'accumulated_eval_time': 1664.2013821601868, 'accumulated_logging_time': 3.0727055072784424}
I0316 00:34:51.249966 140055989430016 logging_writer.py:48] [129119] accumulated_eval_time=1664.201382, accumulated_logging_time=3.072706, accumulated_submission_time=43404.107437, global_step=129119, preemption_count=0, score=43404.107437, test/accuracy=0.643000, test/loss=1.754634, test/num_examples=10000, total_duration=45075.985539, train/accuracy=0.892140, train/loss=0.651174, validation/accuracy=0.766460, validation/loss=1.160341, validation/num_examples=50000
I0316 00:34:51.271236 140055997822720 logging_writer.py:48] [129119] global_step=129119, preemption_count=0, score=43404.107437
I0316 00:34:51.474158 140219736737600 checkpoints.py:490] Saving checkpoint at step: 129119
I0316 00:34:52.436446 140219736737600 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1/checkpoint_129119
I0316 00:34:52.457435 140219736737600 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/imagenet_resnet_large_bn_init_jax/trial_1/checkpoint_129119.
I0316 00:34:53.309518 140219736737600 submission_runner.py:593] Tuning trial 1/1
I0316 00:34:53.310428 140219736737600 submission_runner.py:594] Hyperparameters: Hyperparameters(learning_rate=4.131896390902391, beta1=0.9274758113254791, warmup_steps=6999, decay_steps_factor=0.9007765761611038, end_factor=0.01, weight_decay=5.6687777311501786e-06, label_smoothing=0.2)
I0316 00:34:53.313786 140219736737600 submission_runner.py:595] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0009566326625645161, 'train/loss': 681.6714477539062, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 691.8001708984375, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 681.23779296875, 'test/num_examples': 10000, 'score': 47.302772998809814, 'total_duration': 84.09100985527039, 'accumulated_submission_time': 47.302772998809814, 'accumulated_eval_time': 36.78810667991638, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1519, {'train/accuracy': 0.004544004797935486, 'train/loss': 6.69061803817749, 'validation/accuracy': 0.004540000110864639, 'validation/loss': 6.6995415687561035, 'validation/num_examples': 50000, 'test/accuracy': 0.0034000002779066563, 'test/loss': 6.734652042388916, 'test/num_examples': 10000, 'score': 557.4852783679962, 'total_duration': 612.4016373157501, 'accumulated_submission_time': 557.4852783679962, 'accumulated_eval_time': 54.83740997314453, 'accumulated_logging_time': 0.026354551315307617, 'global_step': 1519, 'preemption_count': 0}), (3039, {'train/accuracy': 0.049605388194322586, 'train/loss': 5.57780122756958, 'validation/accuracy': 0.04690000042319298, 'validation/loss': 5.608048439025879, 'validation/num_examples': 50000, 'test/accuracy': 0.03580000251531601, 'test/loss': 5.819831848144531, 'test/num_examples': 10000, 'score': 1067.7323660850525, 'total_duration': 1140.9426672458649, 'accumulated_submission_time': 1067.7323660850525, 'accumulated_eval_time': 73.04691457748413, 'accumulated_logging_time': 0.05607151985168457, 'global_step': 3039, 'preemption_count': 0}), (4557, {'train/accuracy': 0.1287667453289032, 'train/loss': 4.847797870635986, 'validation/accuracy': 0.1207599937915802, 'validation/loss': 4.9104180335998535, 'validation/num_examples': 50000, 'test/accuracy': 0.09220000356435776, 'test/loss': 5.2158074378967285, 'test/num_examples': 10000, 'score': 1577.8691699504852, 'total_duration': 1669.5600199699402, 'accumulated_submission_time': 1577.8691699504852, 'accumulated_eval_time': 91.44304966926575, 'accumulated_logging_time': 0.0863194465637207, 'global_step': 4557, 'preemption_count': 0}), (6074, {'train/accuracy': 0.26281487941741943, 'train/loss': 3.9351720809936523, 'validation/accuracy': 0.2464199960231781, 'validation/loss': 4.055335998535156, 'validation/num_examples': 50000, 'test/accuracy': 0.18310001492500305, 'test/loss': 4.493728160858154, 'test/num_examples': 10000, 'score': 2088.0122191905975, 'total_duration': 2197.9370057582855, 'accumulated_submission_time': 2088.0122191905975, 'accumulated_eval_time': 109.59606838226318, 'accumulated_logging_time': 0.11431169509887695, 'global_step': 6074, 'preemption_count': 0}), (7591, {'train/accuracy': 0.22765864431858063, 'train/loss': 4.142884731292725, 'validation/accuracy': 0.21345999836921692, 'validation/loss': 4.234279155731201, 'validation/num_examples': 50000, 'test/accuracy': 0.16130000352859497, 'test/loss': 4.688904285430908, 'test/num_examples': 10000, 'score': 2597.9389073848724, 'total_duration': 2726.0270931720734, 'accumulated_submission_time': 2597.9389073848724, 'accumulated_eval_time': 127.67713642120361, 'accumulated_logging_time': 0.14261126518249512, 'global_step': 7591, 'preemption_count': 0}), (9108, {'train/accuracy': 0.4121691584587097, 'train/loss': 2.926903247833252, 'validation/accuracy': 0.3558200001716614, 'validation/loss': 3.2475132942199707, 'validation/num_examples': 50000, 'test/accuracy': 0.2686000168323517, 'test/loss': 3.8534505367279053, 'test/num_examples': 10000, 'score': 3108.1007058620453, 'total_duration': 3254.4554920196533, 'accumulated_submission_time': 3108.1007058620453, 'accumulated_eval_time': 145.84979248046875, 'accumulated_logging_time': 0.18162846565246582, 'global_step': 9108, 'preemption_count': 0}), (10625, {'train/accuracy': 0.4539620578289032, 'train/loss': 2.6911368370056152, 'validation/accuracy': 0.41251999139785767, 'validation/loss': 2.916543960571289, 'validation/num_examples': 50000, 'test/accuracy': 0.3144000172615051, 'test/loss': 3.545785427093506, 'test/num_examples': 10000, 'score': 3618.2318530082703, 'total_duration': 3782.9898648262024, 'accumulated_submission_time': 3618.2318530082703, 'accumulated_eval_time': 164.17187094688416, 'accumulated_logging_time': 0.20866155624389648, 'global_step': 10625, 'preemption_count': 0}), (12142, {'train/accuracy': 0.4854113459587097, 'train/loss': 2.5034611225128174, 'validation/accuracy': 0.4456999897956848, 'validation/loss': 2.707832098007202, 'validation/num_examples': 50000, 'test/accuracy': 0.33230000734329224, 'test/loss': 3.3627805709838867, 'test/num_examples': 10000, 'score': 4128.188938140869, 'total_duration': 4311.387203454971, 'accumulated_submission_time': 4128.188938140869, 'accumulated_eval_time': 182.52180695533752, 'accumulated_logging_time': 0.24398541450500488, 'global_step': 12142, 'preemption_count': 0}), (13659, {'train/accuracy': 0.5143295526504517, 'train/loss': 2.328718900680542, 'validation/accuracy': 0.47585999965667725, 'validation/loss': 2.517012119293213, 'validation/num_examples': 50000, 'test/accuracy': 0.3653000295162201, 'test/loss': 3.148709535598755, 'test/num_examples': 10000, 'score': 4638.151408672333, 'total_duration': 4839.741317749023, 'accumulated_submission_time': 4638.151408672333, 'accumulated_eval_time': 200.82904863357544, 'accumulated_logging_time': 0.27428460121154785, 'global_step': 13659, 'preemption_count': 0}), (15177, {'train/accuracy': 0.5061184763908386, 'train/loss': 2.377655267715454, 'validation/accuracy': 0.47453999519348145, 'validation/loss': 2.5379393100738525, 'validation/num_examples': 50000, 'test/accuracy': 0.35590001940727234, 'test/loss': 3.2392184734344482, 'test/num_examples': 10000, 'score': 5148.252074241638, 'total_duration': 5368.209239721298, 'accumulated_submission_time': 5148.252074241638, 'accumulated_eval_time': 219.11343455314636, 'accumulated_logging_time': 0.30254626274108887, 'global_step': 15177, 'preemption_count': 0}), (16695, {'train/accuracy': 0.5298947691917419, 'train/loss': 2.262759208679199, 'validation/accuracy': 0.49925997853279114, 'validation/loss': 2.423909902572632, 'validation/num_examples': 50000, 'test/accuracy': 0.382500022649765, 'test/loss': 3.0907649993896484, 'test/num_examples': 10000, 'score': 5658.297363042831, 'total_duration': 5900.756187438965, 'accumulated_submission_time': 5658.297363042831, 'accumulated_eval_time': 241.52748775482178, 'accumulated_logging_time': 0.33531689643859863, 'global_step': 16695, 'preemption_count': 0}), (18214, {'train/accuracy': 0.5557836294174194, 'train/loss': 2.1994197368621826, 'validation/accuracy': 0.4882600009441376, 'validation/loss': 2.52398419380188, 'validation/num_examples': 50000, 'test/accuracy': 0.3822000324726105, 'test/loss': 3.1456823348999023, 'test/num_examples': 10000, 'score': 6168.3401889801025, 'total_duration': 6431.965350389481, 'accumulated_submission_time': 6168.3401889801025, 'accumulated_eval_time': 262.6039364337921, 'accumulated_logging_time': 0.3696572780609131, 'global_step': 18214, 'preemption_count': 0}), (19733, {'train/accuracy': 0.5789421200752258, 'train/loss': 2.03883957862854, 'validation/accuracy': 0.5265399813652039, 'validation/loss': 2.2987494468688965, 'validation/num_examples': 50000, 'test/accuracy': 0.41370001435279846, 'test/loss': 2.9405357837677, 'test/num_examples': 10000, 'score': 6678.416119337082, 'total_duration': 6970.8660089969635, 'accumulated_submission_time': 6678.416119337082, 'accumulated_eval_time': 291.3440418243408, 'accumulated_logging_time': 0.40018391609191895, 'global_step': 19733, 'preemption_count': 0}), (21251, {'train/accuracy': 0.5830078125, 'train/loss': 2.0310115814208984, 'validation/accuracy': 0.5385800004005432, 'validation/loss': 2.2524328231811523, 'validation/num_examples': 50000, 'test/accuracy': 0.41540002822875977, 'test/loss': 2.9097514152526855, 'test/num_examples': 10000, 'score': 7188.590972185135, 'total_duration': 7504.862423181534, 'accumulated_submission_time': 7188.590972185135, 'accumulated_eval_time': 315.0826277732849, 'accumulated_logging_time': 0.43010997772216797, 'global_step': 21251, 'preemption_count': 0}), (22770, {'train/accuracy': 0.5297154188156128, 'train/loss': 2.2742745876312256, 'validation/accuracy': 0.4883599877357483, 'validation/loss': 2.461336851119995, 'validation/num_examples': 50000, 'test/accuracy': 0.37470000982284546, 'test/loss': 3.1011805534362793, 'test/num_examples': 10000, 'score': 7698.823069572449, 'total_duration': 8041.734592437744, 'accumulated_submission_time': 7698.823069572449, 'accumulated_eval_time': 341.64503598213196, 'accumulated_logging_time': 0.45485639572143555, 'global_step': 22770, 'preemption_count': 0}), (24288, {'train/accuracy': 0.57421875, 'train/loss': 2.068537712097168, 'validation/accuracy': 0.5332800149917603, 'validation/loss': 2.2714669704437256, 'validation/num_examples': 50000, 'test/accuracy': 0.4066000282764435, 'test/loss': 2.944248676300049, 'test/num_examples': 10000, 'score': 8208.831599235535, 'total_duration': 8573.782970666885, 'accumulated_submission_time': 8208.831599235535, 'accumulated_eval_time': 363.5991675853729, 'accumulated_logging_time': 0.48555660247802734, 'global_step': 24288, 'preemption_count': 0}), (25806, {'train/accuracy': 0.5788823366165161, 'train/loss': 2.0605785846710205, 'validation/accuracy': 0.545520007610321, 'validation/loss': 2.218935012817383, 'validation/num_examples': 50000, 'test/accuracy': 0.42500001192092896, 'test/loss': 2.9056777954101562, 'test/num_examples': 10000, 'score': 8718.980939388275, 'total_duration': 9106.030410051346, 'accumulated_submission_time': 8718.980939388275, 'accumulated_eval_time': 385.61068415641785, 'accumulated_logging_time': 0.5188980102539062, 'global_step': 25806, 'preemption_count': 0}), (27325, {'train/accuracy': 0.625019907951355, 'train/loss': 1.7657756805419922, 'validation/accuracy': 0.5603199601173401, 'validation/loss': 2.084496259689331, 'validation/num_examples': 50000, 'test/accuracy': 0.4336000084877014, 'test/loss': 2.7859420776367188, 'test/num_examples': 10000, 'score': 9228.958266496658, 'total_duration': 9636.904457569122, 'accumulated_submission_time': 9228.958266496658, 'accumulated_eval_time': 406.4220998287201, 'accumulated_logging_time': 0.5506694316864014, 'global_step': 27325, 'preemption_count': 0}), (28843, {'train/accuracy': 0.6181241869926453, 'train/loss': 1.8749414682388306, 'validation/accuracy': 0.5651400089263916, 'validation/loss': 2.1131842136383057, 'validation/num_examples': 50000, 'test/accuracy': 0.44510000944137573, 'test/loss': 2.7610645294189453, 'test/num_examples': 10000, 'score': 9738.925782680511, 'total_duration': 10170.508566141129, 'accumulated_submission_time': 9738.925782680511, 'accumulated_eval_time': 429.9727506637573, 'accumulated_logging_time': 0.5825750827789307, 'global_step': 28843, 'preemption_count': 0}), (30362, {'train/accuracy': 0.6094347834587097, 'train/loss': 1.8473330736160278, 'validation/accuracy': 0.5592799782752991, 'validation/loss': 2.0749523639678955, 'validation/num_examples': 50000, 'test/accuracy': 0.42990002036094666, 'test/loss': 2.7951090335845947, 'test/num_examples': 10000, 'score': 10248.96442580223, 'total_duration': 10704.854495763779, 'accumulated_submission_time': 10248.96442580223, 'accumulated_eval_time': 454.19654631614685, 'accumulated_logging_time': 0.6118781566619873, 'global_step': 30362, 'preemption_count': 0}), (31881, {'train/accuracy': 0.6079798936843872, 'train/loss': 1.8682525157928467, 'validation/accuracy': 0.5659999847412109, 'validation/loss': 2.0625662803649902, 'validation/num_examples': 50000, 'test/accuracy': 0.44380003213882446, 'test/loss': 2.7409098148345947, 'test/num_examples': 10000, 'score': 10758.935925245285, 'total_duration': 11237.556566238403, 'accumulated_submission_time': 10758.935925245285, 'accumulated_eval_time': 476.8433427810669, 'accumulated_logging_time': 0.6411774158477783, 'global_step': 31881, 'preemption_count': 0}), (33401, {'train/accuracy': 0.5858976244926453, 'train/loss': 1.987179160118103, 'validation/accuracy': 0.5421599745750427, 'validation/loss': 2.1853582859039307, 'validation/num_examples': 50000, 'test/accuracy': 0.42510002851486206, 'test/loss': 2.8899283409118652, 'test/num_examples': 10000, 'score': 11269.121939182281, 'total_duration': 11770.466438055038, 'accumulated_submission_time': 11269.121939182281, 'accumulated_eval_time': 499.4775059223175, 'accumulated_logging_time': 0.6751701831817627, 'global_step': 33401, 'preemption_count': 0}), (34921, {'train/accuracy': 0.6458665132522583, 'train/loss': 1.7214691638946533, 'validation/accuracy': 0.5810399651527405, 'validation/loss': 1.9938098192214966, 'validation/num_examples': 50000, 'test/accuracy': 0.4595000147819519, 'test/loss': 2.6522984504699707, 'test/num_examples': 10000, 'score': 11779.20444560051, 'total_duration': 12304.454917669296, 'accumulated_submission_time': 11779.20444560051, 'accumulated_eval_time': 523.2989957332611, 'accumulated_logging_time': 0.7066562175750732, 'global_step': 34921, 'preemption_count': 0}), (36441, {'train/accuracy': 0.6417410373687744, 'train/loss': 1.8034937381744385, 'validation/accuracy': 0.5738599896430969, 'validation/loss': 2.0951340198516846, 'validation/num_examples': 50000, 'test/accuracy': 0.4464000165462494, 'test/loss': 2.7790067195892334, 'test/num_examples': 10000, 'score': 12289.209927797318, 'total_duration': 12840.130129814148, 'accumulated_submission_time': 12289.209927797318, 'accumulated_eval_time': 548.8877904415131, 'accumulated_logging_time': 0.7343935966491699, 'global_step': 36441, 'preemption_count': 0}), (37961, {'train/accuracy': 0.6412029266357422, 'train/loss': 1.6708378791809082, 'validation/accuracy': 0.5851199626922607, 'validation/loss': 1.9359171390533447, 'validation/num_examples': 50000, 'test/accuracy': 0.46320003271102905, 'test/loss': 2.608592987060547, 'test/num_examples': 10000, 'score': 12799.21282839775, 'total_duration': 13373.687015533447, 'accumulated_submission_time': 12799.21282839775, 'accumulated_eval_time': 572.3594927787781, 'accumulated_logging_time': 0.762136697769165, 'global_step': 37961, 'preemption_count': 0}), (39482, {'train/accuracy': 0.6242027878761292, 'train/loss': 1.796441674232483, 'validation/accuracy': 0.5740799903869629, 'validation/loss': 2.023730754852295, 'validation/num_examples': 50000, 'test/accuracy': 0.4482000172138214, 'test/loss': 2.696899175643921, 'test/num_examples': 10000, 'score': 13309.426300764084, 'total_duration': 13905.905908823013, 'accumulated_submission_time': 13309.426300764084, 'accumulated_eval_time': 594.2833342552185, 'accumulated_logging_time': 0.789865255355835, 'global_step': 39482, 'preemption_count': 0}), (41003, {'train/accuracy': 0.5903419852256775, 'train/loss': 1.9976814985275269, 'validation/accuracy': 0.5457000136375427, 'validation/loss': 2.2147979736328125, 'validation/num_examples': 50000, 'test/accuracy': 0.40960001945495605, 'test/loss': 2.966240644454956, 'test/num_examples': 10000, 'score': 13819.610492706299, 'total_duration': 14439.08058643341, 'accumulated_submission_time': 13819.610492706299, 'accumulated_eval_time': 617.1896386146545, 'accumulated_logging_time': 0.8200054168701172, 'global_step': 41003, 'preemption_count': 0}), (42522, {'train/accuracy': 0.6168885231018066, 'train/loss': 1.8260935544967651, 'validation/accuracy': 0.5760799646377563, 'validation/loss': 2.0149435997009277, 'validation/num_examples': 50000, 'test/accuracy': 0.4488000273704529, 'test/loss': 2.704561948776245, 'test/num_examples': 10000, 'score': 14329.532070875168, 'total_duration': 14972.570736169815, 'accumulated_submission_time': 14329.532070875168, 'accumulated_eval_time': 640.67427110672, 'accumulated_logging_time': 0.8497834205627441, 'global_step': 42522, 'preemption_count': 0}), (44042, {'train/accuracy': 0.6665935516357422, 'train/loss': 1.6319551467895508, 'validation/accuracy': 0.579259991645813, 'validation/loss': 2.0244803428649902, 'validation/num_examples': 50000, 'test/accuracy': 0.45000001788139343, 'test/loss': 2.6779887676239014, 'test/num_examples': 10000, 'score': 14839.568438529968, 'total_duration': 15502.191601276398, 'accumulated_submission_time': 14839.568438529968, 'accumulated_eval_time': 660.1732244491577, 'accumulated_logging_time': 0.8819336891174316, 'global_step': 44042, 'preemption_count': 0}), (45562, {'train/accuracy': 0.6618502736091614, 'train/loss': 1.621239185333252, 'validation/accuracy': 0.6011599898338318, 'validation/loss': 1.8938428163528442, 'validation/num_examples': 50000, 'test/accuracy': 0.47280001640319824, 'test/loss': 2.5572855472564697, 'test/num_examples': 10000, 'score': 15349.6850771904, 'total_duration': 16032.415295362473, 'accumulated_submission_time': 15349.6850771904, 'accumulated_eval_time': 680.1943652629852, 'accumulated_logging_time': 0.9130690097808838, 'global_step': 45562, 'preemption_count': 0}), (47082, {'train/accuracy': 0.6599968075752258, 'train/loss': 1.6365338563919067, 'validation/accuracy': 0.6035400032997131, 'validation/loss': 1.8902983665466309, 'validation/num_examples': 50000, 'test/accuracy': 0.4853000342845917, 'test/loss': 2.5268380641937256, 'test/num_examples': 10000, 'score': 15859.610484600067, 'total_duration': 16565.878612041473, 'accumulated_submission_time': 15859.610484600067, 'accumulated_eval_time': 703.6520206928253, 'accumulated_logging_time': 0.9391820430755615, 'global_step': 47082, 'preemption_count': 0}), (48603, {'train/accuracy': 0.6563097834587097, 'train/loss': 1.7036696672439575, 'validation/accuracy': 0.6042799949645996, 'validation/loss': 1.9504328966140747, 'validation/num_examples': 50000, 'test/accuracy': 0.47700002789497375, 'test/loss': 2.6092634201049805, 'test/num_examples': 10000, 'score': 16369.831721305847, 'total_duration': 17097.813205957413, 'accumulated_submission_time': 16369.831721305847, 'accumulated_eval_time': 725.2833213806152, 'accumulated_logging_time': 0.9682011604309082, 'global_step': 48603, 'preemption_count': 0}), (50122, {'train/accuracy': 0.6453284025192261, 'train/loss': 1.7350159883499146, 'validation/accuracy': 0.6012200117111206, 'validation/loss': 1.9408735036849976, 'validation/num_examples': 50000, 'test/accuracy': 0.47360002994537354, 'test/loss': 2.606318235397339, 'test/num_examples': 10000, 'score': 16879.687109470367, 'total_duration': 17628.546664476395, 'accumulated_submission_time': 16879.687109470367, 'accumulated_eval_time': 745.848637342453, 'accumulated_logging_time': 1.2274518013000488, 'global_step': 50122, 'preemption_count': 0}), (51642, {'train/accuracy': 0.6628268361091614, 'train/loss': 1.6016414165496826, 'validation/accuracy': 0.6155799627304077, 'validation/loss': 1.818173885345459, 'validation/num_examples': 50000, 'test/accuracy': 0.49010002613067627, 'test/loss': 2.4969828128814697, 'test/num_examples': 10000, 'score': 17389.647258281708, 'total_duration': 18157.621995925903, 'accumulated_submission_time': 17389.647258281708, 'accumulated_eval_time': 764.8815550804138, 'accumulated_logging_time': 1.2552120685577393, 'global_step': 51642, 'preemption_count': 0}), (53161, {'train/accuracy': 0.6622289419174194, 'train/loss': 1.545854926109314, 'validation/accuracy': 0.5879799723625183, 'validation/loss': 1.8984012603759766, 'validation/num_examples': 50000, 'test/accuracy': 0.4563000202178955, 'test/loss': 2.6356890201568604, 'test/num_examples': 10000, 'score': 17899.738733530045, 'total_duration': 18687.372856378555, 'accumulated_submission_time': 17899.738733530045, 'accumulated_eval_time': 784.4550273418427, 'accumulated_logging_time': 1.286726713180542, 'global_step': 53161, 'preemption_count': 0}), (54681, {'train/accuracy': 0.6690449714660645, 'train/loss': 1.6354987621307373, 'validation/accuracy': 0.6118800044059753, 'validation/loss': 1.8964757919311523, 'validation/num_examples': 50000, 'test/accuracy': 0.4807000160217285, 'test/loss': 2.59613299369812, 'test/num_examples': 10000, 'score': 18409.862342119217, 'total_duration': 19217.039174079895, 'accumulated_submission_time': 18409.862342119217, 'accumulated_eval_time': 803.9163081645966, 'accumulated_logging_time': 1.3136131763458252, 'global_step': 54681, 'preemption_count': 0}), (56200, {'train/accuracy': 0.6720344424247742, 'train/loss': 1.566835641860962, 'validation/accuracy': 0.6166200041770935, 'validation/loss': 1.810349464416504, 'validation/num_examples': 50000, 'test/accuracy': 0.4829000234603882, 'test/loss': 2.4869861602783203, 'test/num_examples': 10000, 'score': 18919.96532702446, 'total_duration': 19745.5115172863, 'accumulated_submission_time': 18919.96532702446, 'accumulated_eval_time': 822.1993520259857, 'accumulated_logging_time': 1.345710277557373, 'global_step': 56200, 'preemption_count': 0}), (57719, {'train/accuracy': 0.6335498690605164, 'train/loss': 1.7657365798950195, 'validation/accuracy': 0.5821200013160706, 'validation/loss': 2.0033061504364014, 'validation/num_examples': 50000, 'test/accuracy': 0.4556000232696533, 'test/loss': 2.6878976821899414, 'test/num_examples': 10000, 'score': 19430.09889483452, 'total_duration': 20274.463276147842, 'accumulated_submission_time': 19430.09889483452, 'accumulated_eval_time': 840.9320335388184, 'accumulated_logging_time': 1.3773596286773682, 'global_step': 57719, 'preemption_count': 0}), (59237, {'train/accuracy': 0.662129282951355, 'train/loss': 1.6116786003112793, 'validation/accuracy': 0.6101199984550476, 'validation/loss': 1.8550580739974976, 'validation/num_examples': 50000, 'test/accuracy': 0.4830000102519989, 'test/loss': 2.505258560180664, 'test/num_examples': 10000, 'score': 19940.321910619736, 'total_duration': 20802.96570944786, 'accumulated_submission_time': 19940.321910619736, 'accumulated_eval_time': 859.1258161067963, 'accumulated_logging_time': 1.4092257022857666, 'global_step': 59237, 'preemption_count': 0}), (60757, {'train/accuracy': 0.6338488459587097, 'train/loss': 1.764035701751709, 'validation/accuracy': 0.5829200148582458, 'validation/loss': 2.0148353576660156, 'validation/num_examples': 50000, 'test/accuracy': 0.45110002160072327, 'test/loss': 2.714724063873291, 'test/num_examples': 10000, 'score': 20450.511591672897, 'total_duration': 21330.88549399376, 'accumulated_submission_time': 20450.511591672897, 'accumulated_eval_time': 876.7660822868347, 'accumulated_logging_time': 1.4434089660644531, 'global_step': 60757, 'preemption_count': 0}), (62276, {'train/accuracy': 0.6950533986091614, 'train/loss': 1.5297223329544067, 'validation/accuracy': 0.6177799701690674, 'validation/loss': 1.8755176067352295, 'validation/num_examples': 50000, 'test/accuracy': 0.4914000332355499, 'test/loss': 2.526862144470215, 'test/num_examples': 10000, 'score': 20960.61719608307, 'total_duration': 21858.611336946487, 'accumulated_submission_time': 20960.61719608307, 'accumulated_eval_time': 894.2997860908508, 'accumulated_logging_time': 1.4753570556640625, 'global_step': 62276, 'preemption_count': 0}), (63794, {'train/accuracy': 0.6825574040412903, 'train/loss': 1.5783780813217163, 'validation/accuracy': 0.617579996585846, 'validation/loss': 1.8705898523330688, 'validation/num_examples': 50000, 'test/accuracy': 0.4853000342845917, 'test/loss': 2.554471492767334, 'test/num_examples': 10000, 'score': 21470.559576272964, 'total_duration': 22386.221648454666, 'accumulated_submission_time': 21470.559576272964, 'accumulated_eval_time': 911.877756357193, 'accumulated_logging_time': 1.509612798690796, 'global_step': 63794, 'preemption_count': 0}), (65313, {'train/accuracy': 0.6825574040412903, 'train/loss': 1.5256329774856567, 'validation/accuracy': 0.625059962272644, 'validation/loss': 1.7955353260040283, 'validation/num_examples': 50000, 'test/accuracy': 0.4974000155925751, 'test/loss': 2.433189868927002, 'test/num_examples': 10000, 'score': 21980.664748430252, 'total_duration': 22914.051850557327, 'accumulated_submission_time': 21980.664748430252, 'accumulated_eval_time': 929.5161347389221, 'accumulated_logging_time': 1.543241024017334, 'global_step': 65313, 'preemption_count': 0}), (66833, {'train/accuracy': 0.6800063848495483, 'train/loss': 1.5886160135269165, 'validation/accuracy': 0.6231799721717834, 'validation/loss': 1.831006646156311, 'validation/num_examples': 50000, 'test/accuracy': 0.5015000104904175, 'test/loss': 2.474353313446045, 'test/num_examples': 10000, 'score': 22490.73743534088, 'total_duration': 23441.95782518387, 'accumulated_submission_time': 22490.73743534088, 'accumulated_eval_time': 947.2563452720642, 'accumulated_logging_time': 1.5833804607391357, 'global_step': 66833, 'preemption_count': 0}), (68352, {'train/accuracy': 0.6900709271430969, 'train/loss': 1.4819682836532593, 'validation/accuracy': 0.6340999603271484, 'validation/loss': 1.7323555946350098, 'validation/num_examples': 50000, 'test/accuracy': 0.503600001335144, 'test/loss': 2.4148378372192383, 'test/num_examples': 10000, 'score': 23000.860374689102, 'total_duration': 23969.89304113388, 'accumulated_submission_time': 23000.860374689102, 'accumulated_eval_time': 964.9811155796051, 'accumulated_logging_time': 1.6150639057159424, 'global_step': 68352, 'preemption_count': 0}), (69872, {'train/accuracy': 0.735750138759613, 'train/loss': 1.310245394706726, 'validation/accuracy': 0.6309799551963806, 'validation/loss': 1.761465072631836, 'validation/num_examples': 50000, 'test/accuracy': 0.49720001220703125, 'test/loss': 2.425360679626465, 'test/num_examples': 10000, 'score': 23510.993293762207, 'total_duration': 24497.920041322708, 'accumulated_submission_time': 23510.993293762207, 'accumulated_eval_time': 982.7848091125488, 'accumulated_logging_time': 1.651102066040039, 'global_step': 69872, 'preemption_count': 0}), (71392, {'train/accuracy': 0.6983617544174194, 'train/loss': 1.4776744842529297, 'validation/accuracy': 0.6286599636077881, 'validation/loss': 1.800763726234436, 'validation/num_examples': 50000, 'test/accuracy': 0.49400001764297485, 'test/loss': 2.4847891330718994, 'test/num_examples': 10000, 'score': 24020.97679042816, 'total_duration': 25025.388818740845, 'accumulated_submission_time': 24020.97679042816, 'accumulated_eval_time': 1000.1813578605652, 'accumulated_logging_time': 1.6846182346343994, 'global_step': 71392, 'preemption_count': 0}), (72913, {'train/accuracy': 0.6980229616165161, 'train/loss': 1.427905797958374, 'validation/accuracy': 0.637499988079071, 'validation/loss': 1.7069525718688965, 'validation/num_examples': 50000, 'test/accuracy': 0.5054000020027161, 'test/loss': 2.4028196334838867, 'test/num_examples': 10000, 'score': 24531.09007692337, 'total_duration': 25553.120299100876, 'accumulated_submission_time': 24531.09007692337, 'accumulated_eval_time': 1017.7072203159332, 'accumulated_logging_time': 1.7220878601074219, 'global_step': 72913, 'preemption_count': 0}), (74433, {'train/accuracy': 0.6910873651504517, 'train/loss': 1.5273631811141968, 'validation/accuracy': 0.6297399997711182, 'validation/loss': 1.8042446374893188, 'validation/num_examples': 50000, 'test/accuracy': 0.5105000138282776, 'test/loss': 2.4476895332336426, 'test/num_examples': 10000, 'score': 25041.03431081772, 'total_duration': 26080.79218506813, 'accumulated_submission_time': 25041.03431081772, 'accumulated_eval_time': 1035.3413667678833, 'accumulated_logging_time': 1.7609531879425049, 'global_step': 74433, 'preemption_count': 0}), (75952, {'train/accuracy': 0.6999362111091614, 'train/loss': 1.4965587854385376, 'validation/accuracy': 0.6417199969291687, 'validation/loss': 1.754271149635315, 'validation/num_examples': 50000, 'test/accuracy': 0.5117000341415405, 'test/loss': 2.413970708847046, 'test/num_examples': 10000, 'score': 25551.18010687828, 'total_duration': 26609.32388329506, 'accumulated_submission_time': 25551.18010687828, 'accumulated_eval_time': 1053.638699054718, 'accumulated_logging_time': 1.796116828918457, 'global_step': 75952, 'preemption_count': 0}), (77472, {'train/accuracy': 0.6788105964660645, 'train/loss': 1.539688229560852, 'validation/accuracy': 0.6212799549102783, 'validation/loss': 1.79335618019104, 'validation/num_examples': 50000, 'test/accuracy': 0.4953000247478485, 'test/loss': 2.4778523445129395, 'test/num_examples': 10000, 'score': 26061.325164079666, 'total_duration': 27136.916464805603, 'accumulated_submission_time': 26061.325164079666, 'accumulated_eval_time': 1070.9950873851776, 'accumulated_logging_time': 1.8330702781677246, 'global_step': 77472, 'preemption_count': 0}), (78991, {'train/accuracy': 0.7440808415412903, 'train/loss': 1.304325819015503, 'validation/accuracy': 0.6543999910354614, 'validation/loss': 1.688109040260315, 'validation/num_examples': 50000, 'test/accuracy': 0.5197000503540039, 'test/loss': 2.376405954360962, 'test/num_examples': 10000, 'score': 26571.27771782875, 'total_duration': 27664.416957378387, 'accumulated_submission_time': 26571.27771782875, 'accumulated_eval_time': 1088.4496076107025, 'accumulated_logging_time': 1.8720881938934326, 'global_step': 78991, 'preemption_count': 0}), (80511, {'train/accuracy': 0.7175741195678711, 'train/loss': 1.402329921722412, 'validation/accuracy': 0.6451599597930908, 'validation/loss': 1.7160725593566895, 'validation/num_examples': 50000, 'test/accuracy': 0.5151000022888184, 'test/loss': 2.3861660957336426, 'test/num_examples': 10000, 'score': 27081.45338320732, 'total_duration': 28192.248603582382, 'accumulated_submission_time': 27081.45338320732, 'accumulated_eval_time': 1106.0136144161224, 'accumulated_logging_time': 1.9104361534118652, 'global_step': 80511, 'preemption_count': 0}), (82029, {'train/accuracy': 0.7053172588348389, 'train/loss': 1.4680125713348389, 'validation/accuracy': 0.6407600045204163, 'validation/loss': 1.7571892738342285, 'validation/num_examples': 50000, 'test/accuracy': 0.5166000127792358, 'test/loss': 2.390846014022827, 'test/num_examples': 10000, 'score': 27591.40394973755, 'total_duration': 28719.964844942093, 'accumulated_submission_time': 27591.40394973755, 'accumulated_eval_time': 1123.690217256546, 'accumulated_logging_time': 1.9442918300628662, 'global_step': 82029, 'preemption_count': 0}), (83550, {'train/accuracy': 0.7248684763908386, 'train/loss': 1.3496756553649902, 'validation/accuracy': 0.6628199815750122, 'validation/loss': 1.6300710439682007, 'validation/num_examples': 50000, 'test/accuracy': 0.5449000000953674, 'test/loss': 2.249837636947632, 'test/num_examples': 10000, 'score': 28101.55716228485, 'total_duration': 29247.901939868927, 'accumulated_submission_time': 28101.55716228485, 'accumulated_eval_time': 1141.383838891983, 'accumulated_logging_time': 1.9798212051391602, 'global_step': 83550, 'preemption_count': 0}), (85069, {'train/accuracy': 0.7144650816917419, 'train/loss': 1.433240532875061, 'validation/accuracy': 0.6558799743652344, 'validation/loss': 1.6867034435272217, 'validation/num_examples': 50000, 'test/accuracy': 0.5259000062942505, 'test/loss': 2.3334290981292725, 'test/num_examples': 10000, 'score': 28611.537837028503, 'total_duration': 29775.600833654404, 'accumulated_submission_time': 28611.537837028503, 'accumulated_eval_time': 1159.0181767940521, 'accumulated_logging_time': 2.008910655975342, 'global_step': 85069, 'preemption_count': 0}), (86587, {'train/accuracy': 0.7221779227256775, 'train/loss': 1.3290126323699951, 'validation/accuracy': 0.6613399982452393, 'validation/loss': 1.6058188676834106, 'validation/num_examples': 50000, 'test/accuracy': 0.5312000513076782, 'test/loss': 2.271061420440674, 'test/num_examples': 10000, 'score': 29121.66387820244, 'total_duration': 30303.2045712471, 'accumulated_submission_time': 29121.66387820244, 'accumulated_eval_time': 1176.4064183235168, 'accumulated_logging_time': 2.043738842010498, 'global_step': 86587, 'preemption_count': 0}), (88105, {'train/accuracy': 0.7548230290412903, 'train/loss': 1.264643669128418, 'validation/accuracy': 0.6629599928855896, 'validation/loss': 1.6557101011276245, 'validation/num_examples': 50000, 'test/accuracy': 0.5333000421524048, 'test/loss': 2.3110227584838867, 'test/num_examples': 10000, 'score': 29631.87465071678, 'total_duration': 30831.08186531067, 'accumulated_submission_time': 29631.87465071678, 'accumulated_eval_time': 1193.9844272136688, 'accumulated_logging_time': 2.0784449577331543, 'global_step': 88105, 'preemption_count': 0}), (89624, {'train/accuracy': 0.7227559089660645, 'train/loss': 1.3492029905319214, 'validation/accuracy': 0.649179995059967, 'validation/loss': 1.6802361011505127, 'validation/num_examples': 50000, 'test/accuracy': 0.5248000025749207, 'test/loss': 2.3291525840759277, 'test/num_examples': 10000, 'score': 30141.839609861374, 'total_duration': 31358.45908021927, 'accumulated_submission_time': 30141.839609861374, 'accumulated_eval_time': 1211.308886051178, 'accumulated_logging_time': 2.1126153469085693, 'global_step': 89624, 'preemption_count': 0}), (91142, {'train/accuracy': 0.7321228981018066, 'train/loss': 1.2703503370285034, 'validation/accuracy': 0.6629199981689453, 'validation/loss': 1.5804736614227295, 'validation/num_examples': 50000, 'test/accuracy': 0.5315999984741211, 'test/loss': 2.240797281265259, 'test/num_examples': 10000, 'score': 30651.993514060974, 'total_duration': 31885.939094781876, 'accumulated_submission_time': 30651.993514060974, 'accumulated_eval_time': 1228.546450138092, 'accumulated_logging_time': 2.147599458694458, 'global_step': 91142, 'preemption_count': 0}), (92659, {'train/accuracy': 0.7361088991165161, 'train/loss': 1.2528094053268433, 'validation/accuracy': 0.6668999791145325, 'validation/loss': 1.5570307970046997, 'validation/num_examples': 50000, 'test/accuracy': 0.5444000363349915, 'test/loss': 2.1921234130859375, 'test/num_examples': 10000, 'score': 31161.964614391327, 'total_duration': 32413.378881692886, 'accumulated_submission_time': 31161.964614391327, 'accumulated_eval_time': 1245.9264180660248, 'accumulated_logging_time': 2.181300640106201, 'global_step': 92659, 'preemption_count': 0}), (94177, {'train/accuracy': 0.7242506146430969, 'train/loss': 1.2950704097747803, 'validation/accuracy': 0.6656999588012695, 'validation/loss': 1.572513222694397, 'validation/num_examples': 50000, 'test/accuracy': 0.5347000360488892, 'test/loss': 2.2459769248962402, 'test/num_examples': 10000, 'score': 31672.038009881973, 'total_duration': 32940.856270074844, 'accumulated_submission_time': 31672.038009881973, 'accumulated_eval_time': 1263.2396013736725, 'accumulated_logging_time': 2.2167887687683105, 'global_step': 94177, 'preemption_count': 0}), (95696, {'train/accuracy': 0.7590082883834839, 'train/loss': 1.2098000049591064, 'validation/accuracy': 0.6653800010681152, 'validation/loss': 1.604893445968628, 'validation/num_examples': 50000, 'test/accuracy': 0.5419000387191772, 'test/loss': 2.2530221939086914, 'test/num_examples': 10000, 'score': 32182.27980208397, 'total_duration': 33468.606795072556, 'accumulated_submission_time': 32182.27980208397, 'accumulated_eval_time': 1280.6584432125092, 'accumulated_logging_time': 2.2529103755950928, 'global_step': 95696, 'preemption_count': 0}), (97214, {'train/accuracy': 0.7708864808082581, 'train/loss': 1.1475695371627808, 'validation/accuracy': 0.6789000034332275, 'validation/loss': 1.5367943048477173, 'validation/num_examples': 50000, 'test/accuracy': 0.5506000518798828, 'test/loss': 2.176283597946167, 'test/num_examples': 10000, 'score': 32692.21554327011, 'total_duration': 33996.285942554474, 'accumulated_submission_time': 32692.21554327011, 'accumulated_eval_time': 1298.3109073638916, 'accumulated_logging_time': 2.28875470161438, 'global_step': 97214, 'preemption_count': 0}), (98734, {'train/accuracy': 0.7511160373687744, 'train/loss': 1.2191133499145508, 'validation/accuracy': 0.6734200119972229, 'validation/loss': 1.5681793689727783, 'validation/num_examples': 50000, 'test/accuracy': 0.5435000061988831, 'test/loss': 2.2351646423339844, 'test/num_examples': 10000, 'score': 33202.435888290405, 'total_duration': 34524.019939661026, 'accumulated_submission_time': 33202.435888290405, 'accumulated_eval_time': 1315.7354176044464, 'accumulated_logging_time': 2.324050188064575, 'global_step': 98734, 'preemption_count': 0}), (100255, {'train/accuracy': 0.7205038070678711, 'train/loss': 1.3478683233261108, 'validation/accuracy': 0.6510199904441833, 'validation/loss': 1.662100076675415, 'validation/num_examples': 50000, 'test/accuracy': 0.5278000235557556, 'test/loss': 2.3079800605773926, 'test/num_examples': 10000, 'score': 33712.410767793655, 'total_duration': 35051.54335141182, 'accumulated_submission_time': 33712.410767793655, 'accumulated_eval_time': 1333.1954073905945, 'accumulated_logging_time': 2.357520341873169, 'global_step': 100255, 'preemption_count': 0}), (101775, {'train/accuracy': 0.7612404227256775, 'train/loss': 1.21299147605896, 'validation/accuracy': 0.684719979763031, 'validation/loss': 1.5416755676269531, 'validation/num_examples': 50000, 'test/accuracy': 0.5610000491142273, 'test/loss': 2.1778295040130615, 'test/num_examples': 10000, 'score': 34222.33161020279, 'total_duration': 35578.85714626312, 'accumulated_submission_time': 34222.33161020279, 'accumulated_eval_time': 1350.4975800514221, 'accumulated_logging_time': 2.3934168815612793, 'global_step': 101775, 'preemption_count': 0}), (103295, {'train/accuracy': 0.7264229655265808, 'train/loss': 1.3491491079330444, 'validation/accuracy': 0.6582599878311157, 'validation/loss': 1.6586755514144897, 'validation/num_examples': 50000, 'test/accuracy': 0.5309000015258789, 'test/loss': 2.3244988918304443, 'test/num_examples': 10000, 'score': 34732.541697740555, 'total_duration': 36106.57509183884, 'accumulated_submission_time': 34732.541697740555, 'accumulated_eval_time': 1367.9093880653381, 'accumulated_logging_time': 2.435002088546753, 'global_step': 103295, 'preemption_count': 0}), (104814, {'train/accuracy': 0.8017378449440002, 'train/loss': 1.0380462408065796, 'validation/accuracy': 0.6862599849700928, 'validation/loss': 1.51997709274292, 'validation/num_examples': 50000, 'test/accuracy': 0.5666000247001648, 'test/loss': 2.1280741691589355, 'test/num_examples': 10000, 'score': 35242.78598356247, 'total_duration': 36634.17669773102, 'accumulated_submission_time': 35242.78598356247, 'accumulated_eval_time': 1385.1785988807678, 'accumulated_logging_time': 2.470041275024414, 'global_step': 104814, 'preemption_count': 0}), (106333, {'train/accuracy': 0.7935466766357422, 'train/loss': 1.0361019372940063, 'validation/accuracy': 0.7030400037765503, 'validation/loss': 1.425618052482605, 'validation/num_examples': 50000, 'test/accuracy': 0.572100043296814, 'test/loss': 2.0632615089416504, 'test/num_examples': 10000, 'score': 35752.73928594589, 'total_duration': 37161.68286848068, 'accumulated_submission_time': 35752.73928594589, 'accumulated_eval_time': 1402.6381130218506, 'accumulated_logging_time': 2.509903907775879, 'global_step': 106333, 'preemption_count': 0}), (107852, {'train/accuracy': 0.7864317297935486, 'train/loss': 1.0807485580444336, 'validation/accuracy': 0.6959599852561951, 'validation/loss': 1.46254563331604, 'validation/num_examples': 50000, 'test/accuracy': 0.5665000081062317, 'test/loss': 2.091984510421753, 'test/num_examples': 10000, 'score': 36262.89731884003, 'total_duration': 37689.46839976311, 'accumulated_submission_time': 36262.89731884003, 'accumulated_eval_time': 1420.1760292053223, 'accumulated_logging_time': 2.5443718433380127, 'global_step': 107852, 'preemption_count': 0}), (109371, {'train/accuracy': 0.7962173223495483, 'train/loss': 1.031316876411438, 'validation/accuracy': 0.7085999846458435, 'validation/loss': 1.4009512662887573, 'validation/num_examples': 50000, 'test/accuracy': 0.5795000195503235, 'test/loss': 2.0282557010650635, 'test/num_examples': 10000, 'score': 36773.13652920723, 'total_duration': 38217.31284785271, 'accumulated_submission_time': 36773.13652920723, 'accumulated_eval_time': 1437.689792394638, 'accumulated_logging_time': 2.581874370574951, 'global_step': 109371, 'preemption_count': 0}), (110889, {'train/accuracy': 0.7971739172935486, 'train/loss': 1.009020447731018, 'validation/accuracy': 0.7094599604606628, 'validation/loss': 1.375060796737671, 'validation/num_examples': 50000, 'test/accuracy': 0.5776000022888184, 'test/loss': 2.030421257019043, 'test/num_examples': 10000, 'score': 37283.3183465004, 'total_duration': 38744.87355494499, 'accumulated_submission_time': 37283.3183465004, 'accumulated_eval_time': 1454.9782001972198, 'accumulated_logging_time': 2.618157148361206, 'global_step': 110889, 'preemption_count': 0}), (112409, {'train/accuracy': 0.7902383208274841, 'train/loss': 1.040706753730774, 'validation/accuracy': 0.7038999795913696, 'validation/loss': 1.4087190628051758, 'validation/num_examples': 50000, 'test/accuracy': 0.5773000121116638, 'test/loss': 2.0421769618988037, 'test/num_examples': 10000, 'score': 37793.321729660034, 'total_duration': 39272.41820645332, 'accumulated_submission_time': 37793.321729660034, 'accumulated_eval_time': 1472.4300179481506, 'accumulated_logging_time': 2.6541287899017334, 'global_step': 112409, 'preemption_count': 0}), (113926, {'train/accuracy': 0.8326291441917419, 'train/loss': 0.8875695466995239, 'validation/accuracy': 0.7185800075531006, 'validation/loss': 1.3616238832473755, 'validation/num_examples': 50000, 'test/accuracy': 0.5887000560760498, 'test/loss': 2.000600814819336, 'test/num_examples': 10000, 'score': 38303.29452633858, 'total_duration': 39799.795472860336, 'accumulated_submission_time': 38303.29452633858, 'accumulated_eval_time': 1489.7348415851593, 'accumulated_logging_time': 2.700051784515381, 'global_step': 113926, 'preemption_count': 0}), (115445, {'train/accuracy': 0.8215879797935486, 'train/loss': 0.9264942407608032, 'validation/accuracy': 0.7172200083732605, 'validation/loss': 1.3684145212173462, 'validation/num_examples': 50000, 'test/accuracy': 0.5905000567436218, 'test/loss': 2.016941785812378, 'test/num_examples': 10000, 'score': 38813.49972128868, 'total_duration': 40327.58888578415, 'accumulated_submission_time': 38813.49972128868, 'accumulated_eval_time': 1507.2312965393066, 'accumulated_logging_time': 2.7389280796051025, 'global_step': 115445, 'preemption_count': 0}), (116963, {'train/accuracy': 0.828543484210968, 'train/loss': 0.883918046951294, 'validation/accuracy': 0.7252999544143677, 'validation/loss': 1.309679388999939, 'validation/num_examples': 50000, 'test/accuracy': 0.5981000065803528, 'test/loss': 1.936470627784729, 'test/num_examples': 10000, 'score': 39323.45069527626, 'total_duration': 40854.83286714554, 'accumulated_submission_time': 39323.45069527626, 'accumulated_eval_time': 1524.433219909668, 'accumulated_logging_time': 2.777219772338867, 'global_step': 116963, 'preemption_count': 0}), (118483, {'train/accuracy': 0.8358976244926453, 'train/loss': 0.8649929165840149, 'validation/accuracy': 0.733299970626831, 'validation/loss': 1.2923582792282104, 'validation/num_examples': 50000, 'test/accuracy': 0.6100000143051147, 'test/loss': 1.9099456071853638, 'test/num_examples': 10000, 'score': 39833.584914684296, 'total_duration': 41382.424394607544, 'accumulated_submission_time': 39833.584914684296, 'accumulated_eval_time': 1541.8003342151642, 'accumulated_logging_time': 2.8139991760253906, 'global_step': 118483, 'preemption_count': 0}), (120002, {'train/accuracy': 0.8349409699440002, 'train/loss': 0.8720414042472839, 'validation/accuracy': 0.7340399622917175, 'validation/loss': 1.2941697835922241, 'validation/num_examples': 50000, 'test/accuracy': 0.6096000075340271, 'test/loss': 1.9135819673538208, 'test/num_examples': 10000, 'score': 40343.50025868416, 'total_duration': 41909.86901688576, 'accumulated_submission_time': 40343.50025868416, 'accumulated_eval_time': 1559.2355153560638, 'accumulated_logging_time': 2.853339195251465, 'global_step': 120002, 'preemption_count': 0}), (121522, {'train/accuracy': 0.8537348508834839, 'train/loss': 0.781994640827179, 'validation/accuracy': 0.7448599934577942, 'validation/loss': 1.2308391332626343, 'validation/num_examples': 50000, 'test/accuracy': 0.617900013923645, 'test/loss': 1.8550323247909546, 'test/num_examples': 10000, 'score': 40853.73813080788, 'total_duration': 42437.535009622574, 'accumulated_submission_time': 40853.73813080788, 'accumulated_eval_time': 1576.574713230133, 'accumulated_logging_time': 2.889094352722168, 'global_step': 121522, 'preemption_count': 0}), (123043, {'train/accuracy': 0.8741031289100647, 'train/loss': 0.7374966740608215, 'validation/accuracy': 0.7486199736595154, 'validation/loss': 1.2402164936065674, 'validation/num_examples': 50000, 'test/accuracy': 0.6232000589370728, 'test/loss': 1.8539561033248901, 'test/num_examples': 10000, 'score': 41363.81107091904, 'total_duration': 42965.16845846176, 'accumulated_submission_time': 41363.81107091904, 'accumulated_eval_time': 1594.0456488132477, 'accumulated_logging_time': 2.924650192260742, 'global_step': 123043, 'preemption_count': 0}), (124562, {'train/accuracy': 0.8776506781578064, 'train/loss': 0.7061590552330017, 'validation/accuracy': 0.7564399838447571, 'validation/loss': 1.199823021888733, 'validation/num_examples': 50000, 'test/accuracy': 0.6358000040054321, 'test/loss': 1.8023020029067993, 'test/num_examples': 10000, 'score': 41873.749415159225, 'total_duration': 43492.91576004028, 'accumulated_submission_time': 41873.749415159225, 'accumulated_eval_time': 1611.7615554332733, 'accumulated_logging_time': 2.9650187492370605, 'global_step': 124562, 'preemption_count': 0}), (126081, {'train/accuracy': 0.8871572017669678, 'train/loss': 0.663292407989502, 'validation/accuracy': 0.7620999813079834, 'validation/loss': 1.1754844188690186, 'validation/num_examples': 50000, 'test/accuracy': 0.641800045967102, 'test/loss': 1.7703522443771362, 'test/num_examples': 10000, 'score': 42383.772540807724, 'total_duration': 44020.43105649948, 'accumulated_submission_time': 42383.772540807724, 'accumulated_eval_time': 1629.1636288166046, 'accumulated_logging_time': 3.0010507106781006, 'global_step': 126081, 'preemption_count': 0}), (127600, {'train/accuracy': 0.8903459906578064, 'train/loss': 0.6631816625595093, 'validation/accuracy': 0.7636799812316895, 'validation/loss': 1.1692726612091064, 'validation/num_examples': 50000, 'test/accuracy': 0.6455000042915344, 'test/loss': 1.7630950212478638, 'test/num_examples': 10000, 'score': 42893.9892706871, 'total_duration': 44548.24864816666, 'accumulated_submission_time': 42893.9892706871, 'accumulated_eval_time': 1646.6727030277252, 'accumulated_logging_time': 3.037792444229126, 'global_step': 127600, 'preemption_count': 0}), (129119, {'train/accuracy': 0.8921396732330322, 'train/loss': 0.6511744260787964, 'validation/accuracy': 0.7664600014686584, 'validation/loss': 1.1603405475616455, 'validation/num_examples': 50000, 'test/accuracy': 0.6430000066757202, 'test/loss': 1.7546344995498657, 'test/num_examples': 10000, 'score': 43404.10743713379, 'total_duration': 45075.9855389595, 'accumulated_submission_time': 43404.10743713379, 'accumulated_eval_time': 1664.2013821601868, 'accumulated_logging_time': 3.0727055072784424, 'global_step': 129119, 'preemption_count': 0})], 'global_step': 129119}
I0316 00:34:53.313967 140219736737600 submission_runner.py:596] Timing: 43404.10743713379
I0316 00:34:53.314028 140219736737600 submission_runner.py:598] Total number of evals: 86
I0316 00:34:53.314077 140219736737600 submission_runner.py:599] ====================
I0316 00:34:53.314358 140219736737600 submission_runner.py:683] Final imagenet_resnet_large_bn_init score: 0

python3 submission_runner.py --framework=jax --workload=ogbg_silu --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/ogbg_silu/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --num_tuning_trials=1 --rng_seed=1884662704 --max_global_steps=80000 2>&1 | tee -a /logs/ogbg_silu_jax_02-15-2024-12-07-29.log
I0215 12:07:54.716968 139966923982656 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax.
I0215 12:07:55.735767 139966923982656 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0215 12:07:55.736528 139966923982656 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0215 12:07:55.736675 139966923982656 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0215 12:07:55.743483 139966923982656 submission_runner.py:542] Using RNG seed 1884662704
I0215 12:07:57.091125 139966923982656 submission_runner.py:551] --- Tuning run 1/1 ---
I0215 12:07:57.091330 139966923982656 submission_runner.py:556] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1.
I0215 12:07:57.091495 139966923982656 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1/hparams.json.
I0215 12:07:57.272352 139966923982656 submission_runner.py:206] Initializing dataset.
I0215 12:07:57.386499 139966923982656 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:07:57.394264 139966923982656 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0215 12:07:57.670680 139966923982656 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0215 12:07:57.731966 139966923982656 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:07:57.819667 139966923982656 submission_runner.py:213] Initializing model.
I0215 12:08:02.367763 139966923982656 submission_runner.py:255] Initializing optimizer.
I0215 12:08:03.001367 139966923982656 submission_runner.py:262] Initializing metrics bundle.
I0215 12:08:03.001550 139966923982656 submission_runner.py:280] Initializing checkpoint and logger.
I0215 12:08:03.002438 139966923982656 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1 with prefix checkpoint_
I0215 12:08:03.002577 139966923982656 submission_runner.py:300] Saving meta data to /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1/meta_data_0.json.
I0215 12:08:03.002778 139966923982656 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0215 12:08:03.002840 139966923982656 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0215 12:08:03.304938 139966923982656 logger_utils.py:220] Unable to record git information. Continuing without it.
I0215 12:08:03.578290 139966923982656 submission_runner.py:304] Saving flags to /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1/flags_0.json.
I0215 12:08:03.587502 139966923982656 submission_runner.py:314] Starting training loop.
I0215 12:08:23.031455 139805773567744 logging_writer.py:48] [0] global_step=0, grad_norm=2.5856876373291016, loss=0.7348871827125549
I0215 12:08:23.046580 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:08:23.052468 139966923982656 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:08:23.056663 139966923982656 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:08:23.123811 139966923982656 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:10:15.544016 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:10:15.547394 139966923982656 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:10:15.551459 139966923982656 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:10:15.615525 139966923982656 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:11:47.673825 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:11:47.677102 139966923982656 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:11:47.681027 139966923982656 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0215 12:11:47.744450 139966923982656 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0215 12:13:21.342768 139966923982656 submission_runner.py:408] Time since start: 317.76s, 	Step: 1, 	{'train/accuracy': 0.507875919342041, 'train/loss': 0.7331976294517517, 'train/mean_average_precision': 0.020742417550586277, 'validation/accuracy': 0.5152865052223206, 'validation/loss': 0.7278426289558411, 'validation/mean_average_precision': 0.024839994554343717, 'validation/num_examples': 43793, 'test/accuracy': 0.5164411067962646, 'test/loss': 0.7269362807273865, 'test/mean_average_precision': 0.026327797636932982, 'test/num_examples': 43793, 'score': 19.459041833877563, 'total_duration': 317.75520968437195, 'accumulated_submission_time': 19.459041833877563, 'accumulated_eval_time': 298.296128988266, 'accumulated_logging_time': 0}
I0215 12:13:21.363422 139798207072000 logging_writer.py:48] [1] accumulated_eval_time=298.296129, accumulated_logging_time=0, accumulated_submission_time=19.459042, global_step=1, preemption_count=0, score=19.459042, test/accuracy=0.516441, test/loss=0.726936, test/mean_average_precision=0.026328, test/num_examples=43793, total_duration=317.755210, train/accuracy=0.507876, train/loss=0.733198, train/mean_average_precision=0.020742, validation/accuracy=0.515287, validation/loss=0.727843, validation/mean_average_precision=0.024840, validation/num_examples=43793
I0215 12:13:21.684792 139799582770944 logging_writer.py:48] [1] global_step=1, grad_norm=2.595139741897583, loss=0.7349568009376526
I0215 12:13:21.992570 139798207072000 logging_writer.py:48] [2] global_step=2, grad_norm=2.6048524379730225, loss=0.7341508865356445
I0215 12:13:22.286681 139799582770944 logging_writer.py:48] [3] global_step=3, grad_norm=2.6073787212371826, loss=0.735898494720459
I0215 12:13:22.593229 139798207072000 logging_writer.py:48] [4] global_step=4, grad_norm=2.5574817657470703, loss=0.7351155877113342
I0215 12:13:22.921626 139799582770944 logging_writer.py:48] [5] global_step=5, grad_norm=2.5962555408477783, loss=0.7321822047233582
I0215 12:13:23.241195 139798207072000 logging_writer.py:48] [6] global_step=6, grad_norm=2.573084831237793, loss=0.7308613061904907
I0215 12:13:23.543596 139799582770944 logging_writer.py:48] [7] global_step=7, grad_norm=2.5843868255615234, loss=0.7333505749702454
I0215 12:13:23.861327 139798207072000 logging_writer.py:48] [8] global_step=8, grad_norm=2.5810344219207764, loss=0.7302629947662354
I0215 12:13:24.160888 139799582770944 logging_writer.py:48] [9] global_step=9, grad_norm=2.580413341522217, loss=0.7299990057945251
I0215 12:13:24.459311 139798207072000 logging_writer.py:48] [10] global_step=10, grad_norm=2.59859299659729, loss=0.7306289672851562
I0215 12:13:24.755940 139799582770944 logging_writer.py:48] [11] global_step=11, grad_norm=2.5700364112854004, loss=0.7287654280662537
I0215 12:13:25.048444 139798207072000 logging_writer.py:48] [12] global_step=12, grad_norm=2.572039842605591, loss=0.7282020449638367
I0215 12:13:25.342676 139799582770944 logging_writer.py:48] [13] global_step=13, grad_norm=2.569603443145752, loss=0.7265943884849548
I0215 12:13:25.635509 139798207072000 logging_writer.py:48] [14] global_step=14, grad_norm=2.517860174179077, loss=0.725735068321228
I0215 12:13:25.942420 139799582770944 logging_writer.py:48] [15] global_step=15, grad_norm=2.522639274597168, loss=0.7232971787452698
I0215 12:13:26.244663 139798207072000 logging_writer.py:48] [16] global_step=16, grad_norm=2.5343592166900635, loss=0.7227282524108887
I0215 12:13:26.546248 139799582770944 logging_writer.py:48] [17] global_step=17, grad_norm=2.508746862411499, loss=0.720811128616333
I0215 12:13:26.848264 139798207072000 logging_writer.py:48] [18] global_step=18, grad_norm=2.487095832824707, loss=0.7179538607597351
I0215 12:13:27.150396 139799582770944 logging_writer.py:48] [19] global_step=19, grad_norm=2.484684467315674, loss=0.7168178558349609
I0215 12:13:27.448079 139798207072000 logging_writer.py:48] [20] global_step=20, grad_norm=2.497232437133789, loss=0.7156672477722168
I0215 12:13:27.746203 139799582770944 logging_writer.py:48] [21] global_step=21, grad_norm=2.475905179977417, loss=0.7158353924751282
I0215 12:13:28.045353 139798207072000 logging_writer.py:48] [22] global_step=22, grad_norm=2.4723193645477295, loss=0.7109577655792236
I0215 12:13:28.337083 139799582770944 logging_writer.py:48] [23] global_step=23, grad_norm=2.473306894302368, loss=0.7111402153968811
I0215 12:13:28.636293 139798207072000 logging_writer.py:48] [24] global_step=24, grad_norm=2.4277639389038086, loss=0.7073066830635071
I0215 12:13:28.934136 139799582770944 logging_writer.py:48] [25] global_step=25, grad_norm=2.4251394271850586, loss=0.7068485021591187
I0215 12:13:29.234394 139798207072000 logging_writer.py:48] [26] global_step=26, grad_norm=2.412982940673828, loss=0.7043205499649048
I0215 12:13:29.533692 139799582770944 logging_writer.py:48] [27] global_step=27, grad_norm=2.382512092590332, loss=0.7008931636810303
I0215 12:13:29.836241 139798207072000 logging_writer.py:48] [28] global_step=28, grad_norm=2.3310937881469727, loss=0.6978583335876465
I0215 12:13:30.141669 139799582770944 logging_writer.py:48] [29] global_step=29, grad_norm=2.3451666831970215, loss=0.6970247626304626
I0215 12:13:30.446347 139798207072000 logging_writer.py:48] [30] global_step=30, grad_norm=2.3266959190368652, loss=0.6935285925865173
I0215 12:13:30.753733 139799582770944 logging_writer.py:48] [31] global_step=31, grad_norm=2.299617052078247, loss=0.691942036151886
I0215 12:13:31.054240 139798207072000 logging_writer.py:48] [32] global_step=32, grad_norm=2.281698226928711, loss=0.6883135437965393
I0215 12:13:31.353893 139799582770944 logging_writer.py:48] [33] global_step=33, grad_norm=2.2658989429473877, loss=0.6857594847679138
I0215 12:13:31.656272 139798207072000 logging_writer.py:48] [34] global_step=34, grad_norm=2.200240135192871, loss=0.6829322576522827
I0215 12:13:31.952811 139799582770944 logging_writer.py:48] [35] global_step=35, grad_norm=2.188474178314209, loss=0.6817119121551514
I0215 12:13:32.268784 139798207072000 logging_writer.py:48] [36] global_step=36, grad_norm=2.1921377182006836, loss=0.678331732749939
I0215 12:13:32.592755 139799582770944 logging_writer.py:48] [37] global_step=37, grad_norm=2.1560966968536377, loss=0.6754043102264404
I0215 12:13:32.909943 139798207072000 logging_writer.py:48] [38] global_step=38, grad_norm=2.1219773292541504, loss=0.6715859174728394
I0215 12:13:33.207832 139799582770944 logging_writer.py:48] [39] global_step=39, grad_norm=2.106250286102295, loss=0.6681602597236633
I0215 12:13:33.501599 139798207072000 logging_writer.py:48] [40] global_step=40, grad_norm=2.072200298309326, loss=0.6664137244224548
I0215 12:13:33.799615 139799582770944 logging_writer.py:48] [41] global_step=41, grad_norm=2.013347864151001, loss=0.6633321046829224
I0215 12:13:34.127594 139798207072000 logging_writer.py:48] [42] global_step=42, grad_norm=1.9742318391799927, loss=0.6613747477531433
I0215 12:13:34.455743 139799582770944 logging_writer.py:48] [43] global_step=43, grad_norm=1.9755350351333618, loss=0.6591184735298157
I0215 12:13:34.754736 139798207072000 logging_writer.py:48] [44] global_step=44, grad_norm=1.9484808444976807, loss=0.6545420289039612
I0215 12:13:35.067875 139799582770944 logging_writer.py:48] [45] global_step=45, grad_norm=1.88502836227417, loss=0.6507607102394104
I0215 12:13:35.396618 139798207072000 logging_writer.py:48] [46] global_step=46, grad_norm=1.8485753536224365, loss=0.6492120623588562
I0215 12:13:35.722850 139799582770944 logging_writer.py:48] [47] global_step=47, grad_norm=1.8129076957702637, loss=0.6474050283432007
I0215 12:13:36.028589 139798207072000 logging_writer.py:48] [48] global_step=48, grad_norm=1.808488130569458, loss=0.6430306434631348
I0215 12:13:36.327736 139799582770944 logging_writer.py:48] [49] global_step=49, grad_norm=1.7692606449127197, loss=0.6405507922172546
I0215 12:13:36.659538 139798207072000 logging_writer.py:48] [50] global_step=50, grad_norm=1.733968734741211, loss=0.6390498280525208
I0215 12:13:36.977358 139799582770944 logging_writer.py:48] [51] global_step=51, grad_norm=1.700168490409851, loss=0.633525013923645
I0215 12:13:37.292876 139798207072000 logging_writer.py:48] [52] global_step=52, grad_norm=1.6730488538742065, loss=0.6329693794250488
I0215 12:13:37.610353 139799582770944 logging_writer.py:48] [53] global_step=53, grad_norm=1.65149986743927, loss=0.629368245601654
I0215 12:13:37.908288 139798207072000 logging_writer.py:48] [54] global_step=54, grad_norm=1.6146386861801147, loss=0.625403881072998
I0215 12:13:38.207545 139799582770944 logging_writer.py:48] [55] global_step=55, grad_norm=1.5964581966400146, loss=0.623607337474823
I0215 12:13:38.502149 139798207072000 logging_writer.py:48] [56] global_step=56, grad_norm=1.5583624839782715, loss=0.6217909455299377
I0215 12:13:38.802453 139799582770944 logging_writer.py:48] [57] global_step=57, grad_norm=1.5348515510559082, loss=0.6190216541290283
I0215 12:13:39.100134 139798207072000 logging_writer.py:48] [58] global_step=58, grad_norm=1.5238233804702759, loss=0.6165618300437927
I0215 12:13:39.395881 139799582770944 logging_writer.py:48] [59] global_step=59, grad_norm=1.4897840023040771, loss=0.6138803958892822
I0215 12:13:39.694013 139798207072000 logging_writer.py:48] [60] global_step=60, grad_norm=1.471954584121704, loss=0.609602153301239
I0215 12:13:39.996354 139799582770944 logging_writer.py:48] [61] global_step=61, grad_norm=1.4555972814559937, loss=0.6093348860740662
I0215 12:13:40.316886 139798207072000 logging_writer.py:48] [62] global_step=62, grad_norm=1.4307905435562134, loss=0.6094678044319153
I0215 12:13:40.645226 139799582770944 logging_writer.py:48] [63] global_step=63, grad_norm=1.438506841659546, loss=0.6041043400764465
I0215 12:13:40.958308 139798207072000 logging_writer.py:48] [64] global_step=64, grad_norm=1.4044603109359741, loss=0.6027093529701233
I0215 12:13:41.261948 139799582770944 logging_writer.py:48] [65] global_step=65, grad_norm=1.4011378288269043, loss=0.5995391607284546
I0215 12:13:41.562555 139798207072000 logging_writer.py:48] [66] global_step=66, grad_norm=1.3630895614624023, loss=0.5983027219772339
I0215 12:13:41.873309 139799582770944 logging_writer.py:48] [67] global_step=67, grad_norm=1.3668075799942017, loss=0.5952831506729126
I0215 12:13:42.177989 139798207072000 logging_writer.py:48] [68] global_step=68, grad_norm=1.3544542789459229, loss=0.5928454399108887
I0215 12:13:42.485175 139799582770944 logging_writer.py:48] [69] global_step=69, grad_norm=1.3431391716003418, loss=0.5902221202850342
I0215 12:13:42.789361 139798207072000 logging_writer.py:48] [70] global_step=70, grad_norm=1.3494350910186768, loss=0.5870794653892517
I0215 12:13:43.113486 139799582770944 logging_writer.py:48] [71] global_step=71, grad_norm=1.3244760036468506, loss=0.5855587124824524
I0215 12:13:43.412399 139798207072000 logging_writer.py:48] [72] global_step=72, grad_norm=1.3228248357772827, loss=0.5852418541908264
I0215 12:13:43.710284 139799582770944 logging_writer.py:48] [73] global_step=73, grad_norm=1.318199872970581, loss=0.5822233557701111
I0215 12:13:44.026129 139798207072000 logging_writer.py:48] [74] global_step=74, grad_norm=1.298797607421875, loss=0.5800387263298035
I0215 12:13:44.328813 139799582770944 logging_writer.py:48] [75] global_step=75, grad_norm=1.2956146001815796, loss=0.5777088403701782
I0215 12:13:44.632135 139798207072000 logging_writer.py:48] [76] global_step=76, grad_norm=1.2715345621109009, loss=0.5749478340148926
I0215 12:13:44.935413 139799582770944 logging_writer.py:48] [77] global_step=77, grad_norm=1.2667778730392456, loss=0.5741275548934937
I0215 12:13:45.259333 139798207072000 logging_writer.py:48] [78] global_step=78, grad_norm=1.237228274345398, loss=0.5715525150299072
I0215 12:13:45.592508 139799582770944 logging_writer.py:48] [79] global_step=79, grad_norm=1.2540754079818726, loss=0.5688199996948242
I0215 12:13:45.917627 139798207072000 logging_writer.py:48] [80] global_step=80, grad_norm=1.24259614944458, loss=0.5678790211677551
I0215 12:13:46.233576 139799582770944 logging_writer.py:48] [81] global_step=81, grad_norm=1.2182984352111816, loss=0.5654983520507812
I0215 12:13:46.538084 139798207072000 logging_writer.py:48] [82] global_step=82, grad_norm=1.2166069746017456, loss=0.5661355257034302
I0215 12:13:46.838894 139799582770944 logging_writer.py:48] [83] global_step=83, grad_norm=1.2128452062606812, loss=0.5609288215637207
I0215 12:13:47.152539 139798207072000 logging_writer.py:48] [84] global_step=84, grad_norm=1.2031421661376953, loss=0.5620194673538208
I0215 12:13:47.456125 139799582770944 logging_writer.py:48] [85] global_step=85, grad_norm=1.1776877641677856, loss=0.5599151253700256
I0215 12:13:47.764678 139798207072000 logging_writer.py:48] [86] global_step=86, grad_norm=1.1738284826278687, loss=0.5580109357833862
I0215 12:13:48.081869 139799582770944 logging_writer.py:48] [87] global_step=87, grad_norm=1.1525449752807617, loss=0.5562849044799805
I0215 12:13:48.385220 139798207072000 logging_writer.py:48] [88] global_step=88, grad_norm=1.155701756477356, loss=0.5536997318267822
I0215 12:13:48.688961 139799582770944 logging_writer.py:48] [89] global_step=89, grad_norm=1.1610515117645264, loss=0.5502020716667175
I0215 12:13:48.989771 139798207072000 logging_writer.py:48] [90] global_step=90, grad_norm=1.1408683061599731, loss=0.5505805611610413
I0215 12:13:49.300294 139799582770944 logging_writer.py:48] [91] global_step=91, grad_norm=1.1443822383880615, loss=0.5457969903945923
I0215 12:13:49.603372 139798207072000 logging_writer.py:48] [92] global_step=92, grad_norm=1.1070435047149658, loss=0.5456571578979492
I0215 12:13:49.930270 139799582770944 logging_writer.py:48] [93] global_step=93, grad_norm=1.1253770589828491, loss=0.5439496040344238
I0215 12:13:50.249954 139798207072000 logging_writer.py:48] [94] global_step=94, grad_norm=1.1082887649536133, loss=0.5410804152488708
I0215 12:13:50.556182 139799582770944 logging_writer.py:48] [95] global_step=95, grad_norm=1.0895650386810303, loss=0.5418119430541992
I0215 12:13:50.859615 139798207072000 logging_writer.py:48] [96] global_step=96, grad_norm=1.080924153327942, loss=0.5387342572212219
I0215 12:13:51.176289 139799582770944 logging_writer.py:48] [97] global_step=97, grad_norm=1.0675048828125, loss=0.5380949974060059
I0215 12:13:51.472873 139798207072000 logging_writer.py:48] [98] global_step=98, grad_norm=1.0691167116165161, loss=0.534548282623291
I0215 12:13:51.763454 139799582770944 logging_writer.py:48] [99] global_step=99, grad_norm=1.065055251121521, loss=0.5328261256217957
I0215 12:13:52.072659 139798207072000 logging_writer.py:48] [100] global_step=100, grad_norm=1.0547466278076172, loss=0.5301040410995483
I0215 12:15:50.253295 139799582770944 logging_writer.py:48] [500] global_step=500, grad_norm=0.24669571220874786, loss=0.2526741027832031
I0215 12:17:21.387148 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:19:06.656358 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:19:09.516237 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:19:12.294761 139966923982656 submission_runner.py:408] Time since start: 668.71s, 	Step: 812, 	{'train/accuracy': 0.986688494682312, 'train/loss': 0.12248104810714722, 'train/mean_average_precision': 0.02750603040144635, 'validation/accuracy': 0.9839299917221069, 'validation/loss': 0.1292034238576889, 'validation/mean_average_precision': 0.02771898750607727, 'validation/num_examples': 43793, 'test/accuracy': 0.9828940033912659, 'test/loss': 0.13195043802261353, 'test/mean_average_precision': 0.028677714295364674, 'test/num_examples': 43793, 'score': 259.4525671005249, 'total_duration': 668.7071697711945, 'accumulated_submission_time': 259.4525671005249, 'accumulated_eval_time': 409.20367765426636, 'accumulated_logging_time': 0.030760526657104492}
I0215 12:19:12.309724 139799216477952 logging_writer.py:48] [812] accumulated_eval_time=409.203678, accumulated_logging_time=0.030761, accumulated_submission_time=259.452567, global_step=812, preemption_count=0, score=259.452567, test/accuracy=0.982894, test/loss=0.131950, test/mean_average_precision=0.028678, test/num_examples=43793, total_duration=668.707170, train/accuracy=0.986688, train/loss=0.122481, train/mean_average_precision=0.027506, validation/accuracy=0.983930, validation/loss=0.129203, validation/mean_average_precision=0.027719, validation/num_examples=43793
I0215 12:20:07.868148 139799607949056 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.05629435181617737, loss=0.08805404603481293
I0215 12:22:35.803235 139799216477952 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.01561114750802517, loss=0.052759818732738495
I0215 12:23:12.391522 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:25:01.514709 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:25:04.385206 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:25:07.217526 139966923982656 submission_runner.py:408] Time since start: 1023.63s, 	Step: 1625, 	{'train/accuracy': 0.9867749214172363, 'train/loss': 0.05773906409740448, 'train/mean_average_precision': 0.031329471085523676, 'validation/accuracy': 0.9841179251670837, 'validation/loss': 0.06707639247179031, 'validation/mean_average_precision': 0.03095288530747215, 'validation/num_examples': 43793, 'test/accuracy': 0.983142077922821, 'test/loss': 0.07025604695081711, 'test/mean_average_precision': 0.033129887382684735, 'test/num_examples': 43793, 'score': 499.5041480064392, 'total_duration': 1023.6299650669098, 'accumulated_submission_time': 499.5041480064392, 'accumulated_eval_time': 524.0296378135681, 'accumulated_logging_time': 0.05606341361999512}
I0215 12:25:07.232943 139799591163648 logging_writer.py:48] [1625] accumulated_eval_time=524.029638, accumulated_logging_time=0.056063, accumulated_submission_time=499.504148, global_step=1625, preemption_count=0, score=499.504148, test/accuracy=0.983142, test/loss=0.070256, test/mean_average_precision=0.033130, test/num_examples=43793, total_duration=1023.629965, train/accuracy=0.986775, train/loss=0.057739, train/mean_average_precision=0.031329, validation/accuracy=0.984118, validation/loss=0.067076, validation/mean_average_precision=0.030953, validation/num_examples=43793
I0215 12:27:06.284961 139799599556352 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.010038520209491253, loss=0.06512261927127838
I0215 12:29:07.497460 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:30:56.773815 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:30:59.953678 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:31:03.066471 139966923982656 submission_runner.py:408] Time since start: 1379.48s, 	Step: 2405, 	{'train/accuracy': 0.9867736101150513, 'train/loss': 0.05535279959440231, 'train/mean_average_precision': 0.035655890236070215, 'validation/accuracy': 0.9841179251670837, 'validation/loss': 0.06524951756000519, 'validation/mean_average_precision': 0.03342550755470287, 'validation/num_examples': 43793, 'test/accuracy': 0.983142077922821, 'test/loss': 0.06860329955816269, 'test/mean_average_precision': 0.035376559349092354, 'test/num_examples': 43793, 'score': 739.7390007972717, 'total_duration': 1379.478887796402, 'accumulated_submission_time': 739.7390007972717, 'accumulated_eval_time': 639.5985925197601, 'accumulated_logging_time': 0.08169317245483398}
I0215 12:31:03.084150 139799582770944 logging_writer.py:48] [2405] accumulated_eval_time=639.598593, accumulated_logging_time=0.081693, accumulated_submission_time=739.739001, global_step=2405, preemption_count=0, score=739.739001, test/accuracy=0.983142, test/loss=0.068603, test/mean_average_precision=0.035377, test/num_examples=43793, total_duration=1379.478888, train/accuracy=0.986774, train/loss=0.055353, train/mean_average_precision=0.035656, validation/accuracy=0.984118, validation/loss=0.065250, validation/mean_average_precision=0.033426, validation/num_examples=43793
I0215 12:31:31.108388 139799607949056 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.01113671064376831, loss=0.051414214074611664
I0215 12:33:57.479678 139799582770944 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.05966806784272194, loss=0.04943205788731575
I0215 12:35:03.201873 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:36:58.906814 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:37:02.024605 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:37:05.230355 139966923982656 submission_runner.py:408] Time since start: 1741.64s, 	Step: 3226, 	{'train/accuracy': 0.9868510365486145, 'train/loss': 0.0520760603249073, 'train/mean_average_precision': 0.04524206544861335, 'validation/accuracy': 0.984256386756897, 'validation/loss': 0.06116614118218422, 'validation/mean_average_precision': 0.04835399943379553, 'validation/num_examples': 43793, 'test/accuracy': 0.9832292795181274, 'test/loss': 0.06427371501922607, 'test/mean_average_precision': 0.05036697216385039, 'test/num_examples': 43793, 'score': 979.8202588558197, 'total_duration': 1741.642778635025, 'accumulated_submission_time': 979.8202588558197, 'accumulated_eval_time': 761.6270353794098, 'accumulated_logging_time': 0.11043119430541992}
I0215 12:37:05.247688 139799224870656 logging_writer.py:48] [3226] accumulated_eval_time=761.627035, accumulated_logging_time=0.110431, accumulated_submission_time=979.820259, global_step=3226, preemption_count=0, score=979.820259, test/accuracy=0.983229, test/loss=0.064274, test/mean_average_precision=0.050367, test/num_examples=43793, total_duration=1741.642779, train/accuracy=0.986851, train/loss=0.052076, train/mean_average_precision=0.045242, validation/accuracy=0.984256, validation/loss=0.061166, validation/mean_average_precision=0.048354, validation/num_examples=43793
I0215 12:38:26.242618 139799599556352 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.0854760929942131, loss=0.04391524940729141
I0215 12:40:52.238757 139799224870656 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.08600068092346191, loss=0.05479498580098152
I0215 12:41:05.233076 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:42:56.221015 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:42:59.322508 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:43:02.264007 139966923982656 submission_runner.py:408] Time since start: 2098.68s, 	Step: 4045, 	{'train/accuracy': 0.9872231483459473, 'train/loss': 0.04754548892378807, 'train/mean_average_precision': 0.08638442899440588, 'validation/accuracy': 0.9845835566520691, 'validation/loss': 0.05689027160406113, 'validation/mean_average_precision': 0.08554132287431046, 'validation/num_examples': 43793, 'test/accuracy': 0.9836074709892273, 'test/loss': 0.06014932319521904, 'test/mean_average_precision': 0.08913040562576426, 'test/num_examples': 43793, 'score': 1219.7688448429108, 'total_duration': 2098.676433801651, 'accumulated_submission_time': 1219.7688448429108, 'accumulated_eval_time': 878.657918214798, 'accumulated_logging_time': 0.13998150825500488}
I0215 12:43:02.280274 139799591163648 logging_writer.py:48] [4045] accumulated_eval_time=878.657918, accumulated_logging_time=0.139982, accumulated_submission_time=1219.768845, global_step=4045, preemption_count=0, score=1219.768845, test/accuracy=0.983607, test/loss=0.060149, test/mean_average_precision=0.089130, test/num_examples=43793, total_duration=2098.676434, train/accuracy=0.987223, train/loss=0.047545, train/mean_average_precision=0.086384, validation/accuracy=0.984584, validation/loss=0.056890, validation/mean_average_precision=0.085541, validation/num_examples=43793
I0215 12:45:18.056128 139799607949056 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.04014839231967926, loss=0.044737089425325394
I0215 12:47:02.484792 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:48:54.673846 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:48:57.616425 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:49:00.485333 139966923982656 submission_runner.py:408] Time since start: 2456.90s, 	Step: 4854, 	{'train/accuracy': 0.9876218438148499, 'train/loss': 0.0448886938393116, 'train/mean_average_precision': 0.11546495425643877, 'validation/accuracy': 0.9848859906196594, 'validation/loss': 0.05425715446472168, 'validation/mean_average_precision': 0.11801370400965205, 'validation/num_examples': 43793, 'test/accuracy': 0.9839174747467041, 'test/loss': 0.05742313340306282, 'test/mean_average_precision': 0.11541597881688358, 'test/num_examples': 43793, 'score': 1459.9423220157623, 'total_duration': 2456.897770166397, 'accumulated_submission_time': 1459.9423220157623, 'accumulated_eval_time': 996.6584203243256, 'accumulated_logging_time': 0.1666727066040039}
I0215 12:49:00.500819 139799616341760 logging_writer.py:48] [4854] accumulated_eval_time=996.658420, accumulated_logging_time=0.166673, accumulated_submission_time=1459.942322, global_step=4854, preemption_count=0, score=1459.942322, test/accuracy=0.983917, test/loss=0.057423, test/mean_average_precision=0.115416, test/num_examples=43793, total_duration=2456.897770, train/accuracy=0.987622, train/loss=0.044889, train/mean_average_precision=0.115465, validation/accuracy=0.984886, validation/loss=0.054257, validation/mean_average_precision=0.118014, validation/num_examples=43793
I0215 12:49:43.549793 139904633779968 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.0880112424492836, loss=0.042377766221761703
I0215 12:52:09.885232 139799616341760 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.07298322767019272, loss=0.045023735612630844
I0215 12:53:00.490891 139966923982656 spec.py:321] Evaluating on the training split.
I0215 12:54:54.936435 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 12:54:57.863224 139966923982656 spec.py:349] Evaluating on the test split.
I0215 12:55:00.734050 139966923982656 submission_runner.py:408] Time since start: 2817.15s, 	Step: 5674, 	{'train/accuracy': 0.9878240823745728, 'train/loss': 0.04323236644268036, 'train/mean_average_precision': 0.14374011980927554, 'validation/accuracy': 0.985043466091156, 'validation/loss': 0.052253272384405136, 'validation/mean_average_precision': 0.13732479338899667, 'validation/num_examples': 43793, 'test/accuracy': 0.9841259717941284, 'test/loss': 0.054881494492292404, 'test/mean_average_precision': 0.1412263903795737, 'test/num_examples': 43793, 'score': 1699.902087688446, 'total_duration': 2817.1464829444885, 'accumulated_submission_time': 1699.902087688446, 'accumulated_eval_time': 1116.9015319347382, 'accumulated_logging_time': 0.19225692749023438}
I0215 12:55:00.751412 139806048024320 logging_writer.py:48] [5674] accumulated_eval_time=1116.901532, accumulated_logging_time=0.192257, accumulated_submission_time=1699.902088, global_step=5674, preemption_count=0, score=1699.902088, test/accuracy=0.984126, test/loss=0.054881, test/mean_average_precision=0.141226, test/num_examples=43793, total_duration=2817.146483, train/accuracy=0.987824, train/loss=0.043232, train/mean_average_precision=0.143740, validation/accuracy=0.985043, validation/loss=0.052253, validation/mean_average_precision=0.137325, validation/num_examples=43793
I0215 12:56:35.769415 139806056417024 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.05288294330239296, loss=0.04339536279439926
I0215 12:59:00.862091 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:00:54.923034 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:00:57.859004 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:01:00.760653 139966923982656 submission_runner.py:408] Time since start: 3177.17s, 	Step: 6497, 	{'train/accuracy': 0.9882999062538147, 'train/loss': 0.04093027487397194, 'train/mean_average_precision': 0.1771145461969626, 'validation/accuracy': 0.9853739142417908, 'validation/loss': 0.05066031962633133, 'validation/mean_average_precision': 0.15778203761557613, 'validation/num_examples': 43793, 'test/accuracy': 0.9843774437904358, 'test/loss': 0.05358709394931793, 'test/mean_average_precision': 0.1573734508817491, 'test/num_examples': 43793, 'score': 1939.9818263053894, 'total_duration': 3177.173084974289, 'accumulated_submission_time': 1939.9818263053894, 'accumulated_eval_time': 1236.8000538349152, 'accumulated_logging_time': 0.21960043907165527}
I0215 13:01:00.776871 139904633779968 logging_writer.py:48] [6497] accumulated_eval_time=1236.800054, accumulated_logging_time=0.219600, accumulated_submission_time=1939.981826, global_step=6497, preemption_count=0, score=1939.981826, test/accuracy=0.984377, test/loss=0.053587, test/mean_average_precision=0.157373, test/num_examples=43793, total_duration=3177.173085, train/accuracy=0.988300, train/loss=0.040930, train/mean_average_precision=0.177115, validation/accuracy=0.985374, validation/loss=0.050660, validation/mean_average_precision=0.157782, validation/num_examples=43793
I0215 13:01:02.029921 139904642172672 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.04192698746919632, loss=0.04295504093170166
I0215 13:03:29.125497 139904633779968 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.06881093978881836, loss=0.041218824684619904
I0215 13:05:00.941039 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:06:55.655065 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:06:58.651626 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:07:01.620957 139966923982656 submission_runner.py:408] Time since start: 3538.03s, 	Step: 7309, 	{'train/accuracy': 0.9885411858558655, 'train/loss': 0.03985226899385452, 'train/mean_average_precision': 0.19027161630262526, 'validation/accuracy': 0.9855537414550781, 'validation/loss': 0.04931538179516792, 'validation/mean_average_precision': 0.17260613083797913, 'validation/num_examples': 43793, 'test/accuracy': 0.9846149682998657, 'test/loss': 0.051854778081178665, 'test/mean_average_precision': 0.17889229812943744, 'test/num_examples': 43793, 'score': 2180.115610599518, 'total_duration': 3538.0333960056305, 'accumulated_submission_time': 2180.115610599518, 'accumulated_eval_time': 1357.4799344539642, 'accumulated_logging_time': 0.24556255340576172}
I0215 13:07:01.637028 139806048024320 logging_writer.py:48] [7309] accumulated_eval_time=1357.479934, accumulated_logging_time=0.245563, accumulated_submission_time=2180.115611, global_step=7309, preemption_count=0, score=2180.115611, test/accuracy=0.984615, test/loss=0.051855, test/mean_average_precision=0.178892, test/num_examples=43793, total_duration=3538.033396, train/accuracy=0.988541, train/loss=0.039852, train/mean_average_precision=0.190272, validation/accuracy=0.985554, validation/loss=0.049315, validation/mean_average_precision=0.172606, validation/num_examples=43793
I0215 13:07:58.876420 139806056417024 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.0659174993634224, loss=0.04602719470858574
I0215 13:10:26.258448 139806048024320 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.048021260648965836, loss=0.03703723102807999
I0215 13:11:01.838420 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:12:54.849090 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:12:57.742441 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:13:00.598995 139966923982656 submission_runner.py:408] Time since start: 3897.01s, 	Step: 8122, 	{'train/accuracy': 0.9885822534561157, 'train/loss': 0.0391816683113575, 'train/mean_average_precision': 0.21031830855263287, 'validation/accuracy': 0.9856284260749817, 'validation/loss': 0.04869327321648598, 'validation/mean_average_precision': 0.19181989493822094, 'validation/num_examples': 43793, 'test/accuracy': 0.9847168922424316, 'test/loss': 0.05128267779946327, 'test/mean_average_precision': 0.18740903411467835, 'test/num_examples': 43793, 'score': 2420.286457300186, 'total_duration': 3897.0114035606384, 'accumulated_submission_time': 2420.286457300186, 'accumulated_eval_time': 1476.2404344081879, 'accumulated_logging_time': 0.2720458507537842}
I0215 13:13:00.619360 139799624734464 logging_writer.py:48] [8122] accumulated_eval_time=1476.240434, accumulated_logging_time=0.272046, accumulated_submission_time=2420.286457, global_step=8122, preemption_count=0, score=2420.286457, test/accuracy=0.984717, test/loss=0.051283, test/mean_average_precision=0.187409, test/num_examples=43793, total_duration=3897.011404, train/accuracy=0.988582, train/loss=0.039182, train/mean_average_precision=0.210318, validation/accuracy=0.985628, validation/loss=0.048693, validation/mean_average_precision=0.191820, validation/num_examples=43793
I0215 13:14:53.589239 139904633779968 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.04104360565543175, loss=0.03829998895525932
I0215 13:17:00.659144 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:18:54.687956 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:18:57.663438 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:19:00.566525 139966923982656 submission_runner.py:408] Time since start: 4256.98s, 	Step: 8929, 	{'train/accuracy': 0.9887849688529968, 'train/loss': 0.038370873779058456, 'train/mean_average_precision': 0.21808191701822913, 'validation/accuracy': 0.9857993125915527, 'validation/loss': 0.04799116775393486, 'validation/mean_average_precision': 0.19991889967266255, 'validation/num_examples': 43793, 'test/accuracy': 0.9849056005477905, 'test/loss': 0.050656020641326904, 'test/mean_average_precision': 0.19460340921404795, 'test/num_examples': 43793, 'score': 2660.294540166855, 'total_duration': 4256.978956699371, 'accumulated_submission_time': 2660.294540166855, 'accumulated_eval_time': 1596.1477723121643, 'accumulated_logging_time': 0.3037993907928467}
I0215 13:19:00.582390 139806056417024 logging_writer.py:48] [8929] accumulated_eval_time=1596.147772, accumulated_logging_time=0.303799, accumulated_submission_time=2660.294540, global_step=8929, preemption_count=0, score=2660.294540, test/accuracy=0.984906, test/loss=0.050656, test/mean_average_precision=0.194603, test/num_examples=43793, total_duration=4256.978957, train/accuracy=0.988785, train/loss=0.038371, train/mean_average_precision=0.218082, validation/accuracy=0.985799, validation/loss=0.047991, validation/mean_average_precision=0.199919, validation/num_examples=43793
I0215 13:19:22.250718 139904642172672 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.04717634618282318, loss=0.044016819447278976
I0215 13:21:51.230458 139806056417024 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.029667655006051064, loss=0.03839491680264473
I0215 13:23:00.595848 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:24:54.434631 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:24:57.421176 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:25:00.337613 139966923982656 submission_runner.py:408] Time since start: 4616.75s, 	Step: 9733, 	{'train/accuracy': 0.9889710545539856, 'train/loss': 0.037631433457136154, 'train/mean_average_precision': 0.226781729507266, 'validation/accuracy': 0.9859166741371155, 'validation/loss': 0.047313857823610306, 'validation/mean_average_precision': 0.20014143431840245, 'validation/num_examples': 43793, 'test/accuracy': 0.9850319623947144, 'test/loss': 0.05004492774605751, 'test/mean_average_precision': 0.20285669880780588, 'test/num_examples': 43793, 'score': 2900.2773122787476, 'total_duration': 4616.750051021576, 'accumulated_submission_time': 2900.2773122787476, 'accumulated_eval_time': 1715.8894956111908, 'accumulated_logging_time': 0.32991838455200195}
I0215 13:25:00.354086 139806048024320 logging_writer.py:48] [9733] accumulated_eval_time=1715.889496, accumulated_logging_time=0.329918, accumulated_submission_time=2900.277312, global_step=9733, preemption_count=0, score=2900.277312, test/accuracy=0.985032, test/loss=0.050045, test/mean_average_precision=0.202857, test/num_examples=43793, total_duration=4616.750051, train/accuracy=0.988971, train/loss=0.037631, train/mean_average_precision=0.226782, validation/accuracy=0.985917, validation/loss=0.047314, validation/mean_average_precision=0.200141, validation/num_examples=43793
I0215 13:26:20.401333 139904633779968 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.032656390219926834, loss=0.0356564074754715
I0215 13:28:50.357295 139806048024320 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.032360829412937164, loss=0.04009196162223816
I0215 13:29:00.466989 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:30:52.803225 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:30:55.765249 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:30:58.628028 139966923982656 submission_runner.py:408] Time since start: 4975.04s, 	Step: 10535, 	{'train/accuracy': 0.9891827702522278, 'train/loss': 0.03695739060640335, 'train/mean_average_precision': 0.26241999960353013, 'validation/accuracy': 0.9860400557518005, 'validation/loss': 0.04695615917444229, 'validation/mean_average_precision': 0.21661746215187952, 'validation/num_examples': 43793, 'test/accuracy': 0.9851511716842651, 'test/loss': 0.04964252561330795, 'test/mean_average_precision': 0.20986765577995567, 'test/num_examples': 43793, 'score': 3140.355771303177, 'total_duration': 4975.040405511856, 'accumulated_submission_time': 3140.355771303177, 'accumulated_eval_time': 1834.0504338741302, 'accumulated_logging_time': 0.3601968288421631}
I0215 13:30:58.643942 139799624734464 logging_writer.py:48] [10535] accumulated_eval_time=1834.050434, accumulated_logging_time=0.360197, accumulated_submission_time=3140.355771, global_step=10535, preemption_count=0, score=3140.355771, test/accuracy=0.985151, test/loss=0.049643, test/mean_average_precision=0.209868, test/num_examples=43793, total_duration=4975.040406, train/accuracy=0.989183, train/loss=0.036957, train/mean_average_precision=0.262420, validation/accuracy=0.986040, validation/loss=0.046956, validation/mean_average_precision=0.216617, validation/num_examples=43793
I0215 13:33:18.120021 139806056417024 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.038687024265527725, loss=0.035058971494436264
I0215 13:34:58.800177 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:36:54.699738 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:36:57.631958 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:37:00.520375 139966923982656 submission_runner.py:408] Time since start: 5336.93s, 	Step: 11339, 	{'train/accuracy': 0.9892692565917969, 'train/loss': 0.036318596452474594, 'train/mean_average_precision': 0.265456507051378, 'validation/accuracy': 0.9861407279968262, 'validation/loss': 0.04664755240082741, 'validation/mean_average_precision': 0.21757290624002315, 'validation/num_examples': 43793, 'test/accuracy': 0.9852438569068909, 'test/loss': 0.049395035952329636, 'test/mean_average_precision': 0.21484294849309607, 'test/num_examples': 43793, 'score': 3380.4808537960052, 'total_duration': 5336.932815074921, 'accumulated_submission_time': 3380.4808537960052, 'accumulated_eval_time': 1955.7705969810486, 'accumulated_logging_time': 0.38653016090393066}
I0215 13:37:00.536625 139806048024320 logging_writer.py:48] [11339] accumulated_eval_time=1955.770597, accumulated_logging_time=0.386530, accumulated_submission_time=3380.480854, global_step=11339, preemption_count=0, score=3380.480854, test/accuracy=0.985244, test/loss=0.049395, test/mean_average_precision=0.214843, test/num_examples=43793, total_duration=5336.932815, train/accuracy=0.989269, train/loss=0.036319, train/mean_average_precision=0.265457, validation/accuracy=0.986141, validation/loss=0.046648, validation/mean_average_precision=0.217573, validation/num_examples=43793
I0215 13:37:47.989501 139904633779968 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.03804638981819153, loss=0.03970186784863472
I0215 13:40:15.466182 139806048024320 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.043869949877262115, loss=0.038465991616249084
I0215 13:41:00.794781 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:42:54.624543 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:42:57.532397 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:43:00.353353 139966923982656 submission_runner.py:408] Time since start: 5696.77s, 	Step: 12156, 	{'train/accuracy': 0.989429235458374, 'train/loss': 0.03587840870022774, 'train/mean_average_precision': 0.28034609122530857, 'validation/accuracy': 0.9861833453178406, 'validation/loss': 0.046157948672771454, 'validation/mean_average_precision': 0.22859804131391764, 'validation/num_examples': 43793, 'test/accuracy': 0.9852661490440369, 'test/loss': 0.04894324764609337, 'test/mean_average_precision': 0.22391472256516748, 'test/num_examples': 43793, 'score': 3620.7080216407776, 'total_duration': 5696.765793085098, 'accumulated_submission_time': 3620.7080216407776, 'accumulated_eval_time': 2075.329130411148, 'accumulated_logging_time': 0.41293811798095703}
I0215 13:43:00.370147 139798177978112 logging_writer.py:48] [12156] accumulated_eval_time=2075.329130, accumulated_logging_time=0.412938, accumulated_submission_time=3620.708022, global_step=12156, preemption_count=0, score=3620.708022, test/accuracy=0.985266, test/loss=0.048943, test/mean_average_precision=0.223915, test/num_examples=43793, total_duration=5696.765793, train/accuracy=0.989429, train/loss=0.035878, train/mean_average_precision=0.280346, validation/accuracy=0.986183, validation/loss=0.046158, validation/mean_average_precision=0.228598, validation/num_examples=43793
I0215 13:44:42.147759 139806056417024 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.044129762798547745, loss=0.03871697187423706
I0215 13:47:00.453371 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:48:50.484551 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:48:53.397139 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:48:56.266778 139966923982656 submission_runner.py:408] Time since start: 6052.68s, 	Step: 12968, 	{'train/accuracy': 0.9894845485687256, 'train/loss': 0.035418786108493805, 'train/mean_average_precision': 0.2879518361699949, 'validation/accuracy': 0.9862824082374573, 'validation/loss': 0.045907240360975266, 'validation/mean_average_precision': 0.23091269995786512, 'validation/num_examples': 43793, 'test/accuracy': 0.9854333400726318, 'test/loss': 0.04850640520453453, 'test/mean_average_precision': 0.2279723798337183, 'test/num_examples': 43793, 'score': 3860.760322570801, 'total_duration': 6052.679210662842, 'accumulated_submission_time': 3860.760322570801, 'accumulated_eval_time': 2191.142496109009, 'accumulated_logging_time': 0.4399683475494385}
I0215 13:48:56.283092 139806048024320 logging_writer.py:48] [12968] accumulated_eval_time=2191.142496, accumulated_logging_time=0.439968, accumulated_submission_time=3860.760323, global_step=12968, preemption_count=0, score=3860.760323, test/accuracy=0.985433, test/loss=0.048506, test/mean_average_precision=0.227972, test/num_examples=43793, total_duration=6052.679211, train/accuracy=0.989485, train/loss=0.035419, train/mean_average_precision=0.287952, validation/accuracy=0.986282, validation/loss=0.045907, validation/mean_average_precision=0.230913, validation/num_examples=43793
I0215 13:49:06.458391 139904633779968 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.039819929748773575, loss=0.034812603145837784
I0215 13:51:36.070407 139806048024320 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.030154766514897346, loss=0.036341592669487
I0215 13:52:56.383375 139966923982656 spec.py:321] Evaluating on the training split.
I0215 13:54:50.052901 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 13:54:53.150401 139966923982656 spec.py:349] Evaluating on the test split.
I0215 13:54:56.185947 139966923982656 submission_runner.py:408] Time since start: 6412.60s, 	Step: 13766, 	{'train/accuracy': 0.9895428419113159, 'train/loss': 0.03540043905377388, 'train/mean_average_precision': 0.2914965546646352, 'validation/accuracy': 0.9862954020500183, 'validation/loss': 0.04585558548569679, 'validation/mean_average_precision': 0.23306611751806486, 'validation/num_examples': 43793, 'test/accuracy': 0.9854245185852051, 'test/loss': 0.04817903786897659, 'test/mean_average_precision': 0.22677191544154993, 'test/num_examples': 43793, 'score': 4100.829528808594, 'total_duration': 6412.598387718201, 'accumulated_submission_time': 4100.829528808594, 'accumulated_eval_time': 2310.945030450821, 'accumulated_logging_time': 0.466719388961792}
I0215 13:54:56.202428 139806056417024 logging_writer.py:48] [13766] accumulated_eval_time=2310.945030, accumulated_logging_time=0.466719, accumulated_submission_time=4100.829529, global_step=13766, preemption_count=0, score=4100.829529, test/accuracy=0.985425, test/loss=0.048179, test/mean_average_precision=0.226772, test/num_examples=43793, total_duration=6412.598388, train/accuracy=0.989543, train/loss=0.035400, train/mean_average_precision=0.291497, validation/accuracy=0.986295, validation/loss=0.045856, validation/mean_average_precision=0.233066, validation/num_examples=43793
I0215 13:56:06.978684 139904642172672 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.03376975283026695, loss=0.03492546081542969
I0215 13:58:36.034477 139806056417024 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.03230433538556099, loss=0.032064829021692276
I0215 13:58:56.311542 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:00:49.319896 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:00:52.242827 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:00:55.103280 139966923982656 submission_runner.py:408] Time since start: 6771.52s, 	Step: 14569, 	{'train/accuracy': 0.9897654056549072, 'train/loss': 0.03436538204550743, 'train/mean_average_precision': 0.30466631071288325, 'validation/accuracy': 0.986381471157074, 'validation/loss': 0.04537307098507881, 'validation/mean_average_precision': 0.2393889000678359, 'validation/num_examples': 43793, 'test/accuracy': 0.9855656027793884, 'test/loss': 0.048058606684207916, 'test/mean_average_precision': 0.23099490841367776, 'test/num_examples': 43793, 'score': 4340.907742738724, 'total_duration': 6771.515719175339, 'accumulated_submission_time': 4340.907742738724, 'accumulated_eval_time': 2429.73672413826, 'accumulated_logging_time': 0.4936976432800293}
I0215 14:00:55.119780 139797635151616 logging_writer.py:48] [14569] accumulated_eval_time=2429.736724, accumulated_logging_time=0.493698, accumulated_submission_time=4340.907743, global_step=14569, preemption_count=0, score=4340.907743, test/accuracy=0.985566, test/loss=0.048059, test/mean_average_precision=0.230995, test/num_examples=43793, total_duration=6771.515719, train/accuracy=0.989765, train/loss=0.034365, train/mean_average_precision=0.304666, validation/accuracy=0.986381, validation/loss=0.045373, validation/mean_average_precision=0.239389, validation/num_examples=43793
I0215 14:03:03.332918 139806048024320 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.024919448420405388, loss=0.029315199702978134
I0215 14:04:55.242162 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:06:46.557198 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:06:49.419533 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:06:52.302567 139966923982656 submission_runner.py:408] Time since start: 7128.71s, 	Step: 15376, 	{'train/accuracy': 0.9898204803466797, 'train/loss': 0.03410983458161354, 'train/mean_average_precision': 0.3179693093784152, 'validation/accuracy': 0.9863494038581848, 'validation/loss': 0.045159485191106796, 'validation/mean_average_precision': 0.24178942115995597, 'validation/num_examples': 43793, 'test/accuracy': 0.9855290055274963, 'test/loss': 0.04780951887369156, 'test/mean_average_precision': 0.23717360011933078, 'test/num_examples': 43793, 'score': 4580.998894929886, 'total_duration': 7128.714997291565, 'accumulated_submission_time': 4580.998894929886, 'accumulated_eval_time': 2546.7970888614655, 'accumulated_logging_time': 0.5205397605895996}
I0215 14:06:52.319898 139806056417024 logging_writer.py:48] [15376] accumulated_eval_time=2546.797089, accumulated_logging_time=0.520540, accumulated_submission_time=4580.998895, global_step=15376, preemption_count=0, score=4580.998895, test/accuracy=0.985529, test/loss=0.047810, test/mean_average_precision=0.237174, test/num_examples=43793, total_duration=7128.714997, train/accuracy=0.989820, train/loss=0.034110, train/mean_average_precision=0.317969, validation/accuracy=0.986349, validation/loss=0.045159, validation/mean_average_precision=0.241789, validation/num_examples=43793
I0215 14:07:29.524093 139904633779968 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.03332509472966194, loss=0.03659023717045784
I0215 14:09:57.332211 139806056417024 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.03258679434657097, loss=0.036019209772348404
I0215 14:10:52.411176 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:12:46.472907 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:12:50.079435 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:12:52.964350 139966923982656 submission_runner.py:408] Time since start: 7489.38s, 	Step: 16187, 	{'train/accuracy': 0.9900246262550354, 'train/loss': 0.03348606079816818, 'train/mean_average_precision': 0.3269363686000759, 'validation/accuracy': 0.9865214824676514, 'validation/loss': 0.045325011014938354, 'validation/mean_average_precision': 0.24810808830464015, 'validation/num_examples': 43793, 'test/accuracy': 0.9857648611068726, 'test/loss': 0.047938764095306396, 'test/mean_average_precision': 0.24036100791963058, 'test/num_examples': 43793, 'score': 4821.05975985527, 'total_duration': 7489.376768112183, 'accumulated_submission_time': 4821.05975985527, 'accumulated_eval_time': 2667.3502099514008, 'accumulated_logging_time': 0.5480506420135498}
I0215 14:12:52.982494 139806048024320 logging_writer.py:48] [16187] accumulated_eval_time=2667.350210, accumulated_logging_time=0.548051, accumulated_submission_time=4821.059760, global_step=16187, preemption_count=0, score=4821.059760, test/accuracy=0.985765, test/loss=0.047939, test/mean_average_precision=0.240361, test/num_examples=43793, total_duration=7489.376768, train/accuracy=0.990025, train/loss=0.033486, train/mean_average_precision=0.326936, validation/accuracy=0.986521, validation/loss=0.045325, validation/mean_average_precision=0.248108, validation/num_examples=43793
I0215 14:14:26.508804 139904642172672 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.03673040494322777, loss=0.034122783690690994
I0215 14:16:53.187774 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:18:44.076319 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:18:46.970634 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:18:49.804667 139966923982656 submission_runner.py:408] Time since start: 7846.22s, 	Step: 16992, 	{'train/accuracy': 0.9900742769241333, 'train/loss': 0.03327163681387901, 'train/mean_average_precision': 0.3445456189051544, 'validation/accuracy': 0.9865637421607971, 'validation/loss': 0.04504217952489853, 'validation/mean_average_precision': 0.24155739383687774, 'validation/num_examples': 43793, 'test/accuracy': 0.9857004284858704, 'test/loss': 0.047561001032590866, 'test/mean_average_precision': 0.24076251324080797, 'test/num_examples': 43793, 'score': 5061.23433971405, 'total_duration': 7846.2171087265015, 'accumulated_submission_time': 5061.23433971405, 'accumulated_eval_time': 2783.9670729637146, 'accumulated_logging_time': 0.5762526988983154}
I0215 14:18:49.821692 139797635151616 logging_writer.py:48] [16992] accumulated_eval_time=2783.967073, accumulated_logging_time=0.576253, accumulated_submission_time=5061.234340, global_step=16992, preemption_count=0, score=5061.234340, test/accuracy=0.985700, test/loss=0.047561, test/mean_average_precision=0.240763, test/num_examples=43793, total_duration=7846.217109, train/accuracy=0.990074, train/loss=0.033272, train/mean_average_precision=0.344546, validation/accuracy=0.986564, validation/loss=0.045042, validation/mean_average_precision=0.241557, validation/num_examples=43793
I0215 14:18:52.504795 139904633779968 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.040181972086429596, loss=0.036216773092746735
I0215 14:21:20.399153 139797635151616 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.03620324283838272, loss=0.03688633069396019
I0215 14:22:49.934180 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:24:42.901180 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:24:45.835320 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:24:48.713072 139966923982656 submission_runner.py:408] Time since start: 8205.13s, 	Step: 17801, 	{'train/accuracy': 0.9900335669517517, 'train/loss': 0.03330467268824577, 'train/mean_average_precision': 0.3374570451025274, 'validation/accuracy': 0.9866286516189575, 'validation/loss': 0.04511040076613426, 'validation/mean_average_precision': 0.25338644999994203, 'validation/num_examples': 43793, 'test/accuracy': 0.9858006238937378, 'test/loss': 0.04767586290836334, 'test/mean_average_precision': 0.24528595571451142, 'test/num_examples': 43793, 'score': 5301.316188812256, 'total_duration': 8205.125508069992, 'accumulated_submission_time': 5301.316188812256, 'accumulated_eval_time': 2902.7459239959717, 'accumulated_logging_time': 0.6034753322601318}
I0215 14:24:48.730544 139806056417024 logging_writer.py:48] [17801] accumulated_eval_time=2902.745924, accumulated_logging_time=0.603475, accumulated_submission_time=5301.316189, global_step=17801, preemption_count=0, score=5301.316189, test/accuracy=0.985801, test/loss=0.047676, test/mean_average_precision=0.245286, test/num_examples=43793, total_duration=8205.125508, train/accuracy=0.990034, train/loss=0.033305, train/mean_average_precision=0.337457, validation/accuracy=0.986629, validation/loss=0.045110, validation/mean_average_precision=0.253386, validation/num_examples=43793
I0215 14:25:48.553037 139904642172672 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.03739425167441368, loss=0.03347752243280411
I0215 14:28:19.035612 139806056417024 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.041112978011369705, loss=0.036775216460227966
I0215 14:28:48.965283 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:30:39.084196 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:30:42.025119 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:30:44.885390 139966923982656 submission_runner.py:408] Time since start: 8561.30s, 	Step: 18599, 	{'train/accuracy': 0.9902493357658386, 'train/loss': 0.032605305314064026, 'train/mean_average_precision': 0.35363536517197114, 'validation/accuracy': 0.9867119193077087, 'validation/loss': 0.04457935690879822, 'validation/mean_average_precision': 0.25751828092768475, 'validation/num_examples': 43793, 'test/accuracy': 0.9858478307723999, 'test/loss': 0.04730139672756195, 'test/mean_average_precision': 0.24531509094569984, 'test/num_examples': 43793, 'score': 5541.519265174866, 'total_duration': 8561.297830581665, 'accumulated_submission_time': 5541.519265174866, 'accumulated_eval_time': 3018.665987968445, 'accumulated_logging_time': 0.6323001384735107}
I0215 14:30:44.902380 139806048024320 logging_writer.py:48] [18599] accumulated_eval_time=3018.665988, accumulated_logging_time=0.632300, accumulated_submission_time=5541.519265, global_step=18599, preemption_count=0, score=5541.519265, test/accuracy=0.985848, test/loss=0.047301, test/mean_average_precision=0.245315, test/num_examples=43793, total_duration=8561.297831, train/accuracy=0.990249, train/loss=0.032605, train/mean_average_precision=0.353635, validation/accuracy=0.986712, validation/loss=0.044579, validation/mean_average_precision=0.257518, validation/num_examples=43793
I0215 14:32:44.455836 139904633779968 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.034302469342947006, loss=0.03495747968554497
I0215 14:34:44.979783 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:36:37.031781 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:36:39.926527 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:36:42.810535 139966923982656 submission_runner.py:408] Time since start: 8919.22s, 	Step: 19409, 	{'train/accuracy': 0.9903755187988281, 'train/loss': 0.03200766071677208, 'train/mean_average_precision': 0.3538674814637105, 'validation/accuracy': 0.9866676330566406, 'validation/loss': 0.044572941958904266, 'validation/mean_average_precision': 0.2566782032295166, 'validation/num_examples': 43793, 'test/accuracy': 0.9858659505844116, 'test/loss': 0.047258954495191574, 'test/mean_average_precision': 0.24414256673950557, 'test/num_examples': 43793, 'score': 5781.565552711487, 'total_duration': 8919.22297334671, 'accumulated_submission_time': 5781.565552711487, 'accumulated_eval_time': 3136.4967041015625, 'accumulated_logging_time': 0.6596133708953857}
I0215 14:36:42.828221 139806056417024 logging_writer.py:48] [19409] accumulated_eval_time=3136.496704, accumulated_logging_time=0.659613, accumulated_submission_time=5781.565553, global_step=19409, preemption_count=0, score=5781.565553, test/accuracy=0.985866, test/loss=0.047259, test/mean_average_precision=0.244143, test/num_examples=43793, total_duration=8919.222973, train/accuracy=0.990376, train/loss=0.032008, train/mean_average_precision=0.353867, validation/accuracy=0.986668, validation/loss=0.044573, validation/mean_average_precision=0.256678, validation/num_examples=43793
I0215 14:37:10.542028 139904642172672 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.035982225090265274, loss=0.03407391905784607
I0215 14:39:38.339381 139806056417024 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.0395745225250721, loss=0.04033295810222626
I0215 14:40:42.872321 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:42:33.160887 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:42:36.068933 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:42:38.881697 139966923982656 submission_runner.py:408] Time since start: 9275.29s, 	Step: 20219, 	{'train/accuracy': 0.9905173778533936, 'train/loss': 0.03172795847058296, 'train/mean_average_precision': 0.37577506434043795, 'validation/accuracy': 0.9867187738418579, 'validation/loss': 0.044347889721393585, 'validation/mean_average_precision': 0.26126878191316366, 'validation/num_examples': 43793, 'test/accuracy': 0.9858967065811157, 'test/loss': 0.04698492959141731, 'test/mean_average_precision': 0.2507108852284147, 'test/num_examples': 43793, 'score': 6021.578060865402, 'total_duration': 9275.294137239456, 'accumulated_submission_time': 6021.578060865402, 'accumulated_eval_time': 3252.50604057312, 'accumulated_logging_time': 0.6888718605041504}
I0215 14:42:38.899982 139806048024320 logging_writer.py:48] [20219] accumulated_eval_time=3252.506041, accumulated_logging_time=0.688872, accumulated_submission_time=6021.578061, global_step=20219, preemption_count=0, score=6021.578061, test/accuracy=0.985897, test/loss=0.046985, test/mean_average_precision=0.250711, test/num_examples=43793, total_duration=9275.294137, train/accuracy=0.990517, train/loss=0.031728, train/mean_average_precision=0.375775, validation/accuracy=0.986719, validation/loss=0.044348, validation/mean_average_precision=0.261269, validation/num_examples=43793
I0215 14:44:01.539638 139904633779968 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.03173012658953667, loss=0.035132113844156265
I0215 14:46:28.839298 139806048024320 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.0271677877753973, loss=0.030788572505116463
I0215 14:46:39.006646 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:48:31.517884 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:48:34.432718 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:48:37.318757 139966923982656 submission_runner.py:408] Time since start: 9633.73s, 	Step: 21036, 	{'train/accuracy': 0.990422248840332, 'train/loss': 0.031691282987594604, 'train/mean_average_precision': 0.39188797776329515, 'validation/accuracy': 0.9866907596588135, 'validation/loss': 0.04435187205672264, 'validation/mean_average_precision': 0.26082665096109553, 'validation/num_examples': 43793, 'test/accuracy': 0.9859160780906677, 'test/loss': 0.046863798052072525, 'test/mean_average_precision': 0.254087313650629, 'test/num_examples': 43793, 'score': 6261.6524839401245, 'total_duration': 9633.73119711876, 'accumulated_submission_time': 6261.6524839401245, 'accumulated_eval_time': 3370.818108558655, 'accumulated_logging_time': 0.7184669971466064}
I0215 14:48:37.336110 139806056417024 logging_writer.py:48] [21036] accumulated_eval_time=3370.818109, accumulated_logging_time=0.718467, accumulated_submission_time=6261.652484, global_step=21036, preemption_count=0, score=6261.652484, test/accuracy=0.985916, test/loss=0.046864, test/mean_average_precision=0.254087, test/num_examples=43793, total_duration=9633.731197, train/accuracy=0.990422, train/loss=0.031691, train/mean_average_precision=0.391888, validation/accuracy=0.986691, validation/loss=0.044352, validation/mean_average_precision=0.260827, validation/num_examples=43793
I0215 14:50:56.318852 139904642172672 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.028667161241173744, loss=0.030040528625249863
I0215 14:52:37.599669 139966923982656 spec.py:321] Evaluating on the training split.
I0215 14:54:33.430675 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 14:54:36.377949 139966923982656 spec.py:349] Evaluating on the test split.
I0215 14:54:39.241245 139966923982656 submission_runner.py:408] Time since start: 9995.65s, 	Step: 21838, 	{'train/accuracy': 0.9906229972839355, 'train/loss': 0.031069735065102577, 'train/mean_average_precision': 0.3855145944649325, 'validation/accuracy': 0.9867740273475647, 'validation/loss': 0.04431076720356941, 'validation/mean_average_precision': 0.25802745119611453, 'validation/num_examples': 43793, 'test/accuracy': 0.9859228134155273, 'test/loss': 0.047091368585824966, 'test/mean_average_precision': 0.249835863245651, 'test/num_examples': 43793, 'score': 6501.885349273682, 'total_duration': 9995.653681278229, 'accumulated_submission_time': 6501.885349273682, 'accumulated_eval_time': 3492.459653377533, 'accumulated_logging_time': 0.7457904815673828}
I0215 14:54:39.258577 139806048024320 logging_writer.py:48] [21838] accumulated_eval_time=3492.459653, accumulated_logging_time=0.745790, accumulated_submission_time=6501.885349, global_step=21838, preemption_count=0, score=6501.885349, test/accuracy=0.985923, test/loss=0.047091, test/mean_average_precision=0.249836, test/num_examples=43793, total_duration=9995.653681, train/accuracy=0.990623, train/loss=0.031070, train/mean_average_precision=0.385515, validation/accuracy=0.986774, validation/loss=0.044311, validation/mean_average_precision=0.258027, validation/num_examples=43793
I0215 14:55:27.390716 139904633779968 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.03417765721678734, loss=0.03388988599181175
I0215 14:57:56.130372 139806048024320 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.029896456748247147, loss=0.031094178557395935
I0215 14:58:39.421988 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:00:31.260885 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:00:34.137497 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:00:36.963994 139966923982656 submission_runner.py:408] Time since start: 10353.38s, 	Step: 22648, 	{'train/accuracy': 0.9905841946601868, 'train/loss': 0.03130149096250534, 'train/mean_average_precision': 0.3790522162902059, 'validation/accuracy': 0.9867504835128784, 'validation/loss': 0.043949104845523834, 'validation/mean_average_precision': 0.2669128302284818, 'validation/num_examples': 43793, 'test/accuracy': 0.9859505891799927, 'test/loss': 0.04667949303984642, 'test/mean_average_precision': 0.25686423406119024, 'test/num_examples': 43793, 'score': 6742.0169196128845, 'total_duration': 10353.376420259476, 'accumulated_submission_time': 6742.0169196128845, 'accumulated_eval_time': 3610.0016040802, 'accumulated_logging_time': 0.7745993137359619}
I0215 15:00:36.982598 139806056417024 logging_writer.py:48] [22648] accumulated_eval_time=3610.001604, accumulated_logging_time=0.774599, accumulated_submission_time=6742.016920, global_step=22648, preemption_count=0, score=6742.016920, test/accuracy=0.985951, test/loss=0.046679, test/mean_average_precision=0.256864, test/num_examples=43793, total_duration=10353.376420, train/accuracy=0.990584, train/loss=0.031301, train/mean_average_precision=0.379052, validation/accuracy=0.986750, validation/loss=0.043949, validation/mean_average_precision=0.266913, validation/num_examples=43793
I0215 15:02:21.877568 139904642172672 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.03140364959836006, loss=0.0317990779876709
I0215 15:04:37.027091 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:06:34.279867 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:06:37.189263 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:06:40.024828 139966923982656 submission_runner.py:408] Time since start: 10716.44s, 	Step: 23452, 	{'train/accuracy': 0.9907667636871338, 'train/loss': 0.03056093491613865, 'train/mean_average_precision': 0.40440791967444173, 'validation/accuracy': 0.9868462681770325, 'validation/loss': 0.043912146240472794, 'validation/mean_average_precision': 0.26993367904816756, 'validation/num_examples': 43793, 'test/accuracy': 0.9860761165618896, 'test/loss': 0.046727124601602554, 'test/mean_average_precision': 0.2576107535043137, 'test/num_examples': 43793, 'score': 6982.030026435852, 'total_duration': 10716.43726348877, 'accumulated_submission_time': 6982.030026435852, 'accumulated_eval_time': 3732.9993028640747, 'accumulated_logging_time': 0.8038833141326904}
I0215 15:06:40.043213 139806048024320 logging_writer.py:48] [23452] accumulated_eval_time=3732.999303, accumulated_logging_time=0.803883, accumulated_submission_time=6982.030026, global_step=23452, preemption_count=0, score=6982.030026, test/accuracy=0.986076, test/loss=0.046727, test/mean_average_precision=0.257611, test/num_examples=43793, total_duration=10716.437263, train/accuracy=0.990767, train/loss=0.030561, train/mean_average_precision=0.404408, validation/accuracy=0.986846, validation/loss=0.043912, validation/mean_average_precision=0.269934, validation/num_examples=43793
I0215 15:06:54.760257 139904633779968 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.028160979971289635, loss=0.032613106071949005
I0215 15:09:23.365471 139806048024320 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.03233092650771141, loss=0.033490024507045746
I0215 15:10:40.155878 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:12:33.926466 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:12:36.868501 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:12:39.744886 139966923982656 submission_runner.py:408] Time since start: 11076.16s, 	Step: 24260, 	{'train/accuracy': 0.9909623265266418, 'train/loss': 0.029766002669930458, 'train/mean_average_precision': 0.41940171796483494, 'validation/accuracy': 0.9868823885917664, 'validation/loss': 0.04384058713912964, 'validation/mean_average_precision': 0.26836681562728504, 'validation/num_examples': 43793, 'test/accuracy': 0.9860853552818298, 'test/loss': 0.04656834900379181, 'test/mean_average_precision': 0.26062431937039815, 'test/num_examples': 43793, 'score': 7222.11169719696, 'total_duration': 11076.157317876816, 'accumulated_submission_time': 7222.11169719696, 'accumulated_eval_time': 3852.588265657425, 'accumulated_logging_time': 0.8326950073242188}
I0215 15:12:39.763087 139797635151616 logging_writer.py:48] [24260] accumulated_eval_time=3852.588266, accumulated_logging_time=0.832695, accumulated_submission_time=7222.111697, global_step=24260, preemption_count=0, score=7222.111697, test/accuracy=0.986085, test/loss=0.046568, test/mean_average_precision=0.260624, test/num_examples=43793, total_duration=11076.157318, train/accuracy=0.990962, train/loss=0.029766, train/mean_average_precision=0.419402, validation/accuracy=0.986882, validation/loss=0.043841, validation/mean_average_precision=0.268367, validation/num_examples=43793
I0215 15:13:51.565148 139904642172672 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.028864748775959015, loss=0.03189196437597275
I0215 15:16:19.710095 139797635151616 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.038331735879182816, loss=0.031650397926568985
I0215 15:16:39.771706 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:18:27.857372 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:18:30.772215 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:18:33.658445 139966923982656 submission_runner.py:408] Time since start: 11430.07s, 	Step: 25069, 	{'train/accuracy': 0.990950882434845, 'train/loss': 0.029953274875879288, 'train/mean_average_precision': 0.4115317897795978, 'validation/accuracy': 0.9869027137756348, 'validation/loss': 0.043803922832012177, 'validation/mean_average_precision': 0.2743862249327082, 'validation/num_examples': 43793, 'test/accuracy': 0.9861119389533997, 'test/loss': 0.0466546006500721, 'test/mean_average_precision': 0.264762448694804, 'test/num_examples': 43793, 'score': 7462.0897653102875, 'total_duration': 11430.070878505707, 'accumulated_submission_time': 7462.0897653102875, 'accumulated_eval_time': 3966.474953651428, 'accumulated_logging_time': 0.8610608577728271}
I0215 15:18:33.676891 139806056417024 logging_writer.py:48] [25069] accumulated_eval_time=3966.474954, accumulated_logging_time=0.861061, accumulated_submission_time=7462.089765, global_step=25069, preemption_count=0, score=7462.089765, test/accuracy=0.986112, test/loss=0.046655, test/mean_average_precision=0.264762, test/num_examples=43793, total_duration=11430.070879, train/accuracy=0.990951, train/loss=0.029953, train/mean_average_precision=0.411532, validation/accuracy=0.986903, validation/loss=0.043804, validation/mean_average_precision=0.274386, validation/num_examples=43793
I0215 15:20:40.380243 139904633779968 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.029454996809363365, loss=0.028991281986236572
I0215 15:22:33.873218 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:24:23.658678 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:24:26.553772 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:24:29.409086 139966923982656 submission_runner.py:408] Time since start: 11785.82s, 	Step: 25886, 	{'train/accuracy': 0.991039514541626, 'train/loss': 0.029489755630493164, 'train/mean_average_precision': 0.44179683320828744, 'validation/accuracy': 0.9868088960647583, 'validation/loss': 0.04370144009590149, 'validation/mean_average_precision': 0.2722742988572569, 'validation/num_examples': 43793, 'test/accuracy': 0.986108124256134, 'test/loss': 0.04627009853720665, 'test/mean_average_precision': 0.2653236445862466, 'test/num_examples': 43793, 'score': 7702.255370616913, 'total_duration': 11785.821524620056, 'accumulated_submission_time': 7702.255370616913, 'accumulated_eval_time': 4082.010786294937, 'accumulated_logging_time': 0.8897280693054199}
I0215 15:24:29.426526 139806048024320 logging_writer.py:48] [25886] accumulated_eval_time=4082.010786, accumulated_logging_time=0.889728, accumulated_submission_time=7702.255371, global_step=25886, preemption_count=0, score=7702.255371, test/accuracy=0.986108, test/loss=0.046270, test/mean_average_precision=0.265324, test/num_examples=43793, total_duration=11785.821525, train/accuracy=0.991040, train/loss=0.029490, train/mean_average_precision=0.441797, validation/accuracy=0.986809, validation/loss=0.043701, validation/mean_average_precision=0.272274, validation/num_examples=43793
I0215 15:25:03.388195 139904642172672 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.031969524919986725, loss=0.03293512016534805
I0215 15:27:31.369738 139806048024320 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.03526606783270836, loss=0.03490646556019783
I0215 15:28:29.423064 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:30:22.327306 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:30:25.223032 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:30:28.055399 139966923982656 submission_runner.py:408] Time since start: 12144.47s, 	Step: 26697, 	{'train/accuracy': 0.9911208748817444, 'train/loss': 0.029216982424259186, 'train/mean_average_precision': 0.42331531350123414, 'validation/accuracy': 0.9868852496147156, 'validation/loss': 0.04372667521238327, 'validation/mean_average_precision': 0.27677687156353764, 'validation/num_examples': 43793, 'test/accuracy': 0.9860908389091492, 'test/loss': 0.04649693891406059, 'test/mean_average_precision': 0.26374389544943055, 'test/num_examples': 43793, 'score': 7942.221064567566, 'total_duration': 12144.46783876419, 'accumulated_submission_time': 7942.221064567566, 'accumulated_eval_time': 4200.643081188202, 'accumulated_logging_time': 0.9173181056976318}
I0215 15:30:28.073670 139797635151616 logging_writer.py:48] [26697] accumulated_eval_time=4200.643081, accumulated_logging_time=0.917318, accumulated_submission_time=7942.221065, global_step=26697, preemption_count=0, score=7942.221065, test/accuracy=0.986091, test/loss=0.046497, test/mean_average_precision=0.263744, test/num_examples=43793, total_duration=12144.467839, train/accuracy=0.991121, train/loss=0.029217, train/mean_average_precision=0.423315, validation/accuracy=0.986885, validation/loss=0.043727, validation/mean_average_precision=0.276777, validation/num_examples=43793
I0215 15:31:59.916346 139904633779968 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.029808789491653442, loss=0.03140363097190857
I0215 15:34:28.222090 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:36:18.397642 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:36:21.327252 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:36:24.227458 139966923982656 submission_runner.py:408] Time since start: 12500.64s, 	Step: 27497, 	{'train/accuracy': 0.9911388158798218, 'train/loss': 0.029260478913784027, 'train/mean_average_precision': 0.43769930355847364, 'validation/accuracy': 0.9868178367614746, 'validation/loss': 0.043730732053518295, 'validation/mean_average_precision': 0.27876411580704547, 'validation/num_examples': 43793, 'test/accuracy': 0.986030638217926, 'test/loss': 0.046461090445518494, 'test/mean_average_precision': 0.2647588595610969, 'test/num_examples': 43793, 'score': 8182.339218378067, 'total_duration': 12500.639820814133, 'accumulated_submission_time': 8182.339218378067, 'accumulated_eval_time': 4316.64834022522, 'accumulated_logging_time': 0.9455633163452148}
I0215 15:36:24.245159 139806056417024 logging_writer.py:48] [27497] accumulated_eval_time=4316.648340, accumulated_logging_time=0.945563, accumulated_submission_time=8182.339218, global_step=27497, preemption_count=0, score=8182.339218, test/accuracy=0.986031, test/loss=0.046461, test/mean_average_precision=0.264759, test/num_examples=43793, total_duration=12500.639821, train/accuracy=0.991139, train/loss=0.029260, train/mean_average_precision=0.437699, validation/accuracy=0.986818, validation/loss=0.043731, validation/mean_average_precision=0.278764, validation/num_examples=43793
I0215 15:36:25.437960 139904642172672 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.0320354588329792, loss=0.029203277081251144
I0215 15:38:53.685449 139806056417024 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.03455037996172905, loss=0.03409132733941078
I0215 15:40:24.229675 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:42:16.921324 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:42:19.782583 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:42:22.636401 139966923982656 submission_runner.py:408] Time since start: 12859.05s, 	Step: 28307, 	{'train/accuracy': 0.9914506077766418, 'train/loss': 0.028327034786343575, 'train/mean_average_precision': 0.452242620813476, 'validation/accuracy': 0.9868357181549072, 'validation/loss': 0.043510861694812775, 'validation/mean_average_precision': 0.27998793861288385, 'validation/num_examples': 43793, 'test/accuracy': 0.9860205054283142, 'test/loss': 0.04633352905511856, 'test/mean_average_precision': 0.26633469470482024, 'test/num_examples': 43793, 'score': 8422.291805744171, 'total_duration': 12859.048772335052, 'accumulated_submission_time': 8422.291805744171, 'accumulated_eval_time': 4435.054961681366, 'accumulated_logging_time': 0.9742684364318848}
I0215 15:42:22.655311 139806048024320 logging_writer.py:48] [28307] accumulated_eval_time=4435.054962, accumulated_logging_time=0.974268, accumulated_submission_time=8422.291806, global_step=28307, preemption_count=0, score=8422.291806, test/accuracy=0.986021, test/loss=0.046334, test/mean_average_precision=0.266335, test/num_examples=43793, total_duration=12859.048772, train/accuracy=0.991451, train/loss=0.028327, train/mean_average_precision=0.452243, validation/accuracy=0.986836, validation/loss=0.043511, validation/mean_average_precision=0.279988, validation/num_examples=43793
I0215 15:43:20.472385 139904633779968 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.030287621542811394, loss=0.02953195758163929
I0215 15:45:48.911962 139806048024320 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.030835457146167755, loss=0.02871560864150524
I0215 15:46:22.847901 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:48:17.184340 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:48:20.429067 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:48:23.593317 139966923982656 submission_runner.py:408] Time since start: 13220.01s, 	Step: 29116, 	{'train/accuracy': 0.9913336634635925, 'train/loss': 0.028675558045506477, 'train/mean_average_precision': 0.45792586088964016, 'validation/accuracy': 0.986702561378479, 'validation/loss': 0.04388319328427315, 'validation/mean_average_precision': 0.27786520909647067, 'validation/num_examples': 43793, 'test/accuracy': 0.9858849048614502, 'test/loss': 0.04656077176332474, 'test/mean_average_precision': 0.2703301182507443, 'test/num_examples': 43793, 'score': 8662.452748060226, 'total_duration': 13220.005733966827, 'accumulated_submission_time': 8662.452748060226, 'accumulated_eval_time': 4555.800324678421, 'accumulated_logging_time': 1.0042052268981934}
I0215 15:48:23.613372 139797635151616 logging_writer.py:48] [29116] accumulated_eval_time=4555.800325, accumulated_logging_time=1.004205, accumulated_submission_time=8662.452748, global_step=29116, preemption_count=0, score=8662.452748, test/accuracy=0.985885, test/loss=0.046561, test/mean_average_precision=0.270330, test/num_examples=43793, total_duration=13220.005734, train/accuracy=0.991334, train/loss=0.028676, train/mean_average_precision=0.457926, validation/accuracy=0.986703, validation/loss=0.043883, validation/mean_average_precision=0.277865, validation/num_examples=43793
I0215 15:50:19.576934 139904642172672 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.030781356617808342, loss=0.028278671205043793
I0215 15:52:23.698632 139966923982656 spec.py:321] Evaluating on the training split.
I0215 15:54:19.160494 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 15:54:22.354643 139966923982656 spec.py:349] Evaluating on the test split.
I0215 15:54:25.491173 139966923982656 submission_runner.py:408] Time since start: 13581.90s, 	Step: 29914, 	{'train/accuracy': 0.9914525747299194, 'train/loss': 0.028125496581196785, 'train/mean_average_precision': 0.4683592043657039, 'validation/accuracy': 0.9868706464767456, 'validation/loss': 0.043644268065690994, 'validation/mean_average_precision': 0.28004715880163983, 'validation/num_examples': 43793, 'test/accuracy': 0.9860668182373047, 'test/loss': 0.046336352825164795, 'test/mean_average_precision': 0.2672884705407264, 'test/num_examples': 43793, 'score': 8902.502653598785, 'total_duration': 13581.903505802155, 'accumulated_submission_time': 8902.502653598785, 'accumulated_eval_time': 4677.592744588852, 'accumulated_logging_time': 1.0346863269805908}
I0215 15:54:25.511594 139806048024320 logging_writer.py:48] [29914] accumulated_eval_time=4677.592745, accumulated_logging_time=1.034686, accumulated_submission_time=8902.502654, global_step=29914, preemption_count=0, score=8902.502654, test/accuracy=0.986067, test/loss=0.046336, test/mean_average_precision=0.267288, test/num_examples=43793, total_duration=13581.903506, train/accuracy=0.991453, train/loss=0.028125, train/mean_average_precision=0.468359, validation/accuracy=0.986871, validation/loss=0.043644, validation/mean_average_precision=0.280047, validation/num_examples=43793
I0215 15:54:51.976843 139904633779968 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.03149329870939255, loss=0.032154373824596405
I0215 15:57:22.988695 139806048024320 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.03562031686306, loss=0.03083927556872368
I0215 15:58:25.644735 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:00:20.140093 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:00:23.082871 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:00:26.005273 139966923982656 submission_runner.py:408] Time since start: 13942.42s, 	Step: 30711, 	{'train/accuracy': 0.9914335608482361, 'train/loss': 0.028026077896356583, 'train/mean_average_precision': 0.45931166006995217, 'validation/accuracy': 0.9869940280914307, 'validation/loss': 0.043538205325603485, 'validation/mean_average_precision': 0.27928126038980905, 'validation/num_examples': 43793, 'test/accuracy': 0.9861700534820557, 'test/loss': 0.04625357687473297, 'test/mean_average_precision': 0.266500297897029, 'test/num_examples': 43793, 'score': 9142.599684000015, 'total_duration': 13942.417710542679, 'accumulated_submission_time': 9142.599684000015, 'accumulated_eval_time': 4797.953253269196, 'accumulated_logging_time': 1.0668222904205322}
I0215 16:00:26.023761 139797635151616 logging_writer.py:48] [30711] accumulated_eval_time=4797.953253, accumulated_logging_time=1.066822, accumulated_submission_time=9142.599684, global_step=30711, preemption_count=0, score=9142.599684, test/accuracy=0.986170, test/loss=0.046254, test/mean_average_precision=0.266500, test/num_examples=43793, total_duration=13942.417711, train/accuracy=0.991434, train/loss=0.028026, train/mean_average_precision=0.459312, validation/accuracy=0.986994, validation/loss=0.043538, validation/mean_average_precision=0.279281, validation/num_examples=43793
I0215 16:01:54.882817 139904642172672 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.030957721173763275, loss=0.030055571347475052
I0215 16:04:23.022427 139797635151616 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.033561866730451584, loss=0.029350152239203453
I0215 16:04:26.223187 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:06:18.546596 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:06:22.414324 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:06:25.287796 139966923982656 submission_runner.py:408] Time since start: 14301.70s, 	Step: 31512, 	{'train/accuracy': 0.9916025996208191, 'train/loss': 0.027679599821567535, 'train/mean_average_precision': 0.4661219092356754, 'validation/accuracy': 0.9869956374168396, 'validation/loss': 0.043523550033569336, 'validation/mean_average_precision': 0.28240882389263167, 'validation/num_examples': 43793, 'test/accuracy': 0.9861489534378052, 'test/loss': 0.04628578945994377, 'test/mean_average_precision': 0.2686872834085632, 'test/num_examples': 43793, 'score': 9382.76790690422, 'total_duration': 14301.700232744217, 'accumulated_submission_time': 9382.76790690422, 'accumulated_eval_time': 4917.017812490463, 'accumulated_logging_time': 1.0954830646514893}
I0215 16:06:25.306636 139806048024320 logging_writer.py:48] [31512] accumulated_eval_time=4917.017812, accumulated_logging_time=1.095483, accumulated_submission_time=9382.767907, global_step=31512, preemption_count=0, score=9382.767907, test/accuracy=0.986149, test/loss=0.046286, test/mean_average_precision=0.268687, test/num_examples=43793, total_duration=14301.700233, train/accuracy=0.991603, train/loss=0.027680, train/mean_average_precision=0.466122, validation/accuracy=0.986996, validation/loss=0.043524, validation/mean_average_precision=0.282409, validation/num_examples=43793
I0215 16:08:51.077570 139806056417024 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.0330716073513031, loss=0.02940468303859234
I0215 16:10:25.400838 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:12:17.656615 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:12:20.583339 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:12:23.482399 139966923982656 submission_runner.py:408] Time since start: 14659.89s, 	Step: 32316, 	{'train/accuracy': 0.9916626214981079, 'train/loss': 0.027442244812846184, 'train/mean_average_precision': 0.47553251275467934, 'validation/accuracy': 0.9870054125785828, 'validation/loss': 0.04352150484919548, 'validation/mean_average_precision': 0.28301205810455077, 'validation/num_examples': 43793, 'test/accuracy': 0.9861898422241211, 'test/loss': 0.04625026881694794, 'test/mean_average_precision': 0.26858153768580867, 'test/num_examples': 43793, 'score': 9622.83142876625, 'total_duration': 14659.894820928574, 'accumulated_submission_time': 9622.83142876625, 'accumulated_eval_time': 5035.09934258461, 'accumulated_logging_time': 1.1243128776550293}
I0215 16:12:23.501100 139791620105984 logging_writer.py:48] [32316] accumulated_eval_time=5035.099343, accumulated_logging_time=1.124313, accumulated_submission_time=9622.831429, global_step=32316, preemption_count=0, score=9622.831429, test/accuracy=0.986190, test/loss=0.046250, test/mean_average_precision=0.268582, test/num_examples=43793, total_duration=14659.894821, train/accuracy=0.991663, train/loss=0.027442, train/mean_average_precision=0.475533, validation/accuracy=0.987005, validation/loss=0.043522, validation/mean_average_precision=0.283012, validation/num_examples=43793
I0215 16:13:18.735591 139797635151616 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.040179260075092316, loss=0.03130968287587166
I0215 16:15:50.041711 139791620105984 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.03517618775367737, loss=0.030846061185002327
I0215 16:16:23.716341 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:18:16.774082 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:18:19.784120 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:18:22.641733 139966923982656 submission_runner.py:408] Time since start: 15019.05s, 	Step: 33113, 	{'train/accuracy': 0.9917760491371155, 'train/loss': 0.027025550603866577, 'train/mean_average_precision': 0.4986171057037929, 'validation/accuracy': 0.9870979189872742, 'validation/loss': 0.04350908845663071, 'validation/mean_average_precision': 0.2870855395922874, 'validation/num_examples': 43793, 'test/accuracy': 0.9862732291221619, 'test/loss': 0.046169281005859375, 'test/mean_average_precision': 0.2696226061468317, 'test/num_examples': 43793, 'score': 9863.016050577164, 'total_duration': 15019.054170131683, 'accumulated_submission_time': 9863.016050577164, 'accumulated_eval_time': 5154.024688959122, 'accumulated_logging_time': 1.1530115604400635}
I0215 16:18:22.659972 139806056417024 logging_writer.py:48] [33113] accumulated_eval_time=5154.024689, accumulated_logging_time=1.153012, accumulated_submission_time=9863.016051, global_step=33113, preemption_count=0, score=9863.016051, test/accuracy=0.986273, test/loss=0.046169, test/mean_average_precision=0.269623, test/num_examples=43793, total_duration=15019.054170, train/accuracy=0.991776, train/loss=0.027026, train/mean_average_precision=0.498617, validation/accuracy=0.987098, validation/loss=0.043509, validation/mean_average_precision=0.287086, validation/num_examples=43793
I0215 16:20:18.332071 139904642172672 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.03385414555668831, loss=0.030083326622843742
I0215 16:22:22.833186 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:24:15.257918 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:24:18.226384 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:24:21.128842 139966923982656 submission_runner.py:408] Time since start: 15377.54s, 	Step: 33925, 	{'train/accuracy': 0.9918119311332703, 'train/loss': 0.026902688667178154, 'train/mean_average_precision': 0.4936205999185998, 'validation/accuracy': 0.9869672060012817, 'validation/loss': 0.04383549839258194, 'validation/mean_average_precision': 0.28230821743017753, 'validation/num_examples': 43793, 'test/accuracy': 0.9861552715301514, 'test/loss': 0.04641077667474747, 'test/mean_average_precision': 0.26779683300393964, 'test/num_examples': 43793, 'score': 10103.158504009247, 'total_duration': 15377.541278362274, 'accumulated_submission_time': 10103.158504009247, 'accumulated_eval_time': 5272.320310592651, 'accumulated_logging_time': 1.1811866760253906}
I0215 16:24:21.147636 139797635151616 logging_writer.py:48] [33925] accumulated_eval_time=5272.320311, accumulated_logging_time=1.181187, accumulated_submission_time=10103.158504, global_step=33925, preemption_count=0, score=10103.158504, test/accuracy=0.986155, test/loss=0.046411, test/mean_average_precision=0.267797, test/num_examples=43793, total_duration=15377.541278, train/accuracy=0.991812, train/loss=0.026903, train/mean_average_precision=0.493621, validation/accuracy=0.986967, validation/loss=0.043835, validation/mean_average_precision=0.282308, validation/num_examples=43793
I0215 16:24:43.985898 139806048024320 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.03298904374241829, loss=0.030210163444280624
I0215 16:27:13.539338 139797635151616 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.03403431922197342, loss=0.028512125834822655
I0215 16:28:21.243711 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:30:12.814379 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:30:15.858900 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:30:18.787072 139966923982656 submission_runner.py:408] Time since start: 15735.20s, 	Step: 34728, 	{'train/accuracy': 0.9917868375778198, 'train/loss': 0.02680364064872265, 'train/mean_average_precision': 0.49740441558866844, 'validation/accuracy': 0.9870249032974243, 'validation/loss': 0.04395166411995888, 'validation/mean_average_precision': 0.28355856142474234, 'validation/num_examples': 43793, 'test/accuracy': 0.9862454533576965, 'test/loss': 0.046687837690114975, 'test/mean_average_precision': 0.26949119835803087, 'test/num_examples': 43793, 'score': 10342.95653629303, 'total_duration': 15735.199508666992, 'accumulated_submission_time': 10342.95653629303, 'accumulated_eval_time': 5389.863627910614, 'accumulated_logging_time': 1.477172613143921}
I0215 16:30:18.806253 139791620105984 logging_writer.py:48] [34728] accumulated_eval_time=5389.863628, accumulated_logging_time=1.477173, accumulated_submission_time=10342.956536, global_step=34728, preemption_count=0, score=10342.956536, test/accuracy=0.986245, test/loss=0.046688, test/mean_average_precision=0.269491, test/num_examples=43793, total_duration=15735.199509, train/accuracy=0.991787, train/loss=0.026804, train/mean_average_precision=0.497404, validation/accuracy=0.987025, validation/loss=0.043952, validation/mean_average_precision=0.283559, validation/num_examples=43793
I0215 16:31:41.153073 139806056417024 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.03803880140185356, loss=0.030506789684295654
I0215 16:34:09.705471 139791620105984 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.03988274931907654, loss=0.03140166029334068
I0215 16:34:18.887577 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:36:09.250057 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:36:12.255152 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:36:15.184809 139966923982656 submission_runner.py:408] Time since start: 16091.60s, 	Step: 35531, 	{'train/accuracy': 0.9917834997177124, 'train/loss': 0.02703705243766308, 'train/mean_average_precision': 0.48823947776446663, 'validation/accuracy': 0.987052857875824, 'validation/loss': 0.043717317283153534, 'validation/mean_average_precision': 0.2838738336038106, 'validation/num_examples': 43793, 'test/accuracy': 0.986253023147583, 'test/loss': 0.04643681272864342, 'test/mean_average_precision': 0.273511011319587, 'test/num_examples': 43793, 'score': 10583.00742483139, 'total_duration': 16091.597248792648, 'accumulated_submission_time': 10583.00742483139, 'accumulated_eval_time': 5506.160814285278, 'accumulated_logging_time': 1.5064325332641602}
I0215 16:36:15.203850 139797635151616 logging_writer.py:48] [35531] accumulated_eval_time=5506.160814, accumulated_logging_time=1.506433, accumulated_submission_time=10583.007425, global_step=35531, preemption_count=0, score=10583.007425, test/accuracy=0.986253, test/loss=0.046437, test/mean_average_precision=0.273511, test/num_examples=43793, total_duration=16091.597249, train/accuracy=0.991783, train/loss=0.027037, train/mean_average_precision=0.488239, validation/accuracy=0.987053, validation/loss=0.043717, validation/mean_average_precision=0.283874, validation/num_examples=43793
I0215 16:38:35.458937 139806048024320 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.036612369120121, loss=0.030504019930958748
I0215 16:40:15.409236 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:42:06.486122 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:42:09.451963 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:42:12.388348 139966923982656 submission_runner.py:408] Time since start: 16448.80s, 	Step: 36336, 	{'train/accuracy': 0.992019772529602, 'train/loss': 0.02626228705048561, 'train/mean_average_precision': 0.4996973152106786, 'validation/accuracy': 0.9870671033859253, 'validation/loss': 0.04361997917294502, 'validation/mean_average_precision': 0.28569757013246677, 'validation/num_examples': 43793, 'test/accuracy': 0.9862290024757385, 'test/loss': 0.046415217220783234, 'test/mean_average_precision': 0.2722847035275321, 'test/num_examples': 43793, 'score': 10823.180500984192, 'total_duration': 16448.800787448883, 'accumulated_submission_time': 10823.180500984192, 'accumulated_eval_time': 5623.139890670776, 'accumulated_logging_time': 1.5369884967803955}
I0215 16:42:12.407551 139790408062720 logging_writer.py:48] [36336] accumulated_eval_time=5623.139891, accumulated_logging_time=1.536988, accumulated_submission_time=10823.180501, global_step=36336, preemption_count=0, score=10823.180501, test/accuracy=0.986229, test/loss=0.046415, test/mean_average_precision=0.272285, test/num_examples=43793, total_duration=16448.800787, train/accuracy=0.992020, train/loss=0.026262, train/mean_average_precision=0.499697, validation/accuracy=0.987067, validation/loss=0.043620, validation/mean_average_precision=0.285698, validation/num_examples=43793
I0215 16:43:01.171107 139791620105984 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.0362357422709465, loss=0.029708612710237503
I0215 16:45:30.423871 139790408062720 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.03619091212749481, loss=0.0313427560031414
I0215 16:46:12.642615 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:48:01.472913 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:48:04.436038 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:48:07.395472 139966923982656 submission_runner.py:408] Time since start: 16803.81s, 	Step: 37143, 	{'train/accuracy': 0.9919503927230835, 'train/loss': 0.026459207758307457, 'train/mean_average_precision': 0.5022079941113572, 'validation/accuracy': 0.9871016144752502, 'validation/loss': 0.043582625687122345, 'validation/mean_average_precision': 0.28610105872813213, 'validation/num_examples': 43793, 'test/accuracy': 0.9862567782402039, 'test/loss': 0.04632896929979324, 'test/mean_average_precision': 0.27192628605127944, 'test/num_examples': 43793, 'score': 11063.384637832642, 'total_duration': 16803.807886123657, 'accumulated_submission_time': 11063.384637832642, 'accumulated_eval_time': 5737.892679691315, 'accumulated_logging_time': 1.5662016868591309}
I0215 16:48:07.415695 139797635151616 logging_writer.py:48] [37143] accumulated_eval_time=5737.892680, accumulated_logging_time=1.566202, accumulated_submission_time=11063.384638, global_step=37143, preemption_count=0, score=11063.384638, test/accuracy=0.986257, test/loss=0.046329, test/mean_average_precision=0.271926, test/num_examples=43793, total_duration=16803.807886, train/accuracy=0.991950, train/loss=0.026459, train/mean_average_precision=0.502208, validation/accuracy=0.987102, validation/loss=0.043583, validation/mean_average_precision=0.286101, validation/num_examples=43793
I0215 16:49:53.811822 139806056417024 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.03770788013935089, loss=0.028718849644064903
I0215 16:52:07.585137 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:53:55.938957 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:53:58.877836 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:54:01.800483 139966923982656 submission_runner.py:408] Time since start: 17158.21s, 	Step: 37951, 	{'train/accuracy': 0.992009162902832, 'train/loss': 0.026190653443336487, 'train/mean_average_precision': 0.5092364715896418, 'validation/accuracy': 0.9869583249092102, 'validation/loss': 0.043758414685726166, 'validation/mean_average_precision': 0.29314003087016427, 'validation/num_examples': 43793, 'test/accuracy': 0.9861654043197632, 'test/loss': 0.046399783343076706, 'test/mean_average_precision': 0.27303717513773235, 'test/num_examples': 43793, 'score': 11303.523490428925, 'total_duration': 17158.2129073143, 'accumulated_submission_time': 11303.523490428925, 'accumulated_eval_time': 5852.107979774475, 'accumulated_logging_time': 1.5964686870574951}
I0215 16:54:01.821434 139791620105984 logging_writer.py:48] [37951] accumulated_eval_time=5852.107980, accumulated_logging_time=1.596469, accumulated_submission_time=11303.523490, global_step=37951, preemption_count=0, score=11303.523490, test/accuracy=0.986165, test/loss=0.046400, test/mean_average_precision=0.273037, test/num_examples=43793, total_duration=17158.212907, train/accuracy=0.992009, train/loss=0.026191, train/mean_average_precision=0.509236, validation/accuracy=0.986958, validation/loss=0.043758, validation/mean_average_precision=0.293140, validation/num_examples=43793
I0215 16:54:17.028539 139806048024320 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.032873548567295074, loss=0.03018326312303543
I0215 16:56:46.485678 139791620105984 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.033072005957365036, loss=0.026637401431798935
I0215 16:58:01.954492 139966923982656 spec.py:321] Evaluating on the training split.
I0215 16:59:49.972991 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 16:59:52.887922 139966923982656 spec.py:349] Evaluating on the test split.
I0215 16:59:55.783755 139966923982656 submission_runner.py:408] Time since start: 17512.20s, 	Step: 38753, 	{'train/accuracy': 0.9920198917388916, 'train/loss': 0.026103172451257706, 'train/mean_average_precision': 0.5085402683082594, 'validation/accuracy': 0.9870200157165527, 'validation/loss': 0.043799374252557755, 'validation/mean_average_precision': 0.2919875351234355, 'validation/num_examples': 43793, 'test/accuracy': 0.986207127571106, 'test/loss': 0.046464718878269196, 'test/mean_average_precision': 0.2726773822086513, 'test/num_examples': 43793, 'score': 11543.625498771667, 'total_duration': 17512.196195364, 'accumulated_submission_time': 11543.625498771667, 'accumulated_eval_time': 5965.937205314636, 'accumulated_logging_time': 1.628067970275879}
I0215 16:59:55.802679 139797635151616 logging_writer.py:48] [38753] accumulated_eval_time=5965.937205, accumulated_logging_time=1.628068, accumulated_submission_time=11543.625499, global_step=38753, preemption_count=0, score=11543.625499, test/accuracy=0.986207, test/loss=0.046465, test/mean_average_precision=0.272677, test/num_examples=43793, total_duration=17512.196195, train/accuracy=0.992020, train/loss=0.026103, train/mean_average_precision=0.508540, validation/accuracy=0.987020, validation/loss=0.043799, validation/mean_average_precision=0.291988, validation/num_examples=43793
I0215 17:01:09.149788 139806056417024 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.03280341252684593, loss=0.02843973971903324
I0215 17:03:37.158194 139797635151616 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.033424217253923416, loss=0.02739241160452366
I0215 17:03:55.921954 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:05:44.784776 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:05:47.676977 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:05:50.572934 139966923982656 submission_runner.py:408] Time since start: 17866.99s, 	Step: 39564, 	{'train/accuracy': 0.9920775890350342, 'train/loss': 0.025897284969687462, 'train/mean_average_precision': 0.5178632674219039, 'validation/accuracy': 0.9870175719261169, 'validation/loss': 0.04383189603686333, 'validation/mean_average_precision': 0.29044556427405527, 'validation/num_examples': 43793, 'test/accuracy': 0.986214280128479, 'test/loss': 0.04652079939842224, 'test/mean_average_precision': 0.27400763814383505, 'test/num_examples': 43793, 'score': 11783.713562488556, 'total_duration': 17866.98537325859, 'accumulated_submission_time': 11783.713562488556, 'accumulated_eval_time': 6080.588138580322, 'accumulated_logging_time': 1.6572272777557373}
I0215 17:05:50.592301 139790408062720 logging_writer.py:48] [39564] accumulated_eval_time=6080.588139, accumulated_logging_time=1.657227, accumulated_submission_time=11783.713562, global_step=39564, preemption_count=0, score=11783.713562, test/accuracy=0.986214, test/loss=0.046521, test/mean_average_precision=0.274008, test/num_examples=43793, total_duration=17866.985373, train/accuracy=0.992078, train/loss=0.025897, train/mean_average_precision=0.517863, validation/accuracy=0.987018, validation/loss=0.043832, validation/mean_average_precision=0.290446, validation/num_examples=43793
I0215 17:08:00.331612 139806048024320 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.030192483216524124, loss=0.026968061923980713
I0215 17:09:50.574247 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:11:37.323012 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:11:40.309455 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:11:43.256909 139966923982656 submission_runner.py:408] Time since start: 18219.67s, 	Step: 40375, 	{'train/accuracy': 0.9921066761016846, 'train/loss': 0.025920024141669273, 'train/mean_average_precision': 0.5134266237921271, 'validation/accuracy': 0.9870930910110474, 'validation/loss': 0.043781496584415436, 'validation/mean_average_precision': 0.2910942052732513, 'validation/num_examples': 43793, 'test/accuracy': 0.9863086342811584, 'test/loss': 0.0464753732085228, 'test/mean_average_precision': 0.2763686988638266, 'test/num_examples': 43793, 'score': 12023.664120674133, 'total_duration': 18219.669342517853, 'accumulated_submission_time': 12023.664120674133, 'accumulated_eval_time': 6193.2707595825195, 'accumulated_logging_time': 1.6868062019348145}
I0215 17:11:43.277354 139797635151616 logging_writer.py:48] [40375] accumulated_eval_time=6193.270760, accumulated_logging_time=1.686806, accumulated_submission_time=12023.664121, global_step=40375, preemption_count=0, score=12023.664121, test/accuracy=0.986309, test/loss=0.046475, test/mean_average_precision=0.276369, test/num_examples=43793, total_duration=18219.669343, train/accuracy=0.992107, train/loss=0.025920, train/mean_average_precision=0.513427, validation/accuracy=0.987093, validation/loss=0.043781, validation/mean_average_precision=0.291094, validation/num_examples=43793
I0215 17:12:20.794957 139806056417024 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.03770710527896881, loss=0.031214231625199318
I0215 17:14:49.370118 139797635151616 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.03602902591228485, loss=0.026506731286644936
I0215 17:15:43.370373 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:17:29.485602 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:17:32.462436 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:17:35.439194 139966923982656 submission_runner.py:408] Time since start: 18571.85s, 	Step: 41182, 	{'train/accuracy': 0.9921951293945312, 'train/loss': 0.02550451084971428, 'train/mean_average_precision': 0.5255392530143148, 'validation/accuracy': 0.9870272874832153, 'validation/loss': 0.04401693865656853, 'validation/mean_average_precision': 0.28724548770166786, 'validation/num_examples': 43793, 'test/accuracy': 0.9862306714057922, 'test/loss': 0.046753447502851486, 'test/mean_average_precision': 0.27558905960036156, 'test/num_examples': 43793, 'score': 12263.72638630867, 'total_duration': 18571.851628780365, 'accumulated_submission_time': 12263.72638630867, 'accumulated_eval_time': 6305.33953332901, 'accumulated_logging_time': 1.717444658279419}
I0215 17:17:35.459265 139791620105984 logging_writer.py:48] [41182] accumulated_eval_time=6305.339533, accumulated_logging_time=1.717445, accumulated_submission_time=12263.726386, global_step=41182, preemption_count=0, score=12263.726386, test/accuracy=0.986231, test/loss=0.046753, test/mean_average_precision=0.275589, test/num_examples=43793, total_duration=18571.851629, train/accuracy=0.992195, train/loss=0.025505, train/mean_average_precision=0.525539, validation/accuracy=0.987027, validation/loss=0.044017, validation/mean_average_precision=0.287245, validation/num_examples=43793
I0215 17:19:09.663707 139806048024320 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.04247186705470085, loss=0.030085330829024315
I0215 17:21:35.594043 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:23:20.232417 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:23:23.135382 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:23:26.023304 139966923982656 submission_runner.py:408] Time since start: 18922.44s, 	Step: 41994, 	{'train/accuracy': 0.9922540783882141, 'train/loss': 0.025394786149263382, 'train/mean_average_precision': 0.5350306245213754, 'validation/accuracy': 0.9871458411216736, 'validation/loss': 0.04370727762579918, 'validation/mean_average_precision': 0.2921886729060299, 'validation/num_examples': 43793, 'test/accuracy': 0.9862546920776367, 'test/loss': 0.04658469557762146, 'test/mean_average_precision': 0.2740913877118571, 'test/num_examples': 43793, 'score': 12503.829927921295, 'total_duration': 18922.435742616653, 'accumulated_submission_time': 12503.829927921295, 'accumulated_eval_time': 6415.768768310547, 'accumulated_logging_time': 1.748032808303833}
I0215 17:23:26.042326 139797635151616 logging_writer.py:48] [41994] accumulated_eval_time=6415.768768, accumulated_logging_time=1.748033, accumulated_submission_time=12503.829928, global_step=41994, preemption_count=0, score=12503.829928, test/accuracy=0.986255, test/loss=0.046585, test/mean_average_precision=0.274091, test/num_examples=43793, total_duration=18922.435743, train/accuracy=0.992254, train/loss=0.025395, train/mean_average_precision=0.535031, validation/accuracy=0.987146, validation/loss=0.043707, validation/mean_average_precision=0.292189, validation/num_examples=43793
I0215 17:23:28.078597 139806056417024 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.036046773195266724, loss=0.02560718171298504
I0215 17:25:55.026870 139797635151616 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.04661216959357262, loss=0.02944175899028778
I0215 17:27:26.264063 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:29:11.363253 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:29:14.305154 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:29:17.164800 139966923982656 submission_runner.py:408] Time since start: 19273.58s, 	Step: 42812, 	{'train/accuracy': 0.9923320412635803, 'train/loss': 0.02514089085161686, 'train/mean_average_precision': 0.5327678635630724, 'validation/accuracy': 0.9870800971984863, 'validation/loss': 0.04380376264452934, 'validation/mean_average_precision': 0.2936450115948592, 'validation/num_examples': 43793, 'test/accuracy': 0.9862861037254333, 'test/loss': 0.046529825776815414, 'test/mean_average_precision': 0.2743511556959688, 'test/num_examples': 43793, 'score': 12744.02012848854, 'total_duration': 19273.577226638794, 'accumulated_submission_time': 12744.02012848854, 'accumulated_eval_time': 6526.669455051422, 'accumulated_logging_time': 1.7772080898284912}
I0215 17:29:17.184820 139791620105984 logging_writer.py:48] [42812] accumulated_eval_time=6526.669455, accumulated_logging_time=1.777208, accumulated_submission_time=12744.020128, global_step=42812, preemption_count=0, score=12744.020128, test/accuracy=0.986286, test/loss=0.046530, test/mean_average_precision=0.274351, test/num_examples=43793, total_duration=19273.577227, train/accuracy=0.992332, train/loss=0.025141, train/mean_average_precision=0.532768, validation/accuracy=0.987080, validation/loss=0.043804, validation/mean_average_precision=0.293645, validation/num_examples=43793
I0215 17:30:12.844880 139806048024320 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.03724266216158867, loss=0.027067774906754494
I0215 17:32:40.487900 139791620105984 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.04245543107390404, loss=0.028951983898878098
I0215 17:33:17.281234 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:35:05.446273 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:35:08.386827 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:35:11.322036 139966923982656 submission_runner.py:408] Time since start: 19627.73s, 	Step: 43625, 	{'train/accuracy': 0.9923545122146606, 'train/loss': 0.025050673633813858, 'train/mean_average_precision': 0.5217645567501001, 'validation/accuracy': 0.9871572256088257, 'validation/loss': 0.04378315061330795, 'validation/mean_average_precision': 0.2947222804090832, 'validation/num_examples': 43793, 'test/accuracy': 0.9862892627716064, 'test/loss': 0.046654798090457916, 'test/mean_average_precision': 0.276628101630696, 'test/num_examples': 43793, 'score': 12984.083931922913, 'total_duration': 19627.734467983246, 'accumulated_submission_time': 12984.083931922913, 'accumulated_eval_time': 6640.710206747055, 'accumulated_logging_time': 1.8087170124053955}
I0215 17:35:11.342440 139790408062720 logging_writer.py:48] [43625] accumulated_eval_time=6640.710207, accumulated_logging_time=1.808717, accumulated_submission_time=12984.083932, global_step=43625, preemption_count=0, score=12984.083932, test/accuracy=0.986289, test/loss=0.046655, test/mean_average_precision=0.276628, test/num_examples=43793, total_duration=19627.734468, train/accuracy=0.992355, train/loss=0.025051, train/mean_average_precision=0.521765, validation/accuracy=0.987157, validation/loss=0.043783, validation/mean_average_precision=0.294722, validation/num_examples=43793
I0215 17:37:02.787549 139806056417024 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.04273904860019684, loss=0.027085959911346436
I0215 17:39:11.409008 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:40:56.430541 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:40:59.357419 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:41:02.240561 139966923982656 submission_runner.py:408] Time since start: 19978.65s, 	Step: 44429, 	{'train/accuracy': 0.9923121929168701, 'train/loss': 0.025105789303779602, 'train/mean_average_precision': 0.5283175810938138, 'validation/accuracy': 0.9870898127555847, 'validation/loss': 0.04396750405430794, 'validation/mean_average_precision': 0.2906926906238737, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.046711377799510956, 'test/mean_average_precision': 0.275740459506899, 'test/num_examples': 43793, 'score': 13224.119028568268, 'total_duration': 19978.65299963951, 'accumulated_submission_time': 13224.119028568268, 'accumulated_eval_time': 6751.541735172272, 'accumulated_logging_time': 1.8395612239837646}
I0215 17:41:02.260233 139797635151616 logging_writer.py:48] [44429] accumulated_eval_time=6751.541735, accumulated_logging_time=1.839561, accumulated_submission_time=13224.119029, global_step=44429, preemption_count=0, score=13224.119029, test/accuracy=0.986337, test/loss=0.046711, test/mean_average_precision=0.275740, test/num_examples=43793, total_duration=19978.653000, train/accuracy=0.992312, train/loss=0.025106, train/mean_average_precision=0.528318, validation/accuracy=0.987090, validation/loss=0.043968, validation/mean_average_precision=0.290693, validation/num_examples=43793
I0215 17:41:23.516039 139806048024320 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.044057734310626984, loss=0.02890615165233612
I0215 17:43:52.860290 139797635151616 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.03309452161192894, loss=0.02661958523094654
I0215 17:45:02.384306 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:46:53.037502 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:46:56.076601 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:46:59.036568 139966923982656 submission_runner.py:408] Time since start: 20335.45s, 	Step: 45237, 	{'train/accuracy': 0.9924154877662659, 'train/loss': 0.02480192855000496, 'train/mean_average_precision': 0.5335555394627821, 'validation/accuracy': 0.9870380759239197, 'validation/loss': 0.043896470218896866, 'validation/mean_average_precision': 0.29144925817264067, 'validation/num_examples': 43793, 'test/accuracy': 0.9862509369850159, 'test/loss': 0.04658137634396553, 'test/mean_average_precision': 0.27627457527476146, 'test/num_examples': 43793, 'score': 13464.211839199066, 'total_duration': 20335.44900393486, 'accumulated_submission_time': 13464.211839199066, 'accumulated_eval_time': 6868.193955659866, 'accumulated_logging_time': 1.8695526123046875}
I0215 17:46:59.057222 139790408062720 logging_writer.py:48] [45237] accumulated_eval_time=6868.193956, accumulated_logging_time=1.869553, accumulated_submission_time=13464.211839, global_step=45237, preemption_count=0, score=13464.211839, test/accuracy=0.986251, test/loss=0.046581, test/mean_average_precision=0.276275, test/num_examples=43793, total_duration=20335.449004, train/accuracy=0.992415, train/loss=0.024802, train/mean_average_precision=0.533556, validation/accuracy=0.987038, validation/loss=0.043896, validation/mean_average_precision=0.291449, validation/num_examples=43793
I0215 17:48:16.662115 139806056417024 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.034937433898448944, loss=0.025081537663936615
I0215 17:50:44.412041 139790408062720 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.0363907590508461, loss=0.02581769786775112
I0215 17:50:59.240775 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:52:46.629065 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:52:49.677376 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:52:52.608697 139966923982656 submission_runner.py:408] Time since start: 20689.02s, 	Step: 46050, 	{'train/accuracy': 0.9924728870391846, 'train/loss': 0.02473508007824421, 'train/mean_average_precision': 0.5482387394588197, 'validation/accuracy': 0.9870654940605164, 'validation/loss': 0.04400653392076492, 'validation/mean_average_precision': 0.29216711898148573, 'validation/num_examples': 43793, 'test/accuracy': 0.9863014221191406, 'test/loss': 0.046741895377635956, 'test/mean_average_precision': 0.27522812435849275, 'test/num_examples': 43793, 'score': 13704.363716602325, 'total_duration': 20689.021132946014, 'accumulated_submission_time': 13704.363716602325, 'accumulated_eval_time': 6981.561831712723, 'accumulated_logging_time': 1.9005815982818604}
I0215 17:52:52.630172 139797635151616 logging_writer.py:48] [46050] accumulated_eval_time=6981.561832, accumulated_logging_time=1.900582, accumulated_submission_time=13704.363717, global_step=46050, preemption_count=0, score=13704.363717, test/accuracy=0.986301, test/loss=0.046742, test/mean_average_precision=0.275228, test/num_examples=43793, total_duration=20689.021133, train/accuracy=0.992473, train/loss=0.024735, train/mean_average_precision=0.548239, validation/accuracy=0.987065, validation/loss=0.044007, validation/mean_average_precision=0.292167, validation/num_examples=43793
I0215 17:55:07.061919 139806048024320 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.03849191963672638, loss=0.027629537507891655
I0215 17:56:52.644174 139966923982656 spec.py:321] Evaluating on the training split.
I0215 17:58:47.841469 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 17:58:52.471718 139966923982656 spec.py:349] Evaluating on the test split.
I0215 17:58:55.621171 139966923982656 submission_runner.py:408] Time since start: 21052.03s, 	Step: 46857, 	{'train/accuracy': 0.9925718307495117, 'train/loss': 0.024340186268091202, 'train/mean_average_precision': 0.5460618432251014, 'validation/accuracy': 0.9871048331260681, 'validation/loss': 0.043858833611011505, 'validation/mean_average_precision': 0.2934634918095831, 'validation/num_examples': 43793, 'test/accuracy': 0.986311137676239, 'test/loss': 0.04658690094947815, 'test/mean_average_precision': 0.2757559089938802, 'test/num_examples': 43793, 'score': 13944.346379995346, 'total_duration': 21052.033588647842, 'accumulated_submission_time': 13944.346379995346, 'accumulated_eval_time': 7104.538774967194, 'accumulated_logging_time': 1.9321987628936768}
I0215 17:58:55.644691 139790408062720 logging_writer.py:48] [46857] accumulated_eval_time=7104.538775, accumulated_logging_time=1.932199, accumulated_submission_time=13944.346380, global_step=46857, preemption_count=0, score=13944.346380, test/accuracy=0.986311, test/loss=0.046587, test/mean_average_precision=0.275756, test/num_examples=43793, total_duration=21052.033589, train/accuracy=0.992572, train/loss=0.024340, train/mean_average_precision=0.546062, validation/accuracy=0.987105, validation/loss=0.043859, validation/mean_average_precision=0.293463, validation/num_examples=43793
I0215 17:59:39.079677 139806056417024 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.03778230398893356, loss=0.029191071167588234
I0215 18:02:09.809161 139790408062720 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.0466427244246006, loss=0.02665196917951107
I0215 18:02:55.802897 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:04:42.182143 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:04:45.099075 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:04:48.028976 139966923982656 submission_runner.py:408] Time since start: 21404.44s, 	Step: 47654, 	{'train/accuracy': 0.9925391674041748, 'train/loss': 0.024330446496605873, 'train/mean_average_precision': 0.5512148948006481, 'validation/accuracy': 0.9871292114257812, 'validation/loss': 0.044019173830747604, 'validation/mean_average_precision': 0.29511728456994485, 'validation/num_examples': 43793, 'test/accuracy': 0.9863258600234985, 'test/loss': 0.04675939306616783, 'test/mean_average_precision': 0.27590182504848065, 'test/num_examples': 43793, 'score': 14184.468867301941, 'total_duration': 21404.441400766373, 'accumulated_submission_time': 14184.468867301941, 'accumulated_eval_time': 7216.7648067474365, 'accumulated_logging_time': 1.9679112434387207}
I0215 18:04:48.049922 139797635151616 logging_writer.py:48] [47654] accumulated_eval_time=7216.764807, accumulated_logging_time=1.967911, accumulated_submission_time=14184.468867, global_step=47654, preemption_count=0, score=14184.468867, test/accuracy=0.986326, test/loss=0.046759, test/mean_average_precision=0.275902, test/num_examples=43793, total_duration=21404.441401, train/accuracy=0.992539, train/loss=0.024330, train/mean_average_precision=0.551215, validation/accuracy=0.987129, validation/loss=0.044019, validation/mean_average_precision=0.295117, validation/num_examples=43793
I0215 18:06:31.739177 139806048024320 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.04624463617801666, loss=0.030791938304901123
I0215 18:08:48.235192 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:10:34.670585 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:10:37.630174 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:10:40.527178 139966923982656 submission_runner.py:408] Time since start: 21756.94s, 	Step: 48456, 	{'train/accuracy': 0.9925549626350403, 'train/loss': 0.024405697360634804, 'train/mean_average_precision': 0.5438710943930942, 'validation/accuracy': 0.9870078563690186, 'validation/loss': 0.043872684240341187, 'validation/mean_average_precision': 0.294882526326833, 'validation/num_examples': 43793, 'test/accuracy': 0.9862774610519409, 'test/loss': 0.04653443768620491, 'test/mean_average_precision': 0.2762400637061657, 'test/num_examples': 43793, 'score': 14424.621384382248, 'total_duration': 21756.93960762024, 'accumulated_submission_time': 14424.621384382248, 'accumulated_eval_time': 7329.056750535965, 'accumulated_logging_time': 2.0004258155822754}
I0215 18:10:40.547402 139790408062720 logging_writer.py:48] [48456] accumulated_eval_time=7329.056751, accumulated_logging_time=2.000426, accumulated_submission_time=14424.621384, global_step=48456, preemption_count=0, score=14424.621384, test/accuracy=0.986277, test/loss=0.046534, test/mean_average_precision=0.276240, test/num_examples=43793, total_duration=21756.939608, train/accuracy=0.992555, train/loss=0.024406, train/mean_average_precision=0.543871, validation/accuracy=0.987008, validation/loss=0.043873, validation/mean_average_precision=0.294883, validation/num_examples=43793
I0215 18:10:54.045605 139806056417024 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.03939445689320564, loss=0.02533750794827938
I0215 18:13:23.357645 139790408062720 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.04059036448597908, loss=0.026519877836108208
I0215 18:14:40.805290 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:16:26.332721 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:16:29.425588 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:16:32.336102 139966923982656 submission_runner.py:408] Time since start: 22108.75s, 	Step: 49258, 	{'train/accuracy': 0.9925353527069092, 'train/loss': 0.024292323738336563, 'train/mean_average_precision': 0.5510165549192585, 'validation/accuracy': 0.9871299862861633, 'validation/loss': 0.044049620628356934, 'validation/mean_average_precision': 0.2942040578632812, 'validation/num_examples': 43793, 'test/accuracy': 0.9863515496253967, 'test/loss': 0.046685002744197845, 'test/mean_average_precision': 0.2779900239441563, 'test/num_examples': 43793, 'score': 14664.846626520157, 'total_duration': 22108.748535633087, 'accumulated_submission_time': 14664.846626520157, 'accumulated_eval_time': 7440.587538719177, 'accumulated_logging_time': 2.0319766998291016}
I0215 18:16:32.357175 139797635151616 logging_writer.py:48] [49258] accumulated_eval_time=7440.587539, accumulated_logging_time=2.031977, accumulated_submission_time=14664.846627, global_step=49258, preemption_count=0, score=14664.846627, test/accuracy=0.986352, test/loss=0.046685, test/mean_average_precision=0.277990, test/num_examples=43793, total_duration=22108.748536, train/accuracy=0.992535, train/loss=0.024292, train/mean_average_precision=0.551017, validation/accuracy=0.987130, validation/loss=0.044050, validation/mean_average_precision=0.294204, validation/num_examples=43793
I0215 18:17:45.492493 139806048024320 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.04447169601917267, loss=0.02820502035319805
I0215 18:20:16.509467 139797635151616 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.03701110556721687, loss=0.023721842095255852
I0215 18:20:32.490518 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:22:17.751610 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:22:20.695136 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:22:23.588193 139966923982656 submission_runner.py:408] Time since start: 22460.00s, 	Step: 50053, 	{'train/accuracy': 0.9926950931549072, 'train/loss': 0.023943951353430748, 'train/mean_average_precision': 0.5364517219031123, 'validation/accuracy': 0.9870837330818176, 'validation/loss': 0.04409274831414223, 'validation/mean_average_precision': 0.2946187640227976, 'validation/num_examples': 43793, 'test/accuracy': 0.9863343238830566, 'test/loss': 0.04679308459162712, 'test/mean_average_precision': 0.27761662892848316, 'test/num_examples': 43793, 'score': 14904.948291301727, 'total_duration': 22460.00063276291, 'accumulated_submission_time': 14904.948291301727, 'accumulated_eval_time': 7551.685168027878, 'accumulated_logging_time': 2.0634572505950928}
I0215 18:22:23.608469 139790408062720 logging_writer.py:48] [50053] accumulated_eval_time=7551.685168, accumulated_logging_time=2.063457, accumulated_submission_time=14904.948291, global_step=50053, preemption_count=0, score=14904.948291, test/accuracy=0.986334, test/loss=0.046793, test/mean_average_precision=0.277617, test/num_examples=43793, total_duration=22460.000633, train/accuracy=0.992695, train/loss=0.023944, train/mean_average_precision=0.536452, validation/accuracy=0.987084, validation/loss=0.044093, validation/mean_average_precision=0.294619, validation/num_examples=43793
I0215 18:24:41.720813 139806056417024 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.03926965594291687, loss=0.02733340673148632
I0215 18:26:23.684816 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:28:10.915977 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:28:13.880962 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:28:16.778659 139966923982656 submission_runner.py:408] Time since start: 22813.19s, 	Step: 50824, 	{'train/accuracy': 0.9926823377609253, 'train/loss': 0.023921485990285873, 'train/mean_average_precision': 0.5659549218465256, 'validation/accuracy': 0.9870930910110474, 'validation/loss': 0.04400347173213959, 'validation/mean_average_precision': 0.2966124778061327, 'validation/num_examples': 43793, 'test/accuracy': 0.9863380789756775, 'test/loss': 0.0467236302793026, 'test/mean_average_precision': 0.27769009613933104, 'test/num_examples': 43793, 'score': 15144.994645357132, 'total_duration': 22813.19109582901, 'accumulated_submission_time': 15144.994645357132, 'accumulated_eval_time': 7664.77897310257, 'accumulated_logging_time': 2.0937917232513428}
I0215 18:28:16.799829 139791620105984 logging_writer.py:48] [50824] accumulated_eval_time=7664.778973, accumulated_logging_time=2.093792, accumulated_submission_time=15144.994645, global_step=50824, preemption_count=0, score=15144.994645, test/accuracy=0.986338, test/loss=0.046724, test/mean_average_precision=0.277690, test/num_examples=43793, total_duration=22813.191096, train/accuracy=0.992682, train/loss=0.023921, train/mean_average_precision=0.565955, validation/accuracy=0.987093, validation/loss=0.044003, validation/mean_average_precision=0.296612, validation/num_examples=43793
I0215 18:29:09.215032 139806048024320 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.038928352296352386, loss=0.024715397506952286
I0215 18:31:36.861713 139791620105984 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.04158423840999603, loss=0.025904709473252296
I0215 18:32:16.969387 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:34:02.320226 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:34:05.240940 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:34:08.118745 139966923982656 submission_runner.py:408] Time since start: 23164.53s, 	Step: 51635, 	{'train/accuracy': 0.9927903413772583, 'train/loss': 0.023641467094421387, 'train/mean_average_precision': 0.5699900778606004, 'validation/accuracy': 0.9871259331703186, 'validation/loss': 0.04407826066017151, 'validation/mean_average_precision': 0.29433424721815926, 'validation/num_examples': 43793, 'test/accuracy': 0.9863317608833313, 'test/loss': 0.046789851039648056, 'test/mean_average_precision': 0.2765277641204706, 'test/num_examples': 43793, 'score': 15385.132538318634, 'total_duration': 23164.5311794281, 'accumulated_submission_time': 15385.132538318634, 'accumulated_eval_time': 7775.928287029266, 'accumulated_logging_time': 2.125009059906006}
I0215 18:34:08.140042 139790408062720 logging_writer.py:48] [51635] accumulated_eval_time=7775.928287, accumulated_logging_time=2.125009, accumulated_submission_time=15385.132538, global_step=51635, preemption_count=0, score=15385.132538, test/accuracy=0.986332, test/loss=0.046790, test/mean_average_precision=0.276528, test/num_examples=43793, total_duration=23164.531179, train/accuracy=0.992790, train/loss=0.023641, train/mean_average_precision=0.569990, validation/accuracy=0.987126, validation/loss=0.044078, validation/mean_average_precision=0.294334, validation/num_examples=43793
I0215 18:35:56.595365 139806056417024 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.0404319241642952, loss=0.02486831694841385
I0215 18:38:08.199021 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:39:55.564775 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:39:58.530395 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:40:01.426347 139966923982656 submission_runner.py:408] Time since start: 23517.84s, 	Step: 52442, 	{'train/accuracy': 0.9926507472991943, 'train/loss': 0.024028539657592773, 'train/mean_average_precision': 0.5561128286747439, 'validation/accuracy': 0.9871198534965515, 'validation/loss': 0.043958283960819244, 'validation/mean_average_precision': 0.2960602320099009, 'validation/num_examples': 43793, 'test/accuracy': 0.9862989187240601, 'test/loss': 0.046676985919475555, 'test/mean_average_precision': 0.27720240111481026, 'test/num_examples': 43793, 'score': 15625.159752607346, 'total_duration': 23517.83878493309, 'accumulated_submission_time': 15625.159752607346, 'accumulated_eval_time': 7889.155577659607, 'accumulated_logging_time': 2.1568806171417236}
I0215 18:40:01.446898 139791620105984 logging_writer.py:48] [52442] accumulated_eval_time=7889.155578, accumulated_logging_time=2.156881, accumulated_submission_time=15625.159753, global_step=52442, preemption_count=0, score=15625.159753, test/accuracy=0.986299, test/loss=0.046677, test/mean_average_precision=0.277202, test/num_examples=43793, total_duration=23517.838785, train/accuracy=0.992651, train/loss=0.024029, train/mean_average_precision=0.556113, validation/accuracy=0.987120, validation/loss=0.043958, validation/mean_average_precision=0.296060, validation/num_examples=43793
I0215 18:40:19.109216 139797635151616 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.03741899132728577, loss=0.02793853171169758
I0215 18:42:48.631882 139791620105984 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.0373549647629261, loss=0.026182599365711212
I0215 18:44:01.432112 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:45:46.008719 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:45:48.948397 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:45:51.885931 139966923982656 submission_runner.py:408] Time since start: 23868.30s, 	Step: 53242, 	{'train/accuracy': 0.992767870426178, 'train/loss': 0.023730114102363586, 'train/mean_average_precision': 0.5641855588005102, 'validation/accuracy': 0.9871519207954407, 'validation/loss': 0.04395059123635292, 'validation/mean_average_precision': 0.2944766385952157, 'validation/num_examples': 43793, 'test/accuracy': 0.9863595962524414, 'test/loss': 0.04665214568376541, 'test/mean_average_precision': 0.27796517027681544, 'test/num_examples': 43793, 'score': 15865.11316204071, 'total_duration': 23868.29835677147, 'accumulated_submission_time': 15865.11316204071, 'accumulated_eval_time': 7999.609346628189, 'accumulated_logging_time': 2.1878764629364014}
I0215 18:45:51.907243 139806048024320 logging_writer.py:48] [53242] accumulated_eval_time=7999.609347, accumulated_logging_time=2.187876, accumulated_submission_time=15865.113162, global_step=53242, preemption_count=0, score=15865.113162, test/accuracy=0.986360, test/loss=0.046652, test/mean_average_precision=0.277965, test/num_examples=43793, total_duration=23868.298357, train/accuracy=0.992768, train/loss=0.023730, train/mean_average_precision=0.564186, validation/accuracy=0.987152, validation/loss=0.043951, validation/mean_average_precision=0.294477, validation/num_examples=43793
I0215 18:47:09.770559 139806056417024 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.041285596787929535, loss=0.03009776584804058
I0215 18:49:39.865946 139806048024320 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.040284279733896255, loss=0.028015900403261185
I0215 18:49:51.981569 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:51:38.675700 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:51:41.593040 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:51:44.491437 139966923982656 submission_runner.py:408] Time since start: 24220.90s, 	Step: 54042, 	{'train/accuracy': 0.9927854537963867, 'train/loss': 0.023622294887900352, 'train/mean_average_precision': 0.557771058757786, 'validation/accuracy': 0.9871466755867004, 'validation/loss': 0.04403487220406532, 'validation/mean_average_precision': 0.2945236227589513, 'validation/num_examples': 43793, 'test/accuracy': 0.9863789677619934, 'test/loss': 0.04675048217177391, 'test/mean_average_precision': 0.2774723888584997, 'test/num_examples': 43793, 'score': 16105.155731916428, 'total_duration': 24220.903874874115, 'accumulated_submission_time': 16105.155731916428, 'accumulated_eval_time': 8112.119167566299, 'accumulated_logging_time': 2.219280958175659}
I0215 18:51:44.511964 139790408062720 logging_writer.py:48] [54042] accumulated_eval_time=8112.119168, accumulated_logging_time=2.219281, accumulated_submission_time=16105.155732, global_step=54042, preemption_count=0, score=16105.155732, test/accuracy=0.986379, test/loss=0.046750, test/mean_average_precision=0.277472, test/num_examples=43793, total_duration=24220.903875, train/accuracy=0.992785, train/loss=0.023622, train/mean_average_precision=0.557771, validation/accuracy=0.987147, validation/loss=0.044035, validation/mean_average_precision=0.294524, validation/num_examples=43793
I0215 18:54:00.178148 139791620105984 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.03817720338702202, loss=0.024269094690680504
I0215 18:55:44.525279 139966923982656 spec.py:321] Evaluating on the training split.
I0215 18:57:30.676734 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 18:57:33.621814 139966923982656 spec.py:349] Evaluating on the test split.
I0215 18:57:36.463765 139966923982656 submission_runner.py:408] Time since start: 24572.88s, 	Step: 54855, 	{'train/accuracy': 0.992757260799408, 'train/loss': 0.023710403591394424, 'train/mean_average_precision': 0.5704894674389012, 'validation/accuracy': 0.9871182441711426, 'validation/loss': 0.04402906447649002, 'validation/mean_average_precision': 0.2939831545527813, 'validation/num_examples': 43793, 'test/accuracy': 0.9863616824150085, 'test/loss': 0.04672276973724365, 'test/mean_average_precision': 0.27746544994406297, 'test/num_examples': 43793, 'score': 16345.138173818588, 'total_duration': 24572.876202583313, 'accumulated_submission_time': 16345.138173818588, 'accumulated_eval_time': 8224.05762052536, 'accumulated_logging_time': 2.2497670650482178}
I0215 18:57:36.484224 139797635151616 logging_writer.py:48] [54855] accumulated_eval_time=8224.057621, accumulated_logging_time=2.249767, accumulated_submission_time=16345.138174, global_step=54855, preemption_count=0, score=16345.138174, test/accuracy=0.986362, test/loss=0.046723, test/mean_average_precision=0.277465, test/num_examples=43793, total_duration=24572.876203, train/accuracy=0.992757, train/loss=0.023710, train/mean_average_precision=0.570489, validation/accuracy=0.987118, validation/loss=0.044029, validation/mean_average_precision=0.293983, validation/num_examples=43793
I0215 18:58:20.358798 139806056417024 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.03855272755026817, loss=0.026442548260092735
I0215 19:00:48.364237 139797635151616 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.047039493918418884, loss=0.030788209289312363
I0215 19:01:36.596974 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:03:19.135463 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:03:22.073992 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:03:24.905810 139966923982656 submission_runner.py:408] Time since start: 24921.32s, 	Step: 55662, 	{'train/accuracy': 0.99288010597229, 'train/loss': 0.02339564450085163, 'train/mean_average_precision': 0.5723252654691878, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04405774921178818, 'validation/mean_average_precision': 0.29443500441431786, 'validation/num_examples': 43793, 'test/accuracy': 0.9863473773002625, 'test/loss': 0.046785611659288406, 'test/mean_average_precision': 0.27797812945632994, 'test/num_examples': 43793, 'score': 16585.21883559227, 'total_duration': 24921.31823015213, 'accumulated_submission_time': 16585.21883559227, 'accumulated_eval_time': 8332.36639714241, 'accumulated_logging_time': 2.2815706729888916}
I0215 19:03:24.927193 139791620105984 logging_writer.py:48] [55662] accumulated_eval_time=8332.366397, accumulated_logging_time=2.281571, accumulated_submission_time=16585.218836, global_step=55662, preemption_count=0, score=16585.218836, test/accuracy=0.986347, test/loss=0.046786, test/mean_average_precision=0.277978, test/num_examples=43793, total_duration=24921.318230, train/accuracy=0.992880, train/loss=0.023396, train/mean_average_precision=0.572325, validation/accuracy=0.987136, validation/loss=0.044058, validation/mean_average_precision=0.294435, validation/num_examples=43793
I0215 19:05:08.131967 139806048024320 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.04559736326336861, loss=0.028254356235265732
I0215 19:07:24.953184 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:09:05.942821 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:09:08.848846 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:09:11.700011 139966923982656 submission_runner.py:408] Time since start: 25268.11s, 	Step: 56461, 	{'train/accuracy': 0.9927176833152771, 'train/loss': 0.023777011781930923, 'train/mean_average_precision': 0.5588775495450433, 'validation/accuracy': 0.9871580004692078, 'validation/loss': 0.04404550418257713, 'validation/mean_average_precision': 0.2942504084355177, 'validation/num_examples': 43793, 'test/accuracy': 0.9863406419754028, 'test/loss': 0.04676348343491554, 'test/mean_average_precision': 0.27751934908575543, 'test/num_examples': 43793, 'score': 16825.213742256165, 'total_duration': 25268.1124458313, 'accumulated_submission_time': 16825.213742256165, 'accumulated_eval_time': 8439.113186120987, 'accumulated_logging_time': 2.3131465911865234}
I0215 19:09:11.721005 139797635151616 logging_writer.py:48] [56461] accumulated_eval_time=8439.113186, accumulated_logging_time=2.313147, accumulated_submission_time=16825.213742, global_step=56461, preemption_count=0, score=16825.213742, test/accuracy=0.986341, test/loss=0.046763, test/mean_average_precision=0.277519, test/num_examples=43793, total_duration=25268.112446, train/accuracy=0.992718, train/loss=0.023777, train/mean_average_precision=0.558878, validation/accuracy=0.987158, validation/loss=0.044046, validation/mean_average_precision=0.294250, validation/num_examples=43793
I0215 19:09:23.587539 139806056417024 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.038355451077222824, loss=0.026562293991446495
I0215 19:11:51.597504 139797635151616 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.03965248167514801, loss=0.027691075578331947
I0215 19:13:11.783226 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:14:54.178602 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:14:57.120297 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:15:00.001789 139966923982656 submission_runner.py:408] Time since start: 25616.41s, 	Step: 57275, 	{'train/accuracy': 0.9927535057067871, 'train/loss': 0.023731792345643044, 'train/mean_average_precision': 0.5730846777096557, 'validation/accuracy': 0.987153947353363, 'validation/loss': 0.04406976327300072, 'validation/mean_average_precision': 0.29432620325649755, 'validation/num_examples': 43793, 'test/accuracy': 0.9863406419754028, 'test/loss': 0.04678366333246231, 'test/mean_average_precision': 0.27771077608807737, 'test/num_examples': 43793, 'score': 17065.243547677994, 'total_duration': 25616.414207935333, 'accumulated_submission_time': 17065.243547677994, 'accumulated_eval_time': 8547.331690073013, 'accumulated_logging_time': 2.3456172943115234}
I0215 19:15:00.022745 139790408062720 logging_writer.py:48] [57275] accumulated_eval_time=8547.331690, accumulated_logging_time=2.345617, accumulated_submission_time=17065.243548, global_step=57275, preemption_count=0, score=17065.243548, test/accuracy=0.986341, test/loss=0.046784, test/mean_average_precision=0.277711, test/num_examples=43793, total_duration=25616.414208, train/accuracy=0.992754, train/loss=0.023732, train/mean_average_precision=0.573085, validation/accuracy=0.987154, validation/loss=0.044070, validation/mean_average_precision=0.294326, validation/num_examples=43793
I0215 19:16:06.518720 139806048024320 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.04088987037539482, loss=0.026749297976493835
I0215 19:18:34.560415 139790408062720 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.040226392447948456, loss=0.028515087440609932
I0215 19:19:00.150381 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:20:41.668128 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:20:44.551478 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:20:47.411932 139966923982656 submission_runner.py:408] Time since start: 25963.82s, 	Step: 58088, 	{'train/accuracy': 0.9928005337715149, 'train/loss': 0.02355715073645115, 'train/mean_average_precision': 0.5632063513388179, 'validation/accuracy': 0.9871689677238464, 'validation/loss': 0.044033218175172806, 'validation/mean_average_precision': 0.2946963852039688, 'validation/num_examples': 43793, 'test/accuracy': 0.9863465428352356, 'test/loss': 0.0467548705637455, 'test/mean_average_precision': 0.2776700650850645, 'test/num_examples': 43793, 'score': 17305.338668107986, 'total_duration': 25963.824363708496, 'accumulated_submission_time': 17305.338668107986, 'accumulated_eval_time': 8654.593199968338, 'accumulated_logging_time': 2.378063201904297}
I0215 19:20:47.433154 139791620105984 logging_writer.py:48] [58088] accumulated_eval_time=8654.593200, accumulated_logging_time=2.378063, accumulated_submission_time=17305.338668, global_step=58088, preemption_count=0, score=17305.338668, test/accuracy=0.986347, test/loss=0.046755, test/mean_average_precision=0.277670, test/num_examples=43793, total_duration=25963.824364, train/accuracy=0.992801, train/loss=0.023557, train/mean_average_precision=0.563206, validation/accuracy=0.987169, validation/loss=0.044033, validation/mean_average_precision=0.294696, validation/num_examples=43793
I0215 19:22:48.677345 139797635151616 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.03791493922472, loss=0.025673747062683105
I0215 19:24:47.502132 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:26:37.133798 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:26:40.261098 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:26:43.347197 139966923982656 submission_runner.py:408] Time since start: 26319.76s, 	Step: 58905, 	{'train/accuracy': 0.9927901029586792, 'train/loss': 0.023619329556822777, 'train/mean_average_precision': 0.5718410748175782, 'validation/accuracy': 0.9871616959571838, 'validation/loss': 0.04402972012758255, 'validation/mean_average_precision': 0.2949296928873249, 'validation/num_examples': 43793, 'test/accuracy': 0.9863431453704834, 'test/loss': 0.04674716666340828, 'test/mean_average_precision': 0.2777846611081124, 'test/num_examples': 43793, 'score': 17545.376329660416, 'total_duration': 26319.759618759155, 'accumulated_submission_time': 17545.376329660416, 'accumulated_eval_time': 8770.438215494156, 'accumulated_logging_time': 2.4096548557281494}
I0215 19:26:43.370272 139790408062720 logging_writer.py:48] [58905] accumulated_eval_time=8770.438215, accumulated_logging_time=2.409655, accumulated_submission_time=17545.376330, global_step=58905, preemption_count=0, score=17545.376330, test/accuracy=0.986343, test/loss=0.046747, test/mean_average_precision=0.277785, test/num_examples=43793, total_duration=26319.759619, train/accuracy=0.992790, train/loss=0.023619, train/mean_average_precision=0.571841, validation/accuracy=0.987162, validation/loss=0.044030, validation/mean_average_precision=0.294930, validation/num_examples=43793
I0215 19:27:12.065525 139806056417024 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.041357483714818954, loss=0.026214737445116043
I0215 19:29:40.765956 139790408062720 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.03915497660636902, loss=0.02480485662817955
I0215 19:30:43.548894 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:32:31.619157 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:32:34.893956 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:32:38.034143 139966923982656 submission_runner.py:408] Time since start: 26674.45s, 	Step: 59713, 	{'train/accuracy': 0.9928460717201233, 'train/loss': 0.023473316803574562, 'train/mean_average_precision': 0.5671348820412629, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.0440271832048893, 'validation/mean_average_precision': 0.2948615903910607, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674341157078743, 'test/mean_average_precision': 0.2777324306154021, 'test/num_examples': 43793, 'score': 17785.518886089325, 'total_duration': 26674.446563243866, 'accumulated_submission_time': 17785.518886089325, 'accumulated_eval_time': 8884.923419713974, 'accumulated_logging_time': 2.44377064704895}
I0215 19:32:38.057887 139791620105984 logging_writer.py:48] [59713] accumulated_eval_time=8884.923420, accumulated_logging_time=2.443771, accumulated_submission_time=17785.518886, global_step=59713, preemption_count=0, score=17785.518886, test/accuracy=0.986337, test/loss=0.046743, test/mean_average_precision=0.277732, test/num_examples=43793, total_duration=26674.446563, train/accuracy=0.992846, train/loss=0.023473, train/mean_average_precision=0.567135, validation/accuracy=0.987154, validation/loss=0.044027, validation/mean_average_precision=0.294862, validation/num_examples=43793
I0215 19:34:03.788571 139797635151616 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.036897532641887665, loss=0.023660143837332726
I0215 19:36:33.866451 139791620105984 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.03966694697737694, loss=0.02745944634079933
I0215 19:36:38.076475 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:38:23.364269 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:38:26.263264 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:38:29.122153 139966923982656 submission_runner.py:408] Time since start: 27025.53s, 	Step: 60515, 	{'train/accuracy': 0.9928585290908813, 'train/loss': 0.023436488583683968, 'train/mean_average_precision': 0.5724790527949595, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04402713477611542, 'validation/mean_average_precision': 0.29476442959706234, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674330726265907, 'test/mean_average_precision': 0.2777204631941807, 'test/num_examples': 43793, 'score': 18025.50324702263, 'total_duration': 27025.534484386444, 'accumulated_submission_time': 18025.50324702263, 'accumulated_eval_time': 8995.968944072723, 'accumulated_logging_time': 2.4787518978118896}
I0215 19:38:29.142963 139806048024320 logging_writer.py:48] [60515] accumulated_eval_time=8995.968944, accumulated_logging_time=2.478752, accumulated_submission_time=18025.503247, global_step=60515, preemption_count=0, score=18025.503247, test/accuracy=0.986337, test/loss=0.046743, test/mean_average_precision=0.277720, test/num_examples=43793, total_duration=27025.534484, train/accuracy=0.992859, train/loss=0.023436, train/mean_average_precision=0.572479, validation/accuracy=0.987154, validation/loss=0.044027, validation/mean_average_precision=0.294764, validation/num_examples=43793
I0215 19:40:52.833290 139806056417024 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.039959538727998734, loss=0.024881048128008842
I0215 19:42:29.337818 139966923982656 spec.py:321] Evaluating on the training split.
I0215 19:44:10.373360 139966923982656 spec.py:333] Evaluating on the validation split.
I0215 19:44:13.287223 139966923982656 spec.py:349] Evaluating on the test split.
I0215 19:44:16.170328 139966923982656 submission_runner.py:408] Time since start: 27372.58s, 	Step: 61328, 	{'train/accuracy': 0.9927020072937012, 'train/loss': 0.023759424686431885, 'train/mean_average_precision': 0.5475151945984724, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04402713477611542, 'validation/mean_average_precision': 0.29481765514736197, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674330726265907, 'test/mean_average_precision': 0.2777384469477052, 'test/num_examples': 43793, 'score': 18265.666171073914, 'total_duration': 27372.58276605606, 'accumulated_submission_time': 18265.666171073914, 'accumulated_eval_time': 9102.801436901093, 'accumulated_logging_time': 2.5098509788513184}
I0215 19:44:16.191905 139791620105984 logging_writer.py:48] [61328] accumulated_eval_time=9102.801437, accumulated_logging_time=2.509851, accumulated_submission_time=18265.666171, global_step=61328, preemption_count=0, score=18265.666171, test/accuracy=0.986337, test/loss=0.046743, test/mean_average_precision=0.277738, test/num_examples=43793, total_duration=27372.582766, train/accuracy=0.992702, train/loss=0.023759, train/mean_average_precision=0.547515, validation/accuracy=0.987154, validation/loss=0.044027, validation/mean_average_precision=0.294818, validation/num_examples=43793
I0215 19:45:07.561706 139797635151616 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.040057405829429626, loss=0.025056954473257065
I0215 19:47:36.897791 139791620105984 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.03642294928431511, loss=0.02398775704205036
I0215 19:47:47.803606 139797635151616 logging_writer.py:48] [62038] global_step=62038, preemption_count=0, score=18477.237470
I0215 19:47:47.854125 139966923982656 checkpoints.py:490] Saving checkpoint at step: 62038
I0215 19:47:47.964516 139966923982656 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1/checkpoint_62038
I0215 19:47:47.965620 139966923982656 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/ogbg_silu_jax/trial_1/checkpoint_62038.
I0215 19:47:48.144767 139966923982656 submission_runner.py:583] Tuning trial 1/1
I0215 19:47:48.144987 139966923982656 submission_runner.py:584] Hyperparameters: Hyperparameters(learning_rate=0.00027866530268792414, beta1=0.9919340993463499, beta2=0.9979843253162892, warmup_steps=6000, weight_decay=0.00032418357325210813)
I0215 19:47:48.149558 139966923982656 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/accuracy': 0.507875919342041, 'train/loss': 0.7331976294517517, 'train/mean_average_precision': 0.020742417550586277, 'validation/accuracy': 0.5152865052223206, 'validation/loss': 0.7278426289558411, 'validation/mean_average_precision': 0.024839994554343717, 'validation/num_examples': 43793, 'test/accuracy': 0.5164411067962646, 'test/loss': 0.7269362807273865, 'test/mean_average_precision': 0.026327797636932982, 'test/num_examples': 43793, 'score': 19.459041833877563, 'total_duration': 317.75520968437195, 'accumulated_submission_time': 19.459041833877563, 'accumulated_eval_time': 298.296128988266, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (812, {'train/accuracy': 0.986688494682312, 'train/loss': 0.12248104810714722, 'train/mean_average_precision': 0.02750603040144635, 'validation/accuracy': 0.9839299917221069, 'validation/loss': 0.1292034238576889, 'validation/mean_average_precision': 0.02771898750607727, 'validation/num_examples': 43793, 'test/accuracy': 0.9828940033912659, 'test/loss': 0.13195043802261353, 'test/mean_average_precision': 0.028677714295364674, 'test/num_examples': 43793, 'score': 259.4525671005249, 'total_duration': 668.7071697711945, 'accumulated_submission_time': 259.4525671005249, 'accumulated_eval_time': 409.20367765426636, 'accumulated_logging_time': 0.030760526657104492, 'global_step': 812, 'preemption_count': 0}), (1625, {'train/accuracy': 0.9867749214172363, 'train/loss': 0.05773906409740448, 'train/mean_average_precision': 0.031329471085523676, 'validation/accuracy': 0.9841179251670837, 'validation/loss': 0.06707639247179031, 'validation/mean_average_precision': 0.03095288530747215, 'validation/num_examples': 43793, 'test/accuracy': 0.983142077922821, 'test/loss': 0.07025604695081711, 'test/mean_average_precision': 0.033129887382684735, 'test/num_examples': 43793, 'score': 499.5041480064392, 'total_duration': 1023.6299650669098, 'accumulated_submission_time': 499.5041480064392, 'accumulated_eval_time': 524.0296378135681, 'accumulated_logging_time': 0.05606341361999512, 'global_step': 1625, 'preemption_count': 0}), (2405, {'train/accuracy': 0.9867736101150513, 'train/loss': 0.05535279959440231, 'train/mean_average_precision': 0.035655890236070215, 'validation/accuracy': 0.9841179251670837, 'validation/loss': 0.06524951756000519, 'validation/mean_average_precision': 0.03342550755470287, 'validation/num_examples': 43793, 'test/accuracy': 0.983142077922821, 'test/loss': 0.06860329955816269, 'test/mean_average_precision': 0.035376559349092354, 'test/num_examples': 43793, 'score': 739.7390007972717, 'total_duration': 1379.478887796402, 'accumulated_submission_time': 739.7390007972717, 'accumulated_eval_time': 639.5985925197601, 'accumulated_logging_time': 0.08169317245483398, 'global_step': 2405, 'preemption_count': 0}), (3226, {'train/accuracy': 0.9868510365486145, 'train/loss': 0.0520760603249073, 'train/mean_average_precision': 0.04524206544861335, 'validation/accuracy': 0.984256386756897, 'validation/loss': 0.06116614118218422, 'validation/mean_average_precision': 0.04835399943379553, 'validation/num_examples': 43793, 'test/accuracy': 0.9832292795181274, 'test/loss': 0.06427371501922607, 'test/mean_average_precision': 0.05036697216385039, 'test/num_examples': 43793, 'score': 979.8202588558197, 'total_duration': 1741.642778635025, 'accumulated_submission_time': 979.8202588558197, 'accumulated_eval_time': 761.6270353794098, 'accumulated_logging_time': 0.11043119430541992, 'global_step': 3226, 'preemption_count': 0}), (4045, {'train/accuracy': 0.9872231483459473, 'train/loss': 0.04754548892378807, 'train/mean_average_precision': 0.08638442899440588, 'validation/accuracy': 0.9845835566520691, 'validation/loss': 0.05689027160406113, 'validation/mean_average_precision': 0.08554132287431046, 'validation/num_examples': 43793, 'test/accuracy': 0.9836074709892273, 'test/loss': 0.06014932319521904, 'test/mean_average_precision': 0.08913040562576426, 'test/num_examples': 43793, 'score': 1219.7688448429108, 'total_duration': 2098.676433801651, 'accumulated_submission_time': 1219.7688448429108, 'accumulated_eval_time': 878.657918214798, 'accumulated_logging_time': 0.13998150825500488, 'global_step': 4045, 'preemption_count': 0}), (4854, {'train/accuracy': 0.9876218438148499, 'train/loss': 0.0448886938393116, 'train/mean_average_precision': 0.11546495425643877, 'validation/accuracy': 0.9848859906196594, 'validation/loss': 0.05425715446472168, 'validation/mean_average_precision': 0.11801370400965205, 'validation/num_examples': 43793, 'test/accuracy': 0.9839174747467041, 'test/loss': 0.05742313340306282, 'test/mean_average_precision': 0.11541597881688358, 'test/num_examples': 43793, 'score': 1459.9423220157623, 'total_duration': 2456.897770166397, 'accumulated_submission_time': 1459.9423220157623, 'accumulated_eval_time': 996.6584203243256, 'accumulated_logging_time': 0.1666727066040039, 'global_step': 4854, 'preemption_count': 0}), (5674, {'train/accuracy': 0.9878240823745728, 'train/loss': 0.04323236644268036, 'train/mean_average_precision': 0.14374011980927554, 'validation/accuracy': 0.985043466091156, 'validation/loss': 0.052253272384405136, 'validation/mean_average_precision': 0.13732479338899667, 'validation/num_examples': 43793, 'test/accuracy': 0.9841259717941284, 'test/loss': 0.054881494492292404, 'test/mean_average_precision': 0.1412263903795737, 'test/num_examples': 43793, 'score': 1699.902087688446, 'total_duration': 2817.1464829444885, 'accumulated_submission_time': 1699.902087688446, 'accumulated_eval_time': 1116.9015319347382, 'accumulated_logging_time': 0.19225692749023438, 'global_step': 5674, 'preemption_count': 0}), (6497, {'train/accuracy': 0.9882999062538147, 'train/loss': 0.04093027487397194, 'train/mean_average_precision': 0.1771145461969626, 'validation/accuracy': 0.9853739142417908, 'validation/loss': 0.05066031962633133, 'validation/mean_average_precision': 0.15778203761557613, 'validation/num_examples': 43793, 'test/accuracy': 0.9843774437904358, 'test/loss': 0.05358709394931793, 'test/mean_average_precision': 0.1573734508817491, 'test/num_examples': 43793, 'score': 1939.9818263053894, 'total_duration': 3177.173084974289, 'accumulated_submission_time': 1939.9818263053894, 'accumulated_eval_time': 1236.8000538349152, 'accumulated_logging_time': 0.21960043907165527, 'global_step': 6497, 'preemption_count': 0}), (7309, {'train/accuracy': 0.9885411858558655, 'train/loss': 0.03985226899385452, 'train/mean_average_precision': 0.19027161630262526, 'validation/accuracy': 0.9855537414550781, 'validation/loss': 0.04931538179516792, 'validation/mean_average_precision': 0.17260613083797913, 'validation/num_examples': 43793, 'test/accuracy': 0.9846149682998657, 'test/loss': 0.051854778081178665, 'test/mean_average_precision': 0.17889229812943744, 'test/num_examples': 43793, 'score': 2180.115610599518, 'total_duration': 3538.0333960056305, 'accumulated_submission_time': 2180.115610599518, 'accumulated_eval_time': 1357.4799344539642, 'accumulated_logging_time': 0.24556255340576172, 'global_step': 7309, 'preemption_count': 0}), (8122, {'train/accuracy': 0.9885822534561157, 'train/loss': 0.0391816683113575, 'train/mean_average_precision': 0.21031830855263287, 'validation/accuracy': 0.9856284260749817, 'validation/loss': 0.04869327321648598, 'validation/mean_average_precision': 0.19181989493822094, 'validation/num_examples': 43793, 'test/accuracy': 0.9847168922424316, 'test/loss': 0.05128267779946327, 'test/mean_average_precision': 0.18740903411467835, 'test/num_examples': 43793, 'score': 2420.286457300186, 'total_duration': 3897.0114035606384, 'accumulated_submission_time': 2420.286457300186, 'accumulated_eval_time': 1476.2404344081879, 'accumulated_logging_time': 0.2720458507537842, 'global_step': 8122, 'preemption_count': 0}), (8929, {'train/accuracy': 0.9887849688529968, 'train/loss': 0.038370873779058456, 'train/mean_average_precision': 0.21808191701822913, 'validation/accuracy': 0.9857993125915527, 'validation/loss': 0.04799116775393486, 'validation/mean_average_precision': 0.19991889967266255, 'validation/num_examples': 43793, 'test/accuracy': 0.9849056005477905, 'test/loss': 0.050656020641326904, 'test/mean_average_precision': 0.19460340921404795, 'test/num_examples': 43793, 'score': 2660.294540166855, 'total_duration': 4256.978956699371, 'accumulated_submission_time': 2660.294540166855, 'accumulated_eval_time': 1596.1477723121643, 'accumulated_logging_time': 0.3037993907928467, 'global_step': 8929, 'preemption_count': 0}), (9733, {'train/accuracy': 0.9889710545539856, 'train/loss': 0.037631433457136154, 'train/mean_average_precision': 0.226781729507266, 'validation/accuracy': 0.9859166741371155, 'validation/loss': 0.047313857823610306, 'validation/mean_average_precision': 0.20014143431840245, 'validation/num_examples': 43793, 'test/accuracy': 0.9850319623947144, 'test/loss': 0.05004492774605751, 'test/mean_average_precision': 0.20285669880780588, 'test/num_examples': 43793, 'score': 2900.2773122787476, 'total_duration': 4616.750051021576, 'accumulated_submission_time': 2900.2773122787476, 'accumulated_eval_time': 1715.8894956111908, 'accumulated_logging_time': 0.32991838455200195, 'global_step': 9733, 'preemption_count': 0}), (10535, {'train/accuracy': 0.9891827702522278, 'train/loss': 0.03695739060640335, 'train/mean_average_precision': 0.26241999960353013, 'validation/accuracy': 0.9860400557518005, 'validation/loss': 0.04695615917444229, 'validation/mean_average_precision': 0.21661746215187952, 'validation/num_examples': 43793, 'test/accuracy': 0.9851511716842651, 'test/loss': 0.04964252561330795, 'test/mean_average_precision': 0.20986765577995567, 'test/num_examples': 43793, 'score': 3140.355771303177, 'total_duration': 4975.040405511856, 'accumulated_submission_time': 3140.355771303177, 'accumulated_eval_time': 1834.0504338741302, 'accumulated_logging_time': 0.3601968288421631, 'global_step': 10535, 'preemption_count': 0}), (11339, {'train/accuracy': 0.9892692565917969, 'train/loss': 0.036318596452474594, 'train/mean_average_precision': 0.265456507051378, 'validation/accuracy': 0.9861407279968262, 'validation/loss': 0.04664755240082741, 'validation/mean_average_precision': 0.21757290624002315, 'validation/num_examples': 43793, 'test/accuracy': 0.9852438569068909, 'test/loss': 0.049395035952329636, 'test/mean_average_precision': 0.21484294849309607, 'test/num_examples': 43793, 'score': 3380.4808537960052, 'total_duration': 5336.932815074921, 'accumulated_submission_time': 3380.4808537960052, 'accumulated_eval_time': 1955.7705969810486, 'accumulated_logging_time': 0.38653016090393066, 'global_step': 11339, 'preemption_count': 0}), (12156, {'train/accuracy': 0.989429235458374, 'train/loss': 0.03587840870022774, 'train/mean_average_precision': 0.28034609122530857, 'validation/accuracy': 0.9861833453178406, 'validation/loss': 0.046157948672771454, 'validation/mean_average_precision': 0.22859804131391764, 'validation/num_examples': 43793, 'test/accuracy': 0.9852661490440369, 'test/loss': 0.04894324764609337, 'test/mean_average_precision': 0.22391472256516748, 'test/num_examples': 43793, 'score': 3620.7080216407776, 'total_duration': 5696.765793085098, 'accumulated_submission_time': 3620.7080216407776, 'accumulated_eval_time': 2075.329130411148, 'accumulated_logging_time': 0.41293811798095703, 'global_step': 12156, 'preemption_count': 0}), (12968, {'train/accuracy': 0.9894845485687256, 'train/loss': 0.035418786108493805, 'train/mean_average_precision': 0.2879518361699949, 'validation/accuracy': 0.9862824082374573, 'validation/loss': 0.045907240360975266, 'validation/mean_average_precision': 0.23091269995786512, 'validation/num_examples': 43793, 'test/accuracy': 0.9854333400726318, 'test/loss': 0.04850640520453453, 'test/mean_average_precision': 0.2279723798337183, 'test/num_examples': 43793, 'score': 3860.760322570801, 'total_duration': 6052.679210662842, 'accumulated_submission_time': 3860.760322570801, 'accumulated_eval_time': 2191.142496109009, 'accumulated_logging_time': 0.4399683475494385, 'global_step': 12968, 'preemption_count': 0}), (13766, {'train/accuracy': 0.9895428419113159, 'train/loss': 0.03540043905377388, 'train/mean_average_precision': 0.2914965546646352, 'validation/accuracy': 0.9862954020500183, 'validation/loss': 0.04585558548569679, 'validation/mean_average_precision': 0.23306611751806486, 'validation/num_examples': 43793, 'test/accuracy': 0.9854245185852051, 'test/loss': 0.04817903786897659, 'test/mean_average_precision': 0.22677191544154993, 'test/num_examples': 43793, 'score': 4100.829528808594, 'total_duration': 6412.598387718201, 'accumulated_submission_time': 4100.829528808594, 'accumulated_eval_time': 2310.945030450821, 'accumulated_logging_time': 0.466719388961792, 'global_step': 13766, 'preemption_count': 0}), (14569, {'train/accuracy': 0.9897654056549072, 'train/loss': 0.03436538204550743, 'train/mean_average_precision': 0.30466631071288325, 'validation/accuracy': 0.986381471157074, 'validation/loss': 0.04537307098507881, 'validation/mean_average_precision': 0.2393889000678359, 'validation/num_examples': 43793, 'test/accuracy': 0.9855656027793884, 'test/loss': 0.048058606684207916, 'test/mean_average_precision': 0.23099490841367776, 'test/num_examples': 43793, 'score': 4340.907742738724, 'total_duration': 6771.515719175339, 'accumulated_submission_time': 4340.907742738724, 'accumulated_eval_time': 2429.73672413826, 'accumulated_logging_time': 0.4936976432800293, 'global_step': 14569, 'preemption_count': 0}), (15376, {'train/accuracy': 0.9898204803466797, 'train/loss': 0.03410983458161354, 'train/mean_average_precision': 0.3179693093784152, 'validation/accuracy': 0.9863494038581848, 'validation/loss': 0.045159485191106796, 'validation/mean_average_precision': 0.24178942115995597, 'validation/num_examples': 43793, 'test/accuracy': 0.9855290055274963, 'test/loss': 0.04780951887369156, 'test/mean_average_precision': 0.23717360011933078, 'test/num_examples': 43793, 'score': 4580.998894929886, 'total_duration': 7128.714997291565, 'accumulated_submission_time': 4580.998894929886, 'accumulated_eval_time': 2546.7970888614655, 'accumulated_logging_time': 0.5205397605895996, 'global_step': 15376, 'preemption_count': 0}), (16187, {'train/accuracy': 0.9900246262550354, 'train/loss': 0.03348606079816818, 'train/mean_average_precision': 0.3269363686000759, 'validation/accuracy': 0.9865214824676514, 'validation/loss': 0.045325011014938354, 'validation/mean_average_precision': 0.24810808830464015, 'validation/num_examples': 43793, 'test/accuracy': 0.9857648611068726, 'test/loss': 0.047938764095306396, 'test/mean_average_precision': 0.24036100791963058, 'test/num_examples': 43793, 'score': 4821.05975985527, 'total_duration': 7489.376768112183, 'accumulated_submission_time': 4821.05975985527, 'accumulated_eval_time': 2667.3502099514008, 'accumulated_logging_time': 0.5480506420135498, 'global_step': 16187, 'preemption_count': 0}), (16992, {'train/accuracy': 0.9900742769241333, 'train/loss': 0.03327163681387901, 'train/mean_average_precision': 0.3445456189051544, 'validation/accuracy': 0.9865637421607971, 'validation/loss': 0.04504217952489853, 'validation/mean_average_precision': 0.24155739383687774, 'validation/num_examples': 43793, 'test/accuracy': 0.9857004284858704, 'test/loss': 0.047561001032590866, 'test/mean_average_precision': 0.24076251324080797, 'test/num_examples': 43793, 'score': 5061.23433971405, 'total_duration': 7846.2171087265015, 'accumulated_submission_time': 5061.23433971405, 'accumulated_eval_time': 2783.9670729637146, 'accumulated_logging_time': 0.5762526988983154, 'global_step': 16992, 'preemption_count': 0}), (17801, {'train/accuracy': 0.9900335669517517, 'train/loss': 0.03330467268824577, 'train/mean_average_precision': 0.3374570451025274, 'validation/accuracy': 0.9866286516189575, 'validation/loss': 0.04511040076613426, 'validation/mean_average_precision': 0.25338644999994203, 'validation/num_examples': 43793, 'test/accuracy': 0.9858006238937378, 'test/loss': 0.04767586290836334, 'test/mean_average_precision': 0.24528595571451142, 'test/num_examples': 43793, 'score': 5301.316188812256, 'total_duration': 8205.125508069992, 'accumulated_submission_time': 5301.316188812256, 'accumulated_eval_time': 2902.7459239959717, 'accumulated_logging_time': 0.6034753322601318, 'global_step': 17801, 'preemption_count': 0}), (18599, {'train/accuracy': 0.9902493357658386, 'train/loss': 0.032605305314064026, 'train/mean_average_precision': 0.35363536517197114, 'validation/accuracy': 0.9867119193077087, 'validation/loss': 0.04457935690879822, 'validation/mean_average_precision': 0.25751828092768475, 'validation/num_examples': 43793, 'test/accuracy': 0.9858478307723999, 'test/loss': 0.04730139672756195, 'test/mean_average_precision': 0.24531509094569984, 'test/num_examples': 43793, 'score': 5541.519265174866, 'total_duration': 8561.297830581665, 'accumulated_submission_time': 5541.519265174866, 'accumulated_eval_time': 3018.665987968445, 'accumulated_logging_time': 0.6323001384735107, 'global_step': 18599, 'preemption_count': 0}), (19409, {'train/accuracy': 0.9903755187988281, 'train/loss': 0.03200766071677208, 'train/mean_average_precision': 0.3538674814637105, 'validation/accuracy': 0.9866676330566406, 'validation/loss': 0.044572941958904266, 'validation/mean_average_precision': 0.2566782032295166, 'validation/num_examples': 43793, 'test/accuracy': 0.9858659505844116, 'test/loss': 0.047258954495191574, 'test/mean_average_precision': 0.24414256673950557, 'test/num_examples': 43793, 'score': 5781.565552711487, 'total_duration': 8919.22297334671, 'accumulated_submission_time': 5781.565552711487, 'accumulated_eval_time': 3136.4967041015625, 'accumulated_logging_time': 0.6596133708953857, 'global_step': 19409, 'preemption_count': 0}), (20219, {'train/accuracy': 0.9905173778533936, 'train/loss': 0.03172795847058296, 'train/mean_average_precision': 0.37577506434043795, 'validation/accuracy': 0.9867187738418579, 'validation/loss': 0.044347889721393585, 'validation/mean_average_precision': 0.26126878191316366, 'validation/num_examples': 43793, 'test/accuracy': 0.9858967065811157, 'test/loss': 0.04698492959141731, 'test/mean_average_precision': 0.2507108852284147, 'test/num_examples': 43793, 'score': 6021.578060865402, 'total_duration': 9275.294137239456, 'accumulated_submission_time': 6021.578060865402, 'accumulated_eval_time': 3252.50604057312, 'accumulated_logging_time': 0.6888718605041504, 'global_step': 20219, 'preemption_count': 0}), (21036, {'train/accuracy': 0.990422248840332, 'train/loss': 0.031691282987594604, 'train/mean_average_precision': 0.39188797776329515, 'validation/accuracy': 0.9866907596588135, 'validation/loss': 0.04435187205672264, 'validation/mean_average_precision': 0.26082665096109553, 'validation/num_examples': 43793, 'test/accuracy': 0.9859160780906677, 'test/loss': 0.046863798052072525, 'test/mean_average_precision': 0.254087313650629, 'test/num_examples': 43793, 'score': 6261.6524839401245, 'total_duration': 9633.73119711876, 'accumulated_submission_time': 6261.6524839401245, 'accumulated_eval_time': 3370.818108558655, 'accumulated_logging_time': 0.7184669971466064, 'global_step': 21036, 'preemption_count': 0}), (21838, {'train/accuracy': 0.9906229972839355, 'train/loss': 0.031069735065102577, 'train/mean_average_precision': 0.3855145944649325, 'validation/accuracy': 0.9867740273475647, 'validation/loss': 0.04431076720356941, 'validation/mean_average_precision': 0.25802745119611453, 'validation/num_examples': 43793, 'test/accuracy': 0.9859228134155273, 'test/loss': 0.047091368585824966, 'test/mean_average_precision': 0.249835863245651, 'test/num_examples': 43793, 'score': 6501.885349273682, 'total_duration': 9995.653681278229, 'accumulated_submission_time': 6501.885349273682, 'accumulated_eval_time': 3492.459653377533, 'accumulated_logging_time': 0.7457904815673828, 'global_step': 21838, 'preemption_count': 0}), (22648, {'train/accuracy': 0.9905841946601868, 'train/loss': 0.03130149096250534, 'train/mean_average_precision': 0.3790522162902059, 'validation/accuracy': 0.9867504835128784, 'validation/loss': 0.043949104845523834, 'validation/mean_average_precision': 0.2669128302284818, 'validation/num_examples': 43793, 'test/accuracy': 0.9859505891799927, 'test/loss': 0.04667949303984642, 'test/mean_average_precision': 0.25686423406119024, 'test/num_examples': 43793, 'score': 6742.0169196128845, 'total_duration': 10353.376420259476, 'accumulated_submission_time': 6742.0169196128845, 'accumulated_eval_time': 3610.0016040802, 'accumulated_logging_time': 0.7745993137359619, 'global_step': 22648, 'preemption_count': 0}), (23452, {'train/accuracy': 0.9907667636871338, 'train/loss': 0.03056093491613865, 'train/mean_average_precision': 0.40440791967444173, 'validation/accuracy': 0.9868462681770325, 'validation/loss': 0.043912146240472794, 'validation/mean_average_precision': 0.26993367904816756, 'validation/num_examples': 43793, 'test/accuracy': 0.9860761165618896, 'test/loss': 0.046727124601602554, 'test/mean_average_precision': 0.2576107535043137, 'test/num_examples': 43793, 'score': 6982.030026435852, 'total_duration': 10716.43726348877, 'accumulated_submission_time': 6982.030026435852, 'accumulated_eval_time': 3732.9993028640747, 'accumulated_logging_time': 0.8038833141326904, 'global_step': 23452, 'preemption_count': 0}), (24260, {'train/accuracy': 0.9909623265266418, 'train/loss': 0.029766002669930458, 'train/mean_average_precision': 0.41940171796483494, 'validation/accuracy': 0.9868823885917664, 'validation/loss': 0.04384058713912964, 'validation/mean_average_precision': 0.26836681562728504, 'validation/num_examples': 43793, 'test/accuracy': 0.9860853552818298, 'test/loss': 0.04656834900379181, 'test/mean_average_precision': 0.26062431937039815, 'test/num_examples': 43793, 'score': 7222.11169719696, 'total_duration': 11076.157317876816, 'accumulated_submission_time': 7222.11169719696, 'accumulated_eval_time': 3852.588265657425, 'accumulated_logging_time': 0.8326950073242188, 'global_step': 24260, 'preemption_count': 0}), (25069, {'train/accuracy': 0.990950882434845, 'train/loss': 0.029953274875879288, 'train/mean_average_precision': 0.4115317897795978, 'validation/accuracy': 0.9869027137756348, 'validation/loss': 0.043803922832012177, 'validation/mean_average_precision': 0.2743862249327082, 'validation/num_examples': 43793, 'test/accuracy': 0.9861119389533997, 'test/loss': 0.0466546006500721, 'test/mean_average_precision': 0.264762448694804, 'test/num_examples': 43793, 'score': 7462.0897653102875, 'total_duration': 11430.070878505707, 'accumulated_submission_time': 7462.0897653102875, 'accumulated_eval_time': 3966.474953651428, 'accumulated_logging_time': 0.8610608577728271, 'global_step': 25069, 'preemption_count': 0}), (25886, {'train/accuracy': 0.991039514541626, 'train/loss': 0.029489755630493164, 'train/mean_average_precision': 0.44179683320828744, 'validation/accuracy': 0.9868088960647583, 'validation/loss': 0.04370144009590149, 'validation/mean_average_precision': 0.2722742988572569, 'validation/num_examples': 43793, 'test/accuracy': 0.986108124256134, 'test/loss': 0.04627009853720665, 'test/mean_average_precision': 0.2653236445862466, 'test/num_examples': 43793, 'score': 7702.255370616913, 'total_duration': 11785.821524620056, 'accumulated_submission_time': 7702.255370616913, 'accumulated_eval_time': 4082.010786294937, 'accumulated_logging_time': 0.8897280693054199, 'global_step': 25886, 'preemption_count': 0}), (26697, {'train/accuracy': 0.9911208748817444, 'train/loss': 0.029216982424259186, 'train/mean_average_precision': 0.42331531350123414, 'validation/accuracy': 0.9868852496147156, 'validation/loss': 0.04372667521238327, 'validation/mean_average_precision': 0.27677687156353764, 'validation/num_examples': 43793, 'test/accuracy': 0.9860908389091492, 'test/loss': 0.04649693891406059, 'test/mean_average_precision': 0.26374389544943055, 'test/num_examples': 43793, 'score': 7942.221064567566, 'total_duration': 12144.46783876419, 'accumulated_submission_time': 7942.221064567566, 'accumulated_eval_time': 4200.643081188202, 'accumulated_logging_time': 0.9173181056976318, 'global_step': 26697, 'preemption_count': 0}), (27497, {'train/accuracy': 0.9911388158798218, 'train/loss': 0.029260478913784027, 'train/mean_average_precision': 0.43769930355847364, 'validation/accuracy': 0.9868178367614746, 'validation/loss': 0.043730732053518295, 'validation/mean_average_precision': 0.27876411580704547, 'validation/num_examples': 43793, 'test/accuracy': 0.986030638217926, 'test/loss': 0.046461090445518494, 'test/mean_average_precision': 0.2647588595610969, 'test/num_examples': 43793, 'score': 8182.339218378067, 'total_duration': 12500.639820814133, 'accumulated_submission_time': 8182.339218378067, 'accumulated_eval_time': 4316.64834022522, 'accumulated_logging_time': 0.9455633163452148, 'global_step': 27497, 'preemption_count': 0}), (28307, {'train/accuracy': 0.9914506077766418, 'train/loss': 0.028327034786343575, 'train/mean_average_precision': 0.452242620813476, 'validation/accuracy': 0.9868357181549072, 'validation/loss': 0.043510861694812775, 'validation/mean_average_precision': 0.27998793861288385, 'validation/num_examples': 43793, 'test/accuracy': 0.9860205054283142, 'test/loss': 0.04633352905511856, 'test/mean_average_precision': 0.26633469470482024, 'test/num_examples': 43793, 'score': 8422.291805744171, 'total_duration': 12859.048772335052, 'accumulated_submission_time': 8422.291805744171, 'accumulated_eval_time': 4435.054961681366, 'accumulated_logging_time': 0.9742684364318848, 'global_step': 28307, 'preemption_count': 0}), (29116, {'train/accuracy': 0.9913336634635925, 'train/loss': 0.028675558045506477, 'train/mean_average_precision': 0.45792586088964016, 'validation/accuracy': 0.986702561378479, 'validation/loss': 0.04388319328427315, 'validation/mean_average_precision': 0.27786520909647067, 'validation/num_examples': 43793, 'test/accuracy': 0.9858849048614502, 'test/loss': 0.04656077176332474, 'test/mean_average_precision': 0.2703301182507443, 'test/num_examples': 43793, 'score': 8662.452748060226, 'total_duration': 13220.005733966827, 'accumulated_submission_time': 8662.452748060226, 'accumulated_eval_time': 4555.800324678421, 'accumulated_logging_time': 1.0042052268981934, 'global_step': 29116, 'preemption_count': 0}), (29914, {'train/accuracy': 0.9914525747299194, 'train/loss': 0.028125496581196785, 'train/mean_average_precision': 0.4683592043657039, 'validation/accuracy': 0.9868706464767456, 'validation/loss': 0.043644268065690994, 'validation/mean_average_precision': 0.28004715880163983, 'validation/num_examples': 43793, 'test/accuracy': 0.9860668182373047, 'test/loss': 0.046336352825164795, 'test/mean_average_precision': 0.2672884705407264, 'test/num_examples': 43793, 'score': 8902.502653598785, 'total_duration': 13581.903505802155, 'accumulated_submission_time': 8902.502653598785, 'accumulated_eval_time': 4677.592744588852, 'accumulated_logging_time': 1.0346863269805908, 'global_step': 29914, 'preemption_count': 0}), (30711, {'train/accuracy': 0.9914335608482361, 'train/loss': 0.028026077896356583, 'train/mean_average_precision': 0.45931166006995217, 'validation/accuracy': 0.9869940280914307, 'validation/loss': 0.043538205325603485, 'validation/mean_average_precision': 0.27928126038980905, 'validation/num_examples': 43793, 'test/accuracy': 0.9861700534820557, 'test/loss': 0.04625357687473297, 'test/mean_average_precision': 0.266500297897029, 'test/num_examples': 43793, 'score': 9142.599684000015, 'total_duration': 13942.417710542679, 'accumulated_submission_time': 9142.599684000015, 'accumulated_eval_time': 4797.953253269196, 'accumulated_logging_time': 1.0668222904205322, 'global_step': 30711, 'preemption_count': 0}), (31512, {'train/accuracy': 0.9916025996208191, 'train/loss': 0.027679599821567535, 'train/mean_average_precision': 0.4661219092356754, 'validation/accuracy': 0.9869956374168396, 'validation/loss': 0.043523550033569336, 'validation/mean_average_precision': 0.28240882389263167, 'validation/num_examples': 43793, 'test/accuracy': 0.9861489534378052, 'test/loss': 0.04628578945994377, 'test/mean_average_precision': 0.2686872834085632, 'test/num_examples': 43793, 'score': 9382.76790690422, 'total_duration': 14301.700232744217, 'accumulated_submission_time': 9382.76790690422, 'accumulated_eval_time': 4917.017812490463, 'accumulated_logging_time': 1.0954830646514893, 'global_step': 31512, 'preemption_count': 0}), (32316, {'train/accuracy': 0.9916626214981079, 'train/loss': 0.027442244812846184, 'train/mean_average_precision': 0.47553251275467934, 'validation/accuracy': 0.9870054125785828, 'validation/loss': 0.04352150484919548, 'validation/mean_average_precision': 0.28301205810455077, 'validation/num_examples': 43793, 'test/accuracy': 0.9861898422241211, 'test/loss': 0.04625026881694794, 'test/mean_average_precision': 0.26858153768580867, 'test/num_examples': 43793, 'score': 9622.83142876625, 'total_duration': 14659.894820928574, 'accumulated_submission_time': 9622.83142876625, 'accumulated_eval_time': 5035.09934258461, 'accumulated_logging_time': 1.1243128776550293, 'global_step': 32316, 'preemption_count': 0}), (33113, {'train/accuracy': 0.9917760491371155, 'train/loss': 0.027025550603866577, 'train/mean_average_precision': 0.4986171057037929, 'validation/accuracy': 0.9870979189872742, 'validation/loss': 0.04350908845663071, 'validation/mean_average_precision': 0.2870855395922874, 'validation/num_examples': 43793, 'test/accuracy': 0.9862732291221619, 'test/loss': 0.046169281005859375, 'test/mean_average_precision': 0.2696226061468317, 'test/num_examples': 43793, 'score': 9863.016050577164, 'total_duration': 15019.054170131683, 'accumulated_submission_time': 9863.016050577164, 'accumulated_eval_time': 5154.024688959122, 'accumulated_logging_time': 1.1530115604400635, 'global_step': 33113, 'preemption_count': 0}), (33925, {'train/accuracy': 0.9918119311332703, 'train/loss': 0.026902688667178154, 'train/mean_average_precision': 0.4936205999185998, 'validation/accuracy': 0.9869672060012817, 'validation/loss': 0.04383549839258194, 'validation/mean_average_precision': 0.28230821743017753, 'validation/num_examples': 43793, 'test/accuracy': 0.9861552715301514, 'test/loss': 0.04641077667474747, 'test/mean_average_precision': 0.26779683300393964, 'test/num_examples': 43793, 'score': 10103.158504009247, 'total_duration': 15377.541278362274, 'accumulated_submission_time': 10103.158504009247, 'accumulated_eval_time': 5272.320310592651, 'accumulated_logging_time': 1.1811866760253906, 'global_step': 33925, 'preemption_count': 0}), (34728, {'train/accuracy': 0.9917868375778198, 'train/loss': 0.02680364064872265, 'train/mean_average_precision': 0.49740441558866844, 'validation/accuracy': 0.9870249032974243, 'validation/loss': 0.04395166411995888, 'validation/mean_average_precision': 0.28355856142474234, 'validation/num_examples': 43793, 'test/accuracy': 0.9862454533576965, 'test/loss': 0.046687837690114975, 'test/mean_average_precision': 0.26949119835803087, 'test/num_examples': 43793, 'score': 10342.95653629303, 'total_duration': 15735.199508666992, 'accumulated_submission_time': 10342.95653629303, 'accumulated_eval_time': 5389.863627910614, 'accumulated_logging_time': 1.477172613143921, 'global_step': 34728, 'preemption_count': 0}), (35531, {'train/accuracy': 0.9917834997177124, 'train/loss': 0.02703705243766308, 'train/mean_average_precision': 0.48823947776446663, 'validation/accuracy': 0.987052857875824, 'validation/loss': 0.043717317283153534, 'validation/mean_average_precision': 0.2838738336038106, 'validation/num_examples': 43793, 'test/accuracy': 0.986253023147583, 'test/loss': 0.04643681272864342, 'test/mean_average_precision': 0.273511011319587, 'test/num_examples': 43793, 'score': 10583.00742483139, 'total_duration': 16091.597248792648, 'accumulated_submission_time': 10583.00742483139, 'accumulated_eval_time': 5506.160814285278, 'accumulated_logging_time': 1.5064325332641602, 'global_step': 35531, 'preemption_count': 0}), (36336, {'train/accuracy': 0.992019772529602, 'train/loss': 0.02626228705048561, 'train/mean_average_precision': 0.4996973152106786, 'validation/accuracy': 0.9870671033859253, 'validation/loss': 0.04361997917294502, 'validation/mean_average_precision': 0.28569757013246677, 'validation/num_examples': 43793, 'test/accuracy': 0.9862290024757385, 'test/loss': 0.046415217220783234, 'test/mean_average_precision': 0.2722847035275321, 'test/num_examples': 43793, 'score': 10823.180500984192, 'total_duration': 16448.800787448883, 'accumulated_submission_time': 10823.180500984192, 'accumulated_eval_time': 5623.139890670776, 'accumulated_logging_time': 1.5369884967803955, 'global_step': 36336, 'preemption_count': 0}), (37143, {'train/accuracy': 0.9919503927230835, 'train/loss': 0.026459207758307457, 'train/mean_average_precision': 0.5022079941113572, 'validation/accuracy': 0.9871016144752502, 'validation/loss': 0.043582625687122345, 'validation/mean_average_precision': 0.28610105872813213, 'validation/num_examples': 43793, 'test/accuracy': 0.9862567782402039, 'test/loss': 0.04632896929979324, 'test/mean_average_precision': 0.27192628605127944, 'test/num_examples': 43793, 'score': 11063.384637832642, 'total_duration': 16803.807886123657, 'accumulated_submission_time': 11063.384637832642, 'accumulated_eval_time': 5737.892679691315, 'accumulated_logging_time': 1.5662016868591309, 'global_step': 37143, 'preemption_count': 0}), (37951, {'train/accuracy': 0.992009162902832, 'train/loss': 0.026190653443336487, 'train/mean_average_precision': 0.5092364715896418, 'validation/accuracy': 0.9869583249092102, 'validation/loss': 0.043758414685726166, 'validation/mean_average_precision': 0.29314003087016427, 'validation/num_examples': 43793, 'test/accuracy': 0.9861654043197632, 'test/loss': 0.046399783343076706, 'test/mean_average_precision': 0.27303717513773235, 'test/num_examples': 43793, 'score': 11303.523490428925, 'total_duration': 17158.2129073143, 'accumulated_submission_time': 11303.523490428925, 'accumulated_eval_time': 5852.107979774475, 'accumulated_logging_time': 1.5964686870574951, 'global_step': 37951, 'preemption_count': 0}), (38753, {'train/accuracy': 0.9920198917388916, 'train/loss': 0.026103172451257706, 'train/mean_average_precision': 0.5085402683082594, 'validation/accuracy': 0.9870200157165527, 'validation/loss': 0.043799374252557755, 'validation/mean_average_precision': 0.2919875351234355, 'validation/num_examples': 43793, 'test/accuracy': 0.986207127571106, 'test/loss': 0.046464718878269196, 'test/mean_average_precision': 0.2726773822086513, 'test/num_examples': 43793, 'score': 11543.625498771667, 'total_duration': 17512.196195364, 'accumulated_submission_time': 11543.625498771667, 'accumulated_eval_time': 5965.937205314636, 'accumulated_logging_time': 1.628067970275879, 'global_step': 38753, 'preemption_count': 0}), (39564, {'train/accuracy': 0.9920775890350342, 'train/loss': 0.025897284969687462, 'train/mean_average_precision': 0.5178632674219039, 'validation/accuracy': 0.9870175719261169, 'validation/loss': 0.04383189603686333, 'validation/mean_average_precision': 0.29044556427405527, 'validation/num_examples': 43793, 'test/accuracy': 0.986214280128479, 'test/loss': 0.04652079939842224, 'test/mean_average_precision': 0.27400763814383505, 'test/num_examples': 43793, 'score': 11783.713562488556, 'total_duration': 17866.98537325859, 'accumulated_submission_time': 11783.713562488556, 'accumulated_eval_time': 6080.588138580322, 'accumulated_logging_time': 1.6572272777557373, 'global_step': 39564, 'preemption_count': 0}), (40375, {'train/accuracy': 0.9921066761016846, 'train/loss': 0.025920024141669273, 'train/mean_average_precision': 0.5134266237921271, 'validation/accuracy': 0.9870930910110474, 'validation/loss': 0.043781496584415436, 'validation/mean_average_precision': 0.2910942052732513, 'validation/num_examples': 43793, 'test/accuracy': 0.9863086342811584, 'test/loss': 0.0464753732085228, 'test/mean_average_precision': 0.2763686988638266, 'test/num_examples': 43793, 'score': 12023.664120674133, 'total_duration': 18219.669342517853, 'accumulated_submission_time': 12023.664120674133, 'accumulated_eval_time': 6193.2707595825195, 'accumulated_logging_time': 1.6868062019348145, 'global_step': 40375, 'preemption_count': 0}), (41182, {'train/accuracy': 0.9921951293945312, 'train/loss': 0.02550451084971428, 'train/mean_average_precision': 0.5255392530143148, 'validation/accuracy': 0.9870272874832153, 'validation/loss': 0.04401693865656853, 'validation/mean_average_precision': 0.28724548770166786, 'validation/num_examples': 43793, 'test/accuracy': 0.9862306714057922, 'test/loss': 0.046753447502851486, 'test/mean_average_precision': 0.27558905960036156, 'test/num_examples': 43793, 'score': 12263.72638630867, 'total_duration': 18571.851628780365, 'accumulated_submission_time': 12263.72638630867, 'accumulated_eval_time': 6305.33953332901, 'accumulated_logging_time': 1.717444658279419, 'global_step': 41182, 'preemption_count': 0}), (41994, {'train/accuracy': 0.9922540783882141, 'train/loss': 0.025394786149263382, 'train/mean_average_precision': 0.5350306245213754, 'validation/accuracy': 0.9871458411216736, 'validation/loss': 0.04370727762579918, 'validation/mean_average_precision': 0.2921886729060299, 'validation/num_examples': 43793, 'test/accuracy': 0.9862546920776367, 'test/loss': 0.04658469557762146, 'test/mean_average_precision': 0.2740913877118571, 'test/num_examples': 43793, 'score': 12503.829927921295, 'total_duration': 18922.435742616653, 'accumulated_submission_time': 12503.829927921295, 'accumulated_eval_time': 6415.768768310547, 'accumulated_logging_time': 1.748032808303833, 'global_step': 41994, 'preemption_count': 0}), (42812, {'train/accuracy': 0.9923320412635803, 'train/loss': 0.02514089085161686, 'train/mean_average_precision': 0.5327678635630724, 'validation/accuracy': 0.9870800971984863, 'validation/loss': 0.04380376264452934, 'validation/mean_average_precision': 0.2936450115948592, 'validation/num_examples': 43793, 'test/accuracy': 0.9862861037254333, 'test/loss': 0.046529825776815414, 'test/mean_average_precision': 0.2743511556959688, 'test/num_examples': 43793, 'score': 12744.02012848854, 'total_duration': 19273.577226638794, 'accumulated_submission_time': 12744.02012848854, 'accumulated_eval_time': 6526.669455051422, 'accumulated_logging_time': 1.7772080898284912, 'global_step': 42812, 'preemption_count': 0}), (43625, {'train/accuracy': 0.9923545122146606, 'train/loss': 0.025050673633813858, 'train/mean_average_precision': 0.5217645567501001, 'validation/accuracy': 0.9871572256088257, 'validation/loss': 0.04378315061330795, 'validation/mean_average_precision': 0.2947222804090832, 'validation/num_examples': 43793, 'test/accuracy': 0.9862892627716064, 'test/loss': 0.046654798090457916, 'test/mean_average_precision': 0.276628101630696, 'test/num_examples': 43793, 'score': 12984.083931922913, 'total_duration': 19627.734467983246, 'accumulated_submission_time': 12984.083931922913, 'accumulated_eval_time': 6640.710206747055, 'accumulated_logging_time': 1.8087170124053955, 'global_step': 43625, 'preemption_count': 0}), (44429, {'train/accuracy': 0.9923121929168701, 'train/loss': 0.025105789303779602, 'train/mean_average_precision': 0.5283175810938138, 'validation/accuracy': 0.9870898127555847, 'validation/loss': 0.04396750405430794, 'validation/mean_average_precision': 0.2906926906238737, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.046711377799510956, 'test/mean_average_precision': 0.275740459506899, 'test/num_examples': 43793, 'score': 13224.119028568268, 'total_duration': 19978.65299963951, 'accumulated_submission_time': 13224.119028568268, 'accumulated_eval_time': 6751.541735172272, 'accumulated_logging_time': 1.8395612239837646, 'global_step': 44429, 'preemption_count': 0}), (45237, {'train/accuracy': 0.9924154877662659, 'train/loss': 0.02480192855000496, 'train/mean_average_precision': 0.5335555394627821, 'validation/accuracy': 0.9870380759239197, 'validation/loss': 0.043896470218896866, 'validation/mean_average_precision': 0.29144925817264067, 'validation/num_examples': 43793, 'test/accuracy': 0.9862509369850159, 'test/loss': 0.04658137634396553, 'test/mean_average_precision': 0.27627457527476146, 'test/num_examples': 43793, 'score': 13464.211839199066, 'total_duration': 20335.44900393486, 'accumulated_submission_time': 13464.211839199066, 'accumulated_eval_time': 6868.193955659866, 'accumulated_logging_time': 1.8695526123046875, 'global_step': 45237, 'preemption_count': 0}), (46050, {'train/accuracy': 0.9924728870391846, 'train/loss': 0.02473508007824421, 'train/mean_average_precision': 0.5482387394588197, 'validation/accuracy': 0.9870654940605164, 'validation/loss': 0.04400653392076492, 'validation/mean_average_precision': 0.29216711898148573, 'validation/num_examples': 43793, 'test/accuracy': 0.9863014221191406, 'test/loss': 0.046741895377635956, 'test/mean_average_precision': 0.27522812435849275, 'test/num_examples': 43793, 'score': 13704.363716602325, 'total_duration': 20689.021132946014, 'accumulated_submission_time': 13704.363716602325, 'accumulated_eval_time': 6981.561831712723, 'accumulated_logging_time': 1.9005815982818604, 'global_step': 46050, 'preemption_count': 0}), (46857, {'train/accuracy': 0.9925718307495117, 'train/loss': 0.024340186268091202, 'train/mean_average_precision': 0.5460618432251014, 'validation/accuracy': 0.9871048331260681, 'validation/loss': 0.043858833611011505, 'validation/mean_average_precision': 0.2934634918095831, 'validation/num_examples': 43793, 'test/accuracy': 0.986311137676239, 'test/loss': 0.04658690094947815, 'test/mean_average_precision': 0.2757559089938802, 'test/num_examples': 43793, 'score': 13944.346379995346, 'total_duration': 21052.033588647842, 'accumulated_submission_time': 13944.346379995346, 'accumulated_eval_time': 7104.538774967194, 'accumulated_logging_time': 1.9321987628936768, 'global_step': 46857, 'preemption_count': 0}), (47654, {'train/accuracy': 0.9925391674041748, 'train/loss': 0.024330446496605873, 'train/mean_average_precision': 0.5512148948006481, 'validation/accuracy': 0.9871292114257812, 'validation/loss': 0.044019173830747604, 'validation/mean_average_precision': 0.29511728456994485, 'validation/num_examples': 43793, 'test/accuracy': 0.9863258600234985, 'test/loss': 0.04675939306616783, 'test/mean_average_precision': 0.27590182504848065, 'test/num_examples': 43793, 'score': 14184.468867301941, 'total_duration': 21404.441400766373, 'accumulated_submission_time': 14184.468867301941, 'accumulated_eval_time': 7216.7648067474365, 'accumulated_logging_time': 1.9679112434387207, 'global_step': 47654, 'preemption_count': 0}), (48456, {'train/accuracy': 0.9925549626350403, 'train/loss': 0.024405697360634804, 'train/mean_average_precision': 0.5438710943930942, 'validation/accuracy': 0.9870078563690186, 'validation/loss': 0.043872684240341187, 'validation/mean_average_precision': 0.294882526326833, 'validation/num_examples': 43793, 'test/accuracy': 0.9862774610519409, 'test/loss': 0.04653443768620491, 'test/mean_average_precision': 0.2762400637061657, 'test/num_examples': 43793, 'score': 14424.621384382248, 'total_duration': 21756.93960762024, 'accumulated_submission_time': 14424.621384382248, 'accumulated_eval_time': 7329.056750535965, 'accumulated_logging_time': 2.0004258155822754, 'global_step': 48456, 'preemption_count': 0}), (49258, {'train/accuracy': 0.9925353527069092, 'train/loss': 0.024292323738336563, 'train/mean_average_precision': 0.5510165549192585, 'validation/accuracy': 0.9871299862861633, 'validation/loss': 0.044049620628356934, 'validation/mean_average_precision': 0.2942040578632812, 'validation/num_examples': 43793, 'test/accuracy': 0.9863515496253967, 'test/loss': 0.046685002744197845, 'test/mean_average_precision': 0.2779900239441563, 'test/num_examples': 43793, 'score': 14664.846626520157, 'total_duration': 22108.748535633087, 'accumulated_submission_time': 14664.846626520157, 'accumulated_eval_time': 7440.587538719177, 'accumulated_logging_time': 2.0319766998291016, 'global_step': 49258, 'preemption_count': 0}), (50053, {'train/accuracy': 0.9926950931549072, 'train/loss': 0.023943951353430748, 'train/mean_average_precision': 0.5364517219031123, 'validation/accuracy': 0.9870837330818176, 'validation/loss': 0.04409274831414223, 'validation/mean_average_precision': 0.2946187640227976, 'validation/num_examples': 43793, 'test/accuracy': 0.9863343238830566, 'test/loss': 0.04679308459162712, 'test/mean_average_precision': 0.27761662892848316, 'test/num_examples': 43793, 'score': 14904.948291301727, 'total_duration': 22460.00063276291, 'accumulated_submission_time': 14904.948291301727, 'accumulated_eval_time': 7551.685168027878, 'accumulated_logging_time': 2.0634572505950928, 'global_step': 50053, 'preemption_count': 0}), (50824, {'train/accuracy': 0.9926823377609253, 'train/loss': 0.023921485990285873, 'train/mean_average_precision': 0.5659549218465256, 'validation/accuracy': 0.9870930910110474, 'validation/loss': 0.04400347173213959, 'validation/mean_average_precision': 0.2966124778061327, 'validation/num_examples': 43793, 'test/accuracy': 0.9863380789756775, 'test/loss': 0.0467236302793026, 'test/mean_average_precision': 0.27769009613933104, 'test/num_examples': 43793, 'score': 15144.994645357132, 'total_duration': 22813.19109582901, 'accumulated_submission_time': 15144.994645357132, 'accumulated_eval_time': 7664.77897310257, 'accumulated_logging_time': 2.0937917232513428, 'global_step': 50824, 'preemption_count': 0}), (51635, {'train/accuracy': 0.9927903413772583, 'train/loss': 0.023641467094421387, 'train/mean_average_precision': 0.5699900778606004, 'validation/accuracy': 0.9871259331703186, 'validation/loss': 0.04407826066017151, 'validation/mean_average_precision': 0.29433424721815926, 'validation/num_examples': 43793, 'test/accuracy': 0.9863317608833313, 'test/loss': 0.046789851039648056, 'test/mean_average_precision': 0.2765277641204706, 'test/num_examples': 43793, 'score': 15385.132538318634, 'total_duration': 23164.5311794281, 'accumulated_submission_time': 15385.132538318634, 'accumulated_eval_time': 7775.928287029266, 'accumulated_logging_time': 2.125009059906006, 'global_step': 51635, 'preemption_count': 0}), (52442, {'train/accuracy': 0.9926507472991943, 'train/loss': 0.024028539657592773, 'train/mean_average_precision': 0.5561128286747439, 'validation/accuracy': 0.9871198534965515, 'validation/loss': 0.043958283960819244, 'validation/mean_average_precision': 0.2960602320099009, 'validation/num_examples': 43793, 'test/accuracy': 0.9862989187240601, 'test/loss': 0.046676985919475555, 'test/mean_average_precision': 0.27720240111481026, 'test/num_examples': 43793, 'score': 15625.159752607346, 'total_duration': 23517.83878493309, 'accumulated_submission_time': 15625.159752607346, 'accumulated_eval_time': 7889.155577659607, 'accumulated_logging_time': 2.1568806171417236, 'global_step': 52442, 'preemption_count': 0}), (53242, {'train/accuracy': 0.992767870426178, 'train/loss': 0.023730114102363586, 'train/mean_average_precision': 0.5641855588005102, 'validation/accuracy': 0.9871519207954407, 'validation/loss': 0.04395059123635292, 'validation/mean_average_precision': 0.2944766385952157, 'validation/num_examples': 43793, 'test/accuracy': 0.9863595962524414, 'test/loss': 0.04665214568376541, 'test/mean_average_precision': 0.27796517027681544, 'test/num_examples': 43793, 'score': 15865.11316204071, 'total_duration': 23868.29835677147, 'accumulated_submission_time': 15865.11316204071, 'accumulated_eval_time': 7999.609346628189, 'accumulated_logging_time': 2.1878764629364014, 'global_step': 53242, 'preemption_count': 0}), (54042, {'train/accuracy': 0.9927854537963867, 'train/loss': 0.023622294887900352, 'train/mean_average_precision': 0.557771058757786, 'validation/accuracy': 0.9871466755867004, 'validation/loss': 0.04403487220406532, 'validation/mean_average_precision': 0.2945236227589513, 'validation/num_examples': 43793, 'test/accuracy': 0.9863789677619934, 'test/loss': 0.04675048217177391, 'test/mean_average_precision': 0.2774723888584997, 'test/num_examples': 43793, 'score': 16105.155731916428, 'total_duration': 24220.903874874115, 'accumulated_submission_time': 16105.155731916428, 'accumulated_eval_time': 8112.119167566299, 'accumulated_logging_time': 2.219280958175659, 'global_step': 54042, 'preemption_count': 0}), (54855, {'train/accuracy': 0.992757260799408, 'train/loss': 0.023710403591394424, 'train/mean_average_precision': 0.5704894674389012, 'validation/accuracy': 0.9871182441711426, 'validation/loss': 0.04402906447649002, 'validation/mean_average_precision': 0.2939831545527813, 'validation/num_examples': 43793, 'test/accuracy': 0.9863616824150085, 'test/loss': 0.04672276973724365, 'test/mean_average_precision': 0.27746544994406297, 'test/num_examples': 43793, 'score': 16345.138173818588, 'total_duration': 24572.876202583313, 'accumulated_submission_time': 16345.138173818588, 'accumulated_eval_time': 8224.05762052536, 'accumulated_logging_time': 2.2497670650482178, 'global_step': 54855, 'preemption_count': 0}), (55662, {'train/accuracy': 0.99288010597229, 'train/loss': 0.02339564450085163, 'train/mean_average_precision': 0.5723252654691878, 'validation/accuracy': 0.9871361255645752, 'validation/loss': 0.04405774921178818, 'validation/mean_average_precision': 0.29443500441431786, 'validation/num_examples': 43793, 'test/accuracy': 0.9863473773002625, 'test/loss': 0.046785611659288406, 'test/mean_average_precision': 0.27797812945632994, 'test/num_examples': 43793, 'score': 16585.21883559227, 'total_duration': 24921.31823015213, 'accumulated_submission_time': 16585.21883559227, 'accumulated_eval_time': 8332.36639714241, 'accumulated_logging_time': 2.2815706729888916, 'global_step': 55662, 'preemption_count': 0}), (56461, {'train/accuracy': 0.9927176833152771, 'train/loss': 0.023777011781930923, 'train/mean_average_precision': 0.5588775495450433, 'validation/accuracy': 0.9871580004692078, 'validation/loss': 0.04404550418257713, 'validation/mean_average_precision': 0.2942504084355177, 'validation/num_examples': 43793, 'test/accuracy': 0.9863406419754028, 'test/loss': 0.04676348343491554, 'test/mean_average_precision': 0.27751934908575543, 'test/num_examples': 43793, 'score': 16825.213742256165, 'total_duration': 25268.1124458313, 'accumulated_submission_time': 16825.213742256165, 'accumulated_eval_time': 8439.113186120987, 'accumulated_logging_time': 2.3131465911865234, 'global_step': 56461, 'preemption_count': 0}), (57275, {'train/accuracy': 0.9927535057067871, 'train/loss': 0.023731792345643044, 'train/mean_average_precision': 0.5730846777096557, 'validation/accuracy': 0.987153947353363, 'validation/loss': 0.04406976327300072, 'validation/mean_average_precision': 0.29432620325649755, 'validation/num_examples': 43793, 'test/accuracy': 0.9863406419754028, 'test/loss': 0.04678366333246231, 'test/mean_average_precision': 0.27771077608807737, 'test/num_examples': 43793, 'score': 17065.243547677994, 'total_duration': 25616.414207935333, 'accumulated_submission_time': 17065.243547677994, 'accumulated_eval_time': 8547.331690073013, 'accumulated_logging_time': 2.3456172943115234, 'global_step': 57275, 'preemption_count': 0}), (58088, {'train/accuracy': 0.9928005337715149, 'train/loss': 0.02355715073645115, 'train/mean_average_precision': 0.5632063513388179, 'validation/accuracy': 0.9871689677238464, 'validation/loss': 0.044033218175172806, 'validation/mean_average_precision': 0.2946963852039688, 'validation/num_examples': 43793, 'test/accuracy': 0.9863465428352356, 'test/loss': 0.0467548705637455, 'test/mean_average_precision': 0.2776700650850645, 'test/num_examples': 43793, 'score': 17305.338668107986, 'total_duration': 25963.824363708496, 'accumulated_submission_time': 17305.338668107986, 'accumulated_eval_time': 8654.593199968338, 'accumulated_logging_time': 2.378063201904297, 'global_step': 58088, 'preemption_count': 0}), (58905, {'train/accuracy': 0.9927901029586792, 'train/loss': 0.023619329556822777, 'train/mean_average_precision': 0.5718410748175782, 'validation/accuracy': 0.9871616959571838, 'validation/loss': 0.04402972012758255, 'validation/mean_average_precision': 0.2949296928873249, 'validation/num_examples': 43793, 'test/accuracy': 0.9863431453704834, 'test/loss': 0.04674716666340828, 'test/mean_average_precision': 0.2777846611081124, 'test/num_examples': 43793, 'score': 17545.376329660416, 'total_duration': 26319.759618759155, 'accumulated_submission_time': 17545.376329660416, 'accumulated_eval_time': 8770.438215494156, 'accumulated_logging_time': 2.4096548557281494, 'global_step': 58905, 'preemption_count': 0}), (59713, {'train/accuracy': 0.9928460717201233, 'train/loss': 0.023473316803574562, 'train/mean_average_precision': 0.5671348820412629, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.0440271832048893, 'validation/mean_average_precision': 0.2948615903910607, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674341157078743, 'test/mean_average_precision': 0.2777324306154021, 'test/num_examples': 43793, 'score': 17785.518886089325, 'total_duration': 26674.446563243866, 'accumulated_submission_time': 17785.518886089325, 'accumulated_eval_time': 8884.923419713974, 'accumulated_logging_time': 2.44377064704895, 'global_step': 59713, 'preemption_count': 0}), (60515, {'train/accuracy': 0.9928585290908813, 'train/loss': 0.023436488583683968, 'train/mean_average_precision': 0.5724790527949595, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04402713477611542, 'validation/mean_average_precision': 0.29476442959706234, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674330726265907, 'test/mean_average_precision': 0.2777204631941807, 'test/num_examples': 43793, 'score': 18025.50324702263, 'total_duration': 27025.534484386444, 'accumulated_submission_time': 18025.50324702263, 'accumulated_eval_time': 8995.968944072723, 'accumulated_logging_time': 2.4787518978118896, 'global_step': 60515, 'preemption_count': 0}), (61328, {'train/accuracy': 0.9927020072937012, 'train/loss': 0.023759424686431885, 'train/mean_average_precision': 0.5475151945984724, 'validation/accuracy': 0.9871543645858765, 'validation/loss': 0.04402713477611542, 'validation/mean_average_precision': 0.29481765514736197, 'validation/num_examples': 43793, 'test/accuracy': 0.9863372445106506, 'test/loss': 0.04674330726265907, 'test/mean_average_precision': 0.2777384469477052, 'test/num_examples': 43793, 'score': 18265.666171073914, 'total_duration': 27372.58276605606, 'accumulated_submission_time': 18265.666171073914, 'accumulated_eval_time': 9102.801436901093, 'accumulated_logging_time': 2.5098509788513184, 'global_step': 61328, 'preemption_count': 0})], 'global_step': 62038}
I0215 19:47:48.149749 139966923982656 submission_runner.py:586] Timing: 18477.237469673157
I0215 19:47:48.149819 139966923982656 submission_runner.py:588] Total number of evals: 77
I0215 19:47:48.149882 139966923982656 submission_runner.py:589] ====================
I0215 19:47:48.150302 139966923982656 submission_runner.py:673] Final ogbg_silu score: 18477.237469673157

python3 submission_runner.py --framework=jax --workload=ogbg_model_size --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --tuning_search_space=reference_algorithms/target_setting_algorithms/ogbg_model_size/tuning_search_space.json --data_dir=/data/ogbg --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --num_tuning_trials=1 --rng_seed=1692305324 --max_global_steps=80000 2>&1 | tee -a /logs/ogbg_model_size_jax_02-16-2024-06-12-16.log
I0216 06:12:36.694029 140416551212864 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax.
I0216 06:12:37.699204 140416551212864 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0216 06:12:37.699949 140416551212864 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0216 06:12:37.700090 140416551212864 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0216 06:12:37.705348 140416551212864 submission_runner.py:542] Using RNG seed 1692305324
I0216 06:12:38.748740 140416551212864 submission_runner.py:551] --- Tuning run 1/1 ---
I0216 06:12:38.748968 140416551212864 submission_runner.py:556] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1.
I0216 06:12:38.749149 140416551212864 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1/hparams.json.
I0216 06:12:38.928761 140416551212864 submission_runner.py:206] Initializing dataset.
I0216 06:12:39.041076 140416551212864 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:12:39.055371 140416551212864 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
W0216 06:12:39.301225 140416551212864 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow_datasets/core/reader.py:101: CounterV2 (from tensorflow.python.data.experimental.ops.counter) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.counter(...)` instead.
I0216 06:12:39.358918 140416551212864 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:12:39.431163 140416551212864 submission_runner.py:213] Initializing model.
I0216 06:12:44.474815 140416551212864 submission_runner.py:255] Initializing optimizer.
I0216 06:12:45.158559 140416551212864 submission_runner.py:262] Initializing metrics bundle.
I0216 06:12:45.158756 140416551212864 submission_runner.py:280] Initializing checkpoint and logger.
I0216 06:12:45.159679 140416551212864 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1 with prefix checkpoint_
I0216 06:12:45.159831 140416551212864 submission_runner.py:300] Saving meta data to /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1/meta_data_0.json.
I0216 06:12:45.160016 140416551212864 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0216 06:12:45.160076 140416551212864 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0216 06:12:45.466266 140416551212864 logger_utils.py:220] Unable to record git information. Continuing without it.
I0216 06:12:45.748310 140416551212864 submission_runner.py:304] Saving flags to /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1/flags_0.json.
I0216 06:12:45.757500 140416551212864 submission_runner.py:314] Starting training loop.
I0216 06:13:04.125090 140251771164416 logging_writer.py:48] [0] global_step=0, grad_norm=1.5858081579208374, loss=0.7445989847183228
I0216 06:13:04.141136 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:13:04.147480 140416551212864 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:13:04.151510 140416551212864 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0216 06:13:04.219035 140416551212864 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split train, from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:14:54.254358 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:14:54.257897 140416551212864 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:14:54.261875 140416551212864 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0216 06:14:54.330747 140416551212864 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split validation, from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:16:24.071233 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:16:24.074579 140416551212864 dataset_info.py:578] Load dataset info from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:16:24.078441 140416551212864 dataset_builder.py:528] Reusing dataset ogbg_molpcba (/data/ogbg/ogbg_molpcba/0.1.3)
I0216 06:16:24.145478 140416551212864 logging_logger.py:49] Constructing tf.data.Dataset ogbg_molpcba for split test, from /data/ogbg/ogbg_molpcba/0.1.3
I0216 06:17:57.065015 140416551212864 submission_runner.py:408] Time since start: 311.31s, 	Step: 1, 	{'train/accuracy': 0.48167362809181213, 'train/loss': 0.7414783835411072, 'train/mean_average_precision': 0.02235064270736375, 'validation/accuracy': 0.4935591220855713, 'validation/loss': 0.734703004360199, 'validation/mean_average_precision': 0.026079343352659427, 'validation/num_examples': 43793, 'test/accuracy': 0.49593061208724976, 'test/loss': 0.7337996363639832, 'test/mean_average_precision': 0.027978340659118965, 'test/num_examples': 43793, 'score': 18.38358187675476, 'total_duration': 311.3073809146881, 'accumulated_submission_time': 18.38358187675476, 'accumulated_eval_time': 292.9237585067749, 'accumulated_logging_time': 0}
I0216 06:17:57.082528 140249186998016 logging_writer.py:48] [1] accumulated_eval_time=292.923759, accumulated_logging_time=0, accumulated_submission_time=18.383582, global_step=1, preemption_count=0, score=18.383582, test/accuracy=0.495931, test/loss=0.733800, test/mean_average_precision=0.027978, test/num_examples=43793, total_duration=311.307381, train/accuracy=0.481674, train/loss=0.741478, train/mean_average_precision=0.022351, validation/accuracy=0.493559, validation/loss=0.734703, validation/mean_average_precision=0.026079, validation/num_examples=43793
I0216 06:17:57.421858 140249212176128 logging_writer.py:48] [1] global_step=1, grad_norm=1.5930554866790771, loss=0.7439773678779602
I0216 06:17:57.740025 140249186998016 logging_writer.py:48] [2] global_step=2, grad_norm=1.5796492099761963, loss=0.7421715259552002
I0216 06:17:58.049455 140249212176128 logging_writer.py:48] [3] global_step=3, grad_norm=1.554689645767212, loss=0.7416566610336304
I0216 06:17:58.359021 140249186998016 logging_writer.py:48] [4] global_step=4, grad_norm=1.5793839693069458, loss=0.7417572736740112
I0216 06:17:58.670554 140249212176128 logging_writer.py:48] [5] global_step=5, grad_norm=1.564422369003296, loss=0.7371025085449219
I0216 06:17:58.976808 140249186998016 logging_writer.py:48] [6] global_step=6, grad_norm=1.556265115737915, loss=0.7342454195022583
I0216 06:17:59.283505 140249212176128 logging_writer.py:48] [7] global_step=7, grad_norm=1.545538306236267, loss=0.7330976128578186
I0216 06:17:59.591392 140249186998016 logging_writer.py:48] [8] global_step=8, grad_norm=1.517621636390686, loss=0.7297334671020508
I0216 06:17:59.899053 140249212176128 logging_writer.py:48] [9] global_step=9, grad_norm=1.4973840713500977, loss=0.7271836996078491
I0216 06:18:00.206876 140249186998016 logging_writer.py:48] [10] global_step=10, grad_norm=1.4527947902679443, loss=0.7199041843414307
I0216 06:18:00.515132 140249212176128 logging_writer.py:48] [11] global_step=11, grad_norm=1.4634674787521362, loss=0.7172282934188843
I0216 06:18:00.821713 140249186998016 logging_writer.py:48] [12] global_step=12, grad_norm=1.405488133430481, loss=0.7120018005371094
I0216 06:18:01.127552 140249212176128 logging_writer.py:48] [13] global_step=13, grad_norm=1.3926341533660889, loss=0.7049851417541504
I0216 06:18:01.435115 140249186998016 logging_writer.py:48] [14] global_step=14, grad_norm=1.3496373891830444, loss=0.7006831765174866
I0216 06:18:01.740018 140249212176128 logging_writer.py:48] [15] global_step=15, grad_norm=1.3480618000030518, loss=0.6967061161994934
I0216 06:18:02.067022 140249186998016 logging_writer.py:48] [16] global_step=16, grad_norm=1.3047668933868408, loss=0.6900918483734131
I0216 06:18:02.387148 140249212176128 logging_writer.py:48] [17] global_step=17, grad_norm=1.2615324258804321, loss=0.684642493724823
I0216 06:18:02.696278 140249186998016 logging_writer.py:48] [18] global_step=18, grad_norm=1.195813536643982, loss=0.6785287857055664
I0216 06:18:03.004495 140249212176128 logging_writer.py:48] [19] global_step=19, grad_norm=1.157098650932312, loss=0.6718101501464844
I0216 06:18:03.313746 140249186998016 logging_writer.py:48] [20] global_step=20, grad_norm=1.1260781288146973, loss=0.6673763394355774
I0216 06:18:03.623650 140249212176128 logging_writer.py:48] [21] global_step=21, grad_norm=1.0830378532409668, loss=0.6628744602203369
I0216 06:18:03.934259 140249186998016 logging_writer.py:48] [22] global_step=22, grad_norm=1.0278860330581665, loss=0.6562751531600952
I0216 06:18:04.250088 140249212176128 logging_writer.py:48] [23] global_step=23, grad_norm=0.995455801486969, loss=0.6504623889923096
I0216 06:18:04.561598 140249186998016 logging_writer.py:48] [24] global_step=24, grad_norm=0.9576878547668457, loss=0.644401490688324
I0216 06:18:04.875735 140249212176128 logging_writer.py:48] [25] global_step=25, grad_norm=0.9303102493286133, loss=0.6388583779335022
I0216 06:18:05.209106 140249186998016 logging_writer.py:48] [26] global_step=26, grad_norm=0.8991024494171143, loss=0.6341943740844727
I0216 06:18:05.543690 140249212176128 logging_writer.py:48] [27] global_step=27, grad_norm=0.8717325329780579, loss=0.6306540966033936
I0216 06:18:05.879015 140249186998016 logging_writer.py:48] [28] global_step=28, grad_norm=0.859362006187439, loss=0.6233628988265991
I0216 06:18:06.197900 140249212176128 logging_writer.py:48] [29] global_step=29, grad_norm=0.8288096189498901, loss=0.620856523513794
I0216 06:18:06.509604 140249186998016 logging_writer.py:48] [30] global_step=30, grad_norm=0.8049378395080566, loss=0.6153422594070435
I0216 06:18:06.817347 140249212176128 logging_writer.py:48] [31] global_step=31, grad_norm=0.797875165939331, loss=0.6112121343612671
I0216 06:18:07.128071 140249186998016 logging_writer.py:48] [32] global_step=32, grad_norm=0.783345103263855, loss=0.6058763861656189
I0216 06:18:07.436301 140249212176128 logging_writer.py:48] [33] global_step=33, grad_norm=0.7647157311439514, loss=0.6031798720359802
I0216 06:18:07.744986 140249186998016 logging_writer.py:48] [34] global_step=34, grad_norm=0.7508149147033691, loss=0.5963149070739746
I0216 06:18:08.056246 140249212176128 logging_writer.py:48] [35] global_step=35, grad_norm=0.7420465350151062, loss=0.5917295813560486
I0216 06:18:08.389717 140249186998016 logging_writer.py:48] [36] global_step=36, grad_norm=0.7224679589271545, loss=0.5878732800483704
I0216 06:18:08.713341 140249212176128 logging_writer.py:48] [37] global_step=37, grad_norm=0.7075877785682678, loss=0.583516001701355
I0216 06:18:09.023496 140249186998016 logging_writer.py:48] [38] global_step=38, grad_norm=0.6826013922691345, loss=0.5781139731407166
I0216 06:18:09.341957 140249212176128 logging_writer.py:48] [39] global_step=39, grad_norm=0.6751333475112915, loss=0.5748146176338196
I0216 06:18:09.649482 140249186998016 logging_writer.py:48] [40] global_step=40, grad_norm=0.6664567589759827, loss=0.568900465965271
I0216 06:18:09.958427 140249212176128 logging_writer.py:48] [41] global_step=41, grad_norm=0.6497010588645935, loss=0.5653586983680725
I0216 06:18:10.269916 140249186998016 logging_writer.py:48] [42] global_step=42, grad_norm=0.6400761008262634, loss=0.5609227418899536
I0216 06:18:10.580880 140249212176128 logging_writer.py:48] [43] global_step=43, grad_norm=0.6334676146507263, loss=0.55778968334198
I0216 06:18:10.891404 140249186998016 logging_writer.py:48] [44] global_step=44, grad_norm=0.623736560344696, loss=0.5528852343559265
I0216 06:18:11.198735 140249212176128 logging_writer.py:48] [45] global_step=45, grad_norm=0.6108706593513489, loss=0.5498566031455994
I0216 06:18:11.506002 140249186998016 logging_writer.py:48] [46] global_step=46, grad_norm=0.6063224077224731, loss=0.5459932684898376
I0216 06:18:11.812756 140249212176128 logging_writer.py:48] [47] global_step=47, grad_norm=0.6045730113983154, loss=0.5404598712921143
I0216 06:18:12.118403 140249186998016 logging_writer.py:48] [48] global_step=48, grad_norm=0.5974625945091248, loss=0.538932204246521
I0216 06:18:12.416248 140249212176128 logging_writer.py:48] [49] global_step=49, grad_norm=0.5943117737770081, loss=0.5338807106018066
I0216 06:18:12.716781 140249186998016 logging_writer.py:48] [50] global_step=50, grad_norm=0.5948166847229004, loss=0.528640627861023
I0216 06:18:13.019114 140249212176128 logging_writer.py:48] [51] global_step=51, grad_norm=0.5897964835166931, loss=0.5248735547065735
I0216 06:18:13.323789 140249186998016 logging_writer.py:48] [52] global_step=52, grad_norm=0.5815463662147522, loss=0.5199675559997559
I0216 06:18:13.634263 140249212176128 logging_writer.py:48] [53] global_step=53, grad_norm=0.5748084783554077, loss=0.5165884494781494
I0216 06:18:13.936139 140249186998016 logging_writer.py:48] [54] global_step=54, grad_norm=0.5707249045372009, loss=0.5107720494270325
I0216 06:18:14.242354 140249212176128 logging_writer.py:48] [55] global_step=55, grad_norm=0.5642225742340088, loss=0.5071836709976196
I0216 06:18:14.552165 140249186998016 logging_writer.py:48] [56] global_step=56, grad_norm=0.557619035243988, loss=0.5030115842819214
I0216 06:18:14.859817 140249212176128 logging_writer.py:48] [57] global_step=57, grad_norm=0.5547828078269958, loss=0.49681493639945984
I0216 06:18:15.173109 140249186998016 logging_writer.py:48] [58] global_step=58, grad_norm=0.5452666878700256, loss=0.49063196778297424
I0216 06:18:15.499551 140249212176128 logging_writer.py:48] [59] global_step=59, grad_norm=0.532295286655426, loss=0.48955029249191284
I0216 06:18:15.807375 140249186998016 logging_writer.py:48] [60] global_step=60, grad_norm=0.5182011127471924, loss=0.48586219549179077
I0216 06:18:16.115535 140249212176128 logging_writer.py:48] [61] global_step=61, grad_norm=0.5124896168708801, loss=0.4787549376487732
I0216 06:18:16.423574 140249186998016 logging_writer.py:48] [62] global_step=62, grad_norm=0.5052043795585632, loss=0.4776788055896759
I0216 06:18:16.729534 140249212176128 logging_writer.py:48] [63] global_step=63, grad_norm=0.4968520998954773, loss=0.4734010100364685
I0216 06:18:17.048230 140249186998016 logging_writer.py:48] [64] global_step=64, grad_norm=0.48947328329086304, loss=0.46783021092414856
I0216 06:18:17.384091 140249212176128 logging_writer.py:48] [65] global_step=65, grad_norm=0.48626354336738586, loss=0.463305801153183
I0216 06:18:17.698475 140249186998016 logging_writer.py:48] [66] global_step=66, grad_norm=0.47506994009017944, loss=0.46162188053131104
I0216 06:18:18.010957 140249212176128 logging_writer.py:48] [67] global_step=67, grad_norm=0.4694637656211853, loss=0.4584462344646454
I0216 06:18:18.339363 140249186998016 logging_writer.py:48] [68] global_step=68, grad_norm=0.46770697832107544, loss=0.4532945454120636
I0216 06:18:18.656304 140249212176128 logging_writer.py:48] [69] global_step=69, grad_norm=0.45970749855041504, loss=0.44975414872169495
I0216 06:18:18.962209 140249186998016 logging_writer.py:48] [70] global_step=70, grad_norm=0.4556959271430969, loss=0.44914698600769043
I0216 06:18:19.267624 140249212176128 logging_writer.py:48] [71] global_step=71, grad_norm=0.45086029171943665, loss=0.4453665018081665
I0216 06:18:19.578419 140249186998016 logging_writer.py:48] [72] global_step=72, grad_norm=0.45104748010635376, loss=0.4396423399448395
I0216 06:18:19.886704 140249212176128 logging_writer.py:48] [73] global_step=73, grad_norm=0.4439084827899933, loss=0.4357509911060333
I0216 06:18:20.192012 140249186998016 logging_writer.py:48] [74] global_step=74, grad_norm=0.4373653531074524, loss=0.4351361393928528
I0216 06:18:20.497701 140249212176128 logging_writer.py:48] [75] global_step=75, grad_norm=0.42937859892845154, loss=0.43350690603256226
I0216 06:18:20.807731 140249186998016 logging_writer.py:48] [76] global_step=76, grad_norm=0.4278980791568756, loss=0.43026456236839294
I0216 06:18:21.112436 140249212176128 logging_writer.py:48] [77] global_step=77, grad_norm=0.4233499765396118, loss=0.42591238021850586
I0216 06:18:21.420933 140249186998016 logging_writer.py:48] [78] global_step=78, grad_norm=0.4240427017211914, loss=0.4219232499599457
I0216 06:18:21.729408 140249212176128 logging_writer.py:48] [79] global_step=79, grad_norm=0.4207475483417511, loss=0.4185912311077118
I0216 06:18:22.032662 140249186998016 logging_writer.py:48] [80] global_step=80, grad_norm=0.41857922077178955, loss=0.41409850120544434
I0216 06:18:22.358477 140249212176128 logging_writer.py:48] [81] global_step=81, grad_norm=0.41350990533828735, loss=0.4154210090637207
I0216 06:18:22.666833 140249186998016 logging_writer.py:48] [82] global_step=82, grad_norm=0.41093507409095764, loss=0.4128605127334595
I0216 06:18:22.970221 140249212176128 logging_writer.py:48] [83] global_step=83, grad_norm=0.4096686840057373, loss=0.40865832567214966
I0216 06:18:23.303945 140249186998016 logging_writer.py:48] [84] global_step=84, grad_norm=0.404644638299942, loss=0.4061287045478821
I0216 06:18:23.629001 140249212176128 logging_writer.py:48] [85] global_step=85, grad_norm=0.4009779393672943, loss=0.4029214680194855
I0216 06:18:23.936505 140249186998016 logging_writer.py:48] [86] global_step=86, grad_norm=0.4027172923088074, loss=0.39785832166671753
I0216 06:18:24.252540 140249212176128 logging_writer.py:48] [87] global_step=87, grad_norm=0.39446547627449036, loss=0.39947524666786194
I0216 06:18:24.562711 140249186998016 logging_writer.py:48] [88] global_step=88, grad_norm=0.3952094316482544, loss=0.395340234041214
I0216 06:18:24.872932 140249212176128 logging_writer.py:48] [89] global_step=89, grad_norm=0.3929029703140259, loss=0.3924236297607422
I0216 06:18:25.192055 140249186998016 logging_writer.py:48] [90] global_step=90, grad_norm=0.39022576808929443, loss=0.38814887404441833
I0216 06:18:25.498439 140249212176128 logging_writer.py:48] [91] global_step=91, grad_norm=0.38667425513267517, loss=0.387802392244339
I0216 06:18:25.808844 140249186998016 logging_writer.py:48] [92] global_step=92, grad_norm=0.3849432170391083, loss=0.38606905937194824
I0216 06:18:26.119596 140249212176128 logging_writer.py:48] [93] global_step=93, grad_norm=0.3836311101913452, loss=0.38177329301834106
I0216 06:18:26.429798 140249186998016 logging_writer.py:48] [94] global_step=94, grad_norm=0.37936848402023315, loss=0.37887459993362427
I0216 06:18:26.739358 140249212176128 logging_writer.py:48] [95] global_step=95, grad_norm=0.38218408823013306, loss=0.37615522742271423
I0216 06:18:27.051469 140249186998016 logging_writer.py:48] [96] global_step=96, grad_norm=0.3760724663734436, loss=0.37679609656333923
I0216 06:18:27.362237 140249212176128 logging_writer.py:48] [97] global_step=97, grad_norm=0.37691783905029297, loss=0.3718985319137573
I0216 06:18:27.670041 140249186998016 logging_writer.py:48] [98] global_step=98, grad_norm=0.3737258017063141, loss=0.370623379945755
I0216 06:18:27.977098 140249212176128 logging_writer.py:48] [99] global_step=99, grad_norm=0.3728449046611786, loss=0.36500006914138794
I0216 06:18:28.289886 140249186998016 logging_writer.py:48] [100] global_step=100, grad_norm=0.3674389719963074, loss=0.3652884364128113
I0216 06:20:29.096588 140249212176128 logging_writer.py:48] [500] global_step=500, grad_norm=0.01312904991209507, loss=0.062165725976228714
I0216 06:21:57.103288 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:23:43.373279 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:23:46.229861 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:23:48.973581 140416551212864 submission_runner.py:408] Time since start: 663.22s, 	Step: 793, 	{'train/accuracy': 0.9868057370185852, 'train/loss': 0.05078306794166565, 'train/mean_average_precision': 0.05168824160589894, 'validation/accuracy': 0.9841329455375671, 'validation/loss': 0.060904696583747864, 'validation/mean_average_precision': 0.051065452575991155, 'validation/num_examples': 43793, 'test/accuracy': 0.9831559658050537, 'test/loss': 0.06420259922742844, 'test/mean_average_precision': 0.05331596142953435, 'test/num_examples': 43793, 'score': 258.375075340271, 'total_duration': 663.2159872055054, 'accumulated_submission_time': 258.375075340271, 'accumulated_eval_time': 404.7939808368683, 'accumulated_logging_time': 0.0282289981842041}
I0216 06:23:48.990006 140248818894592 logging_writer.py:48] [793] accumulated_eval_time=404.793981, accumulated_logging_time=0.028229, accumulated_submission_time=258.375075, global_step=793, preemption_count=0, score=258.375075, test/accuracy=0.983156, test/loss=0.064203, test/mean_average_precision=0.053316, test/num_examples=43793, total_duration=663.215987, train/accuracy=0.986806, train/loss=0.050783, train/mean_average_precision=0.051688, validation/accuracy=0.984133, validation/loss=0.060905, validation/mean_average_precision=0.051065, validation/num_examples=43793
I0216 06:24:51.333807 140249186998016 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.03969445452094078, loss=0.059624675661325455
I0216 06:27:21.312495 140248818894592 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.061877574771642685, loss=0.058060627430677414
I0216 06:27:49.052316 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:29:37.998462 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:29:40.859015 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:29:43.637335 140416551212864 submission_runner.py:408] Time since start: 1017.88s, 	Step: 1595, 	{'train/accuracy': 0.9873453974723816, 'train/loss': 0.046835266053676605, 'train/mean_average_precision': 0.09348125651907607, 'validation/accuracy': 0.9845287203788757, 'validation/loss': 0.05644737184047699, 'validation/mean_average_precision': 0.09511224531556464, 'validation/num_examples': 43793, 'test/accuracy': 0.9835472702980042, 'test/loss': 0.059720586985349655, 'test/mean_average_precision': 0.09338562361469074, 'test/num_examples': 43793, 'score': 498.4070701599121, 'total_duration': 1017.8797771930695, 'accumulated_submission_time': 498.4070701599121, 'accumulated_eval_time': 519.3789639472961, 'accumulated_logging_time': 0.0562899112701416}
I0216 06:29:43.652689 140249203783424 logging_writer.py:48] [1595] accumulated_eval_time=519.378964, accumulated_logging_time=0.056290, accumulated_submission_time=498.407070, global_step=1595, preemption_count=0, score=498.407070, test/accuracy=0.983547, test/loss=0.059721, test/mean_average_precision=0.093386, test/num_examples=43793, total_duration=1017.879777, train/accuracy=0.987345, train/loss=0.046835, train/mean_average_precision=0.093481, validation/accuracy=0.984529, validation/loss=0.056447, validation/mean_average_precision=0.095112, validation/num_examples=43793
I0216 06:31:44.935663 140249212176128 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.013121474534273148, loss=0.04459565877914429
I0216 06:33:43.788685 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:35:33.494852 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:35:36.337383 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:35:39.131309 140416551212864 submission_runner.py:408] Time since start: 1373.37s, 	Step: 2399, 	{'train/accuracy': 0.9874485731124878, 'train/loss': 0.04547134414315224, 'train/mean_average_precision': 0.12485872362402206, 'validation/accuracy': 0.9847138524055481, 'validation/loss': 0.055004335939884186, 'validation/mean_average_precision': 0.1196931239664118, 'validation/num_examples': 43793, 'test/accuracy': 0.9836664795875549, 'test/loss': 0.05817732959985733, 'test/mean_average_precision': 0.11812139833440244, 'test/num_examples': 43793, 'score': 738.5130224227905, 'total_duration': 1373.3737497329712, 'accumulated_submission_time': 738.5130224227905, 'accumulated_eval_time': 634.7215549945831, 'accumulated_logging_time': 0.08283233642578125}
I0216 06:35:39.146749 140248818894592 logging_writer.py:48] [2399] accumulated_eval_time=634.721555, accumulated_logging_time=0.082832, accumulated_submission_time=738.513022, global_step=2399, preemption_count=0, score=738.513022, test/accuracy=0.983666, test/loss=0.058177, test/mean_average_precision=0.118121, test/num_examples=43793, total_duration=1373.373750, train/accuracy=0.987449, train/loss=0.045471, train/mean_average_precision=0.124859, validation/accuracy=0.984714, validation/loss=0.055004, validation/mean_average_precision=0.119693, validation/num_examples=43793
I0216 06:36:09.652992 140249186998016 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.01996850222349167, loss=0.03736001253128052
I0216 06:38:37.043010 140248818894592 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.00901514571160078, loss=0.0400899276137352
I0216 06:39:39.290754 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:41:27.685698 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:41:30.514081 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:41:33.287009 140416551212864 submission_runner.py:408] Time since start: 1727.53s, 	Step: 3212, 	{'train/accuracy': 0.9878000617027283, 'train/loss': 0.043187934905290604, 'train/mean_average_precision': 0.1391459251340874, 'validation/accuracy': 0.9850386381149292, 'validation/loss': 0.052669938653707504, 'validation/mean_average_precision': 0.1350334797594012, 'validation/num_examples': 43793, 'test/accuracy': 0.9840598702430725, 'test/loss': 0.05566246062517166, 'test/mean_average_precision': 0.13459895855938472, 'test/num_examples': 43793, 'score': 978.6268582344055, 'total_duration': 1727.5294523239136, 'accumulated_submission_time': 978.6268582344055, 'accumulated_eval_time': 748.7177813053131, 'accumulated_logging_time': 0.10929632186889648}
I0216 06:41:33.302822 140249203783424 logging_writer.py:48] [3212] accumulated_eval_time=748.717781, accumulated_logging_time=0.109296, accumulated_submission_time=978.626858, global_step=3212, preemption_count=0, score=978.626858, test/accuracy=0.984060, test/loss=0.055662, test/mean_average_precision=0.134599, test/num_examples=43793, total_duration=1727.529452, train/accuracy=0.987800, train/loss=0.043188, train/mean_average_precision=0.139146, validation/accuracy=0.985039, validation/loss=0.052670, validation/mean_average_precision=0.135033, validation/num_examples=43793
I0216 06:42:57.853020 140249212176128 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.008175130933523178, loss=0.03908619284629822
I0216 06:45:23.556509 140249203783424 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.009098081849515438, loss=0.045295555144548416
I0216 06:45:33.294085 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:47:24.295047 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:47:27.134113 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:47:29.897258 140416551212864 submission_runner.py:408] Time since start: 2084.14s, 	Step: 4034, 	{'train/accuracy': 0.9881040453910828, 'train/loss': 0.04137897118926048, 'train/mean_average_precision': 0.17310310525076428, 'validation/accuracy': 0.9852420091629028, 'validation/loss': 0.05126866325736046, 'validation/mean_average_precision': 0.1528905318940395, 'validation/num_examples': 43793, 'test/accuracy': 0.98423171043396, 'test/loss': 0.0542476549744606, 'test/mean_average_precision': 0.14745985573702544, 'test/num_examples': 43793, 'score': 1218.5888166427612, 'total_duration': 2084.139676094055, 'accumulated_submission_time': 1218.5888166427612, 'accumulated_eval_time': 865.32088804245, 'accumulated_logging_time': 0.13540983200073242}
I0216 06:47:29.912613 140249186998016 logging_writer.py:48] [4034] accumulated_eval_time=865.320888, accumulated_logging_time=0.135410, accumulated_submission_time=1218.588817, global_step=4034, preemption_count=0, score=1218.588817, test/accuracy=0.984232, test/loss=0.054248, test/mean_average_precision=0.147460, test/num_examples=43793, total_duration=2084.139676, train/accuracy=0.988104, train/loss=0.041379, train/mean_average_precision=0.173103, validation/accuracy=0.985242, validation/loss=0.051269, validation/mean_average_precision=0.152891, validation/num_examples=43793
I0216 06:49:47.869464 140249195390720 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.010115393437445164, loss=0.04385935515165329
I0216 06:51:29.951268 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:53:22.622764 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:53:25.446572 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:53:28.232374 140416551212864 submission_runner.py:408] Time since start: 2442.47s, 	Step: 4849, 	{'train/accuracy': 0.9882045388221741, 'train/loss': 0.04050733894109726, 'train/mean_average_precision': 0.19442062861541134, 'validation/accuracy': 0.9854709506034851, 'validation/loss': 0.04987342655658722, 'validation/mean_average_precision': 0.17164908166572165, 'validation/num_examples': 43793, 'test/accuracy': 0.9845417141914368, 'test/loss': 0.0526445247232914, 'test/mean_average_precision': 0.16603115145706274, 'test/num_examples': 43793, 'score': 1458.5982029438019, 'total_duration': 2442.474811553955, 'accumulated_submission_time': 1458.5982029438019, 'accumulated_eval_time': 983.6019570827484, 'accumulated_logging_time': 0.16078495979309082}
I0216 06:53:28.248092 140255727752960 logging_writer.py:48] [4849] accumulated_eval_time=983.601957, accumulated_logging_time=0.160785, accumulated_submission_time=1458.598203, global_step=4849, preemption_count=0, score=1458.598203, test/accuracy=0.984542, test/loss=0.052645, test/mean_average_precision=0.166031, test/num_examples=43793, total_duration=2442.474812, train/accuracy=0.988205, train/loss=0.040507, train/mean_average_precision=0.194421, validation/accuracy=0.985471, validation/loss=0.049873, validation/mean_average_precision=0.171649, validation/num_examples=43793
I0216 06:54:12.688912 140354028304128 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.011611424386501312, loss=0.03908515349030495
I0216 06:56:39.051504 140255727752960 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.009746603667736053, loss=0.042252957820892334
I0216 06:57:28.419804 140416551212864 spec.py:321] Evaluating on the training split.
I0216 06:59:18.445200 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 06:59:21.260649 140416551212864 spec.py:349] Evaluating on the test split.
I0216 06:59:23.980616 140416551212864 submission_runner.py:408] Time since start: 2798.22s, 	Step: 5669, 	{'train/accuracy': 0.9883393049240112, 'train/loss': 0.039722491055727005, 'train/mean_average_precision': 0.21933719415693864, 'validation/accuracy': 0.9855290055274963, 'validation/loss': 0.049700673669576645, 'validation/mean_average_precision': 0.18249635403762393, 'validation/num_examples': 43793, 'test/accuracy': 0.9845627546310425, 'test/loss': 0.0527021624147892, 'test/mean_average_precision': 0.17947126482071704, 'test/num_examples': 43793, 'score': 1698.7393758296967, 'total_duration': 2798.2230608463287, 'accumulated_submission_time': 1698.7393758296967, 'accumulated_eval_time': 1099.1627323627472, 'accumulated_logging_time': 0.1876683235168457}
I0216 06:59:23.996222 140255719360256 logging_writer.py:48] [5669] accumulated_eval_time=1099.162732, accumulated_logging_time=0.187668, accumulated_submission_time=1698.739376, global_step=5669, preemption_count=0, score=1698.739376, test/accuracy=0.984563, test/loss=0.052702, test/mean_average_precision=0.179471, test/num_examples=43793, total_duration=2798.223061, train/accuracy=0.988339, train/loss=0.039722, train/mean_average_precision=0.219337, validation/accuracy=0.985529, validation/loss=0.049701, validation/mean_average_precision=0.182496, validation/num_examples=43793
I0216 07:01:02.350302 140355454342912 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.011655985377728939, loss=0.04287894442677498
I0216 07:03:24.195719 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:05:16.625096 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:05:19.512326 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:05:22.306280 140416551212864 submission_runner.py:408] Time since start: 3156.55s, 	Step: 6478, 	{'train/accuracy': 0.98891282081604, 'train/loss': 0.037928201258182526, 'train/mean_average_precision': 0.23965533568496827, 'validation/accuracy': 0.9858176112174988, 'validation/loss': 0.04807098209857941, 'validation/mean_average_precision': 0.18822552654447194, 'validation/num_examples': 43793, 'test/accuracy': 0.9848811626434326, 'test/loss': 0.050769008696079254, 'test/mean_average_precision': 0.18646852820476936, 'test/num_examples': 43793, 'score': 1938.908233165741, 'total_duration': 3156.548723220825, 'accumulated_submission_time': 1938.908233165741, 'accumulated_eval_time': 1217.2732729911804, 'accumulated_logging_time': 0.214646577835083}
I0216 07:05:22.321745 140249228961536 logging_writer.py:48] [6478] accumulated_eval_time=1217.273273, accumulated_logging_time=0.214647, accumulated_submission_time=1938.908233, global_step=6478, preemption_count=0, score=1938.908233, test/accuracy=0.984881, test/loss=0.050769, test/mean_average_precision=0.186469, test/num_examples=43793, total_duration=3156.548723, train/accuracy=0.988913, train/loss=0.037928, train/mean_average_precision=0.239655, validation/accuracy=0.985818, validation/loss=0.048071, validation/mean_average_precision=0.188226, validation/num_examples=43793
I0216 07:05:29.137670 140354028304128 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.0070437220856547356, loss=0.035293612629175186
I0216 07:07:57.428807 140249228961536 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.008607947267591953, loss=0.03501851484179497
I0216 07:09:22.541544 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:11:13.181432 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:11:16.087733 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:11:18.934491 140416551212864 submission_runner.py:408] Time since start: 3513.18s, 	Step: 7285, 	{'train/accuracy': 0.9889923930168152, 'train/loss': 0.037558507174253464, 'train/mean_average_precision': 0.2506327976129368, 'validation/accuracy': 0.9858740568161011, 'validation/loss': 0.04819805547595024, 'validation/mean_average_precision': 0.20329195368986933, 'validation/num_examples': 43793, 'test/accuracy': 0.9849662780761719, 'test/loss': 0.051053132861852646, 'test/mean_average_precision': 0.19663721041068807, 'test/num_examples': 43793, 'score': 2179.098852157593, 'total_duration': 3513.17693400383, 'accumulated_submission_time': 2179.098852157593, 'accumulated_eval_time': 1333.6661846637726, 'accumulated_logging_time': 0.2401752471923828}
I0216 07:11:18.950658 140255719360256 logging_writer.py:48] [7285] accumulated_eval_time=1333.666185, accumulated_logging_time=0.240175, accumulated_submission_time=2179.098852, global_step=7285, preemption_count=0, score=2179.098852, test/accuracy=0.984966, test/loss=0.051053, test/mean_average_precision=0.196637, test/num_examples=43793, total_duration=3513.176934, train/accuracy=0.988992, train/loss=0.037559, train/mean_average_precision=0.250633, validation/accuracy=0.985874, validation/loss=0.048198, validation/mean_average_precision=0.203292, validation/num_examples=43793
I0216 07:12:24.177655 140355454342912 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.009167609736323357, loss=0.04105057194828987
I0216 07:14:52.008892 140255719360256 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.009885010309517384, loss=0.0368029959499836
I0216 07:15:19.128029 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:17:10.076308 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:17:12.996165 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:17:15.845508 140416551212864 submission_runner.py:408] Time since start: 3870.09s, 	Step: 8093, 	{'train/accuracy': 0.9892497062683105, 'train/loss': 0.03660833090543747, 'train/mean_average_precision': 0.2666826090638757, 'validation/accuracy': 0.9859690070152283, 'validation/loss': 0.047449737787246704, 'validation/mean_average_precision': 0.20843739972926995, 'validation/num_examples': 43793, 'test/accuracy': 0.9850972294807434, 'test/loss': 0.05015392601490021, 'test/mean_average_precision': 0.20300071999537167, 'test/num_examples': 43793, 'score': 2419.246979236603, 'total_duration': 3870.087949991226, 'accumulated_submission_time': 2419.246979236603, 'accumulated_eval_time': 1450.383628129959, 'accumulated_logging_time': 0.26656627655029297}
I0216 07:17:15.861329 140249228961536 logging_writer.py:48] [8093] accumulated_eval_time=1450.383628, accumulated_logging_time=0.266566, accumulated_submission_time=2419.246979, global_step=8093, preemption_count=0, score=2419.246979, test/accuracy=0.985097, test/loss=0.050154, test/mean_average_precision=0.203001, test/num_examples=43793, total_duration=3870.087950, train/accuracy=0.989250, train/loss=0.036608, train/mean_average_precision=0.266683, validation/accuracy=0.985969, validation/loss=0.047450, validation/mean_average_precision=0.208437, validation/num_examples=43793
I0216 07:19:17.075072 140354028304128 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.010768675245344639, loss=0.03840179368853569
I0216 07:21:15.906979 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:23:08.916608 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:23:11.798374 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:23:14.649611 140416551212864 submission_runner.py:408] Time since start: 4228.89s, 	Step: 8901, 	{'train/accuracy': 0.9892312288284302, 'train/loss': 0.036238476634025574, 'train/mean_average_precision': 0.28199685745231506, 'validation/accuracy': 0.9859815835952759, 'validation/loss': 0.046859655529260635, 'validation/mean_average_precision': 0.21866582898498918, 'validation/num_examples': 43793, 'test/accuracy': 0.9851385354995728, 'test/loss': 0.049522314220666885, 'test/mean_average_precision': 0.20997792954548714, 'test/num_examples': 43793, 'score': 2659.262021303177, 'total_duration': 4228.892052412033, 'accumulated_submission_time': 2659.262021303177, 'accumulated_eval_time': 1569.1262352466583, 'accumulated_logging_time': 0.29387545585632324}
I0216 07:23:14.665565 140255727752960 logging_writer.py:48] [8901] accumulated_eval_time=1569.126235, accumulated_logging_time=0.293875, accumulated_submission_time=2659.262021, global_step=8901, preemption_count=0, score=2659.262021, test/accuracy=0.985139, test/loss=0.049522, test/mean_average_precision=0.209978, test/num_examples=43793, total_duration=4228.892052, train/accuracy=0.989231, train/loss=0.036238, train/mean_average_precision=0.281997, validation/accuracy=0.985982, validation/loss=0.046860, validation/mean_average_precision=0.218666, validation/num_examples=43793
I0216 07:23:44.459248 140355454342912 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.008834131062030792, loss=0.03764359652996063
I0216 07:26:13.657241 140255727752960 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.011176863685250282, loss=0.0368557907640934
I0216 07:27:14.770567 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:29:04.932396 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:29:07.810255 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:29:10.591396 140416551212864 submission_runner.py:408] Time since start: 4584.83s, 	Step: 9706, 	{'train/accuracy': 0.9894201159477234, 'train/loss': 0.03569912165403366, 'train/mean_average_precision': 0.2871602391480262, 'validation/accuracy': 0.9860473871231079, 'validation/loss': 0.0465821772813797, 'validation/mean_average_precision': 0.21980760651148143, 'validation/num_examples': 43793, 'test/accuracy': 0.9852463603019714, 'test/loss': 0.049317386001348495, 'test/mean_average_precision': 0.22046276249326507, 'test/num_examples': 43793, 'score': 2899.337280035019, 'total_duration': 4584.833826303482, 'accumulated_submission_time': 2899.337280035019, 'accumulated_eval_time': 1684.947012424469, 'accumulated_logging_time': 0.3199949264526367}
I0216 07:29:10.607460 140249228961536 logging_writer.py:48] [9706] accumulated_eval_time=1684.947012, accumulated_logging_time=0.319995, accumulated_submission_time=2899.337280, global_step=9706, preemption_count=0, score=2899.337280, test/accuracy=0.985246, test/loss=0.049317, test/mean_average_precision=0.220463, test/num_examples=43793, total_duration=4584.833826, train/accuracy=0.989420, train/loss=0.035699, train/mean_average_precision=0.287160, validation/accuracy=0.986047, validation/loss=0.046582, validation/mean_average_precision=0.219808, validation/num_examples=43793
I0216 07:30:37.783427 140255719360256 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.010402176529169083, loss=0.03702669218182564
I0216 07:33:06.181734 140249228961536 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.01449156180024147, loss=0.0352599062025547
I0216 07:33:10.643847 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:35:00.263849 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:35:03.103990 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:35:05.915631 140416551212864 submission_runner.py:408] Time since start: 4940.16s, 	Step: 10516, 	{'train/accuracy': 0.9896848201751709, 'train/loss': 0.03468702733516693, 'train/mean_average_precision': 0.3019304039090689, 'validation/accuracy': 0.986333966255188, 'validation/loss': 0.04604193940758705, 'validation/mean_average_precision': 0.22489917876460291, 'validation/num_examples': 43793, 'test/accuracy': 0.985468327999115, 'test/loss': 0.04874479025602341, 'test/mean_average_precision': 0.21936936070714264, 'test/num_examples': 43793, 'score': 3139.3436799049377, 'total_duration': 4940.158073663712, 'accumulated_submission_time': 3139.3436799049377, 'accumulated_eval_time': 1800.2187502384186, 'accumulated_logging_time': 0.3462367057800293}
I0216 07:35:05.932161 140255727752960 logging_writer.py:48] [10516] accumulated_eval_time=1800.218750, accumulated_logging_time=0.346237, accumulated_submission_time=3139.343680, global_step=10516, preemption_count=0, score=3139.343680, test/accuracy=0.985468, test/loss=0.048745, test/mean_average_precision=0.219369, test/num_examples=43793, total_duration=4940.158074, train/accuracy=0.989685, train/loss=0.034687, train/mean_average_precision=0.301930, validation/accuracy=0.986334, validation/loss=0.046042, validation/mean_average_precision=0.224899, validation/num_examples=43793
I0216 07:37:30.865086 140355454342912 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.008874459192156792, loss=0.03383690118789673
I0216 07:39:06.082100 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:41:00.513617 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:41:03.451072 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:41:06.236921 140416551212864 submission_runner.py:408] Time since start: 5300.48s, 	Step: 11321, 	{'train/accuracy': 0.9899202585220337, 'train/loss': 0.0338815338909626, 'train/mean_average_precision': 0.3169519903201963, 'validation/accuracy': 0.9863104224205017, 'validation/loss': 0.04609367623925209, 'validation/mean_average_precision': 0.23148539891773326, 'validation/num_examples': 43793, 'test/accuracy': 0.9854274988174438, 'test/loss': 0.04879941791296005, 'test/mean_average_precision': 0.23076089102976824, 'test/num_examples': 43793, 'score': 3379.463701248169, 'total_duration': 5300.479362487793, 'accumulated_submission_time': 3379.463701248169, 'accumulated_eval_time': 1920.3735365867615, 'accumulated_logging_time': 0.3728978633880615}
I0216 07:41:06.253235 140255719360256 logging_writer.py:48] [11321] accumulated_eval_time=1920.373537, accumulated_logging_time=0.372898, accumulated_submission_time=3379.463701, global_step=11321, preemption_count=0, score=3379.463701, test/accuracy=0.985427, test/loss=0.048799, test/mean_average_precision=0.230761, test/num_examples=43793, total_duration=5300.479362, train/accuracy=0.989920, train/loss=0.033882, train/mean_average_precision=0.316952, validation/accuracy=0.986310, validation/loss=0.046094, validation/mean_average_precision=0.231485, validation/num_examples=43793
I0216 07:42:00.132473 140354028304128 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.011049095541238785, loss=0.0322018563747406
I0216 07:44:28.569000 140255719360256 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.012444373220205307, loss=0.03689850866794586
I0216 07:45:06.300563 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:46:56.494184 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:46:59.332403 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:47:02.143752 140416551212864 submission_runner.py:408] Time since start: 5656.39s, 	Step: 12127, 	{'train/accuracy': 0.9898400902748108, 'train/loss': 0.03390065208077431, 'train/mean_average_precision': 0.336388867552628, 'validation/accuracy': 0.9864143133163452, 'validation/loss': 0.04585133120417595, 'validation/mean_average_precision': 0.233934760699651, 'validation/num_examples': 43793, 'test/accuracy': 0.9855626821517944, 'test/loss': 0.04875577613711357, 'test/mean_average_precision': 0.22939931679488923, 'test/num_examples': 43793, 'score': 3619.4806180000305, 'total_duration': 5656.386184930801, 'accumulated_submission_time': 3619.4806180000305, 'accumulated_eval_time': 2036.2166798114777, 'accumulated_logging_time': 0.3995664119720459}
I0216 07:47:02.161063 140249228961536 logging_writer.py:48] [12127] accumulated_eval_time=2036.216680, accumulated_logging_time=0.399566, accumulated_submission_time=3619.480618, global_step=12127, preemption_count=0, score=3619.480618, test/accuracy=0.985563, test/loss=0.048756, test/mean_average_precision=0.229399, test/num_examples=43793, total_duration=5656.386185, train/accuracy=0.989840, train/loss=0.033901, train/mean_average_precision=0.336389, validation/accuracy=0.986414, validation/loss=0.045851, validation/mean_average_precision=0.233935, validation/num_examples=43793
I0216 07:48:54.008808 140255727752960 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.011602927930653095, loss=0.03211674094200134
I0216 07:51:02.432409 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:52:54.953699 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:52:57.823717 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:53:00.602966 140416551212864 submission_runner.py:408] Time since start: 6014.85s, 	Step: 12930, 	{'train/accuracy': 0.9900326132774353, 'train/loss': 0.03318105638027191, 'train/mean_average_precision': 0.34200915533294274, 'validation/accuracy': 0.9864143133163452, 'validation/loss': 0.04563668742775917, 'validation/mean_average_precision': 0.239900025755602, 'validation/num_examples': 43793, 'test/accuracy': 0.985623300075531, 'test/loss': 0.048326943069696426, 'test/mean_average_precision': 0.23443306236225478, 'test/num_examples': 43793, 'score': 3859.721358060837, 'total_duration': 6014.845408916473, 'accumulated_submission_time': 3859.721358060837, 'accumulated_eval_time': 2154.387207508087, 'accumulated_logging_time': 0.42706990242004395}
I0216 07:53:00.619514 140255719360256 logging_writer.py:48] [12930] accumulated_eval_time=2154.387208, accumulated_logging_time=0.427070, accumulated_submission_time=3859.721358, global_step=12930, preemption_count=0, score=3859.721358, test/accuracy=0.985623, test/loss=0.048327, test/mean_average_precision=0.234433, test/num_examples=43793, total_duration=6014.845409, train/accuracy=0.990033, train/loss=0.033181, train/mean_average_precision=0.342009, validation/accuracy=0.986414, validation/loss=0.045637, validation/mean_average_precision=0.239900, validation/num_examples=43793
I0216 07:53:21.732139 140354028304128 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.012506104074418545, loss=0.036416083574295044
I0216 07:55:49.869431 140255719360256 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.011171728372573853, loss=0.036383483558893204
I0216 07:57:00.794643 140416551212864 spec.py:321] Evaluating on the training split.
I0216 07:58:50.763749 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 07:58:53.593548 140416551212864 spec.py:349] Evaluating on the test split.
I0216 07:58:56.372595 140416551212864 submission_runner.py:408] Time since start: 6370.62s, 	Step: 13739, 	{'train/accuracy': 0.9901013374328613, 'train/loss': 0.032926712185144424, 'train/mean_average_precision': 0.3447498642979649, 'validation/accuracy': 0.986382246017456, 'validation/loss': 0.04576338082551956, 'validation/mean_average_precision': 0.24014079052112472, 'validation/num_examples': 43793, 'test/accuracy': 0.9856106638908386, 'test/loss': 0.04828348383307457, 'test/mean_average_precision': 0.23155845502811173, 'test/num_examples': 43793, 'score': 4099.86542057991, 'total_duration': 6370.615036010742, 'accumulated_submission_time': 4099.86542057991, 'accumulated_eval_time': 2269.9651188850403, 'accumulated_logging_time': 0.45482420921325684}
I0216 07:58:56.390605 140249228961536 logging_writer.py:48] [13739] accumulated_eval_time=2269.965119, accumulated_logging_time=0.454824, accumulated_submission_time=4099.865421, global_step=13739, preemption_count=0, score=4099.865421, test/accuracy=0.985611, test/loss=0.048283, test/mean_average_precision=0.231558, test/num_examples=43793, total_duration=6370.615036, train/accuracy=0.990101, train/loss=0.032927, train/mean_average_precision=0.344750, validation/accuracy=0.986382, validation/loss=0.045763, validation/mean_average_precision=0.240141, validation/num_examples=43793
I0216 08:00:14.554034 140255727752960 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.01092537958174944, loss=0.03325162082910538
I0216 08:02:42.953220 140249228961536 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.012055424973368645, loss=0.03364807739853859
I0216 08:02:56.514653 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:04:50.734217 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:04:53.561022 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:04:56.381895 140416551212864 submission_runner.py:408] Time since start: 6730.62s, 	Step: 14547, 	{'train/accuracy': 0.9902201294898987, 'train/loss': 0.03253340721130371, 'train/mean_average_precision': 0.3550890578263983, 'validation/accuracy': 0.9863721132278442, 'validation/loss': 0.04537105932831764, 'validation/mean_average_precision': 0.2445942358176692, 'validation/num_examples': 43793, 'test/accuracy': 0.9856014251708984, 'test/loss': 0.04815961420536041, 'test/mean_average_precision': 0.24080017935523912, 'test/num_examples': 43793, 'score': 4339.959518432617, 'total_duration': 6730.6243143081665, 'accumulated_submission_time': 4339.959518432617, 'accumulated_eval_time': 2389.8322942256927, 'accumulated_logging_time': 0.48322343826293945}
I0216 08:04:56.398927 140255719360256 logging_writer.py:48] [14547] accumulated_eval_time=2389.832294, accumulated_logging_time=0.483223, accumulated_submission_time=4339.959518, global_step=14547, preemption_count=0, score=4339.959518, test/accuracy=0.985601, test/loss=0.048160, test/mean_average_precision=0.240800, test/num_examples=43793, total_duration=6730.624314, train/accuracy=0.990220, train/loss=0.032533, train/mean_average_precision=0.355089, validation/accuracy=0.986372, validation/loss=0.045371, validation/mean_average_precision=0.244594, validation/num_examples=43793
I0216 08:07:11.505414 140355454342912 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.01686384342610836, loss=0.04006985202431679
I0216 08:08:56.399439 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:10:49.679790 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:10:52.525738 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:10:55.332457 140416551212864 submission_runner.py:408] Time since start: 7089.57s, 	Step: 15351, 	{'train/accuracy': 0.9903188347816467, 'train/loss': 0.03208903223276138, 'train/mean_average_precision': 0.3673918130942452, 'validation/accuracy': 0.9864687323570251, 'validation/loss': 0.04510466009378433, 'validation/mean_average_precision': 0.24675313568796267, 'validation/num_examples': 43793, 'test/accuracy': 0.985623300075531, 'test/loss': 0.04794719070196152, 'test/mean_average_precision': 0.23887921881102916, 'test/num_examples': 43793, 'score': 4579.929854154587, 'total_duration': 7089.57489824295, 'accumulated_submission_time': 4579.929854154587, 'accumulated_eval_time': 2508.765280008316, 'accumulated_logging_time': 0.5106532573699951}
I0216 08:10:55.349618 140249228961536 logging_writer.py:48] [15351] accumulated_eval_time=2508.765280, accumulated_logging_time=0.510653, accumulated_submission_time=4579.929854, global_step=15351, preemption_count=0, score=4579.929854, test/accuracy=0.985623, test/loss=0.047947, test/mean_average_precision=0.238879, test/num_examples=43793, total_duration=7089.574898, train/accuracy=0.990319, train/loss=0.032089, train/mean_average_precision=0.367392, validation/accuracy=0.986469, validation/loss=0.045105, validation/mean_average_precision=0.246753, validation/num_examples=43793
I0216 08:11:40.132454 140255727752960 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.012800389900803566, loss=0.035853397101163864
I0216 08:14:10.967807 140249228961536 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.011852342635393143, loss=0.03399131819605827
I0216 08:14:55.412506 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:16:48.683420 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:16:51.618826 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:16:54.605126 140416551212864 submission_runner.py:408] Time since start: 7448.85s, 	Step: 16146, 	{'train/accuracy': 0.9904552698135376, 'train/loss': 0.031749919056892395, 'train/mean_average_precision': 0.37590593752019996, 'validation/accuracy': 0.9865000247955322, 'validation/loss': 0.045422960072755814, 'validation/mean_average_precision': 0.2465439110624662, 'validation/num_examples': 43793, 'test/accuracy': 0.9856873750686646, 'test/loss': 0.04818981513381004, 'test/mean_average_precision': 0.2416871470637339, 'test/num_examples': 43793, 'score': 4819.962957620621, 'total_duration': 7448.847566127777, 'accumulated_submission_time': 4819.962957620621, 'accumulated_eval_time': 2627.9578578472137, 'accumulated_logging_time': 0.538485050201416}
I0216 08:16:54.622777 140354028304128 logging_writer.py:48] [16146] accumulated_eval_time=2627.957858, accumulated_logging_time=0.538485, accumulated_submission_time=4819.962958, global_step=16146, preemption_count=0, score=4819.962958, test/accuracy=0.985687, test/loss=0.048190, test/mean_average_precision=0.241687, test/num_examples=43793, total_duration=7448.847566, train/accuracy=0.990455, train/loss=0.031750, train/mean_average_precision=0.375906, validation/accuracy=0.986500, validation/loss=0.045423, validation/mean_average_precision=0.246544, validation/num_examples=43793
I0216 08:18:41.900326 140355454342912 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.013394328765571117, loss=0.035240836441516876
I0216 08:20:54.798885 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:22:47.375490 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:22:50.297807 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:22:53.127229 140416551212864 submission_runner.py:408] Time since start: 7807.37s, 	Step: 16943, 	{'train/accuracy': 0.990612804889679, 'train/loss': 0.03107457049190998, 'train/mean_average_precision': 0.39233429934676245, 'validation/accuracy': 0.9866761565208435, 'validation/loss': 0.04493393376469612, 'validation/mean_average_precision': 0.2481883763128292, 'validation/num_examples': 43793, 'test/accuracy': 0.9858095049858093, 'test/loss': 0.047808047384023666, 'test/mean_average_precision': 0.24512845585130877, 'test/num_examples': 43793, 'score': 5060.109432220459, 'total_duration': 7807.369671821594, 'accumulated_submission_time': 5060.109432220459, 'accumulated_eval_time': 2746.2861721515656, 'accumulated_logging_time': 0.5664393901824951}
I0216 08:22:53.144288 140249228961536 logging_writer.py:48] [16943] accumulated_eval_time=2746.286172, accumulated_logging_time=0.566439, accumulated_submission_time=5060.109432, global_step=16943, preemption_count=0, score=5060.109432, test/accuracy=0.985810, test/loss=0.047808, test/mean_average_precision=0.245128, test/num_examples=43793, total_duration=7807.369672, train/accuracy=0.990613, train/loss=0.031075, train/mean_average_precision=0.392334, validation/accuracy=0.986676, validation/loss=0.044934, validation/mean_average_precision=0.248188, validation/num_examples=43793
I0216 08:23:10.595368 140255719360256 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.010110792703926563, loss=0.028684381395578384
I0216 08:25:41.205264 140249228961536 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.012169547379016876, loss=0.03453826531767845
I0216 08:26:53.270936 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:28:47.279113 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:28:50.113349 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:28:52.930508 140416551212864 submission_runner.py:408] Time since start: 8167.17s, 	Step: 17741, 	{'train/accuracy': 0.9904956817626953, 'train/loss': 0.031214365735650063, 'train/mean_average_precision': 0.38275158890208794, 'validation/accuracy': 0.9866238236427307, 'validation/loss': 0.045023247599601746, 'validation/mean_average_precision': 0.25335474403029995, 'validation/num_examples': 43793, 'test/accuracy': 0.9856860637664795, 'test/loss': 0.04797835648059845, 'test/mean_average_precision': 0.24454415557707107, 'test/num_examples': 43793, 'score': 5300.205405473709, 'total_duration': 8167.17295050621, 'accumulated_submission_time': 5300.205405473709, 'accumulated_eval_time': 2865.94571018219, 'accumulated_logging_time': 0.5950961112976074}
I0216 08:28:52.947784 140255727752960 logging_writer.py:48] [17741] accumulated_eval_time=2865.945710, accumulated_logging_time=0.595096, accumulated_submission_time=5300.205405, global_step=17741, preemption_count=0, score=5300.205405, test/accuracy=0.985686, test/loss=0.047978, test/mean_average_precision=0.244544, test/num_examples=43793, total_duration=8167.172951, train/accuracy=0.990496, train/loss=0.031214, train/mean_average_precision=0.382752, validation/accuracy=0.986624, validation/loss=0.045023, validation/mean_average_precision=0.253355, validation/num_examples=43793
I0216 08:30:11.323086 140355454342912 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.012169614434242249, loss=0.031387511640787125
I0216 08:32:41.355387 140255727752960 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.012511744163930416, loss=0.032761216163635254
I0216 08:32:53.226215 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:34:44.306811 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:34:47.130301 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:34:49.909015 140416551212864 submission_runner.py:408] Time since start: 8524.15s, 	Step: 18541, 	{'train/accuracy': 0.9906713366508484, 'train/loss': 0.030988410115242004, 'train/mean_average_precision': 0.3942809964391242, 'validation/accuracy': 0.9865012168884277, 'validation/loss': 0.045165255665779114, 'validation/mean_average_precision': 0.2515437690132111, 'validation/num_examples': 43793, 'test/accuracy': 0.9857690334320068, 'test/loss': 0.047852154821157455, 'test/mean_average_precision': 0.2461328843575586, 'test/num_examples': 43793, 'score': 5540.453552007675, 'total_duration': 8524.151455163956, 'accumulated_submission_time': 5540.453552007675, 'accumulated_eval_time': 2982.6284639835358, 'accumulated_logging_time': 0.623605489730835}
I0216 08:34:49.926280 140249228961536 logging_writer.py:48] [18541] accumulated_eval_time=2982.628464, accumulated_logging_time=0.623605, accumulated_submission_time=5540.453552, global_step=18541, preemption_count=0, score=5540.453552, test/accuracy=0.985769, test/loss=0.047852, test/mean_average_precision=0.246133, test/num_examples=43793, total_duration=8524.151455, train/accuracy=0.990671, train/loss=0.030988, train/mean_average_precision=0.394281, validation/accuracy=0.986501, validation/loss=0.045165, validation/mean_average_precision=0.251544, validation/num_examples=43793
I0216 08:37:08.147212 140255719360256 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.015780869871377945, loss=0.03276148438453674
I0216 08:38:50.068487 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:40:45.321565 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:40:48.172797 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:40:50.966171 140416551212864 submission_runner.py:408] Time since start: 8885.21s, 	Step: 19342, 	{'train/accuracy': 0.9908090233802795, 'train/loss': 0.03019069880247116, 'train/mean_average_precision': 0.4148024368085039, 'validation/accuracy': 0.9866716861724854, 'validation/loss': 0.04501838609576225, 'validation/mean_average_precision': 0.25416378700725173, 'validation/num_examples': 43793, 'test/accuracy': 0.9857636094093323, 'test/loss': 0.04790123179554939, 'test/mean_average_precision': 0.2454797353494288, 'test/num_examples': 43793, 'score': 5780.566792011261, 'total_duration': 8885.208612680435, 'accumulated_submission_time': 5780.566792011261, 'accumulated_eval_time': 3103.5261142253876, 'accumulated_logging_time': 0.6509778499603271}
I0216 08:40:50.983554 140255727752960 logging_writer.py:48] [19342] accumulated_eval_time=3103.526114, accumulated_logging_time=0.650978, accumulated_submission_time=5780.566792, global_step=19342, preemption_count=0, score=5780.566792, test/accuracy=0.985764, test/loss=0.047901, test/mean_average_precision=0.245480, test/num_examples=43793, total_duration=8885.208613, train/accuracy=0.990809, train/loss=0.030191, train/mean_average_precision=0.414802, validation/accuracy=0.986672, validation/loss=0.045018, validation/mean_average_precision=0.254164, validation/num_examples=43793
I0216 08:41:39.049962 140355454342912 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.013960356824100018, loss=0.0321820005774498
I0216 08:44:08.342112 140255727752960 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.014578159898519516, loss=0.037638816982507706
I0216 08:44:51.110408 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:46:45.802518 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:46:48.678986 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:46:51.533058 140416551212864 submission_runner.py:408] Time since start: 9245.78s, 	Step: 20144, 	{'train/accuracy': 0.9909778237342834, 'train/loss': 0.029743582010269165, 'train/mean_average_precision': 0.4217770246896334, 'validation/accuracy': 0.9865962266921997, 'validation/loss': 0.0450168177485466, 'validation/mean_average_precision': 0.2555154354218881, 'validation/num_examples': 43793, 'test/accuracy': 0.9857505559921265, 'test/loss': 0.04772311821579933, 'test/mean_average_precision': 0.24918725581378462, 'test/num_examples': 43793, 'score': 6020.663792848587, 'total_duration': 9245.775425434113, 'accumulated_submission_time': 6020.663792848587, 'accumulated_eval_time': 3223.94864821434, 'accumulated_logging_time': 0.6791856288909912}
I0216 08:46:51.549998 140255719360256 logging_writer.py:48] [20144] accumulated_eval_time=3223.948648, accumulated_logging_time=0.679186, accumulated_submission_time=6020.663793, global_step=20144, preemption_count=0, score=6020.663793, test/accuracy=0.985751, test/loss=0.047723, test/mean_average_precision=0.249187, test/num_examples=43793, total_duration=9245.775425, train/accuracy=0.990978, train/loss=0.029744, train/mean_average_precision=0.421777, validation/accuracy=0.986596, validation/loss=0.045017, validation/mean_average_precision=0.255515, validation/num_examples=43793
I0216 08:48:37.621285 140354028304128 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.016421275213360786, loss=0.03712207078933716
I0216 08:50:51.566084 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:52:43.857637 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:52:46.714334 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:52:49.546125 140416551212864 submission_runner.py:408] Time since start: 9603.79s, 	Step: 20951, 	{'train/accuracy': 0.9909278750419617, 'train/loss': 0.02985651232302189, 'train/mean_average_precision': 0.43761831796315165, 'validation/accuracy': 0.9867184162139893, 'validation/loss': 0.045035701245069504, 'validation/mean_average_precision': 0.25897605582564626, 'validation/num_examples': 43793, 'test/accuracy': 0.9858545660972595, 'test/loss': 0.047893136739730835, 'test/mean_average_precision': 0.24714054132145366, 'test/num_examples': 43793, 'score': 6260.650344848633, 'total_duration': 9603.788563251495, 'accumulated_submission_time': 6260.650344848633, 'accumulated_eval_time': 3341.928655385971, 'accumulated_logging_time': 0.706390380859375}
I0216 08:52:49.563979 140249228961536 logging_writer.py:48] [20951] accumulated_eval_time=3341.928655, accumulated_logging_time=0.706390, accumulated_submission_time=6260.650345, global_step=20951, preemption_count=0, score=6260.650345, test/accuracy=0.985855, test/loss=0.047893, test/mean_average_precision=0.247141, test/num_examples=43793, total_duration=9603.788563, train/accuracy=0.990928, train/loss=0.029857, train/mean_average_precision=0.437618, validation/accuracy=0.986718, validation/loss=0.045036, validation/mean_average_precision=0.258976, validation/num_examples=43793
I0216 08:53:04.425208 140255727752960 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.012760400772094727, loss=0.029749644920229912
I0216 08:55:34.415116 140249228961536 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.014750923030078411, loss=0.031439121812582016
I0216 08:56:49.554664 140416551212864 spec.py:321] Evaluating on the training split.
I0216 08:58:42.931029 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 08:58:45.778519 140416551212864 spec.py:349] Evaluating on the test split.
I0216 08:58:48.593928 140416551212864 submission_runner.py:408] Time since start: 9962.84s, 	Step: 21752, 	{'train/accuracy': 0.9910473823547363, 'train/loss': 0.029282264411449432, 'train/mean_average_precision': 0.4299573748537403, 'validation/accuracy': 0.9867200255393982, 'validation/loss': 0.04476345703005791, 'validation/mean_average_precision': 0.25710807417132997, 'validation/num_examples': 43793, 'test/accuracy': 0.9858187437057495, 'test/loss': 0.0476774200797081, 'test/mean_average_precision': 0.2500796586696012, 'test/num_examples': 43793, 'score': 6500.611852884293, 'total_duration': 9962.836369276047, 'accumulated_submission_time': 6500.611852884293, 'accumulated_eval_time': 3460.967882871628, 'accumulated_logging_time': 0.7341837882995605}
I0216 08:58:48.611443 140255719360256 logging_writer.py:48] [21752] accumulated_eval_time=3460.967883, accumulated_logging_time=0.734184, accumulated_submission_time=6500.611853, global_step=21752, preemption_count=0, score=6500.611853, test/accuracy=0.985819, test/loss=0.047677, test/mean_average_precision=0.250080, test/num_examples=43793, total_duration=9962.836369, train/accuracy=0.991047, train/loss=0.029282, train/mean_average_precision=0.429957, validation/accuracy=0.986720, validation/loss=0.044763, validation/mean_average_precision=0.257108, validation/num_examples=43793
I0216 09:00:04.010564 140355454342912 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.01619410142302513, loss=0.03312485292553902
I0216 09:02:35.440584 140255719360256 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.015359077602624893, loss=0.031151993200182915
I0216 09:02:48.780112 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:04:42.159535 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:04:45.054218 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:04:47.871196 140416551212864 submission_runner.py:408] Time since start: 10322.11s, 	Step: 22545, 	{'train/accuracy': 0.9911746978759766, 'train/loss': 0.02892124466598034, 'train/mean_average_precision': 0.43409493712398334, 'validation/accuracy': 0.9866932034492493, 'validation/loss': 0.044911596924066544, 'validation/mean_average_precision': 0.25689056362501733, 'validation/num_examples': 43793, 'test/accuracy': 0.9858440160751343, 'test/loss': 0.04781201109290123, 'test/mean_average_precision': 0.25152501973539143, 'test/num_examples': 43793, 'score': 6740.751178979874, 'total_duration': 10322.113637924194, 'accumulated_submission_time': 6740.751178979874, 'accumulated_eval_time': 3580.058919906616, 'accumulated_logging_time': 0.7617735862731934}
I0216 09:04:47.889009 140255727752960 logging_writer.py:48] [22545] accumulated_eval_time=3580.058920, accumulated_logging_time=0.761774, accumulated_submission_time=6740.751179, global_step=22545, preemption_count=0, score=6740.751179, test/accuracy=0.985844, test/loss=0.047812, test/mean_average_precision=0.251525, test/num_examples=43793, total_duration=10322.113638, train/accuracy=0.991175, train/loss=0.028921, train/mean_average_precision=0.434095, validation/accuracy=0.986693, validation/loss=0.044912, validation/mean_average_precision=0.256891, validation/num_examples=43793
I0216 09:07:05.921506 140354028304128 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.014474962837994099, loss=0.0325675867497921
I0216 09:08:48.019254 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:10:40.243755 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:10:43.111004 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:10:45.882009 140416551212864 submission_runner.py:408] Time since start: 10680.12s, 	Step: 23340, 	{'train/accuracy': 0.9913663864135742, 'train/loss': 0.02838555909693241, 'train/mean_average_precision': 0.4404243798840853, 'validation/accuracy': 0.9867281317710876, 'validation/loss': 0.04501012712717056, 'validation/mean_average_precision': 0.2604006731856771, 'validation/num_examples': 43793, 'test/accuracy': 0.985854983329773, 'test/loss': 0.047974515706300735, 'test/mean_average_precision': 0.25009127811951803, 'test/num_examples': 43793, 'score': 6980.850264072418, 'total_duration': 10680.12444972992, 'accumulated_submission_time': 6980.850264072418, 'accumulated_eval_time': 3697.921640396118, 'accumulated_logging_time': 0.7909748554229736}
I0216 09:10:45.899664 140255719360256 logging_writer.py:48] [23340] accumulated_eval_time=3697.921640, accumulated_logging_time=0.790975, accumulated_submission_time=6980.850264, global_step=23340, preemption_count=0, score=6980.850264, test/accuracy=0.985855, test/loss=0.047975, test/mean_average_precision=0.250091, test/num_examples=43793, total_duration=10680.124450, train/accuracy=0.991366, train/loss=0.028386, train/mean_average_precision=0.440424, validation/accuracy=0.986728, validation/loss=0.045010, validation/mean_average_precision=0.260401, validation/num_examples=43793
I0216 09:11:34.369308 140355454342912 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.017193730920553207, loss=0.035518791526556015
I0216 09:14:05.701375 140255719360256 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.01788605935871601, loss=0.03331970050930977
I0216 09:14:46.035446 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:16:40.258827 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:16:43.124695 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:16:45.960559 140416551212864 submission_runner.py:408] Time since start: 11040.20s, 	Step: 24136, 	{'train/accuracy': 0.991372287273407, 'train/loss': 0.028289057314395905, 'train/mean_average_precision': 0.46027871333810993, 'validation/accuracy': 0.9867187738418579, 'validation/loss': 0.044788528233766556, 'validation/mean_average_precision': 0.26142029715009113, 'validation/num_examples': 43793, 'test/accuracy': 0.985826313495636, 'test/loss': 0.047689855098724365, 'test/mean_average_precision': 0.25434092903305183, 'test/num_examples': 43793, 'score': 7220.956338167191, 'total_duration': 11040.202916145325, 'accumulated_submission_time': 7220.956338167191, 'accumulated_eval_time': 3817.8466346263885, 'accumulated_logging_time': 0.818695068359375}
I0216 09:16:45.978907 140249228961536 logging_writer.py:48] [24136] accumulated_eval_time=3817.846635, accumulated_logging_time=0.818695, accumulated_submission_time=7220.956338, global_step=24136, preemption_count=0, score=7220.956338, test/accuracy=0.985826, test/loss=0.047690, test/mean_average_precision=0.254341, test/num_examples=43793, total_duration=11040.202916, train/accuracy=0.991372, train/loss=0.028289, train/mean_average_precision=0.460279, validation/accuracy=0.986719, validation/loss=0.044789, validation/mean_average_precision=0.261420, validation/num_examples=43793
I0216 09:18:36.841512 140354028304128 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.017178218811750412, loss=0.03578942269086838
I0216 09:20:46.113732 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:22:41.103896 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:22:44.007109 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:22:46.844463 140416551212864 submission_runner.py:408] Time since start: 11401.09s, 	Step: 24932, 	{'train/accuracy': 0.9915687441825867, 'train/loss': 0.027699299156665802, 'train/mean_average_precision': 0.4716990946912253, 'validation/accuracy': 0.98674476146698, 'validation/loss': 0.0449373722076416, 'validation/mean_average_precision': 0.26186425322178514, 'validation/num_examples': 43793, 'test/accuracy': 0.9858916401863098, 'test/loss': 0.047700054943561554, 'test/mean_average_precision': 0.2539176869882299, 'test/num_examples': 43793, 'score': 7461.059656858444, 'total_duration': 11401.086903572083, 'accumulated_submission_time': 7461.059656858444, 'accumulated_eval_time': 3938.5773425102234, 'accumulated_logging_time': 0.8489046096801758}
I0216 09:22:46.862534 140255719360256 logging_writer.py:48] [24932] accumulated_eval_time=3938.577343, accumulated_logging_time=0.848905, accumulated_submission_time=7461.059657, global_step=24932, preemption_count=0, score=7461.059657, test/accuracy=0.985892, test/loss=0.047700, test/mean_average_precision=0.253918, test/num_examples=43793, total_duration=11401.086904, train/accuracy=0.991569, train/loss=0.027699, train/mean_average_precision=0.471699, validation/accuracy=0.986745, validation/loss=0.044937, validation/mean_average_precision=0.261864, validation/num_examples=43793
I0216 09:23:07.553659 140355454342912 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.01583467237651348, loss=0.03082347847521305
I0216 09:25:37.438247 140255719360256 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.015659695491194725, loss=0.03173846751451492
I0216 09:26:47.052779 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:28:39.735313 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:28:42.591366 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:28:45.417177 140416551212864 submission_runner.py:408] Time since start: 11759.66s, 	Step: 25733, 	{'train/accuracy': 0.9915797114372253, 'train/loss': 0.027492713183164597, 'train/mean_average_precision': 0.4730687510525703, 'validation/accuracy': 0.9867460131645203, 'validation/loss': 0.0448826439678669, 'validation/mean_average_precision': 0.26154000170869923, 'validation/num_examples': 43793, 'test/accuracy': 0.9858928918838501, 'test/loss': 0.04798618704080582, 'test/mean_average_precision': 0.25222066082919237, 'test/num_examples': 43793, 'score': 7701.22026181221, 'total_duration': 11759.659596681595, 'accumulated_submission_time': 7701.22026181221, 'accumulated_eval_time': 4056.9416811466217, 'accumulated_logging_time': 0.8771867752075195}
I0216 09:28:45.436142 140255727752960 logging_writer.py:48] [25733] accumulated_eval_time=4056.941681, accumulated_logging_time=0.877187, accumulated_submission_time=7701.220262, global_step=25733, preemption_count=0, score=7701.220262, test/accuracy=0.985893, test/loss=0.047986, test/mean_average_precision=0.252221, test/num_examples=43793, total_duration=11759.659597, train/accuracy=0.991580, train/loss=0.027493, train/mean_average_precision=0.473069, validation/accuracy=0.986746, validation/loss=0.044883, validation/mean_average_precision=0.261540, validation/num_examples=43793
I0216 09:30:06.245756 140354028304128 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.016895940527319908, loss=0.030396901071071625
I0216 09:32:37.086793 140255727752960 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.017803793773055077, loss=0.032283805310726166
I0216 09:32:45.521274 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:34:40.047204 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:34:42.950004 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:34:45.786788 140416551212864 submission_runner.py:408] Time since start: 12120.03s, 	Step: 26529, 	{'train/accuracy': 0.9913433790206909, 'train/loss': 0.02809208445250988, 'train/mean_average_precision': 0.45075762147258824, 'validation/accuracy': 0.9868685603141785, 'validation/loss': 0.04529117792844772, 'validation/mean_average_precision': 0.2620002614225539, 'validation/num_examples': 43793, 'test/accuracy': 0.9859354496002197, 'test/loss': 0.04851919785141945, 'test/mean_average_precision': 0.2542642290283399, 'test/num_examples': 43793, 'score': 7941.276777505875, 'total_duration': 12120.029221773148, 'accumulated_submission_time': 7941.276777505875, 'accumulated_eval_time': 4177.207139253616, 'accumulated_logging_time': 0.9058983325958252}
I0216 09:34:45.804673 140249228961536 logging_writer.py:48] [26529] accumulated_eval_time=4177.207139, accumulated_logging_time=0.905898, accumulated_submission_time=7941.276778, global_step=26529, preemption_count=0, score=7941.276778, test/accuracy=0.985935, test/loss=0.048519, test/mean_average_precision=0.254264, test/num_examples=43793, total_duration=12120.029222, train/accuracy=0.991343, train/loss=0.028092, train/mean_average_precision=0.450758, validation/accuracy=0.986869, validation/loss=0.045291, validation/mean_average_precision=0.262000, validation/num_examples=43793
I0216 09:37:07.559974 140355454342912 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.016552286222577095, loss=0.030935537070035934
I0216 09:38:45.970708 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:40:38.437382 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:40:41.381945 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:40:44.320996 140416551212864 submission_runner.py:408] Time since start: 12478.56s, 	Step: 27328, 	{'train/accuracy': 0.9916400909423828, 'train/loss': 0.02740594372153282, 'train/mean_average_precision': 0.46238345836105915, 'validation/accuracy': 0.9868117570877075, 'validation/loss': 0.04470028355717659, 'validation/mean_average_precision': 0.2633630571021186, 'validation/num_examples': 43793, 'test/accuracy': 0.9859842658042908, 'test/loss': 0.047634806483983994, 'test/mean_average_precision': 0.2545476116553406, 'test/num_examples': 43793, 'score': 8181.4127452373505, 'total_duration': 12478.563350915909, 'accumulated_submission_time': 8181.4127452373505, 'accumulated_eval_time': 4295.557314634323, 'accumulated_logging_time': 0.9341349601745605}
I0216 09:40:44.339127 140255719360256 logging_writer.py:48] [27328] accumulated_eval_time=4295.557315, accumulated_logging_time=0.934135, accumulated_submission_time=8181.412745, global_step=27328, preemption_count=0, score=8181.412745, test/accuracy=0.985984, test/loss=0.047635, test/mean_average_precision=0.254548, test/num_examples=43793, total_duration=12478.563351, train/accuracy=0.991640, train/loss=0.027406, train/mean_average_precision=0.462383, validation/accuracy=0.986812, validation/loss=0.044700, validation/mean_average_precision=0.263363, validation/num_examples=43793
I0216 09:41:36.701117 140354028304128 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.01590314321219921, loss=0.03223692253232002
I0216 09:44:07.946778 140255719360256 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.018635325133800507, loss=0.03108493611216545
I0216 09:44:44.466266 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:46:38.335068 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:46:41.316683 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:46:44.276286 140416551212864 submission_runner.py:408] Time since start: 12838.52s, 	Step: 28122, 	{'train/accuracy': 0.9915293455123901, 'train/loss': 0.027663227170705795, 'train/mean_average_precision': 0.4664474926785296, 'validation/accuracy': 0.9868231415748596, 'validation/loss': 0.0446750745177269, 'validation/mean_average_precision': 0.2692567573218211, 'validation/num_examples': 43793, 'test/accuracy': 0.9859354496002197, 'test/loss': 0.047677986323833466, 'test/mean_average_precision': 0.26068469743637285, 'test/num_examples': 43793, 'score': 8421.509254932404, 'total_duration': 12838.518723964691, 'accumulated_submission_time': 8421.509254932404, 'accumulated_eval_time': 4415.367299079895, 'accumulated_logging_time': 0.9636819362640381}
I0216 09:46:44.294551 140249228961536 logging_writer.py:48] [28122] accumulated_eval_time=4415.367299, accumulated_logging_time=0.963682, accumulated_submission_time=8421.509255, global_step=28122, preemption_count=0, score=8421.509255, test/accuracy=0.985935, test/loss=0.047678, test/mean_average_precision=0.260685, test/num_examples=43793, total_duration=12838.518724, train/accuracy=0.991529, train/loss=0.027663, train/mean_average_precision=0.466447, validation/accuracy=0.986823, validation/loss=0.044675, validation/mean_average_precision=0.269257, validation/num_examples=43793
I0216 09:48:38.021744 140255727752960 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.015139029361307621, loss=0.02755158022046089
I0216 09:50:44.514100 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:52:35.346012 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:52:38.231403 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:52:41.032633 140416551212864 submission_runner.py:408] Time since start: 13195.27s, 	Step: 28927, 	{'train/accuracy': 0.9917492866516113, 'train/loss': 0.027109364047646523, 'train/mean_average_precision': 0.4802211629750986, 'validation/accuracy': 0.9868393540382385, 'validation/loss': 0.044765908271074295, 'validation/mean_average_precision': 0.26741467625240756, 'validation/num_examples': 43793, 'test/accuracy': 0.9859552383422852, 'test/loss': 0.04780218005180359, 'test/mean_average_precision': 0.2553599243545492, 'test/num_examples': 43793, 'score': 8661.698993682861, 'total_duration': 13195.27497792244, 'accumulated_submission_time': 8661.698993682861, 'accumulated_eval_time': 4531.88570356369, 'accumulated_logging_time': 0.992128849029541}
I0216 09:52:41.050431 140354028304128 logging_writer.py:48] [28927] accumulated_eval_time=4531.885704, accumulated_logging_time=0.992129, accumulated_submission_time=8661.698994, global_step=28927, preemption_count=0, score=8661.698994, test/accuracy=0.985955, test/loss=0.047802, test/mean_average_precision=0.255360, test/num_examples=43793, total_duration=13195.274978, train/accuracy=0.991749, train/loss=0.027109, train/mean_average_precision=0.480221, validation/accuracy=0.986839, validation/loss=0.044766, validation/mean_average_precision=0.267415, validation/num_examples=43793
I0216 09:53:02.910697 140355454342912 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.01712666265666485, loss=0.02738071419298649
I0216 09:55:30.753458 140354028304128 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.016687685623764992, loss=0.030160631984472275
I0216 09:56:41.093385 140416551212864 spec.py:321] Evaluating on the training split.
I0216 09:58:35.710411 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 09:58:38.547959 140416551212864 spec.py:349] Evaluating on the test split.
I0216 09:58:41.331238 140416551212864 submission_runner.py:408] Time since start: 13555.57s, 	Step: 29739, 	{'train/accuracy': 0.9917426109313965, 'train/loss': 0.02703236974775791, 'train/mean_average_precision': 0.4809532278646276, 'validation/accuracy': 0.9868941903114319, 'validation/loss': 0.04467928037047386, 'validation/mean_average_precision': 0.26669006199691603, 'validation/num_examples': 43793, 'test/accuracy': 0.9859615564346313, 'test/loss': 0.04773896560072899, 'test/mean_average_precision': 0.2565497417525822, 'test/num_examples': 43793, 'score': 8901.712589025497, 'total_duration': 13555.573674201965, 'accumulated_submission_time': 8901.712589025497, 'accumulated_eval_time': 4652.123513698578, 'accumulated_logging_time': 1.0198748111724854}
I0216 09:58:41.349997 140255719360256 logging_writer.py:48] [29739] accumulated_eval_time=4652.123514, accumulated_logging_time=1.019875, accumulated_submission_time=8901.712589, global_step=29739, preemption_count=0, score=8901.712589, test/accuracy=0.985962, test/loss=0.047739, test/mean_average_precision=0.256550, test/num_examples=43793, total_duration=13555.573674, train/accuracy=0.991743, train/loss=0.027032, train/mean_average_precision=0.480953, validation/accuracy=0.986894, validation/loss=0.044679, validation/mean_average_precision=0.266690, validation/num_examples=43793
I0216 09:59:59.116275 140255727752960 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.01762201450765133, loss=0.02932683192193508
I0216 10:02:27.687050 140255719360256 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.019510846585035324, loss=0.030961813405156136
I0216 10:02:41.596207 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:04:35.901688 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:04:38.741873 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:04:41.600345 140416551212864 submission_runner.py:408] Time since start: 13915.84s, 	Step: 30548, 	{'train/accuracy': 0.9916932582855225, 'train/loss': 0.027075789868831635, 'train/mean_average_precision': 0.4752708787929151, 'validation/accuracy': 0.986865758895874, 'validation/loss': 0.04494989663362503, 'validation/mean_average_precision': 0.2699758831797729, 'validation/num_examples': 43793, 'test/accuracy': 0.9859446883201599, 'test/loss': 0.048080362379550934, 'test/mean_average_precision': 0.25860096438138347, 'test/num_examples': 43793, 'score': 9141.928536176682, 'total_duration': 13915.84278345108, 'accumulated_submission_time': 9141.928536176682, 'accumulated_eval_time': 4772.127604484558, 'accumulated_logging_time': 1.0492854118347168}
I0216 10:04:41.618795 140249228961536 logging_writer.py:48] [30548] accumulated_eval_time=4772.127604, accumulated_logging_time=1.049285, accumulated_submission_time=9141.928536, global_step=30548, preemption_count=0, score=9141.928536, test/accuracy=0.985945, test/loss=0.048080, test/mean_average_precision=0.258601, test/num_examples=43793, total_duration=13915.842783, train/accuracy=0.991693, train/loss=0.027076, train/mean_average_precision=0.475271, validation/accuracy=0.986866, validation/loss=0.044950, validation/mean_average_precision=0.269976, validation/num_examples=43793
I0216 10:06:57.220864 140355454342912 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.0201962199062109, loss=0.032478347420692444
I0216 10:08:41.844913 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:10:33.090753 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:10:35.935544 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:10:38.757465 140416551212864 submission_runner.py:408] Time since start: 14273.00s, 	Step: 31350, 	{'train/accuracy': 0.9917203187942505, 'train/loss': 0.027021752670407295, 'train/mean_average_precision': 0.4709897739352743, 'validation/accuracy': 0.986737072467804, 'validation/loss': 0.044955238699913025, 'validation/mean_average_precision': 0.26829487684367065, 'validation/num_examples': 43793, 'test/accuracy': 0.9858831763267517, 'test/loss': 0.04802945256233215, 'test/mean_average_precision': 0.2590827958646767, 'test/num_examples': 43793, 'score': 9382.122972011566, 'total_duration': 14272.999755382538, 'accumulated_submission_time': 9382.122972011566, 'accumulated_eval_time': 4889.039973020554, 'accumulated_logging_time': 1.0792818069458008}
I0216 10:10:38.775869 140255719360256 logging_writer.py:48] [31350] accumulated_eval_time=4889.039973, accumulated_logging_time=1.079282, accumulated_submission_time=9382.122972, global_step=31350, preemption_count=0, score=9382.122972, test/accuracy=0.985883, test/loss=0.048029, test/mean_average_precision=0.259083, test/num_examples=43793, total_duration=14272.999755, train/accuracy=0.991720, train/loss=0.027022, train/mean_average_precision=0.470990, validation/accuracy=0.986737, validation/loss=0.044955, validation/mean_average_precision=0.268295, validation/num_examples=43793
I0216 10:11:23.806053 140255727752960 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.017962688580155373, loss=0.02797602489590645
I0216 10:13:53.121378 140255719360256 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.022928301244974136, loss=0.030446672812104225
I0216 10:14:38.995907 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:16:32.967088 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:16:35.835532 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:16:38.659926 140416551212864 submission_runner.py:408] Time since start: 14632.90s, 	Step: 32156, 	{'train/accuracy': 0.9918476939201355, 'train/loss': 0.02664249576628208, 'train/mean_average_precision': 0.4916928244609285, 'validation/accuracy': 0.9868133664131165, 'validation/loss': 0.0448586568236351, 'validation/mean_average_precision': 0.2655469187525397, 'validation/num_examples': 43793, 'test/accuracy': 0.9859653115272522, 'test/loss': 0.04783427715301514, 'test/mean_average_precision': 0.2589094172859118, 'test/num_examples': 43793, 'score': 9622.31300854683, 'total_duration': 14632.902275800705, 'accumulated_submission_time': 9622.31300854683, 'accumulated_eval_time': 5008.703879117966, 'accumulated_logging_time': 1.107926607131958}
I0216 10:16:38.678379 140249228961536 logging_writer.py:48] [32156] accumulated_eval_time=5008.703879, accumulated_logging_time=1.107927, accumulated_submission_time=9622.313009, global_step=32156, preemption_count=0, score=9622.313009, test/accuracy=0.985965, test/loss=0.047834, test/mean_average_precision=0.258909, test/num_examples=43793, total_duration=14632.902276, train/accuracy=0.991848, train/loss=0.026642, train/mean_average_precision=0.491693, validation/accuracy=0.986813, validation/loss=0.044859, validation/mean_average_precision=0.265547, validation/num_examples=43793
I0216 10:18:21.832093 140354028304128 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.018621282652020454, loss=0.02842055819928646
I0216 10:20:38.665034 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:22:27.103048 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:22:29.995285 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:22:32.791857 140416551212864 submission_runner.py:408] Time since start: 14987.03s, 	Step: 32960, 	{'train/accuracy': 0.9917860627174377, 'train/loss': 0.02667124755680561, 'train/mean_average_precision': 0.4956820803213057, 'validation/accuracy': 0.9869368076324463, 'validation/loss': 0.04521826654672623, 'validation/mean_average_precision': 0.2669544895081704, 'validation/num_examples': 43793, 'test/accuracy': 0.9859678745269775, 'test/loss': 0.04850877448916435, 'test/mean_average_precision': 0.25360504780742593, 'test/num_examples': 43793, 'score': 9862.268160581589, 'total_duration': 14987.034296751022, 'accumulated_submission_time': 9862.268160581589, 'accumulated_eval_time': 5122.830671548843, 'accumulated_logging_time': 1.1380386352539062}
I0216 10:22:32.810554 140255719360256 logging_writer.py:48] [32960] accumulated_eval_time=5122.830672, accumulated_logging_time=1.138039, accumulated_submission_time=9862.268161, global_step=32960, preemption_count=0, score=9862.268161, test/accuracy=0.985968, test/loss=0.048509, test/mean_average_precision=0.253605, test/num_examples=43793, total_duration=14987.034297, train/accuracy=0.991786, train/loss=0.026671, train/mean_average_precision=0.495682, validation/accuracy=0.986937, validation/loss=0.045218, validation/mean_average_precision=0.266954, validation/num_examples=43793
I0216 10:22:45.039920 140355454342912 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.01810215786099434, loss=0.026765167713165283
I0216 10:25:14.491048 140255719360256 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.021359020844101906, loss=0.03014690987765789
I0216 10:26:32.817884 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:28:23.883640 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:28:26.715899 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:28:29.521650 140416551212864 submission_runner.py:408] Time since start: 15343.76s, 	Step: 33765, 	{'train/accuracy': 0.9919589757919312, 'train/loss': 0.02623666450381279, 'train/mean_average_precision': 0.49817739130154076, 'validation/accuracy': 0.986812174320221, 'validation/loss': 0.04494292289018631, 'validation/mean_average_precision': 0.26880413084108296, 'validation/num_examples': 43793, 'test/accuracy': 0.9858899712562561, 'test/loss': 0.04812289774417877, 'test/mean_average_precision': 0.2577870568466685, 'test/num_examples': 43793, 'score': 10102.244501113892, 'total_duration': 15343.763989925385, 'accumulated_submission_time': 10102.244501113892, 'accumulated_eval_time': 5239.534306526184, 'accumulated_logging_time': 1.1680183410644531}
I0216 10:28:29.540846 140255727752960 logging_writer.py:48] [33765] accumulated_eval_time=5239.534307, accumulated_logging_time=1.168018, accumulated_submission_time=10102.244501, global_step=33765, preemption_count=0, score=10102.244501, test/accuracy=0.985890, test/loss=0.048123, test/mean_average_precision=0.257787, test/num_examples=43793, total_duration=15343.763990, train/accuracy=0.991959, train/loss=0.026237, train/mean_average_precision=0.498177, validation/accuracy=0.986812, validation/loss=0.044943, validation/mean_average_precision=0.268804, validation/num_examples=43793
I0216 10:29:39.966851 140354028304128 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.018339527770876884, loss=0.027896730229258537
I0216 10:32:08.197595 140255727752960 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.02303321659564972, loss=0.02912812866270542
I0216 10:32:29.716003 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:34:18.667208 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:34:21.549107 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:34:24.382344 140416551212864 submission_runner.py:408] Time since start: 15698.62s, 	Step: 34573, 	{'train/accuracy': 0.9918607473373413, 'train/loss': 0.02646014466881752, 'train/mean_average_precision': 0.493075980768225, 'validation/accuracy': 0.9868962168693542, 'validation/loss': 0.045065563172101974, 'validation/mean_average_precision': 0.2666738464573022, 'validation/num_examples': 43793, 'test/accuracy': 0.9860053658485413, 'test/loss': 0.0481819324195385, 'test/mean_average_precision': 0.25851227341733907, 'test/num_examples': 43793, 'score': 10342.132805585861, 'total_duration': 15698.62466287613, 'accumulated_submission_time': 10342.132805585861, 'accumulated_eval_time': 5354.200483798981, 'accumulated_logging_time': 1.4540390968322754}
I0216 10:34:24.400923 140240548042496 logging_writer.py:48] [34573] accumulated_eval_time=5354.200484, accumulated_logging_time=1.454039, accumulated_submission_time=10342.132806, global_step=34573, preemption_count=0, score=10342.132806, test/accuracy=0.986005, test/loss=0.048182, test/mean_average_precision=0.258512, test/num_examples=43793, total_duration=15698.624663, train/accuracy=0.991861, train/loss=0.026460, train/mean_average_precision=0.493076, validation/accuracy=0.986896, validation/loss=0.045066, validation/mean_average_precision=0.266674, validation/num_examples=43793
I0216 10:36:31.969958 140255719360256 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.022004514932632446, loss=0.031357910484075546
I0216 10:38:24.533857 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:40:14.903613 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:40:17.793334 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:40:20.598429 140416551212864 submission_runner.py:408] Time since start: 16054.84s, 	Step: 35379, 	{'train/accuracy': 0.9919452667236328, 'train/loss': 0.026180777698755264, 'train/mean_average_precision': 0.49923270169716527, 'validation/accuracy': 0.9869120121002197, 'validation/loss': 0.045097459107637405, 'validation/mean_average_precision': 0.26940836127325546, 'validation/num_examples': 43793, 'test/accuracy': 0.9859476685523987, 'test/loss': 0.048286788165569305, 'test/mean_average_precision': 0.25372322280924825, 'test/num_examples': 43793, 'score': 10582.235233783722, 'total_duration': 16054.840868234634, 'accumulated_submission_time': 10582.235233783722, 'accumulated_eval_time': 5470.265028476715, 'accumulated_logging_time': 1.4830470085144043}
I0216 10:40:20.617197 140249228961536 logging_writer.py:48] [35379] accumulated_eval_time=5470.265028, accumulated_logging_time=1.483047, accumulated_submission_time=10582.235234, global_step=35379, preemption_count=0, score=10582.235234, test/accuracy=0.985948, test/loss=0.048287, test/mean_average_precision=0.253723, test/num_examples=43793, total_duration=16054.840868, train/accuracy=0.991945, train/loss=0.026181, train/mean_average_precision=0.499233, validation/accuracy=0.986912, validation/loss=0.045097, validation/mean_average_precision=0.269408, validation/num_examples=43793
I0216 10:40:56.940102 140354028304128 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.02171752043068409, loss=0.03011195920407772
I0216 10:43:26.559389 140249228961536 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.020425215363502502, loss=0.025594381615519524
I0216 10:44:20.630763 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:46:13.839186 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:46:16.698175 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:46:19.479494 140416551212864 submission_runner.py:408] Time since start: 16413.72s, 	Step: 36183, 	{'train/accuracy': 0.991944432258606, 'train/loss': 0.02608388103544712, 'train/mean_average_precision': 0.4997910378006097, 'validation/accuracy': 0.9869709014892578, 'validation/loss': 0.04498779773712158, 'validation/mean_average_precision': 0.27194279500630575, 'validation/num_examples': 43793, 'test/accuracy': 0.9859986305236816, 'test/loss': 0.04804445803165436, 'test/mean_average_precision': 0.25841879550460184, 'test/num_examples': 43793, 'score': 10822.21910572052, 'total_duration': 16413.721934080124, 'accumulated_submission_time': 10822.21910572052, 'accumulated_eval_time': 5589.113726377487, 'accumulated_logging_time': 1.51165771484375}
I0216 10:46:19.498580 140240548042496 logging_writer.py:48] [36183] accumulated_eval_time=5589.113726, accumulated_logging_time=1.511658, accumulated_submission_time=10822.219106, global_step=36183, preemption_count=0, score=10822.219106, test/accuracy=0.985999, test/loss=0.048044, test/mean_average_precision=0.258419, test/num_examples=43793, total_duration=16413.721934, train/accuracy=0.991944, train/loss=0.026084, train/mean_average_precision=0.499791, validation/accuracy=0.986971, validation/loss=0.044988, validation/mean_average_precision=0.271943, validation/num_examples=43793
I0216 10:47:54.867255 140255727752960 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.027005678042769432, loss=0.027384916320443153
I0216 10:50:19.548003 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:52:06.945313 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:52:10.750852 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:52:13.557445 140416551212864 submission_runner.py:408] Time since start: 16767.80s, 	Step: 36985, 	{'train/accuracy': 0.9921455383300781, 'train/loss': 0.025538846850395203, 'train/mean_average_precision': 0.5099983919537467, 'validation/accuracy': 0.9868669509887695, 'validation/loss': 0.045088790357112885, 'validation/mean_average_precision': 0.27147596527803103, 'validation/num_examples': 43793, 'test/accuracy': 0.9859269857406616, 'test/loss': 0.04822063073515892, 'test/mean_average_precision': 0.2552624783581714, 'test/num_examples': 43793, 'score': 11062.236684799194, 'total_duration': 16767.79988336563, 'accumulated_submission_time': 11062.236684799194, 'accumulated_eval_time': 5703.1231327056885, 'accumulated_logging_time': 1.5422985553741455}
I0216 10:52:13.577257 140255719360256 logging_writer.py:48] [36985] accumulated_eval_time=5703.123133, accumulated_logging_time=1.542299, accumulated_submission_time=11062.236685, global_step=36985, preemption_count=0, score=11062.236685, test/accuracy=0.985927, test/loss=0.048221, test/mean_average_precision=0.255262, test/num_examples=43793, total_duration=16767.799883, train/accuracy=0.992146, train/loss=0.025539, train/mean_average_precision=0.509998, validation/accuracy=0.986867, validation/loss=0.045089, validation/mean_average_precision=0.271476, validation/num_examples=43793
I0216 10:52:18.294328 140354028304128 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.02470877207815647, loss=0.03141031786799431
I0216 10:54:47.487544 140255719360256 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.021840857341885567, loss=0.028462756425142288
I0216 10:56:13.851010 140416551212864 spec.py:321] Evaluating on the training split.
I0216 10:58:07.173182 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 10:58:10.011907 140416551212864 spec.py:349] Evaluating on the test split.
I0216 10:58:12.804776 140416551212864 submission_runner.py:408] Time since start: 17127.05s, 	Step: 37790, 	{'train/accuracy': 0.9922175407409668, 'train/loss': 0.02545107714831829, 'train/mean_average_precision': 0.5226939458417625, 'validation/accuracy': 0.9868113398551941, 'validation/loss': 0.044885601848363876, 'validation/mean_average_precision': 0.270119359014984, 'validation/num_examples': 43793, 'test/accuracy': 0.9859526753425598, 'test/loss': 0.04785004258155823, 'test/mean_average_precision': 0.260474715508027, 'test/num_examples': 43793, 'score': 11302.480284929276, 'total_duration': 17127.047206640244, 'accumulated_submission_time': 11302.480284929276, 'accumulated_eval_time': 5822.076856136322, 'accumulated_logging_time': 1.5720384120941162}
I0216 10:58:12.824139 140249228961536 logging_writer.py:48] [37790] accumulated_eval_time=5822.076856, accumulated_logging_time=1.572038, accumulated_submission_time=11302.480285, global_step=37790, preemption_count=0, score=11302.480285, test/accuracy=0.985953, test/loss=0.047850, test/mean_average_precision=0.260475, test/num_examples=43793, total_duration=17127.047207, train/accuracy=0.992218, train/loss=0.025451, train/mean_average_precision=0.522694, validation/accuracy=0.986811, validation/loss=0.044886, validation/mean_average_precision=0.270119, validation/num_examples=43793
I0216 10:59:15.941747 140255727752960 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.026718804612755775, loss=0.02672569267451763
I0216 11:01:46.332120 140249228961536 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.022419853135943413, loss=0.0308452807366848
I0216 11:02:12.819088 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:04:06.387674 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:04:09.281368 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:04:12.129833 140416551212864 submission_runner.py:408] Time since start: 17486.37s, 	Step: 38589, 	{'train/accuracy': 0.992182731628418, 'train/loss': 0.025342701002955437, 'train/mean_average_precision': 0.5217016574919506, 'validation/accuracy': 0.9868559837341309, 'validation/loss': 0.04504327476024628, 'validation/mean_average_precision': 0.2768410704805472, 'validation/num_examples': 43793, 'test/accuracy': 0.9859417676925659, 'test/loss': 0.04802359640598297, 'test/mean_average_precision': 0.25969182007397157, 'test/num_examples': 43793, 'score': 11542.44424200058, 'total_duration': 17486.37224960327, 'accumulated_submission_time': 11542.44424200058, 'accumulated_eval_time': 5941.387535810471, 'accumulated_logging_time': 1.6027278900146484}
I0216 11:04:12.153894 140240548042496 logging_writer.py:48] [38589] accumulated_eval_time=5941.387536, accumulated_logging_time=1.602728, accumulated_submission_time=11542.444242, global_step=38589, preemption_count=0, score=11542.444242, test/accuracy=0.985942, test/loss=0.048024, test/mean_average_precision=0.259692, test/num_examples=43793, total_duration=17486.372250, train/accuracy=0.992183, train/loss=0.025343, train/mean_average_precision=0.521702, validation/accuracy=0.986856, validation/loss=0.045043, validation/mean_average_precision=0.276841, validation/num_examples=43793
I0216 11:06:15.762295 140255719360256 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.025778764858841896, loss=0.026449985802173615
I0216 11:08:12.221645 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:10:03.705890 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:10:06.531576 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:10:09.330471 140416551212864 submission_runner.py:408] Time since start: 17843.57s, 	Step: 39386, 	{'train/accuracy': 0.9921956062316895, 'train/loss': 0.0252446997910738, 'train/mean_average_precision': 0.511250873621642, 'validation/accuracy': 0.9868945479393005, 'validation/loss': 0.04515570029616356, 'validation/mean_average_precision': 0.27264549061422205, 'validation/num_examples': 43793, 'test/accuracy': 0.9860411286354065, 'test/loss': 0.048190921545028687, 'test/mean_average_precision': 0.2582591956926438, 'test/num_examples': 43793, 'score': 11782.47777724266, 'total_duration': 17843.572909116745, 'accumulated_submission_time': 11782.47777724266, 'accumulated_eval_time': 6058.496329307556, 'accumulated_logging_time': 1.6405205726623535}
I0216 11:10:09.349827 140239086876416 logging_writer.py:48] [39386] accumulated_eval_time=6058.496329, accumulated_logging_time=1.640521, accumulated_submission_time=11782.477777, global_step=39386, preemption_count=0, score=11782.477777, test/accuracy=0.986041, test/loss=0.048191, test/mean_average_precision=0.258259, test/num_examples=43793, total_duration=17843.572909, train/accuracy=0.992196, train/loss=0.025245, train/mean_average_precision=0.511251, validation/accuracy=0.986895, validation/loss=0.045156, validation/mean_average_precision=0.272645, validation/num_examples=43793
I0216 11:10:44.866067 140255727752960 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.02570522390305996, loss=0.029560359194874763
I0216 11:13:15.133766 140239086876416 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.02099519781768322, loss=0.028798384591937065
I0216 11:14:09.608534 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:15:59.988173 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:16:02.883787 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:16:05.697999 140416551212864 submission_runner.py:408] Time since start: 18199.94s, 	Step: 40183, 	{'train/accuracy': 0.9922892451286316, 'train/loss': 0.025013025850057602, 'train/mean_average_precision': 0.5225452270794689, 'validation/accuracy': 0.986901044845581, 'validation/loss': 0.04534929618239403, 'validation/mean_average_precision': 0.2729705354671894, 'validation/num_examples': 43793, 'test/accuracy': 0.9860386252403259, 'test/loss': 0.04831911623477936, 'test/mean_average_precision': 0.2562086760981972, 'test/num_examples': 43793, 'score': 12022.704268217087, 'total_duration': 18199.940435647964, 'accumulated_submission_time': 12022.704268217087, 'accumulated_eval_time': 6174.58575129509, 'accumulated_logging_time': 1.6714468002319336}
I0216 11:16:05.717378 140240548042496 logging_writer.py:48] [40183] accumulated_eval_time=6174.585751, accumulated_logging_time=1.671447, accumulated_submission_time=12022.704268, global_step=40183, preemption_count=0, score=12022.704268, test/accuracy=0.986039, test/loss=0.048319, test/mean_average_precision=0.256209, test/num_examples=43793, total_duration=18199.940436, train/accuracy=0.992289, train/loss=0.025013, train/mean_average_precision=0.522545, validation/accuracy=0.986901, validation/loss=0.045349, validation/mean_average_precision=0.272971, validation/num_examples=43793
I0216 11:17:40.268184 140249228961536 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.02317604422569275, loss=0.025181088596582413
I0216 11:20:05.734704 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:21:54.440575 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:21:57.351061 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:22:00.189007 140416551212864 submission_runner.py:408] Time since start: 18554.43s, 	Step: 40991, 	{'train/accuracy': 0.9924004673957825, 'train/loss': 0.02464117854833603, 'train/mean_average_precision': 0.537957910609613, 'validation/accuracy': 0.9868661761283875, 'validation/loss': 0.045313309878110886, 'validation/mean_average_precision': 0.27323351152078496, 'validation/num_examples': 43793, 'test/accuracy': 0.9859472513198853, 'test/loss': 0.048459116369485855, 'test/mean_average_precision': 0.2610771375571753, 'test/num_examples': 43793, 'score': 12262.691478013992, 'total_duration': 18554.431445121765, 'accumulated_submission_time': 12262.691478013992, 'accumulated_eval_time': 6289.040021657944, 'accumulated_logging_time': 1.7009563446044922}
I0216 11:22:00.208556 140239095269120 logging_writer.py:48] [40991] accumulated_eval_time=6289.040022, accumulated_logging_time=1.700956, accumulated_submission_time=12262.691478, global_step=40991, preemption_count=0, score=12262.691478, test/accuracy=0.985947, test/loss=0.048459, test/mean_average_precision=0.261077, test/num_examples=43793, total_duration=18554.431445, train/accuracy=0.992400, train/loss=0.024641, train/mean_average_precision=0.537958, validation/accuracy=0.986866, validation/loss=0.045313, validation/mean_average_precision=0.273234, validation/num_examples=43793
I0216 11:22:03.233833 140255719360256 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.02099037356674671, loss=0.025447484105825424
I0216 11:24:32.485630 140239095269120 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.02409135177731514, loss=0.02746696211397648
I0216 11:26:00.241874 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:27:50.482085 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:27:53.304321 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:27:56.072042 140416551212864 submission_runner.py:408] Time since start: 18910.31s, 	Step: 41795, 	{'train/accuracy': 0.9924507737159729, 'train/loss': 0.024626241996884346, 'train/mean_average_precision': 0.5333804592644633, 'validation/accuracy': 0.986935555934906, 'validation/loss': 0.04509740695357323, 'validation/mean_average_precision': 0.27342447078120585, 'validation/num_examples': 43793, 'test/accuracy': 0.9860251545906067, 'test/loss': 0.048237673938274384, 'test/mean_average_precision': 0.258896535536681, 'test/num_examples': 43793, 'score': 12502.694967746735, 'total_duration': 18910.314481973648, 'accumulated_submission_time': 12502.694967746735, 'accumulated_eval_time': 6404.870155096054, 'accumulated_logging_time': 1.7307236194610596}
I0216 11:27:56.091720 140240548042496 logging_writer.py:48] [41795] accumulated_eval_time=6404.870155, accumulated_logging_time=1.730724, accumulated_submission_time=12502.694968, global_step=41795, preemption_count=0, score=12502.694968, test/accuracy=0.986025, test/loss=0.048238, test/mean_average_precision=0.258897, test/num_examples=43793, total_duration=18910.314482, train/accuracy=0.992451, train/loss=0.024626, train/mean_average_precision=0.533380, validation/accuracy=0.986936, validation/loss=0.045097, validation/mean_average_precision=0.273424, validation/num_examples=43793
I0216 11:28:57.600550 140249228961536 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.024013010784983635, loss=0.026862451806664467
I0216 11:31:26.705299 140240548042496 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.02539178729057312, loss=0.028359634801745415
I0216 11:31:56.113510 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:33:44.179631 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:33:47.006088 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:33:49.799951 140416551212864 submission_runner.py:408] Time since start: 19264.04s, 	Step: 42600, 	{'train/accuracy': 0.9924954771995544, 'train/loss': 0.024203160777688026, 'train/mean_average_precision': 0.5456466575510697, 'validation/accuracy': 0.9869043231010437, 'validation/loss': 0.04519158974289894, 'validation/mean_average_precision': 0.27511370490430326, 'validation/num_examples': 43793, 'test/accuracy': 0.9860247373580933, 'test/loss': 0.04838308319449425, 'test/mean_average_precision': 0.25838264277939843, 'test/num_examples': 43793, 'score': 12742.68578529358, 'total_duration': 19264.04238629341, 'accumulated_submission_time': 12742.68578529358, 'accumulated_eval_time': 6518.5565485954285, 'accumulated_logging_time': 1.7616491317749023}
I0216 11:33:49.820358 140239095269120 logging_writer.py:48] [42600] accumulated_eval_time=6518.556549, accumulated_logging_time=1.761649, accumulated_submission_time=12742.685785, global_step=42600, preemption_count=0, score=12742.685785, test/accuracy=0.986025, test/loss=0.048383, test/mean_average_precision=0.258383, test/num_examples=43793, total_duration=19264.042386, train/accuracy=0.992495, train/loss=0.024203, train/mean_average_precision=0.545647, validation/accuracy=0.986904, validation/loss=0.045192, validation/mean_average_precision=0.275114, validation/num_examples=43793
I0216 11:35:49.062445 140255727752960 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.022450244054198265, loss=0.02572086825966835
I0216 11:37:49.926382 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:39:39.999462 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:39:42.858618 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:39:45.658917 140416551212864 submission_runner.py:408] Time since start: 19619.90s, 	Step: 43404, 	{'train/accuracy': 0.9924352169036865, 'train/loss': 0.02433331124484539, 'train/mean_average_precision': 0.5414993508027892, 'validation/accuracy': 0.9869801998138428, 'validation/loss': 0.04537877440452576, 'validation/mean_average_precision': 0.27512099070949264, 'validation/num_examples': 43793, 'test/accuracy': 0.9860870838165283, 'test/loss': 0.04854248836636543, 'test/mean_average_precision': 0.2594711247718872, 'test/num_examples': 43793, 'score': 12982.761003732681, 'total_duration': 19619.90135717392, 'accumulated_submission_time': 12982.761003732681, 'accumulated_eval_time': 6634.289053916931, 'accumulated_logging_time': 1.7924144268035889}
I0216 11:39:45.679298 140249228961536 logging_writer.py:48] [43404] accumulated_eval_time=6634.289054, accumulated_logging_time=1.792414, accumulated_submission_time=12982.761004, global_step=43404, preemption_count=0, score=12982.761004, test/accuracy=0.986087, test/loss=0.048542, test/mean_average_precision=0.259471, test/num_examples=43793, total_duration=19619.901357, train/accuracy=0.992435, train/loss=0.024333, train/mean_average_precision=0.541499, validation/accuracy=0.986980, validation/loss=0.045379, validation/mean_average_precision=0.275121, validation/num_examples=43793
I0216 11:40:14.460677 140255719360256 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.02752315066754818, loss=0.02954881452023983
I0216 11:42:43.738089 140249228961536 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.024602921679615974, loss=0.02698144130408764
I0216 11:43:45.901952 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:45:31.168615 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:45:34.018913 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:45:36.931130 140416551212864 submission_runner.py:408] Time since start: 19971.17s, 	Step: 44210, 	{'train/accuracy': 0.9925671219825745, 'train/loss': 0.024143295362591743, 'train/mean_average_precision': 0.5367888907544053, 'validation/accuracy': 0.9869238138198853, 'validation/loss': 0.04540529102087021, 'validation/mean_average_precision': 0.27529657458412704, 'validation/num_examples': 43793, 'test/accuracy': 0.9860508441925049, 'test/loss': 0.04852164909243584, 'test/mean_average_precision': 0.2611568913376222, 'test/num_examples': 43793, 'score': 13222.95099234581, 'total_duration': 19971.173470258713, 'accumulated_submission_time': 13222.95099234581, 'accumulated_eval_time': 6745.318096399307, 'accumulated_logging_time': 1.825453281402588}
I0216 11:45:36.950769 140239095269120 logging_writer.py:48] [44210] accumulated_eval_time=6745.318096, accumulated_logging_time=1.825453, accumulated_submission_time=13222.950992, global_step=44210, preemption_count=0, score=13222.950992, test/accuracy=0.986051, test/loss=0.048522, test/mean_average_precision=0.261157, test/num_examples=43793, total_duration=19971.173470, train/accuracy=0.992567, train/loss=0.024143, train/mean_average_precision=0.536789, validation/accuracy=0.986924, validation/loss=0.045405, validation/mean_average_precision=0.275297, validation/num_examples=43793
I0216 11:47:03.283776 140240548042496 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.025256047025322914, loss=0.02626703307032585
I0216 11:49:31.602098 140239095269120 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.024240588769316673, loss=0.026580044999718666
I0216 11:49:37.174921 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:51:23.051403 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:51:25.910663 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:51:28.743599 140416551212864 submission_runner.py:408] Time since start: 20322.99s, 	Step: 45020, 	{'train/accuracy': 0.9926998615264893, 'train/loss': 0.02374185435473919, 'train/mean_average_precision': 0.5486052379780496, 'validation/accuracy': 0.9868945479393005, 'validation/loss': 0.045623648911714554, 'validation/mean_average_precision': 0.2757457969445733, 'validation/num_examples': 43793, 'test/accuracy': 0.9860655665397644, 'test/loss': 0.048745423555374146, 'test/mean_average_precision': 0.2620582261498086, 'test/num_examples': 43793, 'score': 13463.144181013107, 'total_duration': 20322.98603606224, 'accumulated_submission_time': 13463.144181013107, 'accumulated_eval_time': 6856.88672709465, 'accumulated_logging_time': 1.8560996055603027}
I0216 11:51:28.764457 140255719360256 logging_writer.py:48] [45020] accumulated_eval_time=6856.886727, accumulated_logging_time=1.856100, accumulated_submission_time=13463.144181, global_step=45020, preemption_count=0, score=13463.144181, test/accuracy=0.986066, test/loss=0.048745, test/mean_average_precision=0.262058, test/num_examples=43793, total_duration=20322.986036, train/accuracy=0.992700, train/loss=0.023742, train/mean_average_precision=0.548605, validation/accuracy=0.986895, validation/loss=0.045624, validation/mean_average_precision=0.275746, validation/num_examples=43793
I0216 11:53:53.748095 140255727752960 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.03005639836192131, loss=0.029278019443154335
I0216 11:55:28.908294 140416551212864 spec.py:321] Evaluating on the training split.
I0216 11:57:16.885813 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 11:57:19.715996 140416551212864 spec.py:349] Evaluating on the test split.
I0216 11:57:22.525087 140416551212864 submission_runner.py:408] Time since start: 20676.77s, 	Step: 45819, 	{'train/accuracy': 0.9926347732543945, 'train/loss': 0.02389189414680004, 'train/mean_average_precision': 0.5480086924167176, 'validation/accuracy': 0.986940860748291, 'validation/loss': 0.04546483978629112, 'validation/mean_average_precision': 0.27557748654575687, 'validation/num_examples': 43793, 'test/accuracy': 0.9859952330589294, 'test/loss': 0.04865710064768791, 'test/mean_average_precision': 0.2649718800382767, 'test/num_examples': 43793, 'score': 13703.2581346035, 'total_duration': 20676.767524003983, 'accumulated_submission_time': 13703.2581346035, 'accumulated_eval_time': 6970.503480911255, 'accumulated_logging_time': 1.8871448040008545}
I0216 11:57:22.545135 140239095269120 logging_writer.py:48] [45819] accumulated_eval_time=6970.503481, accumulated_logging_time=1.887145, accumulated_submission_time=13703.258135, global_step=45819, preemption_count=0, score=13703.258135, test/accuracy=0.985995, test/loss=0.048657, test/mean_average_precision=0.264972, test/num_examples=43793, total_duration=20676.767524, train/accuracy=0.992635, train/loss=0.023892, train/mean_average_precision=0.548009, validation/accuracy=0.986941, validation/loss=0.045465, validation/mean_average_precision=0.275577, validation/num_examples=43793
I0216 11:58:17.431516 140249228961536 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.02564867213368416, loss=0.02600746415555477
I0216 12:00:47.644708 140239095269120 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.02618996612727642, loss=0.02748476341366768
I0216 12:01:22.654702 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:03:10.662302 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:03:13.539776 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:03:16.317556 140416551212864 submission_runner.py:408] Time since start: 21030.56s, 	Step: 46617, 	{'train/accuracy': 0.9927825927734375, 'train/loss': 0.023420898243784904, 'train/mean_average_precision': 0.5705329375541817, 'validation/accuracy': 0.986935555934906, 'validation/loss': 0.045459624379873276, 'validation/mean_average_precision': 0.2758348421894809, 'validation/num_examples': 43793, 'test/accuracy': 0.9860453605651855, 'test/loss': 0.048574142158031464, 'test/mean_average_precision': 0.26239183982676645, 'test/num_examples': 43793, 'score': 13943.337622642517, 'total_duration': 21030.55988264084, 'accumulated_submission_time': 13943.337622642517, 'accumulated_eval_time': 7084.166176080704, 'accumulated_logging_time': 1.9173269271850586}
I0216 12:03:16.338082 140240548042496 logging_writer.py:48] [46617] accumulated_eval_time=7084.166176, accumulated_logging_time=1.917327, accumulated_submission_time=13943.337623, global_step=46617, preemption_count=0, score=13943.337623, test/accuracy=0.986045, test/loss=0.048574, test/mean_average_precision=0.262392, test/num_examples=43793, total_duration=21030.559883, train/accuracy=0.992783, train/loss=0.023421, train/mean_average_precision=0.570533, validation/accuracy=0.986936, validation/loss=0.045460, validation/mean_average_precision=0.275835, validation/num_examples=43793
I0216 12:05:10.523580 140255719360256 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.024803830310702324, loss=0.02767333574593067
I0216 12:07:16.455817 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:09:04.542755 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:09:07.426564 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:09:10.232737 140416551212864 submission_runner.py:408] Time since start: 21384.48s, 	Step: 47420, 	{'train/accuracy': 0.9927552938461304, 'train/loss': 0.023271989077329636, 'train/mean_average_precision': 0.5661322514400959, 'validation/accuracy': 0.9869875311851501, 'validation/loss': 0.04548894986510277, 'validation/mean_average_precision': 0.2752511137623446, 'validation/num_examples': 43793, 'test/accuracy': 0.9860736131668091, 'test/loss': 0.048696357756853104, 'test/mean_average_precision': 0.26224945138566735, 'test/num_examples': 43793, 'score': 14183.424819469452, 'total_duration': 21384.475169181824, 'accumulated_submission_time': 14183.424819469452, 'accumulated_eval_time': 7197.943068981171, 'accumulated_logging_time': 1.948206901550293}
I0216 12:09:10.252716 140239095269120 logging_writer.py:48] [47420] accumulated_eval_time=7197.943069, accumulated_logging_time=1.948207, accumulated_submission_time=14183.424819, global_step=47420, preemption_count=0, score=14183.424819, test/accuracy=0.986074, test/loss=0.048696, test/mean_average_precision=0.262249, test/num_examples=43793, total_duration=21384.475169, train/accuracy=0.992755, train/loss=0.023272, train/mean_average_precision=0.566132, validation/accuracy=0.986988, validation/loss=0.045489, validation/mean_average_precision=0.275251, validation/num_examples=43793
I0216 12:09:34.695318 140255727752960 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.02405327931046486, loss=0.024927109479904175
I0216 12:12:05.379315 140239095269120 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.024774203076958656, loss=0.02675805054605007
I0216 12:13:10.300050 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:14:56.385020 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:14:59.261507 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:15:02.088241 140416551212864 submission_runner.py:408] Time since start: 21736.33s, 	Step: 48219, 	{'train/accuracy': 0.9928408861160278, 'train/loss': 0.023213736712932587, 'train/mean_average_precision': 0.5647317553810931, 'validation/accuracy': 0.9869347810745239, 'validation/loss': 0.04543416202068329, 'validation/mean_average_precision': 0.274276312298992, 'validation/num_examples': 43793, 'test/accuracy': 0.9860108494758606, 'test/loss': 0.04858929291367531, 'test/mean_average_precision': 0.2626610826882154, 'test/num_examples': 43793, 'score': 14423.4420773983, 'total_duration': 21736.33067893982, 'accumulated_submission_time': 14423.4420773983, 'accumulated_eval_time': 7309.731217622757, 'accumulated_logging_time': 1.9786181449890137}
I0216 12:15:02.110786 140240548042496 logging_writer.py:48] [48219] accumulated_eval_time=7309.731218, accumulated_logging_time=1.978618, accumulated_submission_time=14423.442077, global_step=48219, preemption_count=0, score=14423.442077, test/accuracy=0.986011, test/loss=0.048589, test/mean_average_precision=0.262661, test/num_examples=43793, total_duration=21736.330679, train/accuracy=0.992841, train/loss=0.023214, train/mean_average_precision=0.564732, validation/accuracy=0.986935, validation/loss=0.045434, validation/mean_average_precision=0.274276, validation/num_examples=43793
I0216 12:16:25.907709 140249228961536 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.02775922603905201, loss=0.027875671163201332
I0216 12:18:54.863405 140240548042496 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.0244122464209795, loss=0.025243375450372696
I0216 12:19:02.264630 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:20:54.217301 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:20:57.026951 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:20:59.795715 140416551212864 submission_runner.py:408] Time since start: 22094.04s, 	Step: 49026, 	{'train/accuracy': 0.9929050207138062, 'train/loss': 0.02310350351035595, 'train/mean_average_precision': 0.5581793169504019, 'validation/accuracy': 0.9869603514671326, 'validation/loss': 0.04546210914850235, 'validation/mean_average_precision': 0.27361602015640857, 'validation/num_examples': 43793, 'test/accuracy': 0.9860205054283142, 'test/loss': 0.048650722950696945, 'test/mean_average_precision': 0.26265387758645686, 'test/num_examples': 43793, 'score': 14663.565058469772, 'total_duration': 22094.038153886795, 'accumulated_submission_time': 14663.565058469772, 'accumulated_eval_time': 7427.262252569199, 'accumulated_logging_time': 2.0119221210479736}
I0216 12:20:59.815788 140239095269120 logging_writer.py:48] [49026] accumulated_eval_time=7427.262253, accumulated_logging_time=2.011922, accumulated_submission_time=14663.565058, global_step=49026, preemption_count=0, score=14663.565058, test/accuracy=0.986021, test/loss=0.048651, test/mean_average_precision=0.262654, test/num_examples=43793, total_duration=22094.038154, train/accuracy=0.992905, train/loss=0.023104, train/mean_average_precision=0.558179, validation/accuracy=0.986960, validation/loss=0.045462, validation/mean_average_precision=0.273616, validation/num_examples=43793
I0216 12:23:20.614793 140255719360256 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.024996202439069748, loss=0.0262533538043499
I0216 12:25:00.037591 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:26:49.410056 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:26:52.432394 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:26:55.395665 140416551212864 submission_runner.py:408] Time since start: 22449.64s, 	Step: 49835, 	{'train/accuracy': 0.9928552508354187, 'train/loss': 0.023225126788020134, 'train/mean_average_precision': 0.5696668020599087, 'validation/accuracy': 0.9868860244750977, 'validation/loss': 0.045541830360889435, 'validation/mean_average_precision': 0.2750637256028806, 'validation/num_examples': 43793, 'test/accuracy': 0.9859855771064758, 'test/loss': 0.048730868846178055, 'test/mean_average_precision': 0.26127496866107575, 'test/num_examples': 43793, 'score': 14903.75612449646, 'total_duration': 22449.638098478317, 'accumulated_submission_time': 14903.75612449646, 'accumulated_eval_time': 7542.620284080505, 'accumulated_logging_time': 2.04251766204834}
I0216 12:26:55.416896 140249228961536 logging_writer.py:48] [49835] accumulated_eval_time=7542.620284, accumulated_logging_time=2.042518, accumulated_submission_time=14903.756124, global_step=49835, preemption_count=0, score=14903.756124, test/accuracy=0.985986, test/loss=0.048731, test/mean_average_precision=0.261275, test/num_examples=43793, total_duration=22449.638098, train/accuracy=0.992855, train/loss=0.023225, train/mean_average_precision=0.569667, validation/accuracy=0.986886, validation/loss=0.045542, validation/mean_average_precision=0.275064, validation/num_examples=43793
I0216 12:27:44.950647 140255727752960 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.024845294654369354, loss=0.026219278573989868
I0216 12:30:13.626567 140249228961536 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.026243695989251137, loss=0.0252589900046587
I0216 12:30:55.433122 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:32:47.027177 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:32:49.876586 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:32:52.721976 140416551212864 submission_runner.py:408] Time since start: 22806.96s, 	Step: 50642, 	{'train/accuracy': 0.9930359721183777, 'train/loss': 0.022674283012747765, 'train/mean_average_precision': 0.5714555103717077, 'validation/accuracy': 0.9869185090065002, 'validation/loss': 0.045630745589733124, 'validation/mean_average_precision': 0.27378564147834533, 'validation/num_examples': 43793, 'test/accuracy': 0.9859994649887085, 'test/loss': 0.048813555389642715, 'test/mean_average_precision': 0.26241514720503323, 'test/num_examples': 43793, 'score': 15143.740395784378, 'total_duration': 22806.964408636093, 'accumulated_submission_time': 15143.740395784378, 'accumulated_eval_time': 7659.909089565277, 'accumulated_logging_time': 2.0754642486572266}
I0216 12:32:52.742305 140240548042496 logging_writer.py:48] [50642] accumulated_eval_time=7659.909090, accumulated_logging_time=2.075464, accumulated_submission_time=15143.740396, global_step=50642, preemption_count=0, score=15143.740396, test/accuracy=0.985999, test/loss=0.048814, test/mean_average_precision=0.262415, test/num_examples=43793, total_duration=22806.964409, train/accuracy=0.993036, train/loss=0.022674, train/mean_average_precision=0.571456, validation/accuracy=0.986919, validation/loss=0.045631, validation/mean_average_precision=0.273786, validation/num_examples=43793
I0216 12:34:38.964970 140255719360256 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.02532092295587063, loss=0.02733570523560047
I0216 12:36:53.005549 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:38:43.911534 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:38:46.779837 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:38:49.592857 140416551212864 submission_runner.py:408] Time since start: 23163.84s, 	Step: 51452, 	{'train/accuracy': 0.9929735660552979, 'train/loss': 0.02272365801036358, 'train/mean_average_precision': 0.58130251513542, 'validation/accuracy': 0.9869635701179504, 'validation/loss': 0.04565756395459175, 'validation/mean_average_precision': 0.2749304379779259, 'validation/num_examples': 43793, 'test/accuracy': 0.9860108494758606, 'test/loss': 0.048874031752347946, 'test/mean_average_precision': 0.2631808375592375, 'test/num_examples': 43793, 'score': 15383.973316907883, 'total_duration': 23163.83529639244, 'accumulated_submission_time': 15383.973316907883, 'accumulated_eval_time': 7776.496366739273, 'accumulated_logging_time': 2.1059720516204834}
I0216 12:38:49.613307 140249228961536 logging_writer.py:48] [51452] accumulated_eval_time=7776.496367, accumulated_logging_time=2.105972, accumulated_submission_time=15383.973317, global_step=51452, preemption_count=0, score=15383.973317, test/accuracy=0.986011, test/loss=0.048874, test/mean_average_precision=0.263181, test/num_examples=43793, total_duration=23163.835296, train/accuracy=0.992974, train/loss=0.022724, train/mean_average_precision=0.581303, validation/accuracy=0.986964, validation/loss=0.045658, validation/mean_average_precision=0.274930, validation/num_examples=43793
I0216 12:39:04.172817 140255727752960 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.025427276268601418, loss=0.025730986148118973
I0216 12:41:32.358339 140249228961536 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.031190596520900726, loss=0.027099406346678734
I0216 12:42:49.869324 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:44:43.047697 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:44:45.933852 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:44:48.730683 140416551212864 submission_runner.py:408] Time since start: 23522.97s, 	Step: 52261, 	{'train/accuracy': 0.9929158091545105, 'train/loss': 0.022974791005253792, 'train/mean_average_precision': 0.5673924226760431, 'validation/accuracy': 0.9869436621665955, 'validation/loss': 0.04559377208352089, 'validation/mean_average_precision': 0.27641571737955367, 'validation/num_examples': 43793, 'test/accuracy': 0.9860618114471436, 'test/loss': 0.04877443611621857, 'test/mean_average_precision': 0.26275019311686393, 'test/num_examples': 43793, 'score': 15624.197340488434, 'total_duration': 23522.97312450409, 'accumulated_submission_time': 15624.197340488434, 'accumulated_eval_time': 7895.357687950134, 'accumulated_logging_time': 2.1384670734405518}
I0216 12:44:48.751071 140239095269120 logging_writer.py:48] [52261] accumulated_eval_time=7895.357688, accumulated_logging_time=2.138467, accumulated_submission_time=15624.197340, global_step=52261, preemption_count=0, score=15624.197340, test/accuracy=0.986062, test/loss=0.048774, test/mean_average_precision=0.262750, test/num_examples=43793, total_duration=23522.973125, train/accuracy=0.992916, train/loss=0.022975, train/mean_average_precision=0.567392, validation/accuracy=0.986944, validation/loss=0.045594, validation/mean_average_precision=0.276416, validation/num_examples=43793
I0216 12:46:00.882741 140240548042496 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.025233255699276924, loss=0.02562655694782734
I0216 12:48:29.823425 140239095269120 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.0254865363240242, loss=0.025673195719718933
I0216 12:48:48.959072 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:50:38.243545 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:50:41.096619 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:50:43.950580 140416551212864 submission_runner.py:408] Time since start: 23878.19s, 	Step: 53065, 	{'train/accuracy': 0.9930059909820557, 'train/loss': 0.02265738882124424, 'train/mean_average_precision': 0.57494310110014, 'validation/accuracy': 0.9869607090950012, 'validation/loss': 0.04560108855366707, 'validation/mean_average_precision': 0.27735509995427293, 'validation/num_examples': 43793, 'test/accuracy': 0.9860609769821167, 'test/loss': 0.04881812259554863, 'test/mean_average_precision': 0.2626048558927526, 'test/num_examples': 43793, 'score': 15864.375243663788, 'total_duration': 23878.19301056862, 'accumulated_submission_time': 15864.375243663788, 'accumulated_eval_time': 8010.349139690399, 'accumulated_logging_time': 2.169062852859497}
I0216 12:50:43.972354 140255719360256 logging_writer.py:48] [53065] accumulated_eval_time=8010.349140, accumulated_logging_time=2.169063, accumulated_submission_time=15864.375244, global_step=53065, preemption_count=0, score=15864.375244, test/accuracy=0.986061, test/loss=0.048818, test/mean_average_precision=0.262605, test/num_examples=43793, total_duration=23878.193011, train/accuracy=0.993006, train/loss=0.022657, train/mean_average_precision=0.574943, validation/accuracy=0.986961, validation/loss=0.045601, validation/mean_average_precision=0.277355, validation/num_examples=43793
I0216 12:52:53.636712 140255727752960 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.029674099758267403, loss=0.02610640414059162
I0216 12:54:44.012163 140416551212864 spec.py:321] Evaluating on the training split.
I0216 12:56:27.183617 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 12:56:30.060771 140416551212864 spec.py:349] Evaluating on the test split.
I0216 12:56:33.997043 140416551212864 submission_runner.py:408] Time since start: 24228.24s, 	Step: 53870, 	{'train/accuracy': 0.9930762648582458, 'train/loss': 0.02252272516489029, 'train/mean_average_precision': 0.5758406791448971, 'validation/accuracy': 0.9869347810745239, 'validation/loss': 0.045652274042367935, 'validation/mean_average_precision': 0.27645206263422184, 'validation/num_examples': 43793, 'test/accuracy': 0.9860327243804932, 'test/loss': 0.04883032292127609, 'test/mean_average_precision': 0.26276521935918273, 'test/num_examples': 43793, 'score': 16104.383655309677, 'total_duration': 24228.23948097229, 'accumulated_submission_time': 16104.383655309677, 'accumulated_eval_time': 8120.3339858055115, 'accumulated_logging_time': 2.202131509780884}
I0216 12:56:34.019254 140239095269120 logging_writer.py:48] [53870] accumulated_eval_time=8120.333986, accumulated_logging_time=2.202132, accumulated_submission_time=16104.383655, global_step=53870, preemption_count=0, score=16104.383655, test/accuracy=0.986033, test/loss=0.048830, test/mean_average_precision=0.262765, test/num_examples=43793, total_duration=24228.239481, train/accuracy=0.993076, train/loss=0.022523, train/mean_average_precision=0.575841, validation/accuracy=0.986935, validation/loss=0.045652, validation/mean_average_precision=0.276452, validation/num_examples=43793
I0216 12:57:13.229691 140240548042496 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.026972712948918343, loss=0.02881453186273575
I0216 12:59:42.190655 140239095269120 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.026977414265275, loss=0.024097181856632233
I0216 13:00:34.022771 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:02:16.314850 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:02:19.148800 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:02:21.953939 140416551212864 submission_runner.py:408] Time since start: 24576.20s, 	Step: 54676, 	{'train/accuracy': 0.993075430393219, 'train/loss': 0.0225909985601902, 'train/mean_average_precision': 0.5844517935968967, 'validation/accuracy': 0.9869327545166016, 'validation/loss': 0.04564793035387993, 'validation/mean_average_precision': 0.2757515957837684, 'validation/num_examples': 43793, 'test/accuracy': 0.9859960675239563, 'test/loss': 0.048801444470882416, 'test/mean_average_precision': 0.2625770439332958, 'test/num_examples': 43793, 'score': 16344.355197906494, 'total_duration': 24576.19637823105, 'accumulated_submission_time': 16344.355197906494, 'accumulated_eval_time': 8228.26512002945, 'accumulated_logging_time': 2.2357490062713623}
I0216 13:02:21.975512 140255719360256 logging_writer.py:48] [54676] accumulated_eval_time=8228.265120, accumulated_logging_time=2.235749, accumulated_submission_time=16344.355198, global_step=54676, preemption_count=0, score=16344.355198, test/accuracy=0.985996, test/loss=0.048801, test/mean_average_precision=0.262577, test/num_examples=43793, total_duration=24576.196378, train/accuracy=0.993075, train/loss=0.022591, train/mean_average_precision=0.584452, validation/accuracy=0.986933, validation/loss=0.045648, validation/mean_average_precision=0.275752, validation/num_examples=43793
I0216 13:03:58.501533 140255727752960 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.026909951120615005, loss=0.026865586638450623
I0216 13:06:22.225999 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:08:08.567981 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:08:11.443080 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:08:14.266102 140416551212864 submission_runner.py:408] Time since start: 24928.51s, 	Step: 55486, 	{'train/accuracy': 0.993108332157135, 'train/loss': 0.02241457998752594, 'train/mean_average_precision': 0.5816741442478771, 'validation/accuracy': 0.9868969917297363, 'validation/loss': 0.045634105801582336, 'validation/mean_average_precision': 0.2758789111383522, 'validation/num_examples': 43793, 'test/accuracy': 0.9860057830810547, 'test/loss': 0.04879588261246681, 'test/mean_average_precision': 0.26370216981766487, 'test/num_examples': 43793, 'score': 16584.57560634613, 'total_duration': 24928.508540153503, 'accumulated_submission_time': 16584.57560634613, 'accumulated_eval_time': 8340.305190563202, 'accumulated_logging_time': 2.2675697803497314}
I0216 13:08:14.286581 140239095269120 logging_writer.py:48] [55486] accumulated_eval_time=8340.305191, accumulated_logging_time=2.267570, accumulated_submission_time=16584.575606, global_step=55486, preemption_count=0, score=16584.575606, test/accuracy=0.986006, test/loss=0.048796, test/mean_average_precision=0.263702, test/num_examples=43793, total_duration=24928.508540, train/accuracy=0.993108, train/loss=0.022415, train/mean_average_precision=0.581674, validation/accuracy=0.986897, validation/loss=0.045634, validation/mean_average_precision=0.275879, validation/num_examples=43793
I0216 13:08:18.716159 140240548042496 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.031066564843058586, loss=0.028603751212358475
I0216 13:10:48.283440 140239095269120 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.02442210353910923, loss=0.027672765776515007
I0216 13:12:14.506639 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:13:57.901692 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:14:00.746602 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:14:03.557700 140416551212864 submission_runner.py:408] Time since start: 25277.80s, 	Step: 56291, 	{'train/accuracy': 0.9930509924888611, 'train/loss': 0.022533919662237167, 'train/mean_average_precision': 0.5714913955811379, 'validation/accuracy': 0.9869099855422974, 'validation/loss': 0.04564154893159866, 'validation/mean_average_precision': 0.27661523697477053, 'validation/num_examples': 43793, 'test/accuracy': 0.9860078692436218, 'test/loss': 0.04880673438310623, 'test/mean_average_precision': 0.26317544621862654, 'test/num_examples': 43793, 'score': 16824.76493024826, 'total_duration': 25277.800141096115, 'accumulated_submission_time': 16824.76493024826, 'accumulated_eval_time': 8449.35622048378, 'accumulated_logging_time': 2.298278570175171}
I0216 13:14:03.579167 140255719360256 logging_writer.py:48] [56291] accumulated_eval_time=8449.356220, accumulated_logging_time=2.298279, accumulated_submission_time=16824.764930, global_step=56291, preemption_count=0, score=16824.764930, test/accuracy=0.986008, test/loss=0.048807, test/mean_average_precision=0.263175, test/num_examples=43793, total_duration=25277.800141, train/accuracy=0.993051, train/loss=0.022534, train/mean_average_precision=0.571491, validation/accuracy=0.986910, validation/loss=0.045642, validation/mean_average_precision=0.276615, validation/num_examples=43793
I0216 13:15:06.695679 140255727752960 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.023659782484173775, loss=0.022545630112290382
I0216 13:17:35.952507 140255719360256 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.025994116440415382, loss=0.0251805167645216
I0216 13:18:03.701465 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:19:51.472526 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:19:54.338145 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:19:57.180258 140416551212864 submission_runner.py:408] Time since start: 25631.42s, 	Step: 57095, 	{'train/accuracy': 0.9929907917976379, 'train/loss': 0.022755034267902374, 'train/mean_average_precision': 0.5681405195249059, 'validation/accuracy': 0.9869303107261658, 'validation/loss': 0.045676592737436295, 'validation/mean_average_precision': 0.2764999992484705, 'validation/num_examples': 43793, 'test/accuracy': 0.9860382080078125, 'test/loss': 0.04887561500072479, 'test/mean_average_precision': 0.26340049608308047, 'test/num_examples': 43793, 'score': 17064.856679677963, 'total_duration': 25631.422697782516, 'accumulated_submission_time': 17064.856679677963, 'accumulated_eval_time': 8562.834966897964, 'accumulated_logging_time': 2.3301308155059814}
I0216 13:19:57.201341 140239095269120 logging_writer.py:48] [57095] accumulated_eval_time=8562.834967, accumulated_logging_time=2.330131, accumulated_submission_time=17064.856680, global_step=57095, preemption_count=0, score=17064.856680, test/accuracy=0.986038, test/loss=0.048876, test/mean_average_precision=0.263400, test/num_examples=43793, total_duration=25631.422698, train/accuracy=0.992991, train/loss=0.022755, train/mean_average_precision=0.568141, validation/accuracy=0.986930, validation/loss=0.045677, validation/mean_average_precision=0.276500, validation/num_examples=43793
I0216 13:21:57.689111 140240548042496 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.028914298862218857, loss=0.028838204219937325
I0216 13:23:57.414753 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:25:43.392783 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:25:46.310584 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:25:49.133865 140416551212864 submission_runner.py:408] Time since start: 25983.38s, 	Step: 57901, 	{'train/accuracy': 0.9930864572525024, 'train/loss': 0.02244187518954277, 'train/mean_average_precision': 0.578057153746631, 'validation/accuracy': 0.9869193434715271, 'validation/loss': 0.045689601451158524, 'validation/mean_average_precision': 0.2766180275006385, 'validation/num_examples': 43793, 'test/accuracy': 0.9860268235206604, 'test/loss': 0.04888075962662697, 'test/mean_average_precision': 0.2636164800832383, 'test/num_examples': 43793, 'score': 17305.0386633873, 'total_duration': 25983.376288175583, 'accumulated_submission_time': 17305.0386633873, 'accumulated_eval_time': 8674.55403137207, 'accumulated_logging_time': 2.3628604412078857}
I0216 13:25:49.155390 140249228961536 logging_writer.py:48] [57901] accumulated_eval_time=8674.554031, accumulated_logging_time=2.362860, accumulated_submission_time=17305.038663, global_step=57901, preemption_count=0, score=17305.038663, test/accuracy=0.986027, test/loss=0.048881, test/mean_average_precision=0.263616, test/num_examples=43793, total_duration=25983.376288, train/accuracy=0.993086, train/loss=0.022442, train/mean_average_precision=0.578057, validation/accuracy=0.986919, validation/loss=0.045690, validation/mean_average_precision=0.276618, validation/num_examples=43793
I0216 13:26:18.841182 140255727752960 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.025338049978017807, loss=0.024709757417440414
I0216 13:28:47.950623 140249228961536 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.025872118771076202, loss=0.025115875527262688
I0216 13:29:49.304530 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:31:34.610303 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:31:37.436338 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:31:40.242453 140416551212864 submission_runner.py:408] Time since start: 26334.48s, 	Step: 58708, 	{'train/accuracy': 0.9931564331054688, 'train/loss': 0.022316845133900642, 'train/mean_average_precision': 0.5896502921986553, 'validation/accuracy': 0.9869286417961121, 'validation/loss': 0.04569888487458229, 'validation/mean_average_precision': 0.2768841467123343, 'validation/num_examples': 43793, 'test/accuracy': 0.9860420227050781, 'test/loss': 0.04888811707496643, 'test/mean_average_precision': 0.2638762265067022, 'test/num_examples': 43793, 'score': 17545.15802550316, 'total_duration': 26334.484881162643, 'accumulated_submission_time': 17545.15802550316, 'accumulated_eval_time': 8785.491904258728, 'accumulated_logging_time': 2.3944857120513916}
I0216 13:31:40.263283 140240548042496 logging_writer.py:48] [58708] accumulated_eval_time=8785.491904, accumulated_logging_time=2.394486, accumulated_submission_time=17545.158026, global_step=58708, preemption_count=0, score=17545.158026, test/accuracy=0.986042, test/loss=0.048888, test/mean_average_precision=0.263876, test/num_examples=43793, total_duration=26334.484881, train/accuracy=0.993156, train/loss=0.022317, train/mean_average_precision=0.589650, validation/accuracy=0.986929, validation/loss=0.045699, validation/mean_average_precision=0.276884, validation/num_examples=43793
I0216 13:33:07.839694 140255719360256 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.026733102276921272, loss=0.02781306952238083
I0216 13:35:37.293853 140240548042496 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.025048736482858658, loss=0.02485407516360283
I0216 13:35:40.294429 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:37:23.336090 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:37:27.389278 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:37:30.187788 140416551212864 submission_runner.py:408] Time since start: 26684.43s, 	Step: 59511, 	{'train/accuracy': 0.993064820766449, 'train/loss': 0.022571824491024017, 'train/mean_average_precision': 0.5773330381705069, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568079113960266, 'validation/mean_average_precision': 0.27670099513658825, 'validation/num_examples': 43793, 'test/accuracy': 0.9860302209854126, 'test/loss': 0.048869434744119644, 'test/mean_average_precision': 0.26374298292623455, 'test/num_examples': 43793, 'score': 17785.158355474472, 'total_duration': 26684.430191755295, 'accumulated_submission_time': 17785.158355474472, 'accumulated_eval_time': 8895.385179758072, 'accumulated_logging_time': 2.4266440868377686}
I0216 13:37:30.209281 140239095269120 logging_writer.py:48] [59511] accumulated_eval_time=8895.385180, accumulated_logging_time=2.426644, accumulated_submission_time=17785.158355, global_step=59511, preemption_count=0, score=17785.158355, test/accuracy=0.986030, test/loss=0.048869, test/mean_average_precision=0.263743, test/num_examples=43793, total_duration=26684.430192, train/accuracy=0.993065, train/loss=0.022572, train/mean_average_precision=0.577333, validation/accuracy=0.986913, validation/loss=0.045681, validation/mean_average_precision=0.276701, validation/num_examples=43793
I0216 13:39:54.406985 140255727752960 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.02544880472123623, loss=0.024189243093132973
I0216 13:41:30.309475 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:43:15.282511 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:43:18.104224 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:43:20.918582 140416551212864 submission_runner.py:408] Time since start: 27035.16s, 	Step: 60321, 	{'train/accuracy': 0.9930671453475952, 'train/loss': 0.022445514798164368, 'train/mean_average_precision': 0.5834701249122045, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568023607134819, 'validation/mean_average_precision': 0.27662631487236883, 'validation/num_examples': 43793, 'test/accuracy': 0.9860323071479797, 'test/loss': 0.04886876791715622, 'test/mean_average_precision': 0.2637141685272774, 'test/num_examples': 43793, 'score': 18025.22871351242, 'total_duration': 27035.16091799736, 'accumulated_submission_time': 18025.22871351242, 'accumulated_eval_time': 9005.994149446487, 'accumulated_logging_time': 2.4581356048583984}
I0216 13:43:20.939494 140240548042496 logging_writer.py:48] [60321] accumulated_eval_time=9005.994149, accumulated_logging_time=2.458136, accumulated_submission_time=18025.228714, global_step=60321, preemption_count=0, score=18025.228714, test/accuracy=0.986032, test/loss=0.048869, test/mean_average_precision=0.263714, test/num_examples=43793, total_duration=27035.160918, train/accuracy=0.993067, train/loss=0.022446, train/mean_average_precision=0.583470, validation/accuracy=0.986913, validation/loss=0.045680, validation/mean_average_precision=0.276626, validation/num_examples=43793
I0216 13:44:14.833889 140255719360256 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.025820044800639153, loss=0.02340099960565567
I0216 13:46:44.251796 140240548042496 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.025389503687620163, loss=0.0280233733355999
I0216 13:47:21.073073 140416551212864 spec.py:321] Evaluating on the training split.
I0216 13:49:06.887539 140416551212864 spec.py:333] Evaluating on the validation split.
I0216 13:49:09.756939 140416551212864 spec.py:349] Evaluating on the test split.
I0216 13:49:12.540845 140416551212864 submission_runner.py:408] Time since start: 27386.78s, 	Step: 61124, 	{'train/accuracy': 0.9929941892623901, 'train/loss': 0.022746913135051727, 'train/mean_average_precision': 0.5616075727896844, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568023607134819, 'validation/mean_average_precision': 0.27677575846006097, 'validation/num_examples': 43793, 'test/accuracy': 0.9860323071479797, 'test/loss': 0.04886877164244652, 'test/mean_average_precision': 0.26374356673507854, 'test/num_examples': 43793, 'score': 18265.331235408783, 'total_duration': 27386.783284902573, 'accumulated_submission_time': 18265.331235408783, 'accumulated_eval_time': 9117.461876153946, 'accumulated_logging_time': 2.490337371826172}
I0216 13:49:12.562026 140239095269120 logging_writer.py:48] [61124] accumulated_eval_time=9117.461876, accumulated_logging_time=2.490337, accumulated_submission_time=18265.331235, global_step=61124, preemption_count=0, score=18265.331235, test/accuracy=0.986032, test/loss=0.048869, test/mean_average_precision=0.263744, test/num_examples=43793, total_duration=27386.783285, train/accuracy=0.992994, train/loss=0.022747, train/mean_average_precision=0.561608, validation/accuracy=0.986913, validation/loss=0.045680, validation/mean_average_precision=0.276776, validation/num_examples=43793
I0216 13:51:06.504858 140249228961536 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.026258978992700577, loss=0.027646368369460106
I0216 13:52:44.374555 140239095269120 logging_writer.py:48] [61823] global_step=61823, preemption_count=0, score=18477.103426
I0216 13:52:44.423090 140416551212864 checkpoints.py:490] Saving checkpoint at step: 61823
I0216 13:52:44.504384 140416551212864 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1/checkpoint_61823
I0216 13:52:44.506510 140416551212864 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/ogbg_model_size_jax/trial_1/checkpoint_61823.
I0216 13:52:44.668601 140416551212864 submission_runner.py:583] Tuning trial 1/1
I0216 13:52:44.668820 140416551212864 submission_runner.py:584] Hyperparameters: Hyperparameters(learning_rate=0.001734480757979605, beta1=0.855609542347586, beta2=0.9834185656478605, warmup_steps=3000, weight_decay=0.019843063335529494)
I0216 13:52:44.672616 140416551212864 submission_runner.py:585] Metrics: {'eval_results': [(1, {'train/accuracy': 0.48167362809181213, 'train/loss': 0.7414783835411072, 'train/mean_average_precision': 0.02235064270736375, 'validation/accuracy': 0.4935591220855713, 'validation/loss': 0.734703004360199, 'validation/mean_average_precision': 0.026079343352659427, 'validation/num_examples': 43793, 'test/accuracy': 0.49593061208724976, 'test/loss': 0.7337996363639832, 'test/mean_average_precision': 0.027978340659118965, 'test/num_examples': 43793, 'score': 18.38358187675476, 'total_duration': 311.3073809146881, 'accumulated_submission_time': 18.38358187675476, 'accumulated_eval_time': 292.9237585067749, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (793, {'train/accuracy': 0.9868057370185852, 'train/loss': 0.05078306794166565, 'train/mean_average_precision': 0.05168824160589894, 'validation/accuracy': 0.9841329455375671, 'validation/loss': 0.060904696583747864, 'validation/mean_average_precision': 0.051065452575991155, 'validation/num_examples': 43793, 'test/accuracy': 0.9831559658050537, 'test/loss': 0.06420259922742844, 'test/mean_average_precision': 0.05331596142953435, 'test/num_examples': 43793, 'score': 258.375075340271, 'total_duration': 663.2159872055054, 'accumulated_submission_time': 258.375075340271, 'accumulated_eval_time': 404.7939808368683, 'accumulated_logging_time': 0.0282289981842041, 'global_step': 793, 'preemption_count': 0}), (1595, {'train/accuracy': 0.9873453974723816, 'train/loss': 0.046835266053676605, 'train/mean_average_precision': 0.09348125651907607, 'validation/accuracy': 0.9845287203788757, 'validation/loss': 0.05644737184047699, 'validation/mean_average_precision': 0.09511224531556464, 'validation/num_examples': 43793, 'test/accuracy': 0.9835472702980042, 'test/loss': 0.059720586985349655, 'test/mean_average_precision': 0.09338562361469074, 'test/num_examples': 43793, 'score': 498.4070701599121, 'total_duration': 1017.8797771930695, 'accumulated_submission_time': 498.4070701599121, 'accumulated_eval_time': 519.3789639472961, 'accumulated_logging_time': 0.0562899112701416, 'global_step': 1595, 'preemption_count': 0}), (2399, {'train/accuracy': 0.9874485731124878, 'train/loss': 0.04547134414315224, 'train/mean_average_precision': 0.12485872362402206, 'validation/accuracy': 0.9847138524055481, 'validation/loss': 0.055004335939884186, 'validation/mean_average_precision': 0.1196931239664118, 'validation/num_examples': 43793, 'test/accuracy': 0.9836664795875549, 'test/loss': 0.05817732959985733, 'test/mean_average_precision': 0.11812139833440244, 'test/num_examples': 43793, 'score': 738.5130224227905, 'total_duration': 1373.3737497329712, 'accumulated_submission_time': 738.5130224227905, 'accumulated_eval_time': 634.7215549945831, 'accumulated_logging_time': 0.08283233642578125, 'global_step': 2399, 'preemption_count': 0}), (3212, {'train/accuracy': 0.9878000617027283, 'train/loss': 0.043187934905290604, 'train/mean_average_precision': 0.1391459251340874, 'validation/accuracy': 0.9850386381149292, 'validation/loss': 0.052669938653707504, 'validation/mean_average_precision': 0.1350334797594012, 'validation/num_examples': 43793, 'test/accuracy': 0.9840598702430725, 'test/loss': 0.05566246062517166, 'test/mean_average_precision': 0.13459895855938472, 'test/num_examples': 43793, 'score': 978.6268582344055, 'total_duration': 1727.5294523239136, 'accumulated_submission_time': 978.6268582344055, 'accumulated_eval_time': 748.7177813053131, 'accumulated_logging_time': 0.10929632186889648, 'global_step': 3212, 'preemption_count': 0}), (4034, {'train/accuracy': 0.9881040453910828, 'train/loss': 0.04137897118926048, 'train/mean_average_precision': 0.17310310525076428, 'validation/accuracy': 0.9852420091629028, 'validation/loss': 0.05126866325736046, 'validation/mean_average_precision': 0.1528905318940395, 'validation/num_examples': 43793, 'test/accuracy': 0.98423171043396, 'test/loss': 0.0542476549744606, 'test/mean_average_precision': 0.14745985573702544, 'test/num_examples': 43793, 'score': 1218.5888166427612, 'total_duration': 2084.139676094055, 'accumulated_submission_time': 1218.5888166427612, 'accumulated_eval_time': 865.32088804245, 'accumulated_logging_time': 0.13540983200073242, 'global_step': 4034, 'preemption_count': 0}), (4849, {'train/accuracy': 0.9882045388221741, 'train/loss': 0.04050733894109726, 'train/mean_average_precision': 0.19442062861541134, 'validation/accuracy': 0.9854709506034851, 'validation/loss': 0.04987342655658722, 'validation/mean_average_precision': 0.17164908166572165, 'validation/num_examples': 43793, 'test/accuracy': 0.9845417141914368, 'test/loss': 0.0526445247232914, 'test/mean_average_precision': 0.16603115145706274, 'test/num_examples': 43793, 'score': 1458.5982029438019, 'total_duration': 2442.474811553955, 'accumulated_submission_time': 1458.5982029438019, 'accumulated_eval_time': 983.6019570827484, 'accumulated_logging_time': 0.16078495979309082, 'global_step': 4849, 'preemption_count': 0}), (5669, {'train/accuracy': 0.9883393049240112, 'train/loss': 0.039722491055727005, 'train/mean_average_precision': 0.21933719415693864, 'validation/accuracy': 0.9855290055274963, 'validation/loss': 0.049700673669576645, 'validation/mean_average_precision': 0.18249635403762393, 'validation/num_examples': 43793, 'test/accuracy': 0.9845627546310425, 'test/loss': 0.0527021624147892, 'test/mean_average_precision': 0.17947126482071704, 'test/num_examples': 43793, 'score': 1698.7393758296967, 'total_duration': 2798.2230608463287, 'accumulated_submission_time': 1698.7393758296967, 'accumulated_eval_time': 1099.1627323627472, 'accumulated_logging_time': 0.1876683235168457, 'global_step': 5669, 'preemption_count': 0}), (6478, {'train/accuracy': 0.98891282081604, 'train/loss': 0.037928201258182526, 'train/mean_average_precision': 0.23965533568496827, 'validation/accuracy': 0.9858176112174988, 'validation/loss': 0.04807098209857941, 'validation/mean_average_precision': 0.18822552654447194, 'validation/num_examples': 43793, 'test/accuracy': 0.9848811626434326, 'test/loss': 0.050769008696079254, 'test/mean_average_precision': 0.18646852820476936, 'test/num_examples': 43793, 'score': 1938.908233165741, 'total_duration': 3156.548723220825, 'accumulated_submission_time': 1938.908233165741, 'accumulated_eval_time': 1217.2732729911804, 'accumulated_logging_time': 0.214646577835083, 'global_step': 6478, 'preemption_count': 0}), (7285, {'train/accuracy': 0.9889923930168152, 'train/loss': 0.037558507174253464, 'train/mean_average_precision': 0.2506327976129368, 'validation/accuracy': 0.9858740568161011, 'validation/loss': 0.04819805547595024, 'validation/mean_average_precision': 0.20329195368986933, 'validation/num_examples': 43793, 'test/accuracy': 0.9849662780761719, 'test/loss': 0.051053132861852646, 'test/mean_average_precision': 0.19663721041068807, 'test/num_examples': 43793, 'score': 2179.098852157593, 'total_duration': 3513.17693400383, 'accumulated_submission_time': 2179.098852157593, 'accumulated_eval_time': 1333.6661846637726, 'accumulated_logging_time': 0.2401752471923828, 'global_step': 7285, 'preemption_count': 0}), (8093, {'train/accuracy': 0.9892497062683105, 'train/loss': 0.03660833090543747, 'train/mean_average_precision': 0.2666826090638757, 'validation/accuracy': 0.9859690070152283, 'validation/loss': 0.047449737787246704, 'validation/mean_average_precision': 0.20843739972926995, 'validation/num_examples': 43793, 'test/accuracy': 0.9850972294807434, 'test/loss': 0.05015392601490021, 'test/mean_average_precision': 0.20300071999537167, 'test/num_examples': 43793, 'score': 2419.246979236603, 'total_duration': 3870.087949991226, 'accumulated_submission_time': 2419.246979236603, 'accumulated_eval_time': 1450.383628129959, 'accumulated_logging_time': 0.26656627655029297, 'global_step': 8093, 'preemption_count': 0}), (8901, {'train/accuracy': 0.9892312288284302, 'train/loss': 0.036238476634025574, 'train/mean_average_precision': 0.28199685745231506, 'validation/accuracy': 0.9859815835952759, 'validation/loss': 0.046859655529260635, 'validation/mean_average_precision': 0.21866582898498918, 'validation/num_examples': 43793, 'test/accuracy': 0.9851385354995728, 'test/loss': 0.049522314220666885, 'test/mean_average_precision': 0.20997792954548714, 'test/num_examples': 43793, 'score': 2659.262021303177, 'total_duration': 4228.892052412033, 'accumulated_submission_time': 2659.262021303177, 'accumulated_eval_time': 1569.1262352466583, 'accumulated_logging_time': 0.29387545585632324, 'global_step': 8901, 'preemption_count': 0}), (9706, {'train/accuracy': 0.9894201159477234, 'train/loss': 0.03569912165403366, 'train/mean_average_precision': 0.2871602391480262, 'validation/accuracy': 0.9860473871231079, 'validation/loss': 0.0465821772813797, 'validation/mean_average_precision': 0.21980760651148143, 'validation/num_examples': 43793, 'test/accuracy': 0.9852463603019714, 'test/loss': 0.049317386001348495, 'test/mean_average_precision': 0.22046276249326507, 'test/num_examples': 43793, 'score': 2899.337280035019, 'total_duration': 4584.833826303482, 'accumulated_submission_time': 2899.337280035019, 'accumulated_eval_time': 1684.947012424469, 'accumulated_logging_time': 0.3199949264526367, 'global_step': 9706, 'preemption_count': 0}), (10516, {'train/accuracy': 0.9896848201751709, 'train/loss': 0.03468702733516693, 'train/mean_average_precision': 0.3019304039090689, 'validation/accuracy': 0.986333966255188, 'validation/loss': 0.04604193940758705, 'validation/mean_average_precision': 0.22489917876460291, 'validation/num_examples': 43793, 'test/accuracy': 0.985468327999115, 'test/loss': 0.04874479025602341, 'test/mean_average_precision': 0.21936936070714264, 'test/num_examples': 43793, 'score': 3139.3436799049377, 'total_duration': 4940.158073663712, 'accumulated_submission_time': 3139.3436799049377, 'accumulated_eval_time': 1800.2187502384186, 'accumulated_logging_time': 0.3462367057800293, 'global_step': 10516, 'preemption_count': 0}), (11321, {'train/accuracy': 0.9899202585220337, 'train/loss': 0.0338815338909626, 'train/mean_average_precision': 0.3169519903201963, 'validation/accuracy': 0.9863104224205017, 'validation/loss': 0.04609367623925209, 'validation/mean_average_precision': 0.23148539891773326, 'validation/num_examples': 43793, 'test/accuracy': 0.9854274988174438, 'test/loss': 0.04879941791296005, 'test/mean_average_precision': 0.23076089102976824, 'test/num_examples': 43793, 'score': 3379.463701248169, 'total_duration': 5300.479362487793, 'accumulated_submission_time': 3379.463701248169, 'accumulated_eval_time': 1920.3735365867615, 'accumulated_logging_time': 0.3728978633880615, 'global_step': 11321, 'preemption_count': 0}), (12127, {'train/accuracy': 0.9898400902748108, 'train/loss': 0.03390065208077431, 'train/mean_average_precision': 0.336388867552628, 'validation/accuracy': 0.9864143133163452, 'validation/loss': 0.04585133120417595, 'validation/mean_average_precision': 0.233934760699651, 'validation/num_examples': 43793, 'test/accuracy': 0.9855626821517944, 'test/loss': 0.04875577613711357, 'test/mean_average_precision': 0.22939931679488923, 'test/num_examples': 43793, 'score': 3619.4806180000305, 'total_duration': 5656.386184930801, 'accumulated_submission_time': 3619.4806180000305, 'accumulated_eval_time': 2036.2166798114777, 'accumulated_logging_time': 0.3995664119720459, 'global_step': 12127, 'preemption_count': 0}), (12930, {'train/accuracy': 0.9900326132774353, 'train/loss': 0.03318105638027191, 'train/mean_average_precision': 0.34200915533294274, 'validation/accuracy': 0.9864143133163452, 'validation/loss': 0.04563668742775917, 'validation/mean_average_precision': 0.239900025755602, 'validation/num_examples': 43793, 'test/accuracy': 0.985623300075531, 'test/loss': 0.048326943069696426, 'test/mean_average_precision': 0.23443306236225478, 'test/num_examples': 43793, 'score': 3859.721358060837, 'total_duration': 6014.845408916473, 'accumulated_submission_time': 3859.721358060837, 'accumulated_eval_time': 2154.387207508087, 'accumulated_logging_time': 0.42706990242004395, 'global_step': 12930, 'preemption_count': 0}), (13739, {'train/accuracy': 0.9901013374328613, 'train/loss': 0.032926712185144424, 'train/mean_average_precision': 0.3447498642979649, 'validation/accuracy': 0.986382246017456, 'validation/loss': 0.04576338082551956, 'validation/mean_average_precision': 0.24014079052112472, 'validation/num_examples': 43793, 'test/accuracy': 0.9856106638908386, 'test/loss': 0.04828348383307457, 'test/mean_average_precision': 0.23155845502811173, 'test/num_examples': 43793, 'score': 4099.86542057991, 'total_duration': 6370.615036010742, 'accumulated_submission_time': 4099.86542057991, 'accumulated_eval_time': 2269.9651188850403, 'accumulated_logging_time': 0.45482420921325684, 'global_step': 13739, 'preemption_count': 0}), (14547, {'train/accuracy': 0.9902201294898987, 'train/loss': 0.03253340721130371, 'train/mean_average_precision': 0.3550890578263983, 'validation/accuracy': 0.9863721132278442, 'validation/loss': 0.04537105932831764, 'validation/mean_average_precision': 0.2445942358176692, 'validation/num_examples': 43793, 'test/accuracy': 0.9856014251708984, 'test/loss': 0.04815961420536041, 'test/mean_average_precision': 0.24080017935523912, 'test/num_examples': 43793, 'score': 4339.959518432617, 'total_duration': 6730.6243143081665, 'accumulated_submission_time': 4339.959518432617, 'accumulated_eval_time': 2389.8322942256927, 'accumulated_logging_time': 0.48322343826293945, 'global_step': 14547, 'preemption_count': 0}), (15351, {'train/accuracy': 0.9903188347816467, 'train/loss': 0.03208903223276138, 'train/mean_average_precision': 0.3673918130942452, 'validation/accuracy': 0.9864687323570251, 'validation/loss': 0.04510466009378433, 'validation/mean_average_precision': 0.24675313568796267, 'validation/num_examples': 43793, 'test/accuracy': 0.985623300075531, 'test/loss': 0.04794719070196152, 'test/mean_average_precision': 0.23887921881102916, 'test/num_examples': 43793, 'score': 4579.929854154587, 'total_duration': 7089.57489824295, 'accumulated_submission_time': 4579.929854154587, 'accumulated_eval_time': 2508.765280008316, 'accumulated_logging_time': 0.5106532573699951, 'global_step': 15351, 'preemption_count': 0}), (16146, {'train/accuracy': 0.9904552698135376, 'train/loss': 0.031749919056892395, 'train/mean_average_precision': 0.37590593752019996, 'validation/accuracy': 0.9865000247955322, 'validation/loss': 0.045422960072755814, 'validation/mean_average_precision': 0.2465439110624662, 'validation/num_examples': 43793, 'test/accuracy': 0.9856873750686646, 'test/loss': 0.04818981513381004, 'test/mean_average_precision': 0.2416871470637339, 'test/num_examples': 43793, 'score': 4819.962957620621, 'total_duration': 7448.847566127777, 'accumulated_submission_time': 4819.962957620621, 'accumulated_eval_time': 2627.9578578472137, 'accumulated_logging_time': 0.538485050201416, 'global_step': 16146, 'preemption_count': 0}), (16943, {'train/accuracy': 0.990612804889679, 'train/loss': 0.03107457049190998, 'train/mean_average_precision': 0.39233429934676245, 'validation/accuracy': 0.9866761565208435, 'validation/loss': 0.04493393376469612, 'validation/mean_average_precision': 0.2481883763128292, 'validation/num_examples': 43793, 'test/accuracy': 0.9858095049858093, 'test/loss': 0.047808047384023666, 'test/mean_average_precision': 0.24512845585130877, 'test/num_examples': 43793, 'score': 5060.109432220459, 'total_duration': 7807.369671821594, 'accumulated_submission_time': 5060.109432220459, 'accumulated_eval_time': 2746.2861721515656, 'accumulated_logging_time': 0.5664393901824951, 'global_step': 16943, 'preemption_count': 0}), (17741, {'train/accuracy': 0.9904956817626953, 'train/loss': 0.031214365735650063, 'train/mean_average_precision': 0.38275158890208794, 'validation/accuracy': 0.9866238236427307, 'validation/loss': 0.045023247599601746, 'validation/mean_average_precision': 0.25335474403029995, 'validation/num_examples': 43793, 'test/accuracy': 0.9856860637664795, 'test/loss': 0.04797835648059845, 'test/mean_average_precision': 0.24454415557707107, 'test/num_examples': 43793, 'score': 5300.205405473709, 'total_duration': 8167.17295050621, 'accumulated_submission_time': 5300.205405473709, 'accumulated_eval_time': 2865.94571018219, 'accumulated_logging_time': 0.5950961112976074, 'global_step': 17741, 'preemption_count': 0}), (18541, {'train/accuracy': 0.9906713366508484, 'train/loss': 0.030988410115242004, 'train/mean_average_precision': 0.3942809964391242, 'validation/accuracy': 0.9865012168884277, 'validation/loss': 0.045165255665779114, 'validation/mean_average_precision': 0.2515437690132111, 'validation/num_examples': 43793, 'test/accuracy': 0.9857690334320068, 'test/loss': 0.047852154821157455, 'test/mean_average_precision': 0.2461328843575586, 'test/num_examples': 43793, 'score': 5540.453552007675, 'total_duration': 8524.151455163956, 'accumulated_submission_time': 5540.453552007675, 'accumulated_eval_time': 2982.6284639835358, 'accumulated_logging_time': 0.623605489730835, 'global_step': 18541, 'preemption_count': 0}), (19342, {'train/accuracy': 0.9908090233802795, 'train/loss': 0.03019069880247116, 'train/mean_average_precision': 0.4148024368085039, 'validation/accuracy': 0.9866716861724854, 'validation/loss': 0.04501838609576225, 'validation/mean_average_precision': 0.25416378700725173, 'validation/num_examples': 43793, 'test/accuracy': 0.9857636094093323, 'test/loss': 0.04790123179554939, 'test/mean_average_precision': 0.2454797353494288, 'test/num_examples': 43793, 'score': 5780.566792011261, 'total_duration': 8885.208612680435, 'accumulated_submission_time': 5780.566792011261, 'accumulated_eval_time': 3103.5261142253876, 'accumulated_logging_time': 0.6509778499603271, 'global_step': 19342, 'preemption_count': 0}), (20144, {'train/accuracy': 0.9909778237342834, 'train/loss': 0.029743582010269165, 'train/mean_average_precision': 0.4217770246896334, 'validation/accuracy': 0.9865962266921997, 'validation/loss': 0.0450168177485466, 'validation/mean_average_precision': 0.2555154354218881, 'validation/num_examples': 43793, 'test/accuracy': 0.9857505559921265, 'test/loss': 0.04772311821579933, 'test/mean_average_precision': 0.24918725581378462, 'test/num_examples': 43793, 'score': 6020.663792848587, 'total_duration': 9245.775425434113, 'accumulated_submission_time': 6020.663792848587, 'accumulated_eval_time': 3223.94864821434, 'accumulated_logging_time': 0.6791856288909912, 'global_step': 20144, 'preemption_count': 0}), (20951, {'train/accuracy': 0.9909278750419617, 'train/loss': 0.02985651232302189, 'train/mean_average_precision': 0.43761831796315165, 'validation/accuracy': 0.9867184162139893, 'validation/loss': 0.045035701245069504, 'validation/mean_average_precision': 0.25897605582564626, 'validation/num_examples': 43793, 'test/accuracy': 0.9858545660972595, 'test/loss': 0.047893136739730835, 'test/mean_average_precision': 0.24714054132145366, 'test/num_examples': 43793, 'score': 6260.650344848633, 'total_duration': 9603.788563251495, 'accumulated_submission_time': 6260.650344848633, 'accumulated_eval_time': 3341.928655385971, 'accumulated_logging_time': 0.706390380859375, 'global_step': 20951, 'preemption_count': 0}), (21752, {'train/accuracy': 0.9910473823547363, 'train/loss': 0.029282264411449432, 'train/mean_average_precision': 0.4299573748537403, 'validation/accuracy': 0.9867200255393982, 'validation/loss': 0.04476345703005791, 'validation/mean_average_precision': 0.25710807417132997, 'validation/num_examples': 43793, 'test/accuracy': 0.9858187437057495, 'test/loss': 0.0476774200797081, 'test/mean_average_precision': 0.2500796586696012, 'test/num_examples': 43793, 'score': 6500.611852884293, 'total_duration': 9962.836369276047, 'accumulated_submission_time': 6500.611852884293, 'accumulated_eval_time': 3460.967882871628, 'accumulated_logging_time': 0.7341837882995605, 'global_step': 21752, 'preemption_count': 0}), (22545, {'train/accuracy': 0.9911746978759766, 'train/loss': 0.02892124466598034, 'train/mean_average_precision': 0.43409493712398334, 'validation/accuracy': 0.9866932034492493, 'validation/loss': 0.044911596924066544, 'validation/mean_average_precision': 0.25689056362501733, 'validation/num_examples': 43793, 'test/accuracy': 0.9858440160751343, 'test/loss': 0.04781201109290123, 'test/mean_average_precision': 0.25152501973539143, 'test/num_examples': 43793, 'score': 6740.751178979874, 'total_duration': 10322.113637924194, 'accumulated_submission_time': 6740.751178979874, 'accumulated_eval_time': 3580.058919906616, 'accumulated_logging_time': 0.7617735862731934, 'global_step': 22545, 'preemption_count': 0}), (23340, {'train/accuracy': 0.9913663864135742, 'train/loss': 0.02838555909693241, 'train/mean_average_precision': 0.4404243798840853, 'validation/accuracy': 0.9867281317710876, 'validation/loss': 0.04501012712717056, 'validation/mean_average_precision': 0.2604006731856771, 'validation/num_examples': 43793, 'test/accuracy': 0.985854983329773, 'test/loss': 0.047974515706300735, 'test/mean_average_precision': 0.25009127811951803, 'test/num_examples': 43793, 'score': 6980.850264072418, 'total_duration': 10680.12444972992, 'accumulated_submission_time': 6980.850264072418, 'accumulated_eval_time': 3697.921640396118, 'accumulated_logging_time': 0.7909748554229736, 'global_step': 23340, 'preemption_count': 0}), (24136, {'train/accuracy': 0.991372287273407, 'train/loss': 0.028289057314395905, 'train/mean_average_precision': 0.46027871333810993, 'validation/accuracy': 0.9867187738418579, 'validation/loss': 0.044788528233766556, 'validation/mean_average_precision': 0.26142029715009113, 'validation/num_examples': 43793, 'test/accuracy': 0.985826313495636, 'test/loss': 0.047689855098724365, 'test/mean_average_precision': 0.25434092903305183, 'test/num_examples': 43793, 'score': 7220.956338167191, 'total_duration': 11040.202916145325, 'accumulated_submission_time': 7220.956338167191, 'accumulated_eval_time': 3817.8466346263885, 'accumulated_logging_time': 0.818695068359375, 'global_step': 24136, 'preemption_count': 0}), (24932, {'train/accuracy': 0.9915687441825867, 'train/loss': 0.027699299156665802, 'train/mean_average_precision': 0.4716990946912253, 'validation/accuracy': 0.98674476146698, 'validation/loss': 0.0449373722076416, 'validation/mean_average_precision': 0.26186425322178514, 'validation/num_examples': 43793, 'test/accuracy': 0.9858916401863098, 'test/loss': 0.047700054943561554, 'test/mean_average_precision': 0.2539176869882299, 'test/num_examples': 43793, 'score': 7461.059656858444, 'total_duration': 11401.086903572083, 'accumulated_submission_time': 7461.059656858444, 'accumulated_eval_time': 3938.5773425102234, 'accumulated_logging_time': 0.8489046096801758, 'global_step': 24932, 'preemption_count': 0}), (25733, {'train/accuracy': 0.9915797114372253, 'train/loss': 0.027492713183164597, 'train/mean_average_precision': 0.4730687510525703, 'validation/accuracy': 0.9867460131645203, 'validation/loss': 0.0448826439678669, 'validation/mean_average_precision': 0.26154000170869923, 'validation/num_examples': 43793, 'test/accuracy': 0.9858928918838501, 'test/loss': 0.04798618704080582, 'test/mean_average_precision': 0.25222066082919237, 'test/num_examples': 43793, 'score': 7701.22026181221, 'total_duration': 11759.659596681595, 'accumulated_submission_time': 7701.22026181221, 'accumulated_eval_time': 4056.9416811466217, 'accumulated_logging_time': 0.8771867752075195, 'global_step': 25733, 'preemption_count': 0}), (26529, {'train/accuracy': 0.9913433790206909, 'train/loss': 0.02809208445250988, 'train/mean_average_precision': 0.45075762147258824, 'validation/accuracy': 0.9868685603141785, 'validation/loss': 0.04529117792844772, 'validation/mean_average_precision': 0.2620002614225539, 'validation/num_examples': 43793, 'test/accuracy': 0.9859354496002197, 'test/loss': 0.04851919785141945, 'test/mean_average_precision': 0.2542642290283399, 'test/num_examples': 43793, 'score': 7941.276777505875, 'total_duration': 12120.029221773148, 'accumulated_submission_time': 7941.276777505875, 'accumulated_eval_time': 4177.207139253616, 'accumulated_logging_time': 0.9058983325958252, 'global_step': 26529, 'preemption_count': 0}), (27328, {'train/accuracy': 0.9916400909423828, 'train/loss': 0.02740594372153282, 'train/mean_average_precision': 0.46238345836105915, 'validation/accuracy': 0.9868117570877075, 'validation/loss': 0.04470028355717659, 'validation/mean_average_precision': 0.2633630571021186, 'validation/num_examples': 43793, 'test/accuracy': 0.9859842658042908, 'test/loss': 0.047634806483983994, 'test/mean_average_precision': 0.2545476116553406, 'test/num_examples': 43793, 'score': 8181.4127452373505, 'total_duration': 12478.563350915909, 'accumulated_submission_time': 8181.4127452373505, 'accumulated_eval_time': 4295.557314634323, 'accumulated_logging_time': 0.9341349601745605, 'global_step': 27328, 'preemption_count': 0}), (28122, {'train/accuracy': 0.9915293455123901, 'train/loss': 0.027663227170705795, 'train/mean_average_precision': 0.4664474926785296, 'validation/accuracy': 0.9868231415748596, 'validation/loss': 0.0446750745177269, 'validation/mean_average_precision': 0.2692567573218211, 'validation/num_examples': 43793, 'test/accuracy': 0.9859354496002197, 'test/loss': 0.047677986323833466, 'test/mean_average_precision': 0.26068469743637285, 'test/num_examples': 43793, 'score': 8421.509254932404, 'total_duration': 12838.518723964691, 'accumulated_submission_time': 8421.509254932404, 'accumulated_eval_time': 4415.367299079895, 'accumulated_logging_time': 0.9636819362640381, 'global_step': 28122, 'preemption_count': 0}), (28927, {'train/accuracy': 0.9917492866516113, 'train/loss': 0.027109364047646523, 'train/mean_average_precision': 0.4802211629750986, 'validation/accuracy': 0.9868393540382385, 'validation/loss': 0.044765908271074295, 'validation/mean_average_precision': 0.26741467625240756, 'validation/num_examples': 43793, 'test/accuracy': 0.9859552383422852, 'test/loss': 0.04780218005180359, 'test/mean_average_precision': 0.2553599243545492, 'test/num_examples': 43793, 'score': 8661.698993682861, 'total_duration': 13195.27497792244, 'accumulated_submission_time': 8661.698993682861, 'accumulated_eval_time': 4531.88570356369, 'accumulated_logging_time': 0.992128849029541, 'global_step': 28927, 'preemption_count': 0}), (29739, {'train/accuracy': 0.9917426109313965, 'train/loss': 0.02703236974775791, 'train/mean_average_precision': 0.4809532278646276, 'validation/accuracy': 0.9868941903114319, 'validation/loss': 0.04467928037047386, 'validation/mean_average_precision': 0.26669006199691603, 'validation/num_examples': 43793, 'test/accuracy': 0.9859615564346313, 'test/loss': 0.04773896560072899, 'test/mean_average_precision': 0.2565497417525822, 'test/num_examples': 43793, 'score': 8901.712589025497, 'total_duration': 13555.573674201965, 'accumulated_submission_time': 8901.712589025497, 'accumulated_eval_time': 4652.123513698578, 'accumulated_logging_time': 1.0198748111724854, 'global_step': 29739, 'preemption_count': 0}), (30548, {'train/accuracy': 0.9916932582855225, 'train/loss': 0.027075789868831635, 'train/mean_average_precision': 0.4752708787929151, 'validation/accuracy': 0.986865758895874, 'validation/loss': 0.04494989663362503, 'validation/mean_average_precision': 0.2699758831797729, 'validation/num_examples': 43793, 'test/accuracy': 0.9859446883201599, 'test/loss': 0.048080362379550934, 'test/mean_average_precision': 0.25860096438138347, 'test/num_examples': 43793, 'score': 9141.928536176682, 'total_duration': 13915.84278345108, 'accumulated_submission_time': 9141.928536176682, 'accumulated_eval_time': 4772.127604484558, 'accumulated_logging_time': 1.0492854118347168, 'global_step': 30548, 'preemption_count': 0}), (31350, {'train/accuracy': 0.9917203187942505, 'train/loss': 0.027021752670407295, 'train/mean_average_precision': 0.4709897739352743, 'validation/accuracy': 0.986737072467804, 'validation/loss': 0.044955238699913025, 'validation/mean_average_precision': 0.26829487684367065, 'validation/num_examples': 43793, 'test/accuracy': 0.9858831763267517, 'test/loss': 0.04802945256233215, 'test/mean_average_precision': 0.2590827958646767, 'test/num_examples': 43793, 'score': 9382.122972011566, 'total_duration': 14272.999755382538, 'accumulated_submission_time': 9382.122972011566, 'accumulated_eval_time': 4889.039973020554, 'accumulated_logging_time': 1.0792818069458008, 'global_step': 31350, 'preemption_count': 0}), (32156, {'train/accuracy': 0.9918476939201355, 'train/loss': 0.02664249576628208, 'train/mean_average_precision': 0.4916928244609285, 'validation/accuracy': 0.9868133664131165, 'validation/loss': 0.0448586568236351, 'validation/mean_average_precision': 0.2655469187525397, 'validation/num_examples': 43793, 'test/accuracy': 0.9859653115272522, 'test/loss': 0.04783427715301514, 'test/mean_average_precision': 0.2589094172859118, 'test/num_examples': 43793, 'score': 9622.31300854683, 'total_duration': 14632.902275800705, 'accumulated_submission_time': 9622.31300854683, 'accumulated_eval_time': 5008.703879117966, 'accumulated_logging_time': 1.107926607131958, 'global_step': 32156, 'preemption_count': 0}), (32960, {'train/accuracy': 0.9917860627174377, 'train/loss': 0.02667124755680561, 'train/mean_average_precision': 0.4956820803213057, 'validation/accuracy': 0.9869368076324463, 'validation/loss': 0.04521826654672623, 'validation/mean_average_precision': 0.2669544895081704, 'validation/num_examples': 43793, 'test/accuracy': 0.9859678745269775, 'test/loss': 0.04850877448916435, 'test/mean_average_precision': 0.25360504780742593, 'test/num_examples': 43793, 'score': 9862.268160581589, 'total_duration': 14987.034296751022, 'accumulated_submission_time': 9862.268160581589, 'accumulated_eval_time': 5122.830671548843, 'accumulated_logging_time': 1.1380386352539062, 'global_step': 32960, 'preemption_count': 0}), (33765, {'train/accuracy': 0.9919589757919312, 'train/loss': 0.02623666450381279, 'train/mean_average_precision': 0.49817739130154076, 'validation/accuracy': 0.986812174320221, 'validation/loss': 0.04494292289018631, 'validation/mean_average_precision': 0.26880413084108296, 'validation/num_examples': 43793, 'test/accuracy': 0.9858899712562561, 'test/loss': 0.04812289774417877, 'test/mean_average_precision': 0.2577870568466685, 'test/num_examples': 43793, 'score': 10102.244501113892, 'total_duration': 15343.763989925385, 'accumulated_submission_time': 10102.244501113892, 'accumulated_eval_time': 5239.534306526184, 'accumulated_logging_time': 1.1680183410644531, 'global_step': 33765, 'preemption_count': 0}), (34573, {'train/accuracy': 0.9918607473373413, 'train/loss': 0.02646014466881752, 'train/mean_average_precision': 0.493075980768225, 'validation/accuracy': 0.9868962168693542, 'validation/loss': 0.045065563172101974, 'validation/mean_average_precision': 0.2666738464573022, 'validation/num_examples': 43793, 'test/accuracy': 0.9860053658485413, 'test/loss': 0.0481819324195385, 'test/mean_average_precision': 0.25851227341733907, 'test/num_examples': 43793, 'score': 10342.132805585861, 'total_duration': 15698.62466287613, 'accumulated_submission_time': 10342.132805585861, 'accumulated_eval_time': 5354.200483798981, 'accumulated_logging_time': 1.4540390968322754, 'global_step': 34573, 'preemption_count': 0}), (35379, {'train/accuracy': 0.9919452667236328, 'train/loss': 0.026180777698755264, 'train/mean_average_precision': 0.49923270169716527, 'validation/accuracy': 0.9869120121002197, 'validation/loss': 0.045097459107637405, 'validation/mean_average_precision': 0.26940836127325546, 'validation/num_examples': 43793, 'test/accuracy': 0.9859476685523987, 'test/loss': 0.048286788165569305, 'test/mean_average_precision': 0.25372322280924825, 'test/num_examples': 43793, 'score': 10582.235233783722, 'total_duration': 16054.840868234634, 'accumulated_submission_time': 10582.235233783722, 'accumulated_eval_time': 5470.265028476715, 'accumulated_logging_time': 1.4830470085144043, 'global_step': 35379, 'preemption_count': 0}), (36183, {'train/accuracy': 0.991944432258606, 'train/loss': 0.02608388103544712, 'train/mean_average_precision': 0.4997910378006097, 'validation/accuracy': 0.9869709014892578, 'validation/loss': 0.04498779773712158, 'validation/mean_average_precision': 0.27194279500630575, 'validation/num_examples': 43793, 'test/accuracy': 0.9859986305236816, 'test/loss': 0.04804445803165436, 'test/mean_average_precision': 0.25841879550460184, 'test/num_examples': 43793, 'score': 10822.21910572052, 'total_duration': 16413.721934080124, 'accumulated_submission_time': 10822.21910572052, 'accumulated_eval_time': 5589.113726377487, 'accumulated_logging_time': 1.51165771484375, 'global_step': 36183, 'preemption_count': 0}), (36985, {'train/accuracy': 0.9921455383300781, 'train/loss': 0.025538846850395203, 'train/mean_average_precision': 0.5099983919537467, 'validation/accuracy': 0.9868669509887695, 'validation/loss': 0.045088790357112885, 'validation/mean_average_precision': 0.27147596527803103, 'validation/num_examples': 43793, 'test/accuracy': 0.9859269857406616, 'test/loss': 0.04822063073515892, 'test/mean_average_precision': 0.2552624783581714, 'test/num_examples': 43793, 'score': 11062.236684799194, 'total_duration': 16767.79988336563, 'accumulated_submission_time': 11062.236684799194, 'accumulated_eval_time': 5703.1231327056885, 'accumulated_logging_time': 1.5422985553741455, 'global_step': 36985, 'preemption_count': 0}), (37790, {'train/accuracy': 0.9922175407409668, 'train/loss': 0.02545107714831829, 'train/mean_average_precision': 0.5226939458417625, 'validation/accuracy': 0.9868113398551941, 'validation/loss': 0.044885601848363876, 'validation/mean_average_precision': 0.270119359014984, 'validation/num_examples': 43793, 'test/accuracy': 0.9859526753425598, 'test/loss': 0.04785004258155823, 'test/mean_average_precision': 0.260474715508027, 'test/num_examples': 43793, 'score': 11302.480284929276, 'total_duration': 17127.047206640244, 'accumulated_submission_time': 11302.480284929276, 'accumulated_eval_time': 5822.076856136322, 'accumulated_logging_time': 1.5720384120941162, 'global_step': 37790, 'preemption_count': 0}), (38589, {'train/accuracy': 0.992182731628418, 'train/loss': 0.025342701002955437, 'train/mean_average_precision': 0.5217016574919506, 'validation/accuracy': 0.9868559837341309, 'validation/loss': 0.04504327476024628, 'validation/mean_average_precision': 0.2768410704805472, 'validation/num_examples': 43793, 'test/accuracy': 0.9859417676925659, 'test/loss': 0.04802359640598297, 'test/mean_average_precision': 0.25969182007397157, 'test/num_examples': 43793, 'score': 11542.44424200058, 'total_duration': 17486.37224960327, 'accumulated_submission_time': 11542.44424200058, 'accumulated_eval_time': 5941.387535810471, 'accumulated_logging_time': 1.6027278900146484, 'global_step': 38589, 'preemption_count': 0}), (39386, {'train/accuracy': 0.9921956062316895, 'train/loss': 0.0252446997910738, 'train/mean_average_precision': 0.511250873621642, 'validation/accuracy': 0.9868945479393005, 'validation/loss': 0.04515570029616356, 'validation/mean_average_precision': 0.27264549061422205, 'validation/num_examples': 43793, 'test/accuracy': 0.9860411286354065, 'test/loss': 0.048190921545028687, 'test/mean_average_precision': 0.2582591956926438, 'test/num_examples': 43793, 'score': 11782.47777724266, 'total_duration': 17843.572909116745, 'accumulated_submission_time': 11782.47777724266, 'accumulated_eval_time': 6058.496329307556, 'accumulated_logging_time': 1.6405205726623535, 'global_step': 39386, 'preemption_count': 0}), (40183, {'train/accuracy': 0.9922892451286316, 'train/loss': 0.025013025850057602, 'train/mean_average_precision': 0.5225452270794689, 'validation/accuracy': 0.986901044845581, 'validation/loss': 0.04534929618239403, 'validation/mean_average_precision': 0.2729705354671894, 'validation/num_examples': 43793, 'test/accuracy': 0.9860386252403259, 'test/loss': 0.04831911623477936, 'test/mean_average_precision': 0.2562086760981972, 'test/num_examples': 43793, 'score': 12022.704268217087, 'total_duration': 18199.940435647964, 'accumulated_submission_time': 12022.704268217087, 'accumulated_eval_time': 6174.58575129509, 'accumulated_logging_time': 1.6714468002319336, 'global_step': 40183, 'preemption_count': 0}), (40991, {'train/accuracy': 0.9924004673957825, 'train/loss': 0.02464117854833603, 'train/mean_average_precision': 0.537957910609613, 'validation/accuracy': 0.9868661761283875, 'validation/loss': 0.045313309878110886, 'validation/mean_average_precision': 0.27323351152078496, 'validation/num_examples': 43793, 'test/accuracy': 0.9859472513198853, 'test/loss': 0.048459116369485855, 'test/mean_average_precision': 0.2610771375571753, 'test/num_examples': 43793, 'score': 12262.691478013992, 'total_duration': 18554.431445121765, 'accumulated_submission_time': 12262.691478013992, 'accumulated_eval_time': 6289.040021657944, 'accumulated_logging_time': 1.7009563446044922, 'global_step': 40991, 'preemption_count': 0}), (41795, {'train/accuracy': 0.9924507737159729, 'train/loss': 0.024626241996884346, 'train/mean_average_precision': 0.5333804592644633, 'validation/accuracy': 0.986935555934906, 'validation/loss': 0.04509740695357323, 'validation/mean_average_precision': 0.27342447078120585, 'validation/num_examples': 43793, 'test/accuracy': 0.9860251545906067, 'test/loss': 0.048237673938274384, 'test/mean_average_precision': 0.258896535536681, 'test/num_examples': 43793, 'score': 12502.694967746735, 'total_duration': 18910.314481973648, 'accumulated_submission_time': 12502.694967746735, 'accumulated_eval_time': 6404.870155096054, 'accumulated_logging_time': 1.7307236194610596, 'global_step': 41795, 'preemption_count': 0}), (42600, {'train/accuracy': 0.9924954771995544, 'train/loss': 0.024203160777688026, 'train/mean_average_precision': 0.5456466575510697, 'validation/accuracy': 0.9869043231010437, 'validation/loss': 0.04519158974289894, 'validation/mean_average_precision': 0.27511370490430326, 'validation/num_examples': 43793, 'test/accuracy': 0.9860247373580933, 'test/loss': 0.04838308319449425, 'test/mean_average_precision': 0.25838264277939843, 'test/num_examples': 43793, 'score': 12742.68578529358, 'total_duration': 19264.04238629341, 'accumulated_submission_time': 12742.68578529358, 'accumulated_eval_time': 6518.5565485954285, 'accumulated_logging_time': 1.7616491317749023, 'global_step': 42600, 'preemption_count': 0}), (43404, {'train/accuracy': 0.9924352169036865, 'train/loss': 0.02433331124484539, 'train/mean_average_precision': 0.5414993508027892, 'validation/accuracy': 0.9869801998138428, 'validation/loss': 0.04537877440452576, 'validation/mean_average_precision': 0.27512099070949264, 'validation/num_examples': 43793, 'test/accuracy': 0.9860870838165283, 'test/loss': 0.04854248836636543, 'test/mean_average_precision': 0.2594711247718872, 'test/num_examples': 43793, 'score': 12982.761003732681, 'total_duration': 19619.90135717392, 'accumulated_submission_time': 12982.761003732681, 'accumulated_eval_time': 6634.289053916931, 'accumulated_logging_time': 1.7924144268035889, 'global_step': 43404, 'preemption_count': 0}), (44210, {'train/accuracy': 0.9925671219825745, 'train/loss': 0.024143295362591743, 'train/mean_average_precision': 0.5367888907544053, 'validation/accuracy': 0.9869238138198853, 'validation/loss': 0.04540529102087021, 'validation/mean_average_precision': 0.27529657458412704, 'validation/num_examples': 43793, 'test/accuracy': 0.9860508441925049, 'test/loss': 0.04852164909243584, 'test/mean_average_precision': 0.2611568913376222, 'test/num_examples': 43793, 'score': 13222.95099234581, 'total_duration': 19971.173470258713, 'accumulated_submission_time': 13222.95099234581, 'accumulated_eval_time': 6745.318096399307, 'accumulated_logging_time': 1.825453281402588, 'global_step': 44210, 'preemption_count': 0}), (45020, {'train/accuracy': 0.9926998615264893, 'train/loss': 0.02374185435473919, 'train/mean_average_precision': 0.5486052379780496, 'validation/accuracy': 0.9868945479393005, 'validation/loss': 0.045623648911714554, 'validation/mean_average_precision': 0.2757457969445733, 'validation/num_examples': 43793, 'test/accuracy': 0.9860655665397644, 'test/loss': 0.048745423555374146, 'test/mean_average_precision': 0.2620582261498086, 'test/num_examples': 43793, 'score': 13463.144181013107, 'total_duration': 20322.98603606224, 'accumulated_submission_time': 13463.144181013107, 'accumulated_eval_time': 6856.88672709465, 'accumulated_logging_time': 1.8560996055603027, 'global_step': 45020, 'preemption_count': 0}), (45819, {'train/accuracy': 0.9926347732543945, 'train/loss': 0.02389189414680004, 'train/mean_average_precision': 0.5480086924167176, 'validation/accuracy': 0.986940860748291, 'validation/loss': 0.04546483978629112, 'validation/mean_average_precision': 0.27557748654575687, 'validation/num_examples': 43793, 'test/accuracy': 0.9859952330589294, 'test/loss': 0.04865710064768791, 'test/mean_average_precision': 0.2649718800382767, 'test/num_examples': 43793, 'score': 13703.2581346035, 'total_duration': 20676.767524003983, 'accumulated_submission_time': 13703.2581346035, 'accumulated_eval_time': 6970.503480911255, 'accumulated_logging_time': 1.8871448040008545, 'global_step': 45819, 'preemption_count': 0}), (46617, {'train/accuracy': 0.9927825927734375, 'train/loss': 0.023420898243784904, 'train/mean_average_precision': 0.5705329375541817, 'validation/accuracy': 0.986935555934906, 'validation/loss': 0.045459624379873276, 'validation/mean_average_precision': 0.2758348421894809, 'validation/num_examples': 43793, 'test/accuracy': 0.9860453605651855, 'test/loss': 0.048574142158031464, 'test/mean_average_precision': 0.26239183982676645, 'test/num_examples': 43793, 'score': 13943.337622642517, 'total_duration': 21030.55988264084, 'accumulated_submission_time': 13943.337622642517, 'accumulated_eval_time': 7084.166176080704, 'accumulated_logging_time': 1.9173269271850586, 'global_step': 46617, 'preemption_count': 0}), (47420, {'train/accuracy': 0.9927552938461304, 'train/loss': 0.023271989077329636, 'train/mean_average_precision': 0.5661322514400959, 'validation/accuracy': 0.9869875311851501, 'validation/loss': 0.04548894986510277, 'validation/mean_average_precision': 0.2752511137623446, 'validation/num_examples': 43793, 'test/accuracy': 0.9860736131668091, 'test/loss': 0.048696357756853104, 'test/mean_average_precision': 0.26224945138566735, 'test/num_examples': 43793, 'score': 14183.424819469452, 'total_duration': 21384.475169181824, 'accumulated_submission_time': 14183.424819469452, 'accumulated_eval_time': 7197.943068981171, 'accumulated_logging_time': 1.948206901550293, 'global_step': 47420, 'preemption_count': 0}), (48219, {'train/accuracy': 0.9928408861160278, 'train/loss': 0.023213736712932587, 'train/mean_average_precision': 0.5647317553810931, 'validation/accuracy': 0.9869347810745239, 'validation/loss': 0.04543416202068329, 'validation/mean_average_precision': 0.274276312298992, 'validation/num_examples': 43793, 'test/accuracy': 0.9860108494758606, 'test/loss': 0.04858929291367531, 'test/mean_average_precision': 0.2626610826882154, 'test/num_examples': 43793, 'score': 14423.4420773983, 'total_duration': 21736.33067893982, 'accumulated_submission_time': 14423.4420773983, 'accumulated_eval_time': 7309.731217622757, 'accumulated_logging_time': 1.9786181449890137, 'global_step': 48219, 'preemption_count': 0}), (49026, {'train/accuracy': 0.9929050207138062, 'train/loss': 0.02310350351035595, 'train/mean_average_precision': 0.5581793169504019, 'validation/accuracy': 0.9869603514671326, 'validation/loss': 0.04546210914850235, 'validation/mean_average_precision': 0.27361602015640857, 'validation/num_examples': 43793, 'test/accuracy': 0.9860205054283142, 'test/loss': 0.048650722950696945, 'test/mean_average_precision': 0.26265387758645686, 'test/num_examples': 43793, 'score': 14663.565058469772, 'total_duration': 22094.038153886795, 'accumulated_submission_time': 14663.565058469772, 'accumulated_eval_time': 7427.262252569199, 'accumulated_logging_time': 2.0119221210479736, 'global_step': 49026, 'preemption_count': 0}), (49835, {'train/accuracy': 0.9928552508354187, 'train/loss': 0.023225126788020134, 'train/mean_average_precision': 0.5696668020599087, 'validation/accuracy': 0.9868860244750977, 'validation/loss': 0.045541830360889435, 'validation/mean_average_precision': 0.2750637256028806, 'validation/num_examples': 43793, 'test/accuracy': 0.9859855771064758, 'test/loss': 0.048730868846178055, 'test/mean_average_precision': 0.26127496866107575, 'test/num_examples': 43793, 'score': 14903.75612449646, 'total_duration': 22449.638098478317, 'accumulated_submission_time': 14903.75612449646, 'accumulated_eval_time': 7542.620284080505, 'accumulated_logging_time': 2.04251766204834, 'global_step': 49835, 'preemption_count': 0}), (50642, {'train/accuracy': 0.9930359721183777, 'train/loss': 0.022674283012747765, 'train/mean_average_precision': 0.5714555103717077, 'validation/accuracy': 0.9869185090065002, 'validation/loss': 0.045630745589733124, 'validation/mean_average_precision': 0.27378564147834533, 'validation/num_examples': 43793, 'test/accuracy': 0.9859994649887085, 'test/loss': 0.048813555389642715, 'test/mean_average_precision': 0.26241514720503323, 'test/num_examples': 43793, 'score': 15143.740395784378, 'total_duration': 22806.964408636093, 'accumulated_submission_time': 15143.740395784378, 'accumulated_eval_time': 7659.909089565277, 'accumulated_logging_time': 2.0754642486572266, 'global_step': 50642, 'preemption_count': 0}), (51452, {'train/accuracy': 0.9929735660552979, 'train/loss': 0.02272365801036358, 'train/mean_average_precision': 0.58130251513542, 'validation/accuracy': 0.9869635701179504, 'validation/loss': 0.04565756395459175, 'validation/mean_average_precision': 0.2749304379779259, 'validation/num_examples': 43793, 'test/accuracy': 0.9860108494758606, 'test/loss': 0.048874031752347946, 'test/mean_average_precision': 0.2631808375592375, 'test/num_examples': 43793, 'score': 15383.973316907883, 'total_duration': 23163.83529639244, 'accumulated_submission_time': 15383.973316907883, 'accumulated_eval_time': 7776.496366739273, 'accumulated_logging_time': 2.1059720516204834, 'global_step': 51452, 'preemption_count': 0}), (52261, {'train/accuracy': 0.9929158091545105, 'train/loss': 0.022974791005253792, 'train/mean_average_precision': 0.5673924226760431, 'validation/accuracy': 0.9869436621665955, 'validation/loss': 0.04559377208352089, 'validation/mean_average_precision': 0.27641571737955367, 'validation/num_examples': 43793, 'test/accuracy': 0.9860618114471436, 'test/loss': 0.04877443611621857, 'test/mean_average_precision': 0.26275019311686393, 'test/num_examples': 43793, 'score': 15624.197340488434, 'total_duration': 23522.97312450409, 'accumulated_submission_time': 15624.197340488434, 'accumulated_eval_time': 7895.357687950134, 'accumulated_logging_time': 2.1384670734405518, 'global_step': 52261, 'preemption_count': 0}), (53065, {'train/accuracy': 0.9930059909820557, 'train/loss': 0.02265738882124424, 'train/mean_average_precision': 0.57494310110014, 'validation/accuracy': 0.9869607090950012, 'validation/loss': 0.04560108855366707, 'validation/mean_average_precision': 0.27735509995427293, 'validation/num_examples': 43793, 'test/accuracy': 0.9860609769821167, 'test/loss': 0.04881812259554863, 'test/mean_average_precision': 0.2626048558927526, 'test/num_examples': 43793, 'score': 15864.375243663788, 'total_duration': 23878.19301056862, 'accumulated_submission_time': 15864.375243663788, 'accumulated_eval_time': 8010.349139690399, 'accumulated_logging_time': 2.169062852859497, 'global_step': 53065, 'preemption_count': 0}), (53870, {'train/accuracy': 0.9930762648582458, 'train/loss': 0.02252272516489029, 'train/mean_average_precision': 0.5758406791448971, 'validation/accuracy': 0.9869347810745239, 'validation/loss': 0.045652274042367935, 'validation/mean_average_precision': 0.27645206263422184, 'validation/num_examples': 43793, 'test/accuracy': 0.9860327243804932, 'test/loss': 0.04883032292127609, 'test/mean_average_precision': 0.26276521935918273, 'test/num_examples': 43793, 'score': 16104.383655309677, 'total_duration': 24228.23948097229, 'accumulated_submission_time': 16104.383655309677, 'accumulated_eval_time': 8120.3339858055115, 'accumulated_logging_time': 2.202131509780884, 'global_step': 53870, 'preemption_count': 0}), (54676, {'train/accuracy': 0.993075430393219, 'train/loss': 0.0225909985601902, 'train/mean_average_precision': 0.5844517935968967, 'validation/accuracy': 0.9869327545166016, 'validation/loss': 0.04564793035387993, 'validation/mean_average_precision': 0.2757515957837684, 'validation/num_examples': 43793, 'test/accuracy': 0.9859960675239563, 'test/loss': 0.048801444470882416, 'test/mean_average_precision': 0.2625770439332958, 'test/num_examples': 43793, 'score': 16344.355197906494, 'total_duration': 24576.19637823105, 'accumulated_submission_time': 16344.355197906494, 'accumulated_eval_time': 8228.26512002945, 'accumulated_logging_time': 2.2357490062713623, 'global_step': 54676, 'preemption_count': 0}), (55486, {'train/accuracy': 0.993108332157135, 'train/loss': 0.02241457998752594, 'train/mean_average_precision': 0.5816741442478771, 'validation/accuracy': 0.9868969917297363, 'validation/loss': 0.045634105801582336, 'validation/mean_average_precision': 0.2758789111383522, 'validation/num_examples': 43793, 'test/accuracy': 0.9860057830810547, 'test/loss': 0.04879588261246681, 'test/mean_average_precision': 0.26370216981766487, 'test/num_examples': 43793, 'score': 16584.57560634613, 'total_duration': 24928.508540153503, 'accumulated_submission_time': 16584.57560634613, 'accumulated_eval_time': 8340.305190563202, 'accumulated_logging_time': 2.2675697803497314, 'global_step': 55486, 'preemption_count': 0}), (56291, {'train/accuracy': 0.9930509924888611, 'train/loss': 0.022533919662237167, 'train/mean_average_precision': 0.5714913955811379, 'validation/accuracy': 0.9869099855422974, 'validation/loss': 0.04564154893159866, 'validation/mean_average_precision': 0.27661523697477053, 'validation/num_examples': 43793, 'test/accuracy': 0.9860078692436218, 'test/loss': 0.04880673438310623, 'test/mean_average_precision': 0.26317544621862654, 'test/num_examples': 43793, 'score': 16824.76493024826, 'total_duration': 25277.800141096115, 'accumulated_submission_time': 16824.76493024826, 'accumulated_eval_time': 8449.35622048378, 'accumulated_logging_time': 2.298278570175171, 'global_step': 56291, 'preemption_count': 0}), (57095, {'train/accuracy': 0.9929907917976379, 'train/loss': 0.022755034267902374, 'train/mean_average_precision': 0.5681405195249059, 'validation/accuracy': 0.9869303107261658, 'validation/loss': 0.045676592737436295, 'validation/mean_average_precision': 0.2764999992484705, 'validation/num_examples': 43793, 'test/accuracy': 0.9860382080078125, 'test/loss': 0.04887561500072479, 'test/mean_average_precision': 0.26340049608308047, 'test/num_examples': 43793, 'score': 17064.856679677963, 'total_duration': 25631.422697782516, 'accumulated_submission_time': 17064.856679677963, 'accumulated_eval_time': 8562.834966897964, 'accumulated_logging_time': 2.3301308155059814, 'global_step': 57095, 'preemption_count': 0}), (57901, {'train/accuracy': 0.9930864572525024, 'train/loss': 0.02244187518954277, 'train/mean_average_precision': 0.578057153746631, 'validation/accuracy': 0.9869193434715271, 'validation/loss': 0.045689601451158524, 'validation/mean_average_precision': 0.2766180275006385, 'validation/num_examples': 43793, 'test/accuracy': 0.9860268235206604, 'test/loss': 0.04888075962662697, 'test/mean_average_precision': 0.2636164800832383, 'test/num_examples': 43793, 'score': 17305.0386633873, 'total_duration': 25983.376288175583, 'accumulated_submission_time': 17305.0386633873, 'accumulated_eval_time': 8674.55403137207, 'accumulated_logging_time': 2.3628604412078857, 'global_step': 57901, 'preemption_count': 0}), (58708, {'train/accuracy': 0.9931564331054688, 'train/loss': 0.022316845133900642, 'train/mean_average_precision': 0.5896502921986553, 'validation/accuracy': 0.9869286417961121, 'validation/loss': 0.04569888487458229, 'validation/mean_average_precision': 0.2768841467123343, 'validation/num_examples': 43793, 'test/accuracy': 0.9860420227050781, 'test/loss': 0.04888811707496643, 'test/mean_average_precision': 0.2638762265067022, 'test/num_examples': 43793, 'score': 17545.15802550316, 'total_duration': 26334.484881162643, 'accumulated_submission_time': 17545.15802550316, 'accumulated_eval_time': 8785.491904258728, 'accumulated_logging_time': 2.3944857120513916, 'global_step': 58708, 'preemption_count': 0}), (59511, {'train/accuracy': 0.993064820766449, 'train/loss': 0.022571824491024017, 'train/mean_average_precision': 0.5773330381705069, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568079113960266, 'validation/mean_average_precision': 0.27670099513658825, 'validation/num_examples': 43793, 'test/accuracy': 0.9860302209854126, 'test/loss': 0.048869434744119644, 'test/mean_average_precision': 0.26374298292623455, 'test/num_examples': 43793, 'score': 17785.158355474472, 'total_duration': 26684.430191755295, 'accumulated_submission_time': 17785.158355474472, 'accumulated_eval_time': 8895.385179758072, 'accumulated_logging_time': 2.4266440868377686, 'global_step': 59511, 'preemption_count': 0}), (60321, {'train/accuracy': 0.9930671453475952, 'train/loss': 0.022445514798164368, 'train/mean_average_precision': 0.5834701249122045, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568023607134819, 'validation/mean_average_precision': 0.27662631487236883, 'validation/num_examples': 43793, 'test/accuracy': 0.9860323071479797, 'test/loss': 0.04886876791715622, 'test/mean_average_precision': 0.2637141685272774, 'test/num_examples': 43793, 'score': 18025.22871351242, 'total_duration': 27035.16091799736, 'accumulated_submission_time': 18025.22871351242, 'accumulated_eval_time': 9005.994149446487, 'accumulated_logging_time': 2.4581356048583984, 'global_step': 60321, 'preemption_count': 0}), (61124, {'train/accuracy': 0.9929941892623901, 'train/loss': 0.022746913135051727, 'train/mean_average_precision': 0.5616075727896844, 'validation/accuracy': 0.98691326379776, 'validation/loss': 0.04568023607134819, 'validation/mean_average_precision': 0.27677575846006097, 'validation/num_examples': 43793, 'test/accuracy': 0.9860323071479797, 'test/loss': 0.04886877164244652, 'test/mean_average_precision': 0.26374356673507854, 'test/num_examples': 43793, 'score': 18265.331235408783, 'total_duration': 27386.783284902573, 'accumulated_submission_time': 18265.331235408783, 'accumulated_eval_time': 9117.461876153946, 'accumulated_logging_time': 2.490337371826172, 'global_step': 61124, 'preemption_count': 0})], 'global_step': 61823}
I0216 13:52:44.672799 140416551212864 submission_runner.py:586] Timing: 18477.103425979614
I0216 13:52:44.672855 140416551212864 submission_runner.py:588] Total number of evals: 77
I0216 13:52:44.672898 140416551212864 submission_runner.py:589] ====================
I0216 13:52:44.673347 140416551212864 submission_runner.py:673] Final ogbg_model_size score: 18477.103425979614

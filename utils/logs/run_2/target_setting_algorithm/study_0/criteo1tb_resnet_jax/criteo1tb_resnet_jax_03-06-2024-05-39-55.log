python3 submission_runner.py --framework=jax --workload=criteo1tb_resnet --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=2465481527 --max_global_steps=10666 --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/criteo1tb_resnet/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/criteo1tb_resnet_jax_03-06-2024-05-39-55.log
I0306 05:40:14.472813 140589014792000 logger_utils.py:61] Removing existing experiment directory /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax because --overwrite was set.
I0306 05:40:14.474365 140589014792000 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax.
I0306 05:40:16.176060 140589014792000 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Host Interpreter CUDA
I0306 05:40:16.176943 140589014792000 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0306 05:40:16.177155 140589014792000 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0306 05:40:16.182675 140589014792000 submission_runner.py:547] Using RNG seed 2465481527
I0306 05:40:17.274723 140589014792000 submission_runner.py:556] --- Tuning run 1/1 ---
I0306 05:40:17.274915 140589014792000 submission_runner.py:561] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1.
I0306 05:40:17.275118 140589014792000 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1/hparams.json.
I0306 05:40:17.461670 140589014792000 submission_runner.py:206] Initializing dataset.
I0306 05:40:17.461869 140589014792000 submission_runner.py:213] Initializing model.
I0306 05:40:21.813885 140589014792000 submission_runner.py:255] Initializing optimizer.
I0306 05:40:24.507503 140589014792000 submission_runner.py:262] Initializing metrics bundle.
I0306 05:40:24.507726 140589014792000 submission_runner.py:280] Initializing checkpoint and logger.
I0306 05:40:24.508908 140589014792000 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1 with prefix checkpoint_
I0306 05:40:24.509078 140589014792000 submission_runner.py:300] Saving meta data to /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1/meta_data_0.json.
I0306 05:40:24.509314 140589014792000 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0306 05:40:24.509395 140589014792000 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0306 05:40:24.771586 140589014792000 logger_utils.py:220] Unable to record git information. Continuing without it.
I0306 05:40:25.009771 140589014792000 submission_runner.py:304] Saving flags to /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1/flags_0.json.
I0306 05:40:25.098534 140589014792000 submission_runner.py:314] Starting training loop.
I0306 05:40:37.549834 140427462170368 logging_writer.py:48] [0] global_step=0, grad_norm=16.235172271728516, loss=0.6031586527824402
I0306 05:40:37.562353 140589014792000 spec.py:321] Evaluating on the training split.
I0306 05:44:48.859203 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 05:48:59.551558 140589014792000 spec.py:349] Evaluating on the test split.
I0306 05:53:43.005114 140589014792000 submission_runner.py:413] Time since start: 797.91s, 	Step: 1, 	{'train/loss': 0.6008674404906027, 'validation/loss': 0.6015239482520951, 'validation/num_examples': 83274637, 'test/loss': 0.6020814077302632, 'test/num_examples': 95000000, 'score': 12.463748216629028, 'total_duration': 797.9065113067627, 'accumulated_submission_time': 12.463748216629028, 'accumulated_eval_time': 785.4427063465118, 'accumulated_logging_time': 0}
I0306 05:53:43.021201 140407572784896 logging_writer.py:48] [1] accumulated_eval_time=785.442706, accumulated_logging_time=0, accumulated_submission_time=12.463748, global_step=1, preemption_count=0, score=12.463748, test/loss=0.602081, test/num_examples=95000000, total_duration=797.906511, train/loss=0.600867, validation/loss=0.601524, validation/num_examples=83274637
I0306 05:53:43.109776 140407564392192 logging_writer.py:48] [1] global_step=1, grad_norm=16.275684356689453, loss=0.6034190654754639
I0306 05:53:43.193690 140407572784896 logging_writer.py:48] [2] global_step=2, grad_norm=15.808929443359375, loss=0.5851134061813354
I0306 05:53:43.277685 140407564392192 logging_writer.py:48] [3] global_step=3, grad_norm=14.989099502563477, loss=0.5551233291625977
I0306 05:53:43.359568 140407572784896 logging_writer.py:48] [4] global_step=4, grad_norm=13.909224510192871, loss=0.5152471661567688
I0306 05:53:43.441371 140407564392192 logging_writer.py:48] [5] global_step=5, grad_norm=12.586837768554688, loss=0.46777933835983276
I0306 05:53:43.522130 140407572784896 logging_writer.py:48] [6] global_step=6, grad_norm=11.112627029418945, loss=0.4183717370033264
I0306 05:53:43.602672 140407564392192 logging_writer.py:48] [7] global_step=7, grad_norm=9.480998039245605, loss=0.36823156476020813
I0306 05:53:43.683042 140407572784896 logging_writer.py:48] [8] global_step=8, grad_norm=7.869089126586914, loss=0.3201568126678467
I0306 05:53:43.764128 140407564392192 logging_writer.py:48] [9] global_step=9, grad_norm=6.321060657501221, loss=0.27640634775161743
I0306 05:53:43.846336 140407572784896 logging_writer.py:48] [10] global_step=10, grad_norm=4.879837989807129, loss=0.23966941237449646
I0306 05:53:43.928201 140407564392192 logging_writer.py:48] [11] global_step=11, grad_norm=3.643782377243042, loss=0.20891456305980682
I0306 05:53:44.014132 140407572784896 logging_writer.py:48] [12] global_step=12, grad_norm=2.558866024017334, loss=0.1856004297733307
I0306 05:53:44.096845 140407564392192 logging_writer.py:48] [13] global_step=13, grad_norm=1.6794688701629639, loss=0.17025409638881683
I0306 05:53:44.179566 140407572784896 logging_writer.py:48] [14] global_step=14, grad_norm=0.9915285706520081, loss=0.15888047218322754
I0306 05:53:44.262383 140407564392192 logging_writer.py:48] [15] global_step=15, grad_norm=0.45439791679382324, loss=0.15527288615703583
I0306 05:53:44.344977 140407572784896 logging_writer.py:48] [16] global_step=16, grad_norm=0.1798582822084427, loss=0.15033908188343048
I0306 05:53:44.427507 140407564392192 logging_writer.py:48] [17] global_step=17, grad_norm=0.34226158261299133, loss=0.1520857810974121
I0306 05:53:44.509972 140407572784896 logging_writer.py:48] [18] global_step=18, grad_norm=0.5974757075309753, loss=0.15802323818206787
I0306 05:53:44.592400 140407564392192 logging_writer.py:48] [19] global_step=19, grad_norm=0.7599117159843445, loss=0.16137388348579407
I0306 05:53:44.674483 140407572784896 logging_writer.py:48] [20] global_step=20, grad_norm=0.8723810315132141, loss=0.16585926711559296
I0306 05:53:44.756439 140407564392192 logging_writer.py:48] [21] global_step=21, grad_norm=1.0034970045089722, loss=0.17576372623443604
I0306 05:53:44.838463 140407572784896 logging_writer.py:48] [22] global_step=22, grad_norm=1.0723379850387573, loss=0.1816743016242981
I0306 05:53:44.920171 140407564392192 logging_writer.py:48] [23] global_step=23, grad_norm=1.14572274684906, loss=0.190496563911438
I0306 05:53:45.002095 140407572784896 logging_writer.py:48] [24] global_step=24, grad_norm=1.1926155090332031, loss=0.19767798483371735
I0306 05:53:45.083991 140407564392192 logging_writer.py:48] [25] global_step=25, grad_norm=1.202551007270813, loss=0.20116189122200012
I0306 05:53:45.166621 140407572784896 logging_writer.py:48] [26] global_step=26, grad_norm=1.2579230070114136, loss=0.21095889806747437
I0306 05:53:45.348559 140407564392192 logging_writer.py:48] [27] global_step=27, grad_norm=1.2898964881896973, loss=0.21827058494091034
I0306 05:53:46.161581 140407572784896 logging_writer.py:48] [28] global_step=28, grad_norm=1.3252217769622803, loss=0.22662518918514252
I0306 05:53:47.066146 140407564392192 logging_writer.py:48] [29] global_step=29, grad_norm=1.2915552854537964, loss=0.2237066775560379
I0306 05:53:47.754568 140407572784896 logging_writer.py:48] [30] global_step=30, grad_norm=1.3101680278778076, loss=0.22933077812194824
I0306 05:53:48.609120 140407564392192 logging_writer.py:48] [31] global_step=31, grad_norm=1.3178808689117432, loss=0.2328868955373764
I0306 05:53:49.446544 140407572784896 logging_writer.py:48] [32] global_step=32, grad_norm=1.343111276626587, loss=0.23909488320350647
I0306 05:53:50.297579 140407564392192 logging_writer.py:48] [33] global_step=33, grad_norm=1.3521451950073242, loss=0.24256737530231476
I0306 05:53:51.078597 140407572784896 logging_writer.py:48] [34] global_step=34, grad_norm=1.3685903549194336, loss=0.24687889218330383
I0306 05:53:51.788096 140407564392192 logging_writer.py:48] [35] global_step=35, grad_norm=1.476015567779541, loss=0.2657390832901001
I0306 05:53:52.576391 140407572784896 logging_writer.py:48] [36] global_step=36, grad_norm=1.447152853012085, loss=0.261748731136322
I0306 05:53:53.354556 140407564392192 logging_writer.py:48] [37] global_step=37, grad_norm=1.445510745048523, loss=0.26201021671295166
I0306 05:53:54.109190 140407572784896 logging_writer.py:48] [38] global_step=38, grad_norm=1.4483294486999512, loss=0.2622048258781433
I0306 05:53:54.863517 140407564392192 logging_writer.py:48] [39] global_step=39, grad_norm=1.4054054021835327, loss=0.25519776344299316
I0306 05:53:55.638004 140407572784896 logging_writer.py:48] [40] global_step=40, grad_norm=1.371308445930481, loss=0.24911434948444366
I0306 05:53:56.377916 140407564392192 logging_writer.py:48] [41] global_step=41, grad_norm=1.3622963428497314, loss=0.24705150723457336
I0306 05:53:57.188685 140407572784896 logging_writer.py:48] [42] global_step=42, grad_norm=1.2999588251113892, loss=0.23630961775779724
I0306 05:53:58.068764 140407564392192 logging_writer.py:48] [43] global_step=43, grad_norm=1.317613124847412, loss=0.23853011429309845
I0306 05:53:58.911641 140407572784896 logging_writer.py:48] [44] global_step=44, grad_norm=1.2467052936553955, loss=0.22603219747543335
I0306 05:53:59.649186 140407564392192 logging_writer.py:48] [45] global_step=45, grad_norm=1.1986690759658813, loss=0.21805274486541748
I0306 05:54:00.366862 140407572784896 logging_writer.py:48] [46] global_step=46, grad_norm=1.1498134136199951, loss=0.21066927909851074
I0306 05:54:01.267532 140407564392192 logging_writer.py:48] [47] global_step=47, grad_norm=1.0873572826385498, loss=0.20140941441059113
I0306 05:54:02.123967 140407572784896 logging_writer.py:48] [48] global_step=48, grad_norm=1.0279045104980469, loss=0.19323308765888214
I0306 05:54:02.784644 140407564392192 logging_writer.py:48] [49] global_step=49, grad_norm=0.9445824027061462, loss=0.18336988985538483
I0306 05:54:03.609302 140407572784896 logging_writer.py:48] [50] global_step=50, grad_norm=0.87079918384552, loss=0.17618215084075928
I0306 05:54:04.382018 140407564392192 logging_writer.py:48] [51] global_step=51, grad_norm=0.7890433669090271, loss=0.17003144323825836
I0306 05:54:05.223679 140407572784896 logging_writer.py:48] [52] global_step=52, grad_norm=0.7352909445762634, loss=0.16998577117919922
I0306 05:54:06.096747 140407564392192 logging_writer.py:48] [53] global_step=53, grad_norm=0.5923581123352051, loss=0.15962880849838257
I0306 05:54:06.974804 140407572784896 logging_writer.py:48] [54] global_step=54, grad_norm=0.5159662961959839, loss=0.1587584763765335
I0306 05:54:07.832633 140407564392192 logging_writer.py:48] [55] global_step=55, grad_norm=0.3750622272491455, loss=0.156066432595253
I0306 05:54:08.550592 140407572784896 logging_writer.py:48] [56] global_step=56, grad_norm=0.204382061958313, loss=0.15364643931388855
I0306 05:54:09.287783 140407564392192 logging_writer.py:48] [57] global_step=57, grad_norm=0.08081973344087601, loss=0.15333965420722961
I0306 05:54:10.112767 140407572784896 logging_writer.py:48] [58] global_step=58, grad_norm=0.2501276433467865, loss=0.15255597233772278
I0306 05:54:10.865948 140407564392192 logging_writer.py:48] [59] global_step=59, grad_norm=0.4498986303806305, loss=0.15533411502838135
I0306 05:54:11.628610 140407572784896 logging_writer.py:48] [60] global_step=60, grad_norm=0.6630605459213257, loss=0.15625660121440887
I0306 05:54:12.552733 140407564392192 logging_writer.py:48] [61] global_step=61, grad_norm=0.7998770475387573, loss=0.15942907333374023
I0306 05:54:13.250749 140407572784896 logging_writer.py:48] [62] global_step=62, grad_norm=0.8822917342185974, loss=0.16006973385810852
I0306 05:54:14.053425 140407564392192 logging_writer.py:48] [63] global_step=63, grad_norm=0.8779001832008362, loss=0.16131716966629028
I0306 05:54:14.924448 140407572784896 logging_writer.py:48] [64] global_step=64, grad_norm=0.8499717712402344, loss=0.1568605601787567
I0306 05:54:15.776513 140407564392192 logging_writer.py:48] [65] global_step=65, grad_norm=0.7125281095504761, loss=0.15627779066562653
I0306 05:54:16.721131 140407572784896 logging_writer.py:48] [66] global_step=66, grad_norm=0.5533626675605774, loss=0.15350690484046936
I0306 05:54:17.586917 140407564392192 logging_writer.py:48] [67] global_step=67, grad_norm=0.39476847648620605, loss=0.14942532777786255
I0306 05:54:18.279663 140407572784896 logging_writer.py:48] [68] global_step=68, grad_norm=0.19821694493293762, loss=0.14855793118476868
I0306 05:54:19.165441 140407564392192 logging_writer.py:48] [69] global_step=69, grad_norm=0.0701010450720787, loss=0.15170520544052124
I0306 05:54:19.955800 140407572784896 logging_writer.py:48] [70] global_step=70, grad_norm=0.14240440726280212, loss=0.14653737843036652
I0306 05:54:20.612874 140407564392192 logging_writer.py:48] [71] global_step=71, grad_norm=0.28825485706329346, loss=0.15094323456287384
I0306 05:54:21.325459 140407572784896 logging_writer.py:48] [72] global_step=72, grad_norm=0.3634054362773895, loss=0.15162642300128937
I0306 05:54:22.160068 140407564392192 logging_writer.py:48] [73] global_step=73, grad_norm=0.32209983468055725, loss=0.14497852325439453
I0306 05:54:22.942559 140407572784896 logging_writer.py:48] [74] global_step=74, grad_norm=0.352724552154541, loss=0.1456506848335266
I0306 05:54:23.702957 140407564392192 logging_writer.py:48] [75] global_step=75, grad_norm=0.36963191628456116, loss=0.1467292755842209
I0306 05:54:24.514580 140407572784896 logging_writer.py:48] [76] global_step=76, grad_norm=0.345033198595047, loss=0.14521369338035583
I0306 05:54:25.246021 140407564392192 logging_writer.py:48] [77] global_step=77, grad_norm=0.3114853501319885, loss=0.14465129375457764
I0306 05:54:26.001452 140407572784896 logging_writer.py:48] [78] global_step=78, grad_norm=0.2848924398422241, loss=0.14559173583984375
I0306 05:54:26.739687 140407564392192 logging_writer.py:48] [79] global_step=79, grad_norm=0.21879802644252777, loss=0.14520803093910217
I0306 05:54:27.505691 140407572784896 logging_writer.py:48] [80] global_step=80, grad_norm=0.13743960857391357, loss=0.14238829910755157
I0306 05:54:28.471332 140407564392192 logging_writer.py:48] [81] global_step=81, grad_norm=0.08282479643821716, loss=0.14422482252120972
I0306 05:54:28.968873 140407572784896 logging_writer.py:48] [82] global_step=82, grad_norm=0.04599536955356598, loss=0.14159440994262695
I0306 05:54:29.753848 140407564392192 logging_writer.py:48] [83] global_step=83, grad_norm=0.08800250291824341, loss=0.1422867327928543
I0306 05:54:30.571564 140407572784896 logging_writer.py:48] [84] global_step=84, grad_norm=0.12662096321582794, loss=0.14213453233242035
I0306 05:54:31.212664 140407564392192 logging_writer.py:48] [85] global_step=85, grad_norm=0.14408092200756073, loss=0.14130112528800964
I0306 05:54:32.024086 140407572784896 logging_writer.py:48] [86] global_step=86, grad_norm=0.13686469197273254, loss=0.13985629379749298
I0306 05:54:32.749831 140407564392192 logging_writer.py:48] [87] global_step=87, grad_norm=0.08485903590917587, loss=0.14095208048820496
I0306 05:54:33.519270 140407572784896 logging_writer.py:48] [88] global_step=88, grad_norm=0.03601490333676338, loss=0.14106619358062744
I0306 05:54:34.270453 140407564392192 logging_writer.py:48] [89] global_step=89, grad_norm=0.028611762449145317, loss=0.1388736367225647
I0306 05:54:35.120578 140407572784896 logging_writer.py:48] [90] global_step=90, grad_norm=0.07531364262104034, loss=0.14022406935691833
I0306 05:54:35.920442 140407564392192 logging_writer.py:48] [91] global_step=91, grad_norm=0.0856257900595665, loss=0.14005449414253235
I0306 05:54:36.527740 140407572784896 logging_writer.py:48] [92] global_step=92, grad_norm=0.11201895773410797, loss=0.14600872993469238
I0306 05:54:37.247576 140407564392192 logging_writer.py:48] [93] global_step=93, grad_norm=0.06796175241470337, loss=0.1436537355184555
I0306 05:54:38.105384 140407572784896 logging_writer.py:48] [94] global_step=94, grad_norm=0.02728326991200447, loss=0.14094820618629456
I0306 05:54:38.748872 140407564392192 logging_writer.py:48] [95] global_step=95, grad_norm=0.028582962229847908, loss=0.14341852068901062
I0306 05:54:39.564245 140407572784896 logging_writer.py:48] [96] global_step=96, grad_norm=0.03623630478978157, loss=0.14129950106143951
I0306 05:54:40.205183 140407564392192 logging_writer.py:48] [97] global_step=97, grad_norm=0.035121314227581024, loss=0.1416347175836563
I0306 05:54:41.003159 140407572784896 logging_writer.py:48] [98] global_step=98, grad_norm=0.020046943798661232, loss=0.1429225504398346
I0306 05:54:41.766410 140407564392192 logging_writer.py:48] [99] global_step=99, grad_norm=0.022606702521443367, loss=0.14243827760219574
I0306 05:54:42.491396 140407572784896 logging_writer.py:48] [100] global_step=100, grad_norm=0.0220465287566185, loss=0.14197884500026703
I0306 05:55:43.295178 140589014792000 spec.py:321] Evaluating on the training split.
I0306 05:59:02.582081 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:01:44.372342 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:04:51.089745 140589014792000 submission_runner.py:413] Time since start: 1465.99s, 	Step: 178, 	{'train/loss': 0.12972166206476823, 'validation/loss': 0.13009467129041644, 'validation/num_examples': 83274637, 'test/loss': 0.13289384288651315, 'test/num_examples': 95000000, 'score': 132.72535252571106, 'total_duration': 1465.9911518096924, 'accumulated_submission_time': 132.72535252571106, 'accumulated_eval_time': 1333.2372405529022, 'accumulated_logging_time': 0.023211002349853516}
I0306 06:04:51.102534 140407564392192 logging_writer.py:48] [178] accumulated_eval_time=1333.237241, accumulated_logging_time=0.023211, accumulated_submission_time=132.725353, global_step=178, preemption_count=0, score=132.725353, test/loss=0.132894, test/num_examples=95000000, total_duration=1465.991152, train/loss=0.129722, validation/loss=0.130095, validation/num_examples=83274637
I0306 06:06:51.770470 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:10:11.596627 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:12:51.751936 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:15:55.720683 140589014792000 submission_runner.py:413] Time since start: 2130.62s, 	Step: 359, 	{'train/loss': 0.12913103350116023, 'validation/loss': 0.12782389862368898, 'validation/num_examples': 83274637, 'test/loss': 0.13052424591899672, 'test/num_examples': 95000000, 'score': 253.3798632621765, 'total_duration': 2130.6220512390137, 'accumulated_submission_time': 253.3798632621765, 'accumulated_eval_time': 1877.1873936653137, 'accumulated_logging_time': 0.04369211196899414}
I0306 06:15:55.734161 140407572784896 logging_writer.py:48] [359] accumulated_eval_time=1877.187394, accumulated_logging_time=0.043692, accumulated_submission_time=253.379863, global_step=359, preemption_count=0, score=253.379863, test/loss=0.130524, test/num_examples=95000000, total_duration=2130.622051, train/loss=0.129131, validation/loss=0.127824, validation/num_examples=83274637
I0306 06:17:24.878373 140407564392192 logging_writer.py:48] [500] global_step=500, grad_norm=0.023029619827866554, loss=0.11890172213315964
I0306 06:17:56.140839 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:21:07.858413 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:24:11.377638 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:27:23.530670 140589014792000 submission_runner.py:413] Time since start: 2818.43s, 	Step: 543, 	{'train/loss': 0.12666660237987087, 'validation/loss': 0.12746399982993922, 'validation/num_examples': 83274637, 'test/loss': 0.1301410346011513, 'test/num_examples': 95000000, 'score': 373.77349495887756, 'total_duration': 2818.4320437908173, 'accumulated_submission_time': 373.77349495887756, 'accumulated_eval_time': 2444.5771408081055, 'accumulated_logging_time': 0.06415295600891113}
I0306 06:27:23.543394 140407572784896 logging_writer.py:48] [543] accumulated_eval_time=2444.577141, accumulated_logging_time=0.064153, accumulated_submission_time=373.773495, global_step=543, preemption_count=0, score=373.773495, test/loss=0.130141, test/num_examples=95000000, total_duration=2818.432044, train/loss=0.126667, validation/loss=0.127464, validation/num_examples=83274637
I0306 06:29:24.238575 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:32:25.987908 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:34:52.201898 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:37:43.975417 140589014792000 submission_runner.py:413] Time since start: 3438.88s, 	Step: 722, 	{'train/loss': 0.12666317867408008, 'validation/loss': 0.12734261444078707, 'validation/num_examples': 83274637, 'test/loss': 0.12973512195723685, 'test/num_examples': 95000000, 'score': 494.456018447876, 'total_duration': 3438.876784324646, 'accumulated_submission_time': 494.456018447876, 'accumulated_eval_time': 2944.3139193058014, 'accumulated_logging_time': 0.08374547958374023}
I0306 06:37:43.990004 140407564392192 logging_writer.py:48] [722] accumulated_eval_time=2944.313919, accumulated_logging_time=0.083745, accumulated_submission_time=494.456018, global_step=722, preemption_count=0, score=494.456018, test/loss=0.129735, test/num_examples=95000000, total_duration=3438.876784, train/loss=0.126663, validation/loss=0.127343, validation/num_examples=83274637
I0306 06:39:44.554796 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:42:13.102324 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:44:20.178929 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:46:54.603703 140589014792000 submission_runner.py:413] Time since start: 3989.51s, 	Step: 900, 	{'train/loss': 0.12707647404768183, 'validation/loss': 0.12655150584370004, 'validation/num_examples': 83274637, 'test/loss': 0.12908926797902961, 'test/num_examples': 95000000, 'score': 615.0073156356812, 'total_duration': 3989.5051074028015, 'accumulated_submission_time': 615.0073156356812, 'accumulated_eval_time': 3374.3627943992615, 'accumulated_logging_time': 0.10592293739318848}
I0306 06:46:54.618025 140407572784896 logging_writer.py:48] [900] accumulated_eval_time=3374.362794, accumulated_logging_time=0.105923, accumulated_submission_time=615.007316, global_step=900, preemption_count=0, score=615.007316, test/loss=0.129089, test/num_examples=95000000, total_duration=3989.505107, train/loss=0.127076, validation/loss=0.126552, validation/num_examples=83274637
I0306 06:47:55.488865 140407564392192 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.013772169128060341, loss=0.1235235333442688
I0306 06:48:55.119545 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:50:42.591594 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:52:11.611281 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:54:12.080273 140589014792000 submission_runner.py:413] Time since start: 4426.98s, 	Step: 1076, 	{'train/loss': 0.12514109080130198, 'validation/loss': 0.12633680005188735, 'validation/num_examples': 83274637, 'test/loss': 0.1289586296669408, 'test/num_examples': 95000000, 'score': 735.4950034618378, 'total_duration': 4426.981655359268, 'accumulated_submission_time': 735.4950034618378, 'accumulated_eval_time': 3691.323450565338, 'accumulated_logging_time': 0.12826871871948242}
I0306 06:54:12.093906 140407572784896 logging_writer.py:48] [1076] accumulated_eval_time=3691.323451, accumulated_logging_time=0.128269, accumulated_submission_time=735.495003, global_step=1076, preemption_count=0, score=735.495003, test/loss=0.128959, test/num_examples=95000000, total_duration=4426.981655, train/loss=0.125141, validation/loss=0.126337, validation/num_examples=83274637
I0306 06:56:12.592893 140589014792000 spec.py:321] Evaluating on the training split.
I0306 06:56:24.702131 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 06:57:08.880861 140589014792000 spec.py:349] Evaluating on the test split.
I0306 06:58:09.677884 140589014792000 submission_runner.py:413] Time since start: 4664.58s, 	Step: 1250, 	{'train/loss': 0.12746330945746703, 'validation/loss': 0.12617320774654053, 'validation/num_examples': 83274637, 'test/loss': 0.12867232193667763, 'test/num_examples': 95000000, 'score': 855.9807455539703, 'total_duration': 4664.579290390015, 'accumulated_submission_time': 855.9807455539703, 'accumulated_eval_time': 3808.4084117412567, 'accumulated_logging_time': 0.14899110794067383}
I0306 06:58:09.691755 140407564392192 logging_writer.py:48] [1250] accumulated_eval_time=3808.408412, accumulated_logging_time=0.148991, accumulated_submission_time=855.980746, global_step=1250, preemption_count=0, score=855.980746, test/loss=0.128672, test/num_examples=95000000, total_duration=4664.579290, train/loss=0.127463, validation/loss=0.126173, validation/num_examples=83274637
I0306 07:00:10.419477 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:01:01.213521 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:01:05.050671 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:02:09.298491 140589014792000 submission_runner.py:413] Time since start: 4904.20s, 	Step: 1419, 	{'train/loss': 0.12514298999646925, 'validation/loss': 0.12673185135551837, 'validation/num_examples': 83274637, 'test/loss': 0.12964904058388158, 'test/num_examples': 95000000, 'score': 976.6953589916229, 'total_duration': 4904.199893951416, 'accumulated_submission_time': 976.6953589916229, 'accumulated_eval_time': 3927.287402868271, 'accumulated_logging_time': 0.16984343528747559}
I0306 07:02:09.313602 140407572784896 logging_writer.py:48] [1419] accumulated_eval_time=3927.287403, accumulated_logging_time=0.169843, accumulated_submission_time=976.695359, global_step=1419, preemption_count=0, score=976.695359, test/loss=0.129649, test/num_examples=95000000, total_duration=4904.199894, train/loss=0.125143, validation/loss=0.126732, validation/num_examples=83274637
I0306 07:02:57.536393 140407564392192 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.017279883846640587, loss=0.12219592928886414
I0306 07:04:09.609712 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:05:33.507136 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:05:37.394522 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:06:07.550947 140589014792000 submission_runner.py:413] Time since start: 5142.45s, 	Step: 1593, 	{'train/loss': 0.12468031367415902, 'validation/loss': 0.1260833680611691, 'validation/num_examples': 83274637, 'test/loss': 0.12859175012335528, 'test/num_examples': 95000000, 'score': 1096.9748780727386, 'total_duration': 5142.452356338501, 'accumulated_submission_time': 1096.9748780727386, 'accumulated_eval_time': 4045.228600502014, 'accumulated_logging_time': 0.19536876678466797}
I0306 07:06:07.565146 140407572784896 logging_writer.py:48] [1593] accumulated_eval_time=4045.228601, accumulated_logging_time=0.195369, accumulated_submission_time=1096.974878, global_step=1593, preemption_count=0, score=1096.974878, test/loss=0.128592, test/num_examples=95000000, total_duration=5142.452356, train/loss=0.124680, validation/loss=0.126083, validation/num_examples=83274637
I0306 07:08:07.701613 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:09:56.006484 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:09:59.911700 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:10:04.570437 140589014792000 submission_runner.py:413] Time since start: 5379.47s, 	Step: 1761, 	{'train/loss': 0.12356892092235433, 'validation/loss': 0.12625780452028568, 'validation/num_examples': 83274637, 'test/loss': 0.12865952563733551, 'test/num_examples': 95000000, 'score': 1217.0965530872345, 'total_duration': 5379.471857070923, 'accumulated_submission_time': 1217.0965530872345, 'accumulated_eval_time': 4162.097407817841, 'accumulated_logging_time': 0.21833038330078125}
I0306 07:10:04.583678 140407564392192 logging_writer.py:48] [1761] accumulated_eval_time=4162.097408, accumulated_logging_time=0.218330, accumulated_submission_time=1217.096553, global_step=1761, preemption_count=0, score=1217.096553, test/loss=0.128660, test/num_examples=95000000, total_duration=5379.471857, train/loss=0.123569, validation/loss=0.126258, validation/num_examples=83274637
I0306 07:12:05.225571 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:14:20.236613 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:14:24.172120 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:14:28.781478 140589014792000 submission_runner.py:413] Time since start: 5643.68s, 	Step: 1931, 	{'train/loss': 0.12435986865429008, 'validation/loss': 0.1259153654619053, 'validation/num_examples': 83274637, 'test/loss': 0.12835864148848683, 'test/num_examples': 95000000, 'score': 1337.7251658439636, 'total_duration': 5643.682898283005, 'accumulated_submission_time': 1337.7251658439636, 'accumulated_eval_time': 4305.653298139572, 'accumulated_logging_time': 0.23879551887512207}
I0306 07:14:28.795277 140407572784896 logging_writer.py:48] [1931] accumulated_eval_time=4305.653298, accumulated_logging_time=0.238796, accumulated_submission_time=1337.725166, global_step=1931, preemption_count=0, score=1337.725166, test/loss=0.128359, test/num_examples=95000000, total_duration=5643.682898, train/loss=0.124360, validation/loss=0.125915, validation/num_examples=83274637
I0306 07:15:07.901596 140407564392192 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.026611443608999252, loss=0.12181924283504486
I0306 07:16:28.941162 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:18:54.754659 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:18:58.649338 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:19:03.195554 140589014792000 submission_runner.py:413] Time since start: 5918.10s, 	Step: 2100, 	{'train/loss': 0.12291426370916127, 'validation/loss': 0.12586137594969343, 'validation/num_examples': 83274637, 'test/loss': 0.12820470434827302, 'test/num_examples': 95000000, 'score': 1457.8536732196808, 'total_duration': 5918.096968412399, 'accumulated_submission_time': 1457.8536732196808, 'accumulated_eval_time': 4459.907658815384, 'accumulated_logging_time': 0.26380491256713867}
I0306 07:19:03.208757 140407572784896 logging_writer.py:48] [2100] accumulated_eval_time=4459.907659, accumulated_logging_time=0.263805, accumulated_submission_time=1457.853673, global_step=2100, preemption_count=0, score=1457.853673, test/loss=0.128205, test/num_examples=95000000, total_duration=5918.096968, train/loss=0.122914, validation/loss=0.125861, validation/num_examples=83274637
I0306 07:21:03.378772 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:23:20.466402 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:23:24.427794 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:23:28.999514 140589014792000 submission_runner.py:413] Time since start: 6183.90s, 	Step: 2268, 	{'train/loss': 0.12382372782665228, 'validation/loss': 0.12559567760034188, 'validation/num_examples': 83274637, 'test/loss': 0.1280529490131579, 'test/num_examples': 95000000, 'score': 1578.0095241069794, 'total_duration': 6183.900935649872, 'accumulated_submission_time': 1578.0095241069794, 'accumulated_eval_time': 4605.528385639191, 'accumulated_logging_time': 0.2852022647857666}
I0306 07:23:29.012622 140407564392192 logging_writer.py:48] [2268] accumulated_eval_time=4605.528386, accumulated_logging_time=0.285202, accumulated_submission_time=1578.009524, global_step=2268, preemption_count=0, score=1578.009524, test/loss=0.128053, test/num_examples=95000000, total_duration=6183.900936, train/loss=0.123824, validation/loss=0.125596, validation/num_examples=83274637
I0306 07:25:29.203701 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:27:54.428047 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:27:58.331517 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:28:02.933819 140589014792000 submission_runner.py:413] Time since start: 6457.84s, 	Step: 2437, 	{'train/loss': 0.12344658609081365, 'validation/loss': 0.1252855585567578, 'validation/num_examples': 83274637, 'test/loss': 0.12775793227796053, 'test/num_examples': 95000000, 'score': 1698.187510251999, 'total_duration': 6457.8352127075195, 'accumulated_submission_time': 1698.187510251999, 'accumulated_eval_time': 4759.258464574814, 'accumulated_logging_time': 0.3052043914794922}
I0306 07:28:02.951147 140407572784896 logging_writer.py:48] [2437] accumulated_eval_time=4759.258465, accumulated_logging_time=0.305204, accumulated_submission_time=1698.187510, global_step=2437, preemption_count=0, score=1698.187510, test/loss=0.127758, test/num_examples=95000000, total_duration=6457.835213, train/loss=0.123447, validation/loss=0.125286, validation/num_examples=83274637
I0306 07:28:36.323176 140407564392192 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.00551909115165472, loss=0.1294059157371521
I0306 07:30:03.291350 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:32:22.407600 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:32:26.318366 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:32:30.953037 140589014792000 submission_runner.py:413] Time since start: 6725.85s, 	Step: 2604, 	{'train/loss': 0.12235508592061277, 'validation/loss': 0.12559572385166926, 'validation/num_examples': 83274637, 'test/loss': 0.12788993839432566, 'test/num_examples': 95000000, 'score': 1818.5135910511017, 'total_duration': 6725.854421854019, 'accumulated_submission_time': 1818.5135910511017, 'accumulated_eval_time': 4906.920119047165, 'accumulated_logging_time': 0.33057355880737305}
I0306 07:32:30.968244 140407572784896 logging_writer.py:48] [2604] accumulated_eval_time=4906.920119, accumulated_logging_time=0.330574, accumulated_submission_time=1818.513591, global_step=2604, preemption_count=0, score=1818.513591, test/loss=0.127890, test/num_examples=95000000, total_duration=6725.854422, train/loss=0.122355, validation/loss=0.125596, validation/num_examples=83274637
I0306 07:34:31.082340 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:36:57.280734 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:37:01.349581 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:37:06.121915 140589014792000 submission_runner.py:413] Time since start: 7001.02s, 	Step: 2772, 	{'train/loss': 0.12496458706240984, 'validation/loss': 0.1255404939970648, 'validation/num_examples': 83274637, 'test/loss': 0.1280375599300987, 'test/num_examples': 95000000, 'score': 1938.6138694286346, 'total_duration': 7001.023332118988, 'accumulated_submission_time': 1938.6138694286346, 'accumulated_eval_time': 5061.959703922272, 'accumulated_logging_time': 0.35356807708740234}
I0306 07:37:06.135864 140407564392192 logging_writer.py:48] [2772] accumulated_eval_time=5061.959704, accumulated_logging_time=0.353568, accumulated_submission_time=1938.613869, global_step=2772, preemption_count=0, score=1938.613869, test/loss=0.128038, test/num_examples=95000000, total_duration=7001.023332, train/loss=0.124965, validation/loss=0.125540, validation/num_examples=83274637
I0306 07:39:07.288913 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:41:31.184933 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:41:35.234039 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:41:40.012236 140589014792000 submission_runner.py:413] Time since start: 7274.91s, 	Step: 2942, 	{'train/loss': 0.12410197472609814, 'validation/loss': 0.12552293270578893, 'validation/num_examples': 83274637, 'test/loss': 0.12787568303865132, 'test/num_examples': 95000000, 'score': 2059.7532625198364, 'total_duration': 7274.913640975952, 'accumulated_submission_time': 2059.7532625198364, 'accumulated_eval_time': 5214.683004617691, 'accumulated_logging_time': 0.37507033348083496}
I0306 07:41:40.027601 140407572784896 logging_writer.py:48] [2942] accumulated_eval_time=5214.683005, accumulated_logging_time=0.375070, accumulated_submission_time=2059.753263, global_step=2942, preemption_count=0, score=2059.753263, test/loss=0.127876, test/num_examples=95000000, total_duration=7274.913641, train/loss=0.124102, validation/loss=0.125523, validation/num_examples=83274637
I0306 07:42:09.468737 140407564392192 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.01731220632791519, loss=0.12452255189418793
I0306 07:43:40.914456 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:46:01.601269 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:46:05.589305 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:46:10.270336 140589014792000 submission_runner.py:413] Time since start: 7545.17s, 	Step: 3114, 	{'train/loss': 0.12383935000724013, 'validation/loss': 0.12532131922937711, 'validation/num_examples': 83274637, 'test/loss': 0.12779071351768093, 'test/num_examples': 95000000, 'score': 2180.626472234726, 'total_duration': 7545.171762943268, 'accumulated_submission_time': 2180.626472234726, 'accumulated_eval_time': 5364.038871049881, 'accumulated_logging_time': 0.39807891845703125}
I0306 07:46:10.283543 140407572784896 logging_writer.py:48] [3114] accumulated_eval_time=5364.038871, accumulated_logging_time=0.398079, accumulated_submission_time=2180.626472, global_step=3114, preemption_count=0, score=2180.626472, test/loss=0.127791, test/num_examples=95000000, total_duration=7545.171763, train/loss=0.123839, validation/loss=0.125321, validation/num_examples=83274637
I0306 07:48:10.694309 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:50:31.629145 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:50:35.649260 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:50:40.411013 140589014792000 submission_runner.py:413] Time since start: 7815.31s, 	Step: 3280, 	{'train/loss': 0.12438426541644822, 'validation/loss': 0.1253703843824621, 'validation/num_examples': 83274637, 'test/loss': 0.12783062663445724, 'test/num_examples': 95000000, 'score': 2301.02455163002, 'total_duration': 7815.312426805496, 'accumulated_submission_time': 2301.02455163002, 'accumulated_eval_time': 5513.755568742752, 'accumulated_logging_time': 0.41811585426330566}
I0306 07:50:40.425934 140407564392192 logging_writer.py:48] [3280] accumulated_eval_time=5513.755569, accumulated_logging_time=0.418116, accumulated_submission_time=2301.024552, global_step=3280, preemption_count=0, score=2301.024552, test/loss=0.127831, test/num_examples=95000000, total_duration=7815.312427, train/loss=0.124384, validation/loss=0.125370, validation/num_examples=83274637
I0306 07:52:41.367762 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:55:03.286615 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:55:07.277456 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:55:12.031560 140589014792000 submission_runner.py:413] Time since start: 8086.93s, 	Step: 3458, 	{'train/loss': 0.12323650853626383, 'validation/loss': 0.12526828420196237, 'validation/num_examples': 83274637, 'test/loss': 0.1276778966899671, 'test/num_examples': 95000000, 'score': 2421.952827692032, 'total_duration': 8086.93297958374, 'accumulated_submission_time': 2421.952827692032, 'accumulated_eval_time': 5664.419347047806, 'accumulated_logging_time': 0.44020652770996094}
I0306 07:55:12.045332 140407572784896 logging_writer.py:48] [3458] accumulated_eval_time=5664.419347, accumulated_logging_time=0.440207, accumulated_submission_time=2421.952828, global_step=3458, preemption_count=0, score=2421.952828, test/loss=0.127678, test/num_examples=95000000, total_duration=8086.932980, train/loss=0.123237, validation/loss=0.125268, validation/num_examples=83274637
I0306 07:55:27.728727 140407564392192 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.005553449969738722, loss=0.1294647753238678
I0306 07:57:12.244130 140589014792000 spec.py:321] Evaluating on the training split.
I0306 07:59:30.135956 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 07:59:34.230769 140589014792000 spec.py:349] Evaluating on the test split.
I0306 07:59:39.018936 140589014792000 submission_runner.py:413] Time since start: 8353.92s, 	Step: 3626, 	{'train/loss': 0.12427422404289246, 'validation/loss': 0.12501321329123596, 'validation/num_examples': 83274637, 'test/loss': 0.12738409165296052, 'test/num_examples': 95000000, 'score': 2542.134447813034, 'total_duration': 8353.920348882675, 'accumulated_submission_time': 2542.134447813034, 'accumulated_eval_time': 5811.194124698639, 'accumulated_logging_time': 0.4652845859527588}
I0306 07:59:39.034889 140407572784896 logging_writer.py:48] [3626] accumulated_eval_time=5811.194125, accumulated_logging_time=0.465285, accumulated_submission_time=2542.134448, global_step=3626, preemption_count=0, score=2542.134448, test/loss=0.127384, test/num_examples=95000000, total_duration=8353.920349, train/loss=0.124274, validation/loss=0.125013, validation/num_examples=83274637
I0306 08:01:39.452775 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:03:50.466390 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:03:54.656400 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:03:59.474074 140589014792000 submission_runner.py:413] Time since start: 8614.38s, 	Step: 3795, 	{'train/loss': 0.12421559429955932, 'validation/loss': 0.12497962422632655, 'validation/num_examples': 83274637, 'test/loss': 0.12749173812705591, 'test/num_examples': 95000000, 'score': 2662.538522720337, 'total_duration': 8614.375497341156, 'accumulated_submission_time': 2662.538522720337, 'accumulated_eval_time': 5951.215406179428, 'accumulated_logging_time': 0.48896265029907227}
I0306 08:03:59.487857 140407564392192 logging_writer.py:48] [3795] accumulated_eval_time=5951.215406, accumulated_logging_time=0.488963, accumulated_submission_time=2662.538523, global_step=3795, preemption_count=0, score=2662.538523, test/loss=0.127492, test/num_examples=95000000, total_duration=8614.375497, train/loss=0.124216, validation/loss=0.124980, validation/num_examples=83274637
I0306 08:05:59.529809 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:08:13.986566 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:08:18.068093 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:08:22.850225 140589014792000 submission_runner.py:413] Time since start: 8877.75s, 	Step: 3963, 	{'train/loss': 0.12156705647332114, 'validation/loss': 0.1251213023150134, 'validation/num_examples': 83274637, 'test/loss': 0.12746999868421052, 'test/num_examples': 95000000, 'score': 2782.567374229431, 'total_duration': 8877.751650094986, 'accumulated_submission_time': 2782.567374229431, 'accumulated_eval_time': 6094.535807847977, 'accumulated_logging_time': 0.5098962783813477}
I0306 08:08:22.863728 140407572784896 logging_writer.py:48] [3963] accumulated_eval_time=6094.535808, accumulated_logging_time=0.509896, accumulated_submission_time=2782.567374, global_step=3963, preemption_count=0, score=2782.567374, test/loss=0.127470, test/num_examples=95000000, total_duration=8877.751650, train/loss=0.121567, validation/loss=0.125121, validation/num_examples=83274637
I0306 08:08:34.630697 140407564392192 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.009218615479767323, loss=0.11637420952320099
I0306 08:10:23.269266 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:12:35.412208 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:12:39.507375 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:12:44.332895 140589014792000 submission_runner.py:413] Time since start: 9139.23s, 	Step: 4134, 	{'train/loss': 0.12260949063413548, 'validation/loss': 0.12473233732956711, 'validation/num_examples': 83274637, 'test/loss': 0.12714995966282894, 'test/num_examples': 95000000, 'score': 2902.959949016571, 'total_duration': 9139.23431301117, 'accumulated_submission_time': 2902.959949016571, 'accumulated_eval_time': 6235.5994119644165, 'accumulated_logging_time': 0.5304808616638184}
I0306 08:12:44.346393 140407572784896 logging_writer.py:48] [4134] accumulated_eval_time=6235.599412, accumulated_logging_time=0.530481, accumulated_submission_time=2902.959949, global_step=4134, preemption_count=0, score=2902.959949, test/loss=0.127150, test/num_examples=95000000, total_duration=9139.234313, train/loss=0.122609, validation/loss=0.124732, validation/num_examples=83274637
I0306 08:14:44.678159 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:17:04.150527 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:17:08.253209 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:17:13.126806 140589014792000 submission_runner.py:413] Time since start: 9408.03s, 	Step: 4303, 	{'train/loss': 0.12201463988741988, 'validation/loss': 0.12499313613414491, 'validation/num_examples': 83274637, 'test/loss': 0.12736128972039473, 'test/num_examples': 95000000, 'score': 3023.275255918503, 'total_duration': 9408.028228521347, 'accumulated_submission_time': 3023.275255918503, 'accumulated_eval_time': 6384.048043727875, 'accumulated_logging_time': 0.554480791091919}
I0306 08:17:13.141099 140407564392192 logging_writer.py:48] [4303] accumulated_eval_time=6384.048044, accumulated_logging_time=0.554481, accumulated_submission_time=3023.275256, global_step=4303, preemption_count=0, score=3023.275256, test/loss=0.127361, test/num_examples=95000000, total_duration=9408.028229, train/loss=0.122015, validation/loss=0.124993, validation/num_examples=83274637
I0306 08:19:13.726613 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:21:36.578326 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:21:40.747162 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:21:45.650506 140589014792000 submission_runner.py:413] Time since start: 9680.55s, 	Step: 4472, 	{'train/loss': 0.12322908728939932, 'validation/loss': 0.12478691328609454, 'validation/num_examples': 83274637, 'test/loss': 0.1272033984683388, 'test/num_examples': 95000000, 'score': 3143.8477489948273, 'total_duration': 9680.55193400383, 'accumulated_submission_time': 3143.8477489948273, 'accumulated_eval_time': 6535.971926212311, 'accumulated_logging_time': 0.5756454467773438}
I0306 08:21:45.664673 140407572784896 logging_writer.py:48] [4472] accumulated_eval_time=6535.971926, accumulated_logging_time=0.575645, accumulated_submission_time=3143.847749, global_step=4472, preemption_count=0, score=3143.847749, test/loss=0.127203, test/num_examples=95000000, total_duration=9680.551934, train/loss=0.123229, validation/loss=0.124787, validation/num_examples=83274637
I0306 08:21:49.295429 140407564392192 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.008420503698289394, loss=0.12418866902589798
I0306 08:23:46.212818 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:26:01.326160 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:26:05.530294 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:26:10.437793 140589014792000 submission_runner.py:413] Time since start: 9945.34s, 	Step: 4639, 	{'train/loss': 0.12251611391328415, 'validation/loss': 0.12496754212247421, 'validation/num_examples': 83274637, 'test/loss': 0.12741041692023025, 'test/num_examples': 95000000, 'score': 3264.3826990127563, 'total_duration': 9945.339216947556, 'accumulated_submission_time': 3264.3826990127563, 'accumulated_eval_time': 6680.196882486343, 'accumulated_logging_time': 0.5970909595489502}
I0306 08:26:10.451463 140407572784896 logging_writer.py:48] [4639] accumulated_eval_time=6680.196882, accumulated_logging_time=0.597091, accumulated_submission_time=3264.382699, global_step=4639, preemption_count=0, score=3264.382699, test/loss=0.127410, test/num_examples=95000000, total_duration=9945.339217, train/loss=0.122516, validation/loss=0.124968, validation/num_examples=83274637
I0306 08:28:10.469710 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:30:30.649982 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:30:34.831401 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:30:39.741717 140589014792000 submission_runner.py:413] Time since start: 10214.64s, 	Step: 4807, 	{'train/loss': 0.12112039646262643, 'validation/loss': 0.124504470548983, 'validation/num_examples': 83274637, 'test/loss': 0.12697430828536185, 'test/num_examples': 95000000, 'score': 3384.3856303691864, 'total_duration': 10214.643136262894, 'accumulated_submission_time': 3384.3856303691864, 'accumulated_eval_time': 6829.468868494034, 'accumulated_logging_time': 0.6201989650726318}
I0306 08:30:39.755898 140407564392192 logging_writer.py:48] [4807] accumulated_eval_time=6829.468868, accumulated_logging_time=0.620199, accumulated_submission_time=3384.385630, global_step=4807, preemption_count=0, score=3384.385630, test/loss=0.126974, test/num_examples=95000000, total_duration=10214.643136, train/loss=0.121120, validation/loss=0.124504, validation/num_examples=83274637
I0306 08:32:39.875156 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:34:56.756119 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:35:00.945551 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:35:05.878657 140589014792000 submission_runner.py:413] Time since start: 10480.78s, 	Step: 4974, 	{'train/loss': 0.12400955046122929, 'validation/loss': 0.12482571678944995, 'validation/num_examples': 83274637, 'test/loss': 0.12717721374383223, 'test/num_examples': 95000000, 'score': 3504.4920194149017, 'total_duration': 10480.780037641525, 'accumulated_submission_time': 3504.4920194149017, 'accumulated_eval_time': 6975.472341299057, 'accumulated_logging_time': 0.6412858963012695}
I0306 08:35:05.898875 140407572784896 logging_writer.py:48] [4974] accumulated_eval_time=6975.472341, accumulated_logging_time=0.641286, accumulated_submission_time=3504.492019, global_step=4974, preemption_count=0, score=3504.492019, test/loss=0.127177, test/num_examples=95000000, total_duration=10480.780038, train/loss=0.124010, validation/loss=0.124826, validation/num_examples=83274637
I0306 08:35:08.461985 140407564392192 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.006394810974597931, loss=0.12170366942882538
I0306 08:37:06.165210 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:39:20.681129 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:39:24.899452 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:39:29.847060 140589014792000 submission_runner.py:413] Time since start: 10744.75s, 	Step: 5146, 	{'train/loss': 0.1216374860151009, 'validation/loss': 0.12456851869292748, 'validation/num_examples': 83274637, 'test/loss': 0.1270187224506579, 'test/num_examples': 95000000, 'score': 3624.7433757781982, 'total_duration': 10744.748449802399, 'accumulated_submission_time': 3624.7433757781982, 'accumulated_eval_time': 7119.154141187668, 'accumulated_logging_time': 0.6703791618347168}
I0306 08:39:29.867987 140407572784896 logging_writer.py:48] [5146] accumulated_eval_time=7119.154141, accumulated_logging_time=0.670379, accumulated_submission_time=3624.743376, global_step=5146, preemption_count=0, score=3624.743376, test/loss=0.127019, test/num_examples=95000000, total_duration=10744.748450, train/loss=0.121637, validation/loss=0.124569, validation/num_examples=83274637
I0306 08:41:30.103458 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:43:49.590013 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:43:53.814039 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:43:58.731592 140589014792000 submission_runner.py:413] Time since start: 11013.63s, 	Step: 5314, 	{'train/loss': 0.1214827723660559, 'validation/loss': 0.12451223847349223, 'validation/num_examples': 83274637, 'test/loss': 0.12688801361019736, 'test/num_examples': 95000000, 'score': 3744.9651362895966, 'total_duration': 11013.633011102676, 'accumulated_submission_time': 3744.9651362895966, 'accumulated_eval_time': 7267.782253265381, 'accumulated_logging_time': 0.6989274024963379}
I0306 08:43:58.745497 140407564392192 logging_writer.py:48] [5314] accumulated_eval_time=7267.782253, accumulated_logging_time=0.698927, accumulated_submission_time=3744.965136, global_step=5314, preemption_count=0, score=3744.965136, test/loss=0.126888, test/num_examples=95000000, total_duration=11013.633011, train/loss=0.121483, validation/loss=0.124512, validation/num_examples=83274637
I0306 08:45:58.757634 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:48:18.527327 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:48:22.751987 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:48:27.702033 140589014792000 submission_runner.py:413] Time since start: 11282.60s, 	Step: 5481, 	{'train/loss': 0.12158618201999544, 'validation/loss': 0.12457275472347601, 'validation/num_examples': 83274637, 'test/loss': 0.12692426928453948, 'test/num_examples': 95000000, 'score': 3864.964122056961, 'total_duration': 11282.60345196724, 'accumulated_submission_time': 3864.964122056961, 'accumulated_eval_time': 7416.726633071899, 'accumulated_logging_time': 0.7201194763183594}
I0306 08:48:27.718913 140407572784896 logging_writer.py:48] [5481] accumulated_eval_time=7416.726633, accumulated_logging_time=0.720119, accumulated_submission_time=3864.964122, global_step=5481, preemption_count=0, score=3864.964122, test/loss=0.126924, test/num_examples=95000000, total_duration=11282.603452, train/loss=0.121586, validation/loss=0.124573, validation/num_examples=83274637
I0306 08:48:29.211479 140407564392192 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.01015608012676239, loss=0.1232772022485733
I0306 08:50:27.918076 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:52:52.006987 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:52:56.231590 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:53:01.197067 140589014792000 submission_runner.py:413] Time since start: 11556.10s, 	Step: 5649, 	{'train/loss': 0.12229999867062899, 'validation/loss': 0.12452694733376622, 'validation/num_examples': 83274637, 'test/loss': 0.12695782584292764, 'test/num_examples': 95000000, 'score': 3985.1487872600555, 'total_duration': 11556.09846830368, 'accumulated_submission_time': 3985.1487872600555, 'accumulated_eval_time': 7570.005583047867, 'accumulated_logging_time': 0.7455096244812012}
I0306 08:53:01.219134 140407572784896 logging_writer.py:48] [5649] accumulated_eval_time=7570.005583, accumulated_logging_time=0.745510, accumulated_submission_time=3985.148787, global_step=5649, preemption_count=0, score=3985.148787, test/loss=0.126958, test/num_examples=95000000, total_duration=11556.098468, train/loss=0.122300, validation/loss=0.124527, validation/num_examples=83274637
I0306 08:55:01.416158 140589014792000 spec.py:321] Evaluating on the training split.
I0306 08:57:22.698003 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 08:57:26.879707 140589014792000 spec.py:349] Evaluating on the test split.
I0306 08:57:31.802936 140589014792000 submission_runner.py:413] Time since start: 11826.70s, 	Step: 5816, 	{'train/loss': 0.1222322683945392, 'validation/loss': 0.12449116414528771, 'validation/num_examples': 83274637, 'test/loss': 0.1268896113178454, 'test/num_examples': 95000000, 'score': 4105.325268268585, 'total_duration': 11826.704360485077, 'accumulated_submission_time': 4105.325268268585, 'accumulated_eval_time': 7720.392364501953, 'accumulated_logging_time': 0.7821109294891357}
I0306 08:57:31.821300 140407564392192 logging_writer.py:48] [5816] accumulated_eval_time=7720.392365, accumulated_logging_time=0.782111, accumulated_submission_time=4105.325268, global_step=5816, preemption_count=0, score=4105.325268, test/loss=0.126890, test/num_examples=95000000, total_duration=11826.704360, train/loss=0.122232, validation/loss=0.124491, validation/num_examples=83274637
I0306 08:59:31.816830 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:01:55.403034 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:01:59.627295 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:02:04.638405 140589014792000 submission_runner.py:413] Time since start: 12099.54s, 	Step: 5985, 	{'train/loss': 0.12324640965499219, 'validation/loss': 0.1245282337867621, 'validation/num_examples': 83274637, 'test/loss': 0.12690423430304276, 'test/num_examples': 95000000, 'score': 4225.304925203323, 'total_duration': 12099.539812088013, 'accumulated_submission_time': 4225.304925203323, 'accumulated_eval_time': 7873.213907003403, 'accumulated_logging_time': 0.810250997543335}
I0306 09:02:04.654929 140407572784896 logging_writer.py:48] [5985] accumulated_eval_time=7873.213907, accumulated_logging_time=0.810251, accumulated_submission_time=4225.304925, global_step=5985, preemption_count=0, score=4225.304925, test/loss=0.126904, test/num_examples=95000000, total_duration=12099.539812, train/loss=0.123246, validation/loss=0.124528, validation/num_examples=83274637
I0306 09:02:05.850277 140407564392192 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.0066382987424731255, loss=0.11796586215496063
I0306 09:04:05.004951 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:06:34.888056 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:06:39.154349 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:06:44.184260 140589014792000 submission_runner.py:413] Time since start: 12379.09s, 	Step: 6158, 	{'train/loss': 0.12403709024378338, 'validation/loss': 0.12437574714750783, 'validation/num_examples': 83274637, 'test/loss': 0.12671834671052631, 'test/num_examples': 95000000, 'score': 4345.639629602432, 'total_duration': 12379.085680246353, 'accumulated_submission_time': 4345.639629602432, 'accumulated_eval_time': 8032.393202543259, 'accumulated_logging_time': 0.8358597755432129}
I0306 09:06:44.199470 140407572784896 logging_writer.py:48] [6158] accumulated_eval_time=8032.393203, accumulated_logging_time=0.835860, accumulated_submission_time=4345.639630, global_step=6158, preemption_count=0, score=4345.639630, test/loss=0.126718, test/num_examples=95000000, total_duration=12379.085680, train/loss=0.124037, validation/loss=0.124376, validation/num_examples=83274637
I0306 09:08:44.699671 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:11:08.352569 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:11:12.594094 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:11:17.565428 140589014792000 submission_runner.py:413] Time since start: 12652.47s, 	Step: 6327, 	{'train/loss': 0.12292648331736619, 'validation/loss': 0.12440795115872136, 'validation/num_examples': 83274637, 'test/loss': 0.12683341616981908, 'test/num_examples': 95000000, 'score': 4466.122906446457, 'total_duration': 12652.46684384346, 'accumulated_submission_time': 4466.122906446457, 'accumulated_eval_time': 8185.258936405182, 'accumulated_logging_time': 0.8616881370544434}
I0306 09:11:17.579761 140407564392192 logging_writer.py:48] [6327] accumulated_eval_time=8185.258936, accumulated_logging_time=0.861688, accumulated_submission_time=4466.122906, global_step=6327, preemption_count=0, score=4466.122906, test/loss=0.126833, test/num_examples=95000000, total_duration=12652.466844, train/loss=0.122926, validation/loss=0.124408, validation/num_examples=83274637
I0306 09:13:18.059849 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:15:32.851891 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:15:37.120013 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:15:42.066094 140589014792000 submission_runner.py:413] Time since start: 12916.97s, 	Step: 6495, 	{'train/loss': 0.1232858456249507, 'validation/loss': 0.12428192407829108, 'validation/num_examples': 83274637, 'test/loss': 0.12667274971217105, 'test/num_examples': 95000000, 'score': 4586.589813709259, 'total_duration': 12916.967513561249, 'accumulated_submission_time': 4586.589813709259, 'accumulated_eval_time': 8329.26518535614, 'accumulated_logging_time': 0.8831233978271484}
I0306 09:15:42.081011 140407572784896 logging_writer.py:48] [6495] accumulated_eval_time=8329.265185, accumulated_logging_time=0.883123, accumulated_submission_time=4586.589814, global_step=6495, preemption_count=0, score=4586.589814, test/loss=0.126673, test/num_examples=95000000, total_duration=12916.967514, train/loss=0.123286, validation/loss=0.124282, validation/num_examples=83274637
I0306 09:15:42.536101 140407564392192 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.01893250085413456, loss=0.12299590557813644
I0306 09:17:42.084010 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:20:07.197837 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:20:11.446534 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:20:16.410829 140589014792000 submission_runner.py:413] Time since start: 13191.31s, 	Step: 6663, 	{'train/loss': 0.12298741224426893, 'validation/loss': 0.12432959381100335, 'validation/num_examples': 83274637, 'test/loss': 0.12669366120476974, 'test/num_examples': 95000000, 'score': 4706.579119205475, 'total_duration': 13191.312245368958, 'accumulated_submission_time': 4706.579119205475, 'accumulated_eval_time': 8483.591983318329, 'accumulated_logging_time': 0.9057960510253906}
I0306 09:20:16.425897 140407572784896 logging_writer.py:48] [6663] accumulated_eval_time=8483.591983, accumulated_logging_time=0.905796, accumulated_submission_time=4706.579119, global_step=6663, preemption_count=0, score=4706.579119, test/loss=0.126694, test/num_examples=95000000, total_duration=13191.312245, train/loss=0.122987, validation/loss=0.124330, validation/num_examples=83274637
I0306 09:22:16.498604 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:24:38.158812 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:24:42.401120 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:24:47.473127 140589014792000 submission_runner.py:413] Time since start: 13462.37s, 	Step: 6831, 	{'train/loss': 0.12245097381513824, 'validation/loss': 0.12426382479870492, 'validation/num_examples': 83274637, 'test/loss': 0.1267290832339638, 'test/num_examples': 95000000, 'score': 4826.638483047485, 'total_duration': 13462.37453508377, 'accumulated_submission_time': 4826.638483047485, 'accumulated_eval_time': 8634.56647825241, 'accumulated_logging_time': 0.928074836730957}
I0306 09:24:47.490031 140407564392192 logging_writer.py:48] [6831] accumulated_eval_time=8634.566478, accumulated_logging_time=0.928075, accumulated_submission_time=4826.638483, global_step=6831, preemption_count=0, score=4826.638483, test/loss=0.126729, test/num_examples=95000000, total_duration=13462.374535, train/loss=0.122451, validation/loss=0.124264, validation/num_examples=83274637
I0306 09:26:47.869530 140407572784896 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.007256993558257818, loss=0.12807510793209076
I0306 09:26:47.873654 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:29:04.892088 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:29:09.162287 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:29:14.153971 140589014792000 submission_runner.py:413] Time since start: 13729.06s, 	Step: 7001, 	{'train/loss': 0.12415364520542277, 'validation/loss': 0.12424506298996235, 'validation/num_examples': 83274637, 'test/loss': 0.12664624886924342, 'test/num_examples': 95000000, 'score': 4947.007377386093, 'total_duration': 13729.055393457413, 'accumulated_submission_time': 4947.007377386093, 'accumulated_eval_time': 8780.846737146378, 'accumulated_logging_time': 0.9535160064697266}
I0306 09:29:14.170118 140407564392192 logging_writer.py:48] [7001] accumulated_eval_time=8780.846737, accumulated_logging_time=0.953516, accumulated_submission_time=4947.007377, global_step=7001, preemption_count=0, score=4947.007377, test/loss=0.126646, test/num_examples=95000000, total_duration=13729.055393, train/loss=0.124154, validation/loss=0.124245, validation/num_examples=83274637
I0306 09:31:14.700559 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:33:35.928508 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:33:40.179835 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:33:45.192839 140589014792000 submission_runner.py:413] Time since start: 14000.09s, 	Step: 7168, 	{'train/loss': 0.12385529827959132, 'validation/loss': 0.12420977153846675, 'validation/num_examples': 83274637, 'test/loss': 0.12660329095394737, 'test/num_examples': 95000000, 'score': 5067.524134159088, 'total_duration': 14000.094252824783, 'accumulated_submission_time': 5067.524134159088, 'accumulated_eval_time': 8931.338992357254, 'accumulated_logging_time': 0.9774575233459473}
I0306 09:33:45.211450 140407572784896 logging_writer.py:48] [7168] accumulated_eval_time=8931.338992, accumulated_logging_time=0.977458, accumulated_submission_time=5067.524134, global_step=7168, preemption_count=0, score=5067.524134, test/loss=0.126603, test/num_examples=95000000, total_duration=14000.094253, train/loss=0.123855, validation/loss=0.124210, validation/num_examples=83274637
I0306 09:35:47.077762 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:38:12.042464 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:38:16.287161 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:38:21.315176 140589014792000 submission_runner.py:413] Time since start: 14276.22s, 	Step: 7341, 	{'train/loss': 0.12272485144108346, 'validation/loss': 0.12418553035466849, 'validation/num_examples': 83274637, 'test/loss': 0.12653958024259868, 'test/num_examples': 95000000, 'score': 5189.375959634781, 'total_duration': 14276.216595888138, 'accumulated_submission_time': 5189.375959634781, 'accumulated_eval_time': 9085.576388120651, 'accumulated_logging_time': 1.0043892860412598}
I0306 09:38:21.331283 140407564392192 logging_writer.py:48] [7341] accumulated_eval_time=9085.576388, accumulated_logging_time=1.004389, accumulated_submission_time=5189.375960, global_step=7341, preemption_count=0, score=5189.375960, test/loss=0.126540, test/num_examples=95000000, total_duration=14276.216596, train/loss=0.122725, validation/loss=0.124186, validation/num_examples=83274637
I0306 09:40:14.792109 140407572784896 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.009339005686342716, loss=0.1251680850982666
I0306 09:40:21.610908 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:42:46.420725 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:42:50.626774 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:42:55.625831 140589014792000 submission_runner.py:413] Time since start: 14550.53s, 	Step: 7509, 	{'train/loss': 0.12429889314954386, 'validation/loss': 0.12419371421276805, 'validation/num_examples': 83274637, 'test/loss': 0.1264799502055921, 'test/num_examples': 95000000, 'score': 5309.640488862991, 'total_duration': 14550.527242183685, 'accumulated_submission_time': 5309.640488862991, 'accumulated_eval_time': 9239.591262578964, 'accumulated_logging_time': 1.029554843902588}
I0306 09:42:55.643467 140407564392192 logging_writer.py:48] [7509] accumulated_eval_time=9239.591263, accumulated_logging_time=1.029555, accumulated_submission_time=5309.640489, global_step=7509, preemption_count=0, score=5309.640489, test/loss=0.126480, test/num_examples=95000000, total_duration=14550.527242, train/loss=0.124299, validation/loss=0.124194, validation/num_examples=83274637
I0306 09:44:55.818555 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:47:18.164837 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:47:22.444857 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:47:27.493223 140589014792000 submission_runner.py:413] Time since start: 14822.39s, 	Step: 7678, 	{'train/loss': 0.12327248842086432, 'validation/loss': 0.12415582443112301, 'validation/num_examples': 83274637, 'test/loss': 0.12650313391241777, 'test/num_examples': 95000000, 'score': 5429.801173686981, 'total_duration': 14822.394619703293, 'accumulated_submission_time': 5429.801173686981, 'accumulated_eval_time': 9391.265887260437, 'accumulated_logging_time': 1.055837869644165}
I0306 09:47:27.517697 140407572784896 logging_writer.py:48] [7678] accumulated_eval_time=9391.265887, accumulated_logging_time=1.055838, accumulated_submission_time=5429.801174, global_step=7678, preemption_count=0, score=5429.801174, test/loss=0.126503, test/num_examples=95000000, total_duration=14822.394620, train/loss=0.123272, validation/loss=0.124156, validation/num_examples=83274637
I0306 09:49:27.553025 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:51:45.380713 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:51:49.596117 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:51:54.611365 140589014792000 submission_runner.py:413] Time since start: 15089.51s, 	Step: 7845, 	{'train/loss': 0.12294240684816672, 'validation/loss': 0.12415016084819439, 'validation/num_examples': 83274637, 'test/loss': 0.1264902542763158, 'test/num_examples': 95000000, 'score': 5549.819905281067, 'total_duration': 15089.51276063919, 'accumulated_submission_time': 5549.819905281067, 'accumulated_eval_time': 9538.324207782745, 'accumulated_logging_time': 1.0907785892486572}
I0306 09:51:54.639336 140407564392192 logging_writer.py:48] [7845] accumulated_eval_time=9538.324208, accumulated_logging_time=1.090779, accumulated_submission_time=5549.819905, global_step=7845, preemption_count=0, score=5549.819905, test/loss=0.126490, test/num_examples=95000000, total_duration=15089.512761, train/loss=0.122942, validation/loss=0.124150, validation/num_examples=83274637
I0306 09:53:44.269464 140407572784896 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.006892821751534939, loss=0.11639981716871262
I0306 09:53:55.006104 140589014792000 spec.py:321] Evaluating on the training split.
I0306 09:56:12.610522 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 09:56:16.832242 140589014792000 spec.py:349] Evaluating on the test split.
I0306 09:56:21.866171 140589014792000 submission_runner.py:413] Time since start: 15356.77s, 	Step: 8014, 	{'train/loss': 0.12373550737616401, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5670.167506933212, 'total_duration': 15356.767590045929, 'accumulated_submission_time': 5670.167506933212, 'accumulated_eval_time': 9685.184237003326, 'accumulated_logging_time': 1.1316077709197998}
I0306 09:56:21.881258 140407564392192 logging_writer.py:48] [8014] accumulated_eval_time=9685.184237, accumulated_logging_time=1.131608, accumulated_submission_time=5670.167507, global_step=8014, preemption_count=0, score=5670.167507, test/loss=0.126490, test/num_examples=95000000, total_duration=15356.767590, train/loss=0.123736, validation/loss=0.124149, validation/num_examples=83274637
I0306 09:58:22.372337 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:00:38.673338 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:00:42.891177 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:00:47.923489 140589014792000 submission_runner.py:413] Time since start: 15622.82s, 	Step: 8182, 	{'train/loss': 0.12317854287864277, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5790.645438909531, 'total_duration': 15622.824906349182, 'accumulated_submission_time': 5790.645438909531, 'accumulated_eval_time': 9830.735363721848, 'accumulated_logging_time': 1.1536240577697754}
I0306 10:00:47.942383 140407572784896 logging_writer.py:48] [8182] accumulated_eval_time=9830.735364, accumulated_logging_time=1.153624, accumulated_submission_time=5790.645439, global_step=8182, preemption_count=0, score=5790.645439, test/loss=0.126490, test/num_examples=95000000, total_duration=15622.824906, train/loss=0.123179, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:02:48.423768 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:05:02.486740 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:05:06.748637 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:05:11.756220 140589014792000 submission_runner.py:413] Time since start: 15886.66s, 	Step: 8358, 	{'train/loss': 0.12266260690096789, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5911.111374616623, 'total_duration': 15886.657624959946, 'accumulated_submission_time': 5911.111374616623, 'accumulated_eval_time': 9974.06777882576, 'accumulated_logging_time': 1.1816885471343994}
I0306 10:05:11.781333 140407564392192 logging_writer.py:48] [8358] accumulated_eval_time=9974.067779, accumulated_logging_time=1.181689, accumulated_submission_time=5911.111375, global_step=8358, preemption_count=0, score=5911.111375, test/loss=0.126490, test/num_examples=95000000, total_duration=15886.657625, train/loss=0.122663, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:06:52.059952 140407572784896 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.007261591497808695, loss=0.12312725186347961
I0306 10:07:11.987352 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:09:35.541748 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:09:39.796173 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:09:44.821106 140589014792000 submission_runner.py:413] Time since start: 16159.72s, 	Step: 8525, 	{'train/loss': 0.1230050394744993, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6031.302855491638, 'total_duration': 16159.722524166107, 'accumulated_submission_time': 6031.302855491638, 'accumulated_eval_time': 10126.901505231857, 'accumulated_logging_time': 1.215198278427124}
I0306 10:09:44.836614 140407564392192 logging_writer.py:48] [8525] accumulated_eval_time=10126.901505, accumulated_logging_time=1.215198, accumulated_submission_time=6031.302855, global_step=8525, preemption_count=0, score=6031.302855, test/loss=0.126490, test/num_examples=95000000, total_duration=16159.722524, train/loss=0.123005, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:11:45.194565 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:14:04.547648 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:14:08.800466 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:14:13.876452 140589014792000 submission_runner.py:413] Time since start: 16428.78s, 	Step: 8698, 	{'train/loss': 0.12306827578529622, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6151.641670703888, 'total_duration': 16428.777859210968, 'accumulated_submission_time': 6151.641670703888, 'accumulated_eval_time': 10275.583359003067, 'accumulated_logging_time': 1.2436904907226562}
I0306 10:14:13.896700 140407572784896 logging_writer.py:48] [8698] accumulated_eval_time=10275.583359, accumulated_logging_time=1.243690, accumulated_submission_time=6151.641671, global_step=8698, preemption_count=0, score=6151.641671, test/loss=0.126490, test/num_examples=95000000, total_duration=16428.777859, train/loss=0.123068, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:16:14.774577 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:18:29.234042 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:18:33.468873 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:18:38.505692 140589014792000 submission_runner.py:413] Time since start: 16693.41s, 	Step: 8866, 	{'train/loss': 0.12137633557402112, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6272.504487037659, 'total_duration': 16693.407087802887, 'accumulated_submission_time': 6272.504487037659, 'accumulated_eval_time': 10419.314430713654, 'accumulated_logging_time': 1.2728030681610107}
I0306 10:18:38.526727 140407564392192 logging_writer.py:48] [8866] accumulated_eval_time=10419.314431, accumulated_logging_time=1.272803, accumulated_submission_time=6272.504487, global_step=8866, preemption_count=0, score=6272.504487, test/loss=0.126490, test/num_examples=95000000, total_duration=16693.407088, train/loss=0.121376, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:20:10.762419 140407572784896 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.007504031993448734, loss=0.13163194060325623
I0306 10:20:38.650304 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:23:00.173375 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:23:04.407883 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:23:09.456653 140589014792000 submission_runner.py:413] Time since start: 16964.36s, 	Step: 9034, 	{'train/loss': 0.12406195531476219, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6392.61322593689, 'total_duration': 16964.358067512512, 'accumulated_submission_time': 6392.61322593689, 'accumulated_eval_time': 10570.120740175247, 'accumulated_logging_time': 1.3025922775268555}
I0306 10:23:09.472611 140407564392192 logging_writer.py:48] [9034] accumulated_eval_time=10570.120740, accumulated_logging_time=1.302592, accumulated_submission_time=6392.613226, global_step=9034, preemption_count=0, score=6392.613226, test/loss=0.126490, test/num_examples=95000000, total_duration=16964.358068, train/loss=0.124062, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:25:09.641341 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:27:34.236548 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:27:38.539902 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:27:43.661402 140589014792000 submission_runner.py:413] Time since start: 17238.56s, 	Step: 9205, 	{'train/loss': 0.12276238629465583, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6512.768201589584, 'total_duration': 17238.562821626663, 'accumulated_submission_time': 6512.768201589584, 'accumulated_eval_time': 10724.140794038773, 'accumulated_logging_time': 1.3262543678283691}
I0306 10:27:43.679280 140407572784896 logging_writer.py:48] [9205] accumulated_eval_time=10724.140794, accumulated_logging_time=1.326254, accumulated_submission_time=6512.768202, global_step=9205, preemption_count=0, score=6512.768202, test/loss=0.126490, test/num_examples=95000000, total_duration=17238.562822, train/loss=0.122762, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:29:43.930896 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:32:22.372651 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:32:26.666087 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:32:31.776151 140589014792000 submission_runner.py:413] Time since start: 17526.68s, 	Step: 9374, 	{'train/loss': 0.12516544623382436, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6633.006072282791, 'total_duration': 17526.677567481995, 'accumulated_submission_time': 6633.006072282791, 'accumulated_eval_time': 10891.98603773117, 'accumulated_logging_time': 1.3516933917999268}
I0306 10:32:31.796118 140407564392192 logging_writer.py:48] [9374] accumulated_eval_time=10891.986038, accumulated_logging_time=1.351693, accumulated_submission_time=6633.006072, global_step=9374, preemption_count=0, score=6633.006072, test/loss=0.126490, test/num_examples=95000000, total_duration=17526.677567, train/loss=0.125165, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:33:57.680267 140407572784896 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.00830860435962677, loss=0.12737995386123657
I0306 10:34:32.168260 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:36:49.121992 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:36:53.426368 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:36:58.481457 140589014792000 submission_runner.py:413] Time since start: 17793.38s, 	Step: 9542, 	{'train/loss': 0.12364970470936794, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6753.363312005997, 'total_duration': 17793.382875919342, 'accumulated_submission_time': 6753.363312005997, 'accumulated_eval_time': 11038.299199104309, 'accumulated_logging_time': 1.380382776260376}
I0306 10:36:58.497422 140407564392192 logging_writer.py:48] [9542] accumulated_eval_time=11038.299199, accumulated_logging_time=1.380383, accumulated_submission_time=6753.363312, global_step=9542, preemption_count=0, score=6753.363312, test/loss=0.126490, test/num_examples=95000000, total_duration=17793.382876, train/loss=0.123650, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:38:58.726255 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:41:23.192014 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:41:27.453561 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:41:32.486182 140589014792000 submission_runner.py:413] Time since start: 18067.39s, 	Step: 9713, 	{'train/loss': 0.12310819004504185, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6873.578608512878, 'total_duration': 18067.38759803772, 'accumulated_submission_time': 6873.578608512878, 'accumulated_eval_time': 11192.059101104736, 'accumulated_logging_time': 1.4035840034484863}
I0306 10:41:32.501281 140407572784896 logging_writer.py:48] [9713] accumulated_eval_time=11192.059101, accumulated_logging_time=1.403584, accumulated_submission_time=6873.578609, global_step=9713, preemption_count=0, score=6873.578609, test/loss=0.126490, test/num_examples=95000000, total_duration=18067.387598, train/loss=0.123108, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:43:33.138089 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:45:53.941523 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:45:58.192068 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:46:03.309216 140589014792000 submission_runner.py:413] Time since start: 18338.21s, 	Step: 9890, 	{'train/loss': 0.12173471745080168, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6994.200517654419, 'total_duration': 18338.21062350273, 'accumulated_submission_time': 6994.200517654419, 'accumulated_eval_time': 11342.230197906494, 'accumulated_logging_time': 1.427201509475708}
I0306 10:46:03.326845 140407564392192 logging_writer.py:48] [9890] accumulated_eval_time=11342.230198, accumulated_logging_time=1.427202, accumulated_submission_time=6994.200518, global_step=9890, preemption_count=0, score=6994.200518, test/loss=0.126490, test/num_examples=95000000, total_duration=18338.210624, train/loss=0.121735, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:47:14.752720 140407572784896 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.02005086839199066, loss=0.1331201195716858
I0306 10:48:03.467972 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:50:20.481123 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:50:24.799464 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:50:29.862560 140589014792000 submission_runner.py:413] Time since start: 18604.76s, 	Step: 10062, 	{'train/loss': 0.12331624024506635, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7114.3279457092285, 'total_duration': 18604.76394534111, 'accumulated_submission_time': 7114.3279457092285, 'accumulated_eval_time': 11488.62471985817, 'accumulated_logging_time': 1.4524385929107666}
I0306 10:50:29.889052 140407564392192 logging_writer.py:48] [10062] accumulated_eval_time=11488.624720, accumulated_logging_time=1.452439, accumulated_submission_time=7114.327946, global_step=10062, preemption_count=0, score=7114.327946, test/loss=0.126490, test/num_examples=95000000, total_duration=18604.763945, train/loss=0.123316, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:52:30.241634 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:54:55.635516 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:54:59.912822 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:55:04.979107 140589014792000 submission_runner.py:413] Time since start: 18879.88s, 	Step: 10230, 	{'train/loss': 0.12539913823956964, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7234.665671348572, 'total_duration': 18879.880497932434, 'accumulated_submission_time': 7234.665671348572, 'accumulated_eval_time': 11643.362159490585, 'accumulated_logging_time': 1.4875414371490479}
I0306 10:55:05.001155 140407572784896 logging_writer.py:48] [10230] accumulated_eval_time=11643.362159, accumulated_logging_time=1.487541, accumulated_submission_time=7234.665671, global_step=10230, preemption_count=0, score=7234.665671, test/loss=0.126490, test/num_examples=95000000, total_duration=18879.880498, train/loss=0.125399, validation/loss=0.124149, validation/num_examples=83274637
I0306 10:57:05.463720 140589014792000 spec.py:321] Evaluating on the training split.
I0306 10:59:27.008348 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 10:59:31.301697 140589014792000 spec.py:349] Evaluating on the test split.
I0306 10:59:36.381084 140589014792000 submission_runner.py:413] Time since start: 19151.28s, 	Step: 10397, 	{'train/loss': 0.1233795684932163, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7355.112859010696, 'total_duration': 19151.282508134842, 'accumulated_submission_time': 7355.112859010696, 'accumulated_eval_time': 11794.279506921768, 'accumulated_logging_time': 1.51881742477417}
I0306 10:59:36.396680 140407564392192 logging_writer.py:48] [10397] accumulated_eval_time=11794.279507, accumulated_logging_time=1.518817, accumulated_submission_time=7355.112859, global_step=10397, preemption_count=0, score=7355.112859, test/loss=0.126490, test/num_examples=95000000, total_duration=19151.282508, train/loss=0.123380, validation/loss=0.124149, validation/num_examples=83274637
I0306 11:00:43.697839 140407572784896 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.008624068461358547, loss=0.12489334493875504
I0306 11:01:37.335890 140589014792000 spec.py:321] Evaluating on the training split.
I0306 11:03:57.229427 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 11:04:01.545945 140589014792000 spec.py:349] Evaluating on the test split.
I0306 11:04:06.615597 140589014792000 submission_runner.py:413] Time since start: 19421.52s, 	Step: 10564, 	{'train/loss': 0.12469538334030775, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7476.037807941437, 'total_duration': 19421.51701927185, 'accumulated_submission_time': 7476.037807941437, 'accumulated_eval_time': 11943.559185504913, 'accumulated_logging_time': 1.5425903797149658}
I0306 11:04:06.630290 140407564392192 logging_writer.py:48] [10564] accumulated_eval_time=11943.559186, accumulated_logging_time=1.542590, accumulated_submission_time=7476.037808, global_step=10564, preemption_count=0, score=7476.037808, test/loss=0.126490, test/num_examples=95000000, total_duration=19421.517019, train/loss=0.124695, validation/loss=0.124149, validation/num_examples=83274637
I0306 11:05:12.456082 140589014792000 spec.py:321] Evaluating on the training split.
I0306 11:08:22.884368 140589014792000 spec.py:333] Evaluating on the validation split.
I0306 11:08:27.038434 140589014792000 spec.py:349] Evaluating on the test split.
I0306 11:08:32.120814 140589014792000 submission_runner.py:413] Time since start: 19687.02s, 	Step: 10666, 	{'train/loss': 0.12427277089852207, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7541.851372003555, 'total_duration': 19687.02222943306, 'accumulated_submission_time': 7541.851372003555, 'accumulated_eval_time': 12143.223886013031, 'accumulated_logging_time': 1.5656373500823975}
I0306 11:08:32.136144 140407572784896 logging_writer.py:48] [10666] accumulated_eval_time=12143.223886, accumulated_logging_time=1.565637, accumulated_submission_time=7541.851372, global_step=10666, preemption_count=0, score=7541.851372, test/loss=0.126490, test/num_examples=95000000, total_duration=19687.022229, train/loss=0.124273, validation/loss=0.124149, validation/num_examples=83274637
I0306 11:08:32.149394 140407564392192 logging_writer.py:48] [10666] global_step=10666, preemption_count=0, score=7541.851372
I0306 11:08:35.069548 140589014792000 checkpoints.py:490] Saving checkpoint at step: 10666
I0306 11:09:01.366084 140589014792000 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1/checkpoint_10666
I0306 11:09:01.826763 140589014792000 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/criteo1tb_resnet_jax/trial_1/checkpoint_10666.
I0306 11:09:01.943728 140589014792000 submission_runner.py:588] Tuning trial 1/1
I0306 11:09:01.943961 140589014792000 submission_runner.py:589] Hyperparameters: Hyperparameters(learning_rate=0.001493629901423942, beta1=0.9592129978682067, beta2=0.9824918272399145, warmup_steps=399, weight_decay=0.00038587516415285595)
I0306 11:09:01.945067 140589014792000 submission_runner.py:590] Metrics: {'eval_results': [(1, {'train/loss': 0.6008674404906027, 'validation/loss': 0.6015239482520951, 'validation/num_examples': 83274637, 'test/loss': 0.6020814077302632, 'test/num_examples': 95000000, 'score': 12.463748216629028, 'total_duration': 797.9065113067627, 'accumulated_submission_time': 12.463748216629028, 'accumulated_eval_time': 785.4427063465118, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (178, {'train/loss': 0.12972166206476823, 'validation/loss': 0.13009467129041644, 'validation/num_examples': 83274637, 'test/loss': 0.13289384288651315, 'test/num_examples': 95000000, 'score': 132.72535252571106, 'total_duration': 1465.9911518096924, 'accumulated_submission_time': 132.72535252571106, 'accumulated_eval_time': 1333.2372405529022, 'accumulated_logging_time': 0.023211002349853516, 'global_step': 178, 'preemption_count': 0}), (359, {'train/loss': 0.12913103350116023, 'validation/loss': 0.12782389862368898, 'validation/num_examples': 83274637, 'test/loss': 0.13052424591899672, 'test/num_examples': 95000000, 'score': 253.3798632621765, 'total_duration': 2130.6220512390137, 'accumulated_submission_time': 253.3798632621765, 'accumulated_eval_time': 1877.1873936653137, 'accumulated_logging_time': 0.04369211196899414, 'global_step': 359, 'preemption_count': 0}), (543, {'train/loss': 0.12666660237987087, 'validation/loss': 0.12746399982993922, 'validation/num_examples': 83274637, 'test/loss': 0.1301410346011513, 'test/num_examples': 95000000, 'score': 373.77349495887756, 'total_duration': 2818.4320437908173, 'accumulated_submission_time': 373.77349495887756, 'accumulated_eval_time': 2444.5771408081055, 'accumulated_logging_time': 0.06415295600891113, 'global_step': 543, 'preemption_count': 0}), (722, {'train/loss': 0.12666317867408008, 'validation/loss': 0.12734261444078707, 'validation/num_examples': 83274637, 'test/loss': 0.12973512195723685, 'test/num_examples': 95000000, 'score': 494.456018447876, 'total_duration': 3438.876784324646, 'accumulated_submission_time': 494.456018447876, 'accumulated_eval_time': 2944.3139193058014, 'accumulated_logging_time': 0.08374547958374023, 'global_step': 722, 'preemption_count': 0}), (900, {'train/loss': 0.12707647404768183, 'validation/loss': 0.12655150584370004, 'validation/num_examples': 83274637, 'test/loss': 0.12908926797902961, 'test/num_examples': 95000000, 'score': 615.0073156356812, 'total_duration': 3989.5051074028015, 'accumulated_submission_time': 615.0073156356812, 'accumulated_eval_time': 3374.3627943992615, 'accumulated_logging_time': 0.10592293739318848, 'global_step': 900, 'preemption_count': 0}), (1076, {'train/loss': 0.12514109080130198, 'validation/loss': 0.12633680005188735, 'validation/num_examples': 83274637, 'test/loss': 0.1289586296669408, 'test/num_examples': 95000000, 'score': 735.4950034618378, 'total_duration': 4426.981655359268, 'accumulated_submission_time': 735.4950034618378, 'accumulated_eval_time': 3691.323450565338, 'accumulated_logging_time': 0.12826871871948242, 'global_step': 1076, 'preemption_count': 0}), (1250, {'train/loss': 0.12746330945746703, 'validation/loss': 0.12617320774654053, 'validation/num_examples': 83274637, 'test/loss': 0.12867232193667763, 'test/num_examples': 95000000, 'score': 855.9807455539703, 'total_duration': 4664.579290390015, 'accumulated_submission_time': 855.9807455539703, 'accumulated_eval_time': 3808.4084117412567, 'accumulated_logging_time': 0.14899110794067383, 'global_step': 1250, 'preemption_count': 0}), (1419, {'train/loss': 0.12514298999646925, 'validation/loss': 0.12673185135551837, 'validation/num_examples': 83274637, 'test/loss': 0.12964904058388158, 'test/num_examples': 95000000, 'score': 976.6953589916229, 'total_duration': 4904.199893951416, 'accumulated_submission_time': 976.6953589916229, 'accumulated_eval_time': 3927.287402868271, 'accumulated_logging_time': 0.16984343528747559, 'global_step': 1419, 'preemption_count': 0}), (1593, {'train/loss': 0.12468031367415902, 'validation/loss': 0.1260833680611691, 'validation/num_examples': 83274637, 'test/loss': 0.12859175012335528, 'test/num_examples': 95000000, 'score': 1096.9748780727386, 'total_duration': 5142.452356338501, 'accumulated_submission_time': 1096.9748780727386, 'accumulated_eval_time': 4045.228600502014, 'accumulated_logging_time': 0.19536876678466797, 'global_step': 1593, 'preemption_count': 0}), (1761, {'train/loss': 0.12356892092235433, 'validation/loss': 0.12625780452028568, 'validation/num_examples': 83274637, 'test/loss': 0.12865952563733551, 'test/num_examples': 95000000, 'score': 1217.0965530872345, 'total_duration': 5379.471857070923, 'accumulated_submission_time': 1217.0965530872345, 'accumulated_eval_time': 4162.097407817841, 'accumulated_logging_time': 0.21833038330078125, 'global_step': 1761, 'preemption_count': 0}), (1931, {'train/loss': 0.12435986865429008, 'validation/loss': 0.1259153654619053, 'validation/num_examples': 83274637, 'test/loss': 0.12835864148848683, 'test/num_examples': 95000000, 'score': 1337.7251658439636, 'total_duration': 5643.682898283005, 'accumulated_submission_time': 1337.7251658439636, 'accumulated_eval_time': 4305.653298139572, 'accumulated_logging_time': 0.23879551887512207, 'global_step': 1931, 'preemption_count': 0}), (2100, {'train/loss': 0.12291426370916127, 'validation/loss': 0.12586137594969343, 'validation/num_examples': 83274637, 'test/loss': 0.12820470434827302, 'test/num_examples': 95000000, 'score': 1457.8536732196808, 'total_duration': 5918.096968412399, 'accumulated_submission_time': 1457.8536732196808, 'accumulated_eval_time': 4459.907658815384, 'accumulated_logging_time': 0.26380491256713867, 'global_step': 2100, 'preemption_count': 0}), (2268, {'train/loss': 0.12382372782665228, 'validation/loss': 0.12559567760034188, 'validation/num_examples': 83274637, 'test/loss': 0.1280529490131579, 'test/num_examples': 95000000, 'score': 1578.0095241069794, 'total_duration': 6183.900935649872, 'accumulated_submission_time': 1578.0095241069794, 'accumulated_eval_time': 4605.528385639191, 'accumulated_logging_time': 0.2852022647857666, 'global_step': 2268, 'preemption_count': 0}), (2437, {'train/loss': 0.12344658609081365, 'validation/loss': 0.1252855585567578, 'validation/num_examples': 83274637, 'test/loss': 0.12775793227796053, 'test/num_examples': 95000000, 'score': 1698.187510251999, 'total_duration': 6457.8352127075195, 'accumulated_submission_time': 1698.187510251999, 'accumulated_eval_time': 4759.258464574814, 'accumulated_logging_time': 0.3052043914794922, 'global_step': 2437, 'preemption_count': 0}), (2604, {'train/loss': 0.12235508592061277, 'validation/loss': 0.12559572385166926, 'validation/num_examples': 83274637, 'test/loss': 0.12788993839432566, 'test/num_examples': 95000000, 'score': 1818.5135910511017, 'total_duration': 6725.854421854019, 'accumulated_submission_time': 1818.5135910511017, 'accumulated_eval_time': 4906.920119047165, 'accumulated_logging_time': 0.33057355880737305, 'global_step': 2604, 'preemption_count': 0}), (2772, {'train/loss': 0.12496458706240984, 'validation/loss': 0.1255404939970648, 'validation/num_examples': 83274637, 'test/loss': 0.1280375599300987, 'test/num_examples': 95000000, 'score': 1938.6138694286346, 'total_duration': 7001.023332118988, 'accumulated_submission_time': 1938.6138694286346, 'accumulated_eval_time': 5061.959703922272, 'accumulated_logging_time': 0.35356807708740234, 'global_step': 2772, 'preemption_count': 0}), (2942, {'train/loss': 0.12410197472609814, 'validation/loss': 0.12552293270578893, 'validation/num_examples': 83274637, 'test/loss': 0.12787568303865132, 'test/num_examples': 95000000, 'score': 2059.7532625198364, 'total_duration': 7274.913640975952, 'accumulated_submission_time': 2059.7532625198364, 'accumulated_eval_time': 5214.683004617691, 'accumulated_logging_time': 0.37507033348083496, 'global_step': 2942, 'preemption_count': 0}), (3114, {'train/loss': 0.12383935000724013, 'validation/loss': 0.12532131922937711, 'validation/num_examples': 83274637, 'test/loss': 0.12779071351768093, 'test/num_examples': 95000000, 'score': 2180.626472234726, 'total_duration': 7545.171762943268, 'accumulated_submission_time': 2180.626472234726, 'accumulated_eval_time': 5364.038871049881, 'accumulated_logging_time': 0.39807891845703125, 'global_step': 3114, 'preemption_count': 0}), (3280, {'train/loss': 0.12438426541644822, 'validation/loss': 0.1253703843824621, 'validation/num_examples': 83274637, 'test/loss': 0.12783062663445724, 'test/num_examples': 95000000, 'score': 2301.02455163002, 'total_duration': 7815.312426805496, 'accumulated_submission_time': 2301.02455163002, 'accumulated_eval_time': 5513.755568742752, 'accumulated_logging_time': 0.41811585426330566, 'global_step': 3280, 'preemption_count': 0}), (3458, {'train/loss': 0.12323650853626383, 'validation/loss': 0.12526828420196237, 'validation/num_examples': 83274637, 'test/loss': 0.1276778966899671, 'test/num_examples': 95000000, 'score': 2421.952827692032, 'total_duration': 8086.93297958374, 'accumulated_submission_time': 2421.952827692032, 'accumulated_eval_time': 5664.419347047806, 'accumulated_logging_time': 0.44020652770996094, 'global_step': 3458, 'preemption_count': 0}), (3626, {'train/loss': 0.12427422404289246, 'validation/loss': 0.12501321329123596, 'validation/num_examples': 83274637, 'test/loss': 0.12738409165296052, 'test/num_examples': 95000000, 'score': 2542.134447813034, 'total_duration': 8353.920348882675, 'accumulated_submission_time': 2542.134447813034, 'accumulated_eval_time': 5811.194124698639, 'accumulated_logging_time': 0.4652845859527588, 'global_step': 3626, 'preemption_count': 0}), (3795, {'train/loss': 0.12421559429955932, 'validation/loss': 0.12497962422632655, 'validation/num_examples': 83274637, 'test/loss': 0.12749173812705591, 'test/num_examples': 95000000, 'score': 2662.538522720337, 'total_duration': 8614.375497341156, 'accumulated_submission_time': 2662.538522720337, 'accumulated_eval_time': 5951.215406179428, 'accumulated_logging_time': 0.48896265029907227, 'global_step': 3795, 'preemption_count': 0}), (3963, {'train/loss': 0.12156705647332114, 'validation/loss': 0.1251213023150134, 'validation/num_examples': 83274637, 'test/loss': 0.12746999868421052, 'test/num_examples': 95000000, 'score': 2782.567374229431, 'total_duration': 8877.751650094986, 'accumulated_submission_time': 2782.567374229431, 'accumulated_eval_time': 6094.535807847977, 'accumulated_logging_time': 0.5098962783813477, 'global_step': 3963, 'preemption_count': 0}), (4134, {'train/loss': 0.12260949063413548, 'validation/loss': 0.12473233732956711, 'validation/num_examples': 83274637, 'test/loss': 0.12714995966282894, 'test/num_examples': 95000000, 'score': 2902.959949016571, 'total_duration': 9139.23431301117, 'accumulated_submission_time': 2902.959949016571, 'accumulated_eval_time': 6235.5994119644165, 'accumulated_logging_time': 0.5304808616638184, 'global_step': 4134, 'preemption_count': 0}), (4303, {'train/loss': 0.12201463988741988, 'validation/loss': 0.12499313613414491, 'validation/num_examples': 83274637, 'test/loss': 0.12736128972039473, 'test/num_examples': 95000000, 'score': 3023.275255918503, 'total_duration': 9408.028228521347, 'accumulated_submission_time': 3023.275255918503, 'accumulated_eval_time': 6384.048043727875, 'accumulated_logging_time': 0.554480791091919, 'global_step': 4303, 'preemption_count': 0}), (4472, {'train/loss': 0.12322908728939932, 'validation/loss': 0.12478691328609454, 'validation/num_examples': 83274637, 'test/loss': 0.1272033984683388, 'test/num_examples': 95000000, 'score': 3143.8477489948273, 'total_duration': 9680.55193400383, 'accumulated_submission_time': 3143.8477489948273, 'accumulated_eval_time': 6535.971926212311, 'accumulated_logging_time': 0.5756454467773438, 'global_step': 4472, 'preemption_count': 0}), (4639, {'train/loss': 0.12251611391328415, 'validation/loss': 0.12496754212247421, 'validation/num_examples': 83274637, 'test/loss': 0.12741041692023025, 'test/num_examples': 95000000, 'score': 3264.3826990127563, 'total_duration': 9945.339216947556, 'accumulated_submission_time': 3264.3826990127563, 'accumulated_eval_time': 6680.196882486343, 'accumulated_logging_time': 0.5970909595489502, 'global_step': 4639, 'preemption_count': 0}), (4807, {'train/loss': 0.12112039646262643, 'validation/loss': 0.124504470548983, 'validation/num_examples': 83274637, 'test/loss': 0.12697430828536185, 'test/num_examples': 95000000, 'score': 3384.3856303691864, 'total_duration': 10214.643136262894, 'accumulated_submission_time': 3384.3856303691864, 'accumulated_eval_time': 6829.468868494034, 'accumulated_logging_time': 0.6201989650726318, 'global_step': 4807, 'preemption_count': 0}), (4974, {'train/loss': 0.12400955046122929, 'validation/loss': 0.12482571678944995, 'validation/num_examples': 83274637, 'test/loss': 0.12717721374383223, 'test/num_examples': 95000000, 'score': 3504.4920194149017, 'total_duration': 10480.780037641525, 'accumulated_submission_time': 3504.4920194149017, 'accumulated_eval_time': 6975.472341299057, 'accumulated_logging_time': 0.6412858963012695, 'global_step': 4974, 'preemption_count': 0}), (5146, {'train/loss': 0.1216374860151009, 'validation/loss': 0.12456851869292748, 'validation/num_examples': 83274637, 'test/loss': 0.1270187224506579, 'test/num_examples': 95000000, 'score': 3624.7433757781982, 'total_duration': 10744.748449802399, 'accumulated_submission_time': 3624.7433757781982, 'accumulated_eval_time': 7119.154141187668, 'accumulated_logging_time': 0.6703791618347168, 'global_step': 5146, 'preemption_count': 0}), (5314, {'train/loss': 0.1214827723660559, 'validation/loss': 0.12451223847349223, 'validation/num_examples': 83274637, 'test/loss': 0.12688801361019736, 'test/num_examples': 95000000, 'score': 3744.9651362895966, 'total_duration': 11013.633011102676, 'accumulated_submission_time': 3744.9651362895966, 'accumulated_eval_time': 7267.782253265381, 'accumulated_logging_time': 0.6989274024963379, 'global_step': 5314, 'preemption_count': 0}), (5481, {'train/loss': 0.12158618201999544, 'validation/loss': 0.12457275472347601, 'validation/num_examples': 83274637, 'test/loss': 0.12692426928453948, 'test/num_examples': 95000000, 'score': 3864.964122056961, 'total_duration': 11282.60345196724, 'accumulated_submission_time': 3864.964122056961, 'accumulated_eval_time': 7416.726633071899, 'accumulated_logging_time': 0.7201194763183594, 'global_step': 5481, 'preemption_count': 0}), (5649, {'train/loss': 0.12229999867062899, 'validation/loss': 0.12452694733376622, 'validation/num_examples': 83274637, 'test/loss': 0.12695782584292764, 'test/num_examples': 95000000, 'score': 3985.1487872600555, 'total_duration': 11556.09846830368, 'accumulated_submission_time': 3985.1487872600555, 'accumulated_eval_time': 7570.005583047867, 'accumulated_logging_time': 0.7455096244812012, 'global_step': 5649, 'preemption_count': 0}), (5816, {'train/loss': 0.1222322683945392, 'validation/loss': 0.12449116414528771, 'validation/num_examples': 83274637, 'test/loss': 0.1268896113178454, 'test/num_examples': 95000000, 'score': 4105.325268268585, 'total_duration': 11826.704360485077, 'accumulated_submission_time': 4105.325268268585, 'accumulated_eval_time': 7720.392364501953, 'accumulated_logging_time': 0.7821109294891357, 'global_step': 5816, 'preemption_count': 0}), (5985, {'train/loss': 0.12324640965499219, 'validation/loss': 0.1245282337867621, 'validation/num_examples': 83274637, 'test/loss': 0.12690423430304276, 'test/num_examples': 95000000, 'score': 4225.304925203323, 'total_duration': 12099.539812088013, 'accumulated_submission_time': 4225.304925203323, 'accumulated_eval_time': 7873.213907003403, 'accumulated_logging_time': 0.810250997543335, 'global_step': 5985, 'preemption_count': 0}), (6158, {'train/loss': 0.12403709024378338, 'validation/loss': 0.12437574714750783, 'validation/num_examples': 83274637, 'test/loss': 0.12671834671052631, 'test/num_examples': 95000000, 'score': 4345.639629602432, 'total_duration': 12379.085680246353, 'accumulated_submission_time': 4345.639629602432, 'accumulated_eval_time': 8032.393202543259, 'accumulated_logging_time': 0.8358597755432129, 'global_step': 6158, 'preemption_count': 0}), (6327, {'train/loss': 0.12292648331736619, 'validation/loss': 0.12440795115872136, 'validation/num_examples': 83274637, 'test/loss': 0.12683341616981908, 'test/num_examples': 95000000, 'score': 4466.122906446457, 'total_duration': 12652.46684384346, 'accumulated_submission_time': 4466.122906446457, 'accumulated_eval_time': 8185.258936405182, 'accumulated_logging_time': 0.8616881370544434, 'global_step': 6327, 'preemption_count': 0}), (6495, {'train/loss': 0.1232858456249507, 'validation/loss': 0.12428192407829108, 'validation/num_examples': 83274637, 'test/loss': 0.12667274971217105, 'test/num_examples': 95000000, 'score': 4586.589813709259, 'total_duration': 12916.967513561249, 'accumulated_submission_time': 4586.589813709259, 'accumulated_eval_time': 8329.26518535614, 'accumulated_logging_time': 0.8831233978271484, 'global_step': 6495, 'preemption_count': 0}), (6663, {'train/loss': 0.12298741224426893, 'validation/loss': 0.12432959381100335, 'validation/num_examples': 83274637, 'test/loss': 0.12669366120476974, 'test/num_examples': 95000000, 'score': 4706.579119205475, 'total_duration': 13191.312245368958, 'accumulated_submission_time': 4706.579119205475, 'accumulated_eval_time': 8483.591983318329, 'accumulated_logging_time': 0.9057960510253906, 'global_step': 6663, 'preemption_count': 0}), (6831, {'train/loss': 0.12245097381513824, 'validation/loss': 0.12426382479870492, 'validation/num_examples': 83274637, 'test/loss': 0.1267290832339638, 'test/num_examples': 95000000, 'score': 4826.638483047485, 'total_duration': 13462.37453508377, 'accumulated_submission_time': 4826.638483047485, 'accumulated_eval_time': 8634.56647825241, 'accumulated_logging_time': 0.928074836730957, 'global_step': 6831, 'preemption_count': 0}), (7001, {'train/loss': 0.12415364520542277, 'validation/loss': 0.12424506298996235, 'validation/num_examples': 83274637, 'test/loss': 0.12664624886924342, 'test/num_examples': 95000000, 'score': 4947.007377386093, 'total_duration': 13729.055393457413, 'accumulated_submission_time': 4947.007377386093, 'accumulated_eval_time': 8780.846737146378, 'accumulated_logging_time': 0.9535160064697266, 'global_step': 7001, 'preemption_count': 0}), (7168, {'train/loss': 0.12385529827959132, 'validation/loss': 0.12420977153846675, 'validation/num_examples': 83274637, 'test/loss': 0.12660329095394737, 'test/num_examples': 95000000, 'score': 5067.524134159088, 'total_duration': 14000.094252824783, 'accumulated_submission_time': 5067.524134159088, 'accumulated_eval_time': 8931.338992357254, 'accumulated_logging_time': 0.9774575233459473, 'global_step': 7168, 'preemption_count': 0}), (7341, {'train/loss': 0.12272485144108346, 'validation/loss': 0.12418553035466849, 'validation/num_examples': 83274637, 'test/loss': 0.12653958024259868, 'test/num_examples': 95000000, 'score': 5189.375959634781, 'total_duration': 14276.216595888138, 'accumulated_submission_time': 5189.375959634781, 'accumulated_eval_time': 9085.576388120651, 'accumulated_logging_time': 1.0043892860412598, 'global_step': 7341, 'preemption_count': 0}), (7509, {'train/loss': 0.12429889314954386, 'validation/loss': 0.12419371421276805, 'validation/num_examples': 83274637, 'test/loss': 0.1264799502055921, 'test/num_examples': 95000000, 'score': 5309.640488862991, 'total_duration': 14550.527242183685, 'accumulated_submission_time': 5309.640488862991, 'accumulated_eval_time': 9239.591262578964, 'accumulated_logging_time': 1.029554843902588, 'global_step': 7509, 'preemption_count': 0}), (7678, {'train/loss': 0.12327248842086432, 'validation/loss': 0.12415582443112301, 'validation/num_examples': 83274637, 'test/loss': 0.12650313391241777, 'test/num_examples': 95000000, 'score': 5429.801173686981, 'total_duration': 14822.394619703293, 'accumulated_submission_time': 5429.801173686981, 'accumulated_eval_time': 9391.265887260437, 'accumulated_logging_time': 1.055837869644165, 'global_step': 7678, 'preemption_count': 0}), (7845, {'train/loss': 0.12294240684816672, 'validation/loss': 0.12415016084819439, 'validation/num_examples': 83274637, 'test/loss': 0.1264902542763158, 'test/num_examples': 95000000, 'score': 5549.819905281067, 'total_duration': 15089.51276063919, 'accumulated_submission_time': 5549.819905281067, 'accumulated_eval_time': 9538.324207782745, 'accumulated_logging_time': 1.0907785892486572, 'global_step': 7845, 'preemption_count': 0}), (8014, {'train/loss': 0.12373550737616401, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5670.167506933212, 'total_duration': 15356.767590045929, 'accumulated_submission_time': 5670.167506933212, 'accumulated_eval_time': 9685.184237003326, 'accumulated_logging_time': 1.1316077709197998, 'global_step': 8014, 'preemption_count': 0}), (8182, {'train/loss': 0.12317854287864277, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5790.645438909531, 'total_duration': 15622.824906349182, 'accumulated_submission_time': 5790.645438909531, 'accumulated_eval_time': 9830.735363721848, 'accumulated_logging_time': 1.1536240577697754, 'global_step': 8182, 'preemption_count': 0}), (8358, {'train/loss': 0.12266260690096789, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 5911.111374616623, 'total_duration': 15886.657624959946, 'accumulated_submission_time': 5911.111374616623, 'accumulated_eval_time': 9974.06777882576, 'accumulated_logging_time': 1.1816885471343994, 'global_step': 8358, 'preemption_count': 0}), (8525, {'train/loss': 0.1230050394744993, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6031.302855491638, 'total_duration': 16159.722524166107, 'accumulated_submission_time': 6031.302855491638, 'accumulated_eval_time': 10126.901505231857, 'accumulated_logging_time': 1.215198278427124, 'global_step': 8525, 'preemption_count': 0}), (8698, {'train/loss': 0.12306827578529622, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6151.641670703888, 'total_duration': 16428.777859210968, 'accumulated_submission_time': 6151.641670703888, 'accumulated_eval_time': 10275.583359003067, 'accumulated_logging_time': 1.2436904907226562, 'global_step': 8698, 'preemption_count': 0}), (8866, {'train/loss': 0.12137633557402112, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6272.504487037659, 'total_duration': 16693.407087802887, 'accumulated_submission_time': 6272.504487037659, 'accumulated_eval_time': 10419.314430713654, 'accumulated_logging_time': 1.2728030681610107, 'global_step': 8866, 'preemption_count': 0}), (9034, {'train/loss': 0.12406195531476219, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6392.61322593689, 'total_duration': 16964.358067512512, 'accumulated_submission_time': 6392.61322593689, 'accumulated_eval_time': 10570.120740175247, 'accumulated_logging_time': 1.3025922775268555, 'global_step': 9034, 'preemption_count': 0}), (9205, {'train/loss': 0.12276238629465583, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6512.768201589584, 'total_duration': 17238.562821626663, 'accumulated_submission_time': 6512.768201589584, 'accumulated_eval_time': 10724.140794038773, 'accumulated_logging_time': 1.3262543678283691, 'global_step': 9205, 'preemption_count': 0}), (9374, {'train/loss': 0.12516544623382436, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6633.006072282791, 'total_duration': 17526.677567481995, 'accumulated_submission_time': 6633.006072282791, 'accumulated_eval_time': 10891.98603773117, 'accumulated_logging_time': 1.3516933917999268, 'global_step': 9374, 'preemption_count': 0}), (9542, {'train/loss': 0.12364970470936794, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6753.363312005997, 'total_duration': 17793.382875919342, 'accumulated_submission_time': 6753.363312005997, 'accumulated_eval_time': 11038.299199104309, 'accumulated_logging_time': 1.380382776260376, 'global_step': 9542, 'preemption_count': 0}), (9713, {'train/loss': 0.12310819004504185, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6873.578608512878, 'total_duration': 18067.38759803772, 'accumulated_submission_time': 6873.578608512878, 'accumulated_eval_time': 11192.059101104736, 'accumulated_logging_time': 1.4035840034484863, 'global_step': 9713, 'preemption_count': 0}), (9890, {'train/loss': 0.12173471745080168, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 6994.200517654419, 'total_duration': 18338.21062350273, 'accumulated_submission_time': 6994.200517654419, 'accumulated_eval_time': 11342.230197906494, 'accumulated_logging_time': 1.427201509475708, 'global_step': 9890, 'preemption_count': 0}), (10062, {'train/loss': 0.12331624024506635, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7114.3279457092285, 'total_duration': 18604.76394534111, 'accumulated_submission_time': 7114.3279457092285, 'accumulated_eval_time': 11488.62471985817, 'accumulated_logging_time': 1.4524385929107666, 'global_step': 10062, 'preemption_count': 0}), (10230, {'train/loss': 0.12539913823956964, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7234.665671348572, 'total_duration': 18879.880497932434, 'accumulated_submission_time': 7234.665671348572, 'accumulated_eval_time': 11643.362159490585, 'accumulated_logging_time': 1.4875414371490479, 'global_step': 10230, 'preemption_count': 0}), (10397, {'train/loss': 0.1233795684932163, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7355.112859010696, 'total_duration': 19151.282508134842, 'accumulated_submission_time': 7355.112859010696, 'accumulated_eval_time': 11794.279506921768, 'accumulated_logging_time': 1.51881742477417, 'global_step': 10397, 'preemption_count': 0}), (10564, {'train/loss': 0.12469538334030775, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7476.037807941437, 'total_duration': 19421.51701927185, 'accumulated_submission_time': 7476.037807941437, 'accumulated_eval_time': 11943.559185504913, 'accumulated_logging_time': 1.5425903797149658, 'global_step': 10564, 'preemption_count': 0}), (10666, {'train/loss': 0.12427277089852207, 'validation/loss': 0.12414909232995215, 'validation/num_examples': 83274637, 'test/loss': 0.12648996437088816, 'test/num_examples': 95000000, 'score': 7541.851372003555, 'total_duration': 19687.02222943306, 'accumulated_submission_time': 7541.851372003555, 'accumulated_eval_time': 12143.223886013031, 'accumulated_logging_time': 1.5656373500823975, 'global_step': 10666, 'preemption_count': 0})], 'global_step': 10666}
I0306 11:09:01.945183 140589014792000 submission_runner.py:591] Timing: 7541.851372003555
I0306 11:09:01.945234 140589014792000 submission_runner.py:593] Total number of evals: 64
I0306 11:09:01.945279 140589014792000 submission_runner.py:594] ====================
I0306 11:09:01.945434 140589014792000 submission_runner.py:678] Final criteo1tb_resnet score: 7541.851372003555

python3 submission_runner.py --framework=jax --workload=criteo1tb_embed_init --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/criteo1tb --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=2465481527 --max_global_steps=10666 --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/criteo1tb_embed_init/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/criteo1tb_embed_init_jax_03-06-2024-00-04-16.log
I0306 00:04:35.483720 139827085571904 logger_utils.py:61] Removing existing experiment directory /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax because --overwrite was set.
I0306 00:04:35.485039 139827085571904 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax.
I0306 00:04:37.079022 139827085571904 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I0306 00:04:37.079854 139827085571904 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0306 00:04:37.080022 139827085571904 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0306 00:04:37.086128 139827085571904 submission_runner.py:547] Using RNG seed 2465481527
I0306 00:04:38.100345 139827085571904 submission_runner.py:556] --- Tuning run 1/1 ---
I0306 00:04:38.100533 139827085571904 submission_runner.py:561] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1.
I0306 00:04:38.100697 139827085571904 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1/hparams.json.
I0306 00:04:38.279182 139827085571904 submission_runner.py:206] Initializing dataset.
I0306 00:04:38.279380 139827085571904 submission_runner.py:213] Initializing model.
I0306 00:04:43.679015 139827085571904 submission_runner.py:255] Initializing optimizer.
I0306 00:04:46.545466 139827085571904 submission_runner.py:262] Initializing metrics bundle.
I0306 00:04:46.545704 139827085571904 submission_runner.py:280] Initializing checkpoint and logger.
I0306 00:04:46.547081 139827085571904 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1 with prefix checkpoint_
I0306 00:04:46.547226 139827085571904 submission_runner.py:300] Saving meta data to /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1/meta_data_0.json.
I0306 00:04:46.547414 139827085571904 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0306 00:04:46.547475 139827085571904 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0306 00:04:46.800390 139827085571904 logger_utils.py:220] Unable to record git information. Continuing without it.
I0306 00:04:47.036156 139827085571904 submission_runner.py:304] Saving flags to /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1/flags_0.json.
I0306 00:04:47.128721 139827085571904 submission_runner.py:314] Starting training loop.
I0306 00:05:07.212798 139665802774272 logging_writer.py:48] [0] global_step=0, grad_norm=516.7490844726562, loss=6.097844123840332
I0306 00:05:07.223977 139827085571904 spec.py:321] Evaluating on the training split.
I0306 00:09:17.809067 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 00:13:26.164574 139827085571904 spec.py:349] Evaluating on the test split.
I0306 00:18:09.252247 139827085571904 submission_runner.py:413] Time since start: 802.12s, 	Step: 1, 	{'train/loss': 6.109228727952489, 'validation/loss': 6.167542957887646, 'validation/num_examples': 83274637, 'test/loss': 6.0549652388157895, 'test/num_examples': 95000000, 'score': 20.095224142074585, 'total_duration': 802.123473405838, 'accumulated_submission_time': 20.095224142074585, 'accumulated_eval_time': 782.0281999111176, 'accumulated_logging_time': 0}
I0306 00:18:09.268562 139646180759296 logging_writer.py:48] [1] accumulated_eval_time=782.028200, accumulated_logging_time=0, accumulated_submission_time=20.095224, global_step=1, preemption_count=0, score=20.095224, test/loss=6.054965, test/num_examples=95000000, total_duration=802.123473, train/loss=6.109229, validation/loss=6.167543, validation/num_examples=83274637
I0306 00:18:09.382597 139645962680064 logging_writer.py:48] [1] global_step=1, grad_norm=516.5078735351562, loss=6.098535537719727
I0306 00:18:09.488687 139646180759296 logging_writer.py:48] [2] global_step=2, grad_norm=516.3818359375, loss=4.829626560211182
I0306 00:18:09.593283 139645962680064 logging_writer.py:48] [3] global_step=3, grad_norm=480.20880126953125, loss=2.6128933429718018
I0306 00:18:09.695520 139646180759296 logging_writer.py:48] [4] global_step=4, grad_norm=170.25448608398438, loss=0.47416242957115173
I0306 00:18:09.798280 139645962680064 logging_writer.py:48] [5] global_step=5, grad_norm=10.324518203735352, loss=0.1668008714914322
I0306 00:18:09.900503 139646180759296 logging_writer.py:48] [6] global_step=6, grad_norm=18.06536865234375, loss=0.2775881290435791
I0306 00:18:10.002866 139645962680064 logging_writer.py:48] [7] global_step=7, grad_norm=18.30626678466797, loss=0.41954874992370605
I0306 00:18:10.105680 139646180759296 logging_writer.py:48] [8] global_step=8, grad_norm=17.746036529541016, loss=0.5522347092628479
I0306 00:18:10.208878 139645962680064 logging_writer.py:48] [9] global_step=9, grad_norm=17.757789611816406, loss=0.6947831511497498
I0306 00:18:10.312015 139646180759296 logging_writer.py:48] [10] global_step=10, grad_norm=17.853635787963867, loss=0.8393881320953369
I0306 00:18:10.415279 139645962680064 logging_writer.py:48] [11] global_step=11, grad_norm=17.527236938476562, loss=0.9630863666534424
I0306 00:18:10.518565 139646180759296 logging_writer.py:48] [12] global_step=12, grad_norm=17.485441207885742, loss=1.0926663875579834
I0306 00:18:10.624750 139645962680064 logging_writer.py:48] [13] global_step=13, grad_norm=17.888452529907227, loss=1.2389355897903442
I0306 00:18:10.729335 139646180759296 logging_writer.py:48] [14] global_step=14, grad_norm=17.615949630737305, loss=1.3426986932754517
I0306 00:18:10.833905 139645962680064 logging_writer.py:48] [15] global_step=15, grad_norm=18.165611267089844, loss=1.509902000427246
I0306 00:18:10.937318 139646180759296 logging_writer.py:48] [16] global_step=16, grad_norm=17.885784149169922, loss=1.5975816249847412
I0306 00:18:11.039970 139645962680064 logging_writer.py:48] [17] global_step=17, grad_norm=17.560997009277344, loss=1.6694689989089966
I0306 00:18:11.142570 139646180759296 logging_writer.py:48] [18] global_step=18, grad_norm=17.87299156188965, loss=1.7984763383865356
I0306 00:18:11.245648 139645962680064 logging_writer.py:48] [19] global_step=19, grad_norm=16.756338119506836, loss=1.7531299591064453
I0306 00:18:11.348468 139646180759296 logging_writer.py:48] [20] global_step=20, grad_norm=16.671777725219727, loss=1.7822932004928589
I0306 00:18:11.451385 139645962680064 logging_writer.py:48] [21] global_step=21, grad_norm=17.04622459411621, loss=1.8423644304275513
I0306 00:18:11.554476 139646180759296 logging_writer.py:48] [22] global_step=22, grad_norm=16.956178665161133, loss=1.8329836130142212
I0306 00:18:11.661919 139645962680064 logging_writer.py:48] [23] global_step=23, grad_norm=17.356868743896484, loss=1.8694539070129395
I0306 00:18:11.765554 139646180759296 logging_writer.py:48] [24] global_step=24, grad_norm=17.625192642211914, loss=1.8782310485839844
I0306 00:18:11.869199 139645962680064 logging_writer.py:48] [25] global_step=25, grad_norm=17.26377296447754, loss=1.8069489002227783
I0306 00:18:11.972018 139646180759296 logging_writer.py:48] [26] global_step=26, grad_norm=17.289030075073242, loss=1.763590693473816
I0306 00:18:12.074882 139645962680064 logging_writer.py:48] [27] global_step=27, grad_norm=17.62615203857422, loss=1.7414026260375977
I0306 00:18:12.542619 139646180759296 logging_writer.py:48] [28] global_step=28, grad_norm=17.39624786376953, loss=1.6588196754455566
I0306 00:18:13.172055 139645962680064 logging_writer.py:48] [29] global_step=29, grad_norm=17.494918823242188, loss=1.6122714281082153
I0306 00:18:14.009079 139646180759296 logging_writer.py:48] [30] global_step=30, grad_norm=17.828908920288086, loss=1.5737998485565186
I0306 00:18:14.975187 139645962680064 logging_writer.py:48] [31] global_step=31, grad_norm=17.816009521484375, loss=1.4839820861816406
I0306 00:18:15.717092 139646180759296 logging_writer.py:48] [32] global_step=32, grad_norm=17.82805061340332, loss=1.3830022811889648
I0306 00:18:16.383546 139645962680064 logging_writer.py:48] [33] global_step=33, grad_norm=18.25649642944336, loss=1.2930876016616821
I0306 00:18:17.208469 139646180759296 logging_writer.py:48] [34] global_step=34, grad_norm=17.98113441467285, loss=1.1518055200576782
I0306 00:18:18.226192 139645962680064 logging_writer.py:48] [35] global_step=35, grad_norm=17.621755599975586, loss=1.0377106666564941
I0306 00:18:18.953716 139646180759296 logging_writer.py:48] [36] global_step=36, grad_norm=18.078683853149414, loss=0.9328262805938721
I0306 00:18:19.812230 139645962680064 logging_writer.py:48] [37] global_step=37, grad_norm=18.043333053588867, loss=0.7891817688941956
I0306 00:18:20.637767 139646180759296 logging_writer.py:48] [38] global_step=38, grad_norm=18.364503860473633, loss=0.6458150148391724
I0306 00:18:21.508689 139645962680064 logging_writer.py:48] [39] global_step=39, grad_norm=18.558000564575195, loss=0.4813143312931061
I0306 00:18:22.277114 139646180759296 logging_writer.py:48] [40] global_step=40, grad_norm=18.882225036621094, loss=0.30444827675819397
I0306 00:18:23.108032 139645962680064 logging_writer.py:48] [41] global_step=41, grad_norm=3.264328718185425, loss=0.14933735132217407
I0306 00:18:23.847042 139646180759296 logging_writer.py:48] [42] global_step=42, grad_norm=499.361083984375, loss=1.9016956090927124
I0306 00:18:24.633956 139645962680064 logging_writer.py:48] [43] global_step=43, grad_norm=14.967110633850098, loss=0.16891182959079742
I0306 00:18:25.422785 139646180759296 logging_writer.py:48] [44] global_step=44, grad_norm=19.489763259887695, loss=0.25314003229141235
I0306 00:18:26.221320 139645962680064 logging_writer.py:48] [45] global_step=45, grad_norm=20.57688331604004, loss=0.35138195753097534
I0306 00:18:27.034462 139646180759296 logging_writer.py:48] [46] global_step=46, grad_norm=20.536632537841797, loss=0.43279513716697693
I0306 00:18:27.820398 139645962680064 logging_writer.py:48] [47] global_step=47, grad_norm=20.698272705078125, loss=0.5126926302909851
I0306 00:18:28.613660 139646180759296 logging_writer.py:48] [48] global_step=48, grad_norm=21.02029800415039, loss=0.5910437703132629
I0306 00:18:29.511502 139645962680064 logging_writer.py:48] [49] global_step=49, grad_norm=21.02304458618164, loss=0.6541057825088501
I0306 00:18:30.275630 139646180759296 logging_writer.py:48] [50] global_step=50, grad_norm=21.105941772460938, loss=0.7122334241867065
I0306 00:18:30.948344 139645962680064 logging_writer.py:48] [51] global_step=51, grad_norm=21.44566535949707, loss=0.7735332250595093
I0306 00:18:31.759087 139646180759296 logging_writer.py:48] [52] global_step=52, grad_norm=21.893009185791016, loss=0.8301194906234741
I0306 00:18:32.621405 139645962680064 logging_writer.py:48] [53] global_step=53, grad_norm=23.133150100708008, loss=0.9103114008903503
I0306 00:18:33.276936 139646180759296 logging_writer.py:48] [54] global_step=54, grad_norm=25.09583854675293, loss=1.0123820304870605
I0306 00:18:34.242128 139645962680064 logging_writer.py:48] [55] global_step=55, grad_norm=24.82361602783203, loss=1.0175299644470215
I0306 00:18:34.908064 139646180759296 logging_writer.py:48] [56] global_step=56, grad_norm=25.80775260925293, loss=1.0635970830917358
I0306 00:18:35.666393 139645962680064 logging_writer.py:48] [57] global_step=57, grad_norm=25.210540771484375, loss=1.0316611528396606
I0306 00:18:36.480636 139646180759296 logging_writer.py:48] [58] global_step=58, grad_norm=26.139965057373047, loss=1.0518251657485962
I0306 00:18:37.344702 139645962680064 logging_writer.py:48] [59] global_step=59, grad_norm=26.352022171020508, loss=1.0291908979415894
I0306 00:18:38.401551 139646180759296 logging_writer.py:48] [60] global_step=60, grad_norm=27.4852352142334, loss=1.023140549659729
I0306 00:18:39.071256 139645962680064 logging_writer.py:48] [61] global_step=61, grad_norm=27.98398780822754, loss=0.977035641670227
I0306 00:18:39.803799 139646180759296 logging_writer.py:48] [62] global_step=62, grad_norm=28.199405670166016, loss=0.9044374823570251
I0306 00:18:40.747613 139645962680064 logging_writer.py:48] [63] global_step=63, grad_norm=28.869565963745117, loss=0.8286904096603394
I0306 00:18:41.546030 139646180759296 logging_writer.py:48] [64] global_step=64, grad_norm=29.099185943603516, loss=0.7269311547279358
I0306 00:18:42.301258 139645962680064 logging_writer.py:48] [65] global_step=65, grad_norm=29.76829719543457, loss=0.6241589188575745
I0306 00:18:43.017029 139646180759296 logging_writer.py:48] [66] global_step=66, grad_norm=29.85430335998535, loss=0.48425987362861633
I0306 00:18:43.722961 139645962680064 logging_writer.py:48] [67] global_step=67, grad_norm=31.154054641723633, loss=0.3413657546043396
I0306 00:18:44.601106 139646180759296 logging_writer.py:48] [68] global_step=68, grad_norm=16.049129486083984, loss=0.17592813074588776
I0306 00:18:45.492153 139645962680064 logging_writer.py:48] [69] global_step=69, grad_norm=538.4461669921875, loss=1.1870497465133667
I0306 00:18:46.195631 139646180759296 logging_writer.py:48] [70] global_step=70, grad_norm=30.239646911621094, loss=0.25425633788108826
I0306 00:18:47.139888 139645962680064 logging_writer.py:48] [71] global_step=71, grad_norm=32.017459869384766, loss=0.3439784348011017
I0306 00:18:47.811622 139646180759296 logging_writer.py:48] [72] global_step=72, grad_norm=32.545169830322266, loss=0.4225199818611145
I0306 00:18:48.664774 139645962680064 logging_writer.py:48] [73] global_step=73, grad_norm=31.08759880065918, loss=0.4626971483230591
I0306 00:18:49.304537 139646180759296 logging_writer.py:48] [74] global_step=74, grad_norm=31.931623458862305, loss=0.5254627466201782
I0306 00:18:50.125564 139645962680064 logging_writer.py:48] [75] global_step=75, grad_norm=31.950620651245117, loss=0.5639941096305847
I0306 00:18:50.925947 139646180759296 logging_writer.py:48] [76] global_step=76, grad_norm=32.88936996459961, loss=0.6078606247901917
I0306 00:18:51.583871 139645962680064 logging_writer.py:48] [77] global_step=77, grad_norm=33.3443717956543, loss=0.6310637593269348
I0306 00:18:52.356801 139646180759296 logging_writer.py:48] [78] global_step=78, grad_norm=33.9566650390625, loss=0.644352912902832
I0306 00:18:53.170698 139645962680064 logging_writer.py:48] [79] global_step=79, grad_norm=34.28578186035156, loss=0.6385711431503296
I0306 00:18:53.971706 139646180759296 logging_writer.py:48] [80] global_step=80, grad_norm=34.382423400878906, loss=0.6143901348114014
I0306 00:18:54.704615 139645962680064 logging_writer.py:48] [81] global_step=81, grad_norm=35.38182067871094, loss=0.590865969657898
I0306 00:18:55.355829 139646180759296 logging_writer.py:48] [82] global_step=82, grad_norm=34.67005157470703, loss=0.5239368677139282
I0306 00:18:56.159447 139645962680064 logging_writer.py:48] [83] global_step=83, grad_norm=35.369140625, loss=0.4645903706550598
I0306 00:18:57.047299 139646180759296 logging_writer.py:48] [84] global_step=84, grad_norm=35.562076568603516, loss=0.3820359706878662
I0306 00:18:57.717857 139645962680064 logging_writer.py:48] [85] global_step=85, grad_norm=35.22426223754883, loss=0.28365767002105713
I0306 00:18:58.456141 139646180759296 logging_writer.py:48] [86] global_step=86, grad_norm=26.790935516357422, loss=0.18037474155426025
I0306 00:18:59.269157 139645962680064 logging_writer.py:48] [87] global_step=87, grad_norm=177.19735717773438, loss=0.2897792160511017
I0306 00:18:59.903949 139646180759296 logging_writer.py:48] [88] global_step=88, grad_norm=25.471660614013672, loss=0.16311857104301453
I0306 00:19:00.718010 139645962680064 logging_writer.py:48] [89] global_step=89, grad_norm=30.089170455932617, loss=0.16613076627254486
I0306 00:19:01.716931 139646180759296 logging_writer.py:48] [90] global_step=90, grad_norm=9.537077903747559, loss=0.15546733140945435
I0306 00:19:02.436118 139645962680064 logging_writer.py:48] [91] global_step=91, grad_norm=6.004272937774658, loss=0.15599927306175232
I0306 00:19:03.399273 139646180759296 logging_writer.py:48] [92] global_step=92, grad_norm=4.013781547546387, loss=0.15113845467567444
I0306 00:19:04.008765 139645962680064 logging_writer.py:48] [93] global_step=93, grad_norm=3.0210132598876953, loss=0.1509566605091095
I0306 00:19:04.747952 139646180759296 logging_writer.py:48] [94] global_step=94, grad_norm=1.770848035812378, loss=0.14847519993782043
I0306 00:19:05.602670 139645962680064 logging_writer.py:48] [95] global_step=95, grad_norm=1.8089320659637451, loss=0.14873212575912476
I0306 00:19:06.162396 139646180759296 logging_writer.py:48] [96] global_step=96, grad_norm=1.6450308561325073, loss=0.14977149665355682
I0306 00:19:06.973613 139645962680064 logging_writer.py:48] [97] global_step=97, grad_norm=0.8806089162826538, loss=0.14844386279582977
I0306 00:19:07.641223 139646180759296 logging_writer.py:48] [98] global_step=98, grad_norm=0.7820650935173035, loss=0.14820365607738495
I0306 00:19:08.454238 139645962680064 logging_writer.py:48] [99] global_step=99, grad_norm=1.4076364040374756, loss=0.14565694332122803
I0306 00:19:09.178624 139646180759296 logging_writer.py:48] [100] global_step=100, grad_norm=2.31968355178833, loss=0.14811468124389648
I0306 00:20:09.395287 139827085571904 spec.py:321] Evaluating on the training split.
I0306 00:23:32.416315 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 00:26:11.202459 139827085571904 spec.py:349] Evaluating on the test split.
I0306 00:29:25.720761 139827085571904 submission_runner.py:413] Time since start: 1478.59s, 	Step: 181, 	{'train/loss': 1.0292331924978293, 'validation/loss': 1.0355964892257652, 'validation/num_examples': 83274637, 'test/loss': 1.0667826981085526, 'test/num_examples': 95000000, 'score': 140.2082736492157, 'total_duration': 1478.591975927353, 'accumulated_submission_time': 140.2082736492157, 'accumulated_eval_time': 1338.3536128997803, 'accumulated_logging_time': 0.025177478790283203}
I0306 00:29:25.734112 139645962680064 logging_writer.py:48] [181] accumulated_eval_time=1338.353613, accumulated_logging_time=0.025177, accumulated_submission_time=140.208274, global_step=181, preemption_count=0, score=140.208274, test/loss=1.066783, test/num_examples=95000000, total_duration=1478.591976, train/loss=1.029233, validation/loss=1.035596, validation/num_examples=83274637
I0306 00:31:26.048109 139827085571904 spec.py:321] Evaluating on the training split.
I0306 00:34:44.747347 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 00:37:20.037306 139827085571904 spec.py:349] Evaluating on the test split.
I0306 00:40:30.931129 139827085571904 submission_runner.py:413] Time since start: 2143.80s, 	Step: 360, 	{'train/loss': 0.14613674374871283, 'validation/loss': 0.14416453528041198, 'validation/num_examples': 83274637, 'test/loss': 0.1475941744037829, 'test/num_examples': 95000000, 'score': 260.5102393627167, 'total_duration': 2143.8023307323456, 'accumulated_submission_time': 260.5102393627167, 'accumulated_eval_time': 1883.2365686893463, 'accumulated_logging_time': 0.0453038215637207}
I0306 00:40:30.943959 139646180759296 logging_writer.py:48] [360] accumulated_eval_time=1883.236569, accumulated_logging_time=0.045304, accumulated_submission_time=260.510239, global_step=360, preemption_count=0, score=260.510239, test/loss=0.147594, test/num_examples=95000000, total_duration=2143.802331, train/loss=0.146137, validation/loss=0.144165, validation/num_examples=83274637
I0306 00:42:00.882879 139645962680064 logging_writer.py:48] [500] global_step=500, grad_norm=1.043931245803833, loss=0.13358564674854279
I0306 00:42:31.646642 139827085571904 spec.py:321] Evaluating on the training split.
I0306 00:45:43.069779 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 00:48:15.570456 139827085571904 spec.py:349] Evaluating on the test split.
I0306 00:51:22.909165 139827085571904 submission_runner.py:413] Time since start: 2795.78s, 	Step: 543, 	{'train/loss': 0.1408584550866541, 'validation/loss': 0.1370924884480433, 'validation/num_examples': 83274637, 'test/loss': 0.14047363409745064, 'test/num_examples': 95000000, 'score': 381.20074915885925, 'total_duration': 2795.7803695201874, 'accumulated_submission_time': 381.20074915885925, 'accumulated_eval_time': 2414.4990158081055, 'accumulated_logging_time': 0.06494522094726562}
I0306 00:51:22.926004 139646180759296 logging_writer.py:48] [543] accumulated_eval_time=2414.499016, accumulated_logging_time=0.064945, accumulated_submission_time=381.200749, global_step=543, preemption_count=0, score=381.200749, test/loss=0.140474, test/num_examples=95000000, total_duration=2795.780370, train/loss=0.140858, validation/loss=0.137092, validation/num_examples=83274637
I0306 00:53:22.958868 139827085571904 spec.py:321] Evaluating on the training split.
I0306 00:56:27.124154 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 00:58:50.003604 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:01:48.239787 139827085571904 submission_runner.py:413] Time since start: 3421.11s, 	Step: 719, 	{'train/loss': 0.1346092497777639, 'validation/loss': 0.13442303210670256, 'validation/num_examples': 83274637, 'test/loss': 0.1371794584189967, 'test/num_examples': 95000000, 'score': 501.219598531723, 'total_duration': 3421.111014842987, 'accumulated_submission_time': 501.219598531723, 'accumulated_eval_time': 2919.7799072265625, 'accumulated_logging_time': 0.0905008316040039}
I0306 01:01:48.253457 139645962680064 logging_writer.py:48] [719] accumulated_eval_time=2919.779907, accumulated_logging_time=0.090501, accumulated_submission_time=501.219599, global_step=719, preemption_count=0, score=501.219599, test/loss=0.137179, test/num_examples=95000000, total_duration=3421.111015, train/loss=0.134609, validation/loss=0.134423, validation/num_examples=83274637
I0306 01:03:48.863707 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:06:24.184530 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:08:29.423538 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:11:08.397009 139827085571904 submission_runner.py:413] Time since start: 3981.27s, 	Step: 898, 	{'train/loss': 0.13271532685689205, 'validation/loss': 0.13345795828866838, 'validation/num_examples': 83274637, 'test/loss': 0.13580814927014803, 'test/num_examples': 95000000, 'score': 621.8137724399567, 'total_duration': 3981.2682223320007, 'accumulated_submission_time': 621.8137724399567, 'accumulated_eval_time': 3359.313163995743, 'accumulated_logging_time': 0.1148374080657959}
I0306 01:11:08.410302 139646180759296 logging_writer.py:48] [898] accumulated_eval_time=3359.313164, accumulated_logging_time=0.114837, accumulated_submission_time=621.813772, global_step=898, preemption_count=0, score=621.813772, test/loss=0.135808, test/num_examples=95000000, total_duration=3981.268222, train/loss=0.132715, validation/loss=0.133458, validation/num_examples=83274637
I0306 01:12:11.135932 139645962680064 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.07762499898672104, loss=0.1342036873102188
I0306 01:13:09.097679 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:14:58.253314 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:16:28.731301 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:18:33.856422 139827085571904 submission_runner.py:413] Time since start: 4426.73s, 	Step: 1075, 	{'train/loss': 0.134810209133715, 'validation/loss': 0.13302400807072867, 'validation/num_examples': 83274637, 'test/loss': 0.13570753902138158, 'test/num_examples': 95000000, 'score': 742.4888572692871, 'total_duration': 4426.727645158768, 'accumulated_submission_time': 742.4888572692871, 'accumulated_eval_time': 3684.0718517303467, 'accumulated_logging_time': 0.13515233993530273}
I0306 01:18:33.869960 139646180759296 logging_writer.py:48] [1075] accumulated_eval_time=3684.071852, accumulated_logging_time=0.135152, accumulated_submission_time=742.488857, global_step=1075, preemption_count=0, score=742.488857, test/loss=0.135708, test/num_examples=95000000, total_duration=4426.727645, train/loss=0.134810, validation/loss=0.133024, validation/num_examples=83274637
I0306 01:20:34.260900 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:20:45.552771 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:21:26.523566 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:22:40.480556 139827085571904 submission_runner.py:413] Time since start: 4673.35s, 	Step: 1246, 	{'train/loss': 0.1316567547853638, 'validation/loss': 0.1324533089078491, 'validation/num_examples': 83274637, 'test/loss': 0.13509689385279605, 'test/num_examples': 95000000, 'score': 862.8673768043518, 'total_duration': 4673.351754188538, 'accumulated_submission_time': 862.8673768043518, 'accumulated_eval_time': 3810.291472196579, 'accumulated_logging_time': 0.15576720237731934}
I0306 01:22:40.494517 139645962680064 logging_writer.py:48] [1246] accumulated_eval_time=3810.291472, accumulated_logging_time=0.155767, accumulated_submission_time=862.867377, global_step=1246, preemption_count=0, score=862.867377, test/loss=0.135097, test/num_examples=95000000, total_duration=4673.351754, train/loss=0.131657, validation/loss=0.132453, validation/num_examples=83274637
I0306 01:24:41.301496 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:25:21.155829 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:25:27.191187 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:26:44.266785 139827085571904 submission_runner.py:413] Time since start: 4917.14s, 	Step: 1420, 	{'train/loss': 0.13107645994274872, 'validation/loss': 0.13247138904895497, 'validation/num_examples': 83274637, 'test/loss': 0.13497659274259868, 'test/num_examples': 95000000, 'score': 983.6590650081635, 'total_duration': 4917.13800907135, 'accumulated_submission_time': 983.6590650081635, 'accumulated_eval_time': 3933.256739139557, 'accumulated_logging_time': 0.17933344841003418}
I0306 01:26:44.281829 139646180759296 logging_writer.py:48] [1420] accumulated_eval_time=3933.256739, accumulated_logging_time=0.179333, accumulated_submission_time=983.659065, global_step=1420, preemption_count=0, score=983.659065, test/loss=0.134977, test/num_examples=95000000, total_duration=4917.138009, train/loss=0.131076, validation/loss=0.132471, validation/num_examples=83274637
I0306 01:27:30.478192 139645962680064 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.09725403785705566, loss=0.1279447376728058
I0306 01:28:45.048817 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:29:44.217664 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:29:50.252709 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:30:47.270901 139827085571904 submission_runner.py:413] Time since start: 5160.14s, 	Step: 1593, 	{'train/loss': 0.1317302388308933, 'validation/loss': 0.1320736700381834, 'validation/num_examples': 83274637, 'test/loss': 0.1345820564555921, 'test/num_examples': 95000000, 'score': 1104.4129085540771, 'total_duration': 5160.142123937607, 'accumulated_submission_time': 1104.4129085540771, 'accumulated_eval_time': 4055.4788019657135, 'accumulated_logging_time': 0.20142126083374023}
I0306 01:30:47.284762 139646180759296 logging_writer.py:48] [1593] accumulated_eval_time=4055.478802, accumulated_logging_time=0.201421, accumulated_submission_time=1104.412909, global_step=1593, preemption_count=0, score=1104.412909, test/loss=0.134582, test/num_examples=95000000, total_duration=5160.142124, train/loss=0.131730, validation/loss=0.132074, validation/num_examples=83274637
I0306 01:32:48.005606 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:34:04.552237 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:34:10.562973 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:34:49.039862 139827085571904 submission_runner.py:413] Time since start: 5401.91s, 	Step: 1763, 	{'train/loss': 0.13105140546770216, 'validation/loss': 0.13217193276575015, 'validation/num_examples': 83274637, 'test/loss': 0.13481217767269738, 'test/num_examples': 95000000, 'score': 1225.1209287643433, 'total_duration': 5401.911085367203, 'accumulated_submission_time': 1225.1209287643433, 'accumulated_eval_time': 4176.51301908493, 'accumulated_logging_time': 0.22223329544067383}
I0306 01:34:49.053549 139645962680064 logging_writer.py:48] [1763] accumulated_eval_time=4176.513019, accumulated_logging_time=0.222233, accumulated_submission_time=1225.120929, global_step=1763, preemption_count=0, score=1225.120929, test/loss=0.134812, test/num_examples=95000000, total_duration=5401.911085, train/loss=0.131051, validation/loss=0.132172, validation/num_examples=83274637
I0306 01:36:49.169715 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:38:29.276785 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:38:35.428279 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:38:50.386338 139827085571904 submission_runner.py:413] Time since start: 5643.26s, 	Step: 1937, 	{'train/loss': 0.13002524792023426, 'validation/loss': 0.13151014367751013, 'validation/num_examples': 83274637, 'test/loss': 0.13409731219161183, 'test/num_examples': 95000000, 'score': 1345.2244369983673, 'total_duration': 5643.257565021515, 'accumulated_submission_time': 1345.2244369983673, 'accumulated_eval_time': 4297.729638576508, 'accumulated_logging_time': 0.2428886890411377}
I0306 01:38:50.401031 139646180759296 logging_writer.py:48] [1937] accumulated_eval_time=4297.729639, accumulated_logging_time=0.242889, accumulated_submission_time=1345.224437, global_step=1937, preemption_count=0, score=1345.224437, test/loss=0.134097, test/num_examples=95000000, total_duration=5643.257565, train/loss=0.130025, validation/loss=0.131510, validation/num_examples=83274637
I0306 01:39:24.378238 139645962680064 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.003961552400141954, loss=0.12539821863174438
I0306 01:40:51.124777 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:42:55.850419 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:43:01.913447 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:43:09.062647 139827085571904 submission_runner.py:413] Time since start: 5901.93s, 	Step: 2106, 	{'train/loss': 0.13063489149014154, 'validation/loss': 0.13158152448626104, 'validation/num_examples': 83274637, 'test/loss': 0.13406168797286183, 'test/num_examples': 95000000, 'score': 1465.9347670078278, 'total_duration': 5901.933885574341, 'accumulated_submission_time': 1465.9347670078278, 'accumulated_eval_time': 4435.667479753494, 'accumulated_logging_time': 0.2652931213378906}
I0306 01:43:09.083567 139646180759296 logging_writer.py:48] [2106] accumulated_eval_time=4435.667480, accumulated_logging_time=0.265293, accumulated_submission_time=1465.934767, global_step=2106, preemption_count=0, score=1465.934767, test/loss=0.134062, test/num_examples=95000000, total_duration=5901.933886, train/loss=0.130635, validation/loss=0.131582, validation/num_examples=83274637
I0306 01:45:10.090766 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:47:19.966845 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:47:26.088782 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:47:33.165772 139827085571904 submission_runner.py:413] Time since start: 6166.04s, 	Step: 2280, 	{'train/loss': 0.12992139915062947, 'validation/loss': 0.1314656815165703, 'validation/num_examples': 83274637, 'test/loss': 0.1339436931743421, 'test/num_examples': 95000000, 'score': 1586.92808842659, 'total_duration': 6166.037005186081, 'accumulated_submission_time': 1586.92808842659, 'accumulated_eval_time': 4578.74246764183, 'accumulated_logging_time': 0.29433465003967285}
I0306 01:47:33.180879 139645962680064 logging_writer.py:48] [2280] accumulated_eval_time=4578.742468, accumulated_logging_time=0.294335, accumulated_submission_time=1586.928088, global_step=2280, preemption_count=0, score=1586.928088, test/loss=0.133944, test/num_examples=95000000, total_duration=6166.037005, train/loss=0.129921, validation/loss=0.131466, validation/num_examples=83274637
I0306 01:49:33.580366 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:51:43.286650 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:51:49.454875 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:51:56.537314 139827085571904 submission_runner.py:413] Time since start: 6429.41s, 	Step: 2452, 	{'train/loss': 0.1282057983320464, 'validation/loss': 0.1313638672405741, 'validation/num_examples': 83274637, 'test/loss': 0.1339249580180921, 'test/num_examples': 95000000, 'score': 1707.3107225894928, 'total_duration': 6429.408533811569, 'accumulated_submission_time': 1707.3107225894928, 'accumulated_eval_time': 4721.699376344681, 'accumulated_logging_time': 0.32056307792663574}
I0306 01:51:56.552928 139646180759296 logging_writer.py:48] [2452] accumulated_eval_time=4721.699376, accumulated_logging_time=0.320563, accumulated_submission_time=1707.310723, global_step=2452, preemption_count=0, score=1707.310723, test/loss=0.133925, test/num_examples=95000000, total_duration=6429.408534, train/loss=0.128206, validation/loss=0.131364, validation/num_examples=83274637
I0306 01:52:14.906343 139645962680064 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.0028224033303558826, loss=0.12725432217121124
I0306 01:53:57.203047 139827085571904 spec.py:321] Evaluating on the training split.
I0306 01:56:10.661637 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 01:56:16.796023 139827085571904 spec.py:349] Evaluating on the test split.
I0306 01:56:23.897999 139827085571904 submission_runner.py:413] Time since start: 6696.77s, 	Step: 2629, 	{'train/loss': 0.12998447534423205, 'validation/loss': 0.13116356826816608, 'validation/num_examples': 83274637, 'test/loss': 0.13356058246299343, 'test/num_examples': 95000000, 'score': 1827.946754693985, 'total_duration': 6696.769212245941, 'accumulated_submission_time': 1827.946754693985, 'accumulated_eval_time': 4868.3942856788635, 'accumulated_logging_time': 0.3444957733154297}
I0306 01:56:23.912907 139646180759296 logging_writer.py:48] [2629] accumulated_eval_time=4868.394286, accumulated_logging_time=0.344496, accumulated_submission_time=1827.946755, global_step=2629, preemption_count=0, score=1827.946755, test/loss=0.133561, test/num_examples=95000000, total_duration=6696.769212, train/loss=0.129984, validation/loss=0.131164, validation/num_examples=83274637
I0306 01:58:25.244893 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:00:34.744195 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:00:40.866865 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:00:48.108473 139827085571904 submission_runner.py:413] Time since start: 6960.98s, 	Step: 2797, 	{'train/loss': 0.1297653577050323, 'validation/loss': 0.1309964910707146, 'validation/num_examples': 83274637, 'test/loss': 0.13345417218338815, 'test/num_examples': 95000000, 'score': 1949.261926651001, 'total_duration': 6960.97970700264, 'accumulated_submission_time': 1949.261926651001, 'accumulated_eval_time': 5011.2578637599945, 'accumulated_logging_time': 0.3702840805053711}
I0306 02:00:48.122997 139645962680064 logging_writer.py:48] [2797] accumulated_eval_time=5011.257864, accumulated_logging_time=0.370284, accumulated_submission_time=1949.261927, global_step=2797, preemption_count=0, score=1949.261927, test/loss=0.133454, test/num_examples=95000000, total_duration=6960.979707, train/loss=0.129765, validation/loss=0.130996, validation/num_examples=83274637
I0306 02:02:49.065947 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:05:03.110222 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:05:09.376259 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:05:16.627837 139827085571904 submission_runner.py:413] Time since start: 7229.50s, 	Step: 2967, 	{'train/loss': 0.1275362218232275, 'validation/loss': 0.13100985742288496, 'validation/num_examples': 83274637, 'test/loss': 0.1332381970703125, 'test/num_examples': 95000000, 'score': 2070.1923229694366, 'total_duration': 7229.499065876007, 'accumulated_submission_time': 2070.1923229694366, 'accumulated_eval_time': 5158.819734811783, 'accumulated_logging_time': 0.3914461135864258}
I0306 02:05:16.642476 139646180759296 logging_writer.py:48] [2967] accumulated_eval_time=5158.819735, accumulated_logging_time=0.391446, accumulated_submission_time=2070.192323, global_step=2967, preemption_count=0, score=2070.192323, test/loss=0.133238, test/num_examples=95000000, total_duration=7229.499066, train/loss=0.127536, validation/loss=0.131010, validation/num_examples=83274637
I0306 02:05:24.889657 139645962680064 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.004627738147974014, loss=0.12672559916973114
I0306 02:07:16.682953 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:09:29.092321 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:09:35.327220 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:09:42.533921 139827085571904 submission_runner.py:413] Time since start: 7495.41s, 	Step: 3136, 	{'train/loss': 0.12966926681732982, 'validation/loss': 0.13062459062040102, 'validation/num_examples': 83274637, 'test/loss': 0.1330101122944079, 'test/num_examples': 95000000, 'score': 2190.217220544815, 'total_duration': 7495.405162334442, 'accumulated_submission_time': 2190.217220544815, 'accumulated_eval_time': 5304.670695304871, 'accumulated_logging_time': 0.4160161018371582}
I0306 02:09:42.548550 139646180759296 logging_writer.py:48] [3136] accumulated_eval_time=5304.670695, accumulated_logging_time=0.416016, accumulated_submission_time=2190.217221, global_step=3136, preemption_count=0, score=2190.217221, test/loss=0.133010, test/num_examples=95000000, total_duration=7495.405162, train/loss=0.129669, validation/loss=0.130625, validation/num_examples=83274637
I0306 02:11:43.078380 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:13:55.253915 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:14:01.474786 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:14:08.639520 139827085571904 submission_runner.py:413] Time since start: 7761.51s, 	Step: 3305, 	{'train/loss': 0.1304276871418803, 'validation/loss': 0.13068166306972315, 'validation/num_examples': 83274637, 'test/loss': 0.1332013373046875, 'test/num_examples': 95000000, 'score': 2310.7342343330383, 'total_duration': 7761.510757923126, 'accumulated_submission_time': 2310.7342343330383, 'accumulated_eval_time': 5450.231810331345, 'accumulated_logging_time': 0.437877893447876}
I0306 02:14:08.654310 139645962680064 logging_writer.py:48] [3305] accumulated_eval_time=5450.231810, accumulated_logging_time=0.437878, accumulated_submission_time=2310.734234, global_step=3305, preemption_count=0, score=2310.734234, test/loss=0.133201, test/num_examples=95000000, total_duration=7761.510758, train/loss=0.130428, validation/loss=0.130682, validation/num_examples=83274637
I0306 02:16:08.768447 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:18:21.249762 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:18:27.524270 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:18:34.795228 139827085571904 submission_runner.py:413] Time since start: 8027.67s, 	Step: 3478, 	{'train/loss': 0.1300596429866815, 'validation/loss': 0.13057972373689242, 'validation/num_examples': 83274637, 'test/loss': 0.13286286328125, 'test/num_examples': 95000000, 'score': 2430.834977388382, 'total_duration': 8027.666455030441, 'accumulated_submission_time': 2430.834977388382, 'accumulated_eval_time': 5596.258558034897, 'accumulated_logging_time': 0.46037936210632324}
I0306 02:18:34.813219 139646180759296 logging_writer.py:48] [3478] accumulated_eval_time=5596.258558, accumulated_logging_time=0.460379, accumulated_submission_time=2430.834977, global_step=3478, preemption_count=0, score=2430.834977, test/loss=0.132863, test/num_examples=95000000, total_duration=8027.666455, train/loss=0.130060, validation/loss=0.130580, validation/num_examples=83274637
I0306 02:18:37.006042 139645962680064 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.010411722585558891, loss=0.13771909475326538
I0306 02:20:35.799526 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:22:45.672253 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:22:51.930852 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:22:59.214770 139827085571904 submission_runner.py:413] Time since start: 8292.09s, 	Step: 3649, 	{'train/loss': 0.1285871615012487, 'validation/loss': 0.13035082751246338, 'validation/num_examples': 83274637, 'test/loss': 0.13268681461759868, 'test/num_examples': 95000000, 'score': 2551.807795524597, 'total_duration': 8292.085990667343, 'accumulated_submission_time': 2551.807795524597, 'accumulated_eval_time': 5739.673795938492, 'accumulated_logging_time': 0.4860258102416992}
I0306 02:22:59.234333 139646180759296 logging_writer.py:48] [3649] accumulated_eval_time=5739.673796, accumulated_logging_time=0.486026, accumulated_submission_time=2551.807796, global_step=3649, preemption_count=0, score=2551.807796, test/loss=0.132687, test/num_examples=95000000, total_duration=8292.085991, train/loss=0.128587, validation/loss=0.130351, validation/num_examples=83274637
I0306 02:25:00.454443 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:27:12.858229 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:27:19.082303 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:27:26.327866 139827085571904 submission_runner.py:413] Time since start: 8559.20s, 	Step: 3819, 	{'train/loss': 0.1275556819900027, 'validation/loss': 0.13032559703810237, 'validation/num_examples': 83274637, 'test/loss': 0.13265292453741775, 'test/num_examples': 95000000, 'score': 2673.0149159431458, 'total_duration': 8559.199102163315, 'accumulated_submission_time': 2673.0149159431458, 'accumulated_eval_time': 5885.547197341919, 'accumulated_logging_time': 0.5128910541534424}
I0306 02:27:26.346580 139645962680064 logging_writer.py:48] [3819] accumulated_eval_time=5885.547197, accumulated_logging_time=0.512891, accumulated_submission_time=2673.014916, global_step=3819, preemption_count=0, score=2673.014916, test/loss=0.132653, test/num_examples=95000000, total_duration=8559.199102, train/loss=0.127556, validation/loss=0.130326, validation/num_examples=83274637
I0306 02:29:27.298683 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:31:41.529366 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:31:47.779784 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:31:55.088427 139827085571904 submission_runner.py:413] Time since start: 8827.96s, 	Step: 3989, 	{'train/loss': 0.12926367576579628, 'validation/loss': 0.13040773695634664, 'validation/num_examples': 83274637, 'test/loss': 0.13273741698190789, 'test/num_examples': 95000000, 'score': 2793.950444459915, 'total_duration': 8827.959662914276, 'accumulated_submission_time': 2793.950444459915, 'accumulated_eval_time': 6033.336914777756, 'accumulated_logging_time': 0.5424618721008301}
I0306 02:31:55.108758 139646180759296 logging_writer.py:48] [3989] accumulated_eval_time=6033.336915, accumulated_logging_time=0.542462, accumulated_submission_time=2793.950444, global_step=3989, preemption_count=0, score=2793.950444, test/loss=0.132737, test/num_examples=95000000, total_duration=8827.959663, train/loss=0.129264, validation/loss=0.130408, validation/num_examples=83274637
I0306 02:31:56.261948 139645962680064 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.0021689075510948896, loss=0.12781763076782227
I0306 02:33:55.372846 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:36:08.554459 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:36:14.832269 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:36:22.152813 139827085571904 submission_runner.py:413] Time since start: 9095.02s, 	Step: 4161, 	{'train/loss': 0.1298518533226829, 'validation/loss': 0.13055444278948042, 'validation/num_examples': 83274637, 'test/loss': 0.13287225047286183, 'test/num_examples': 95000000, 'score': 2914.198286294937, 'total_duration': 9095.024054288864, 'accumulated_submission_time': 2914.198286294937, 'accumulated_eval_time': 6180.116861343384, 'accumulated_logging_time': 0.5731680393218994}
I0306 02:36:22.167989 139646180759296 logging_writer.py:48] [4161] accumulated_eval_time=6180.116861, accumulated_logging_time=0.573168, accumulated_submission_time=2914.198286, global_step=4161, preemption_count=0, score=2914.198286, test/loss=0.132872, test/num_examples=95000000, total_duration=9095.024054, train/loss=0.129852, validation/loss=0.130554, validation/num_examples=83274637
I0306 02:38:22.729942 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:40:42.477889 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:40:48.696955 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:40:56.009322 139827085571904 submission_runner.py:413] Time since start: 9368.88s, 	Step: 4335, 	{'train/loss': 0.12814454279793133, 'validation/loss': 0.13028338416458662, 'validation/num_examples': 83274637, 'test/loss': 0.13254378745888157, 'test/num_examples': 95000000, 'score': 3034.7467846870422, 'total_duration': 9368.880550384521, 'accumulated_submission_time': 3034.7467846870422, 'accumulated_eval_time': 6333.396206855774, 'accumulated_logging_time': 0.5960559844970703}
I0306 02:40:56.027675 139645962680064 logging_writer.py:48] [4335] accumulated_eval_time=6333.396207, accumulated_logging_time=0.596056, accumulated_submission_time=3034.746785, global_step=4335, preemption_count=0, score=3034.746785, test/loss=0.132544, test/num_examples=95000000, total_duration=9368.880550, train/loss=0.128145, validation/loss=0.130283, validation/num_examples=83274637
I0306 02:42:53.488123 139646180759296 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.0020384027156978846, loss=0.13808217644691467
I0306 02:42:57.026639 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:45:13.843638 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:45:20.085056 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:45:27.489774 139827085571904 submission_runner.py:413] Time since start: 9640.36s, 	Step: 4505, 	{'train/loss': 0.12964003481580028, 'validation/loss': 0.13045328682091703, 'validation/num_examples': 83274637, 'test/loss': 0.13275666548108553, 'test/num_examples': 95000000, 'score': 3155.732577085495, 'total_duration': 9640.360978126526, 'accumulated_submission_time': 3155.732577085495, 'accumulated_eval_time': 6483.859271764755, 'accumulated_logging_time': 0.6221106052398682}
I0306 02:45:27.512455 139645962680064 logging_writer.py:48] [4505] accumulated_eval_time=6483.859272, accumulated_logging_time=0.622111, accumulated_submission_time=3155.732577, global_step=4505, preemption_count=0, score=3155.732577, test/loss=0.132757, test/num_examples=95000000, total_duration=9640.360978, train/loss=0.129640, validation/loss=0.130453, validation/num_examples=83274637
I0306 02:47:28.122742 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:49:44.806319 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:49:51.042476 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:49:58.443171 139827085571904 submission_runner.py:413] Time since start: 9911.31s, 	Step: 4674, 	{'train/loss': 0.12741434199255217, 'validation/loss': 0.1302821550801236, 'validation/num_examples': 83274637, 'test/loss': 0.13259115851151315, 'test/num_examples': 95000000, 'score': 3276.329290866852, 'total_duration': 9911.314411640167, 'accumulated_submission_time': 3276.329290866852, 'accumulated_eval_time': 6634.179695606232, 'accumulated_logging_time': 0.6527330875396729}
I0306 02:49:58.460875 139646180759296 logging_writer.py:48] [4674] accumulated_eval_time=6634.179696, accumulated_logging_time=0.652733, accumulated_submission_time=3276.329291, global_step=4674, preemption_count=0, score=3276.329291, test/loss=0.132591, test/num_examples=95000000, total_duration=9911.314412, train/loss=0.127414, validation/loss=0.130282, validation/num_examples=83274637
I0306 02:51:58.610544 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:54:08.427192 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:54:14.655291 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:54:22.020313 139827085571904 submission_runner.py:413] Time since start: 10174.89s, 	Step: 4842, 	{'train/loss': 0.13040790589725446, 'validation/loss': 0.13007074959727835, 'validation/num_examples': 83274637, 'test/loss': 0.13234405121299342, 'test/num_examples': 95000000, 'score': 3396.4643602371216, 'total_duration': 10174.89155459404, 'accumulated_submission_time': 3396.4643602371216, 'accumulated_eval_time': 6777.589445590973, 'accumulated_logging_time': 0.6794803142547607}
I0306 02:54:22.035424 139645962680064 logging_writer.py:48] [4842] accumulated_eval_time=6777.589446, accumulated_logging_time=0.679480, accumulated_submission_time=3396.464360, global_step=4842, preemption_count=0, score=3396.464360, test/loss=0.132344, test/num_examples=95000000, total_duration=10174.891555, train/loss=0.130408, validation/loss=0.130071, validation/num_examples=83274637
I0306 02:56:14.307340 139646180759296 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.004519721958786249, loss=0.13184888660907745
I0306 02:56:22.401754 139827085571904 spec.py:321] Evaluating on the training split.
I0306 02:58:40.991734 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 02:58:47.265088 139827085571904 spec.py:349] Evaluating on the test split.
I0306 02:58:54.640674 139827085571904 submission_runner.py:413] Time since start: 10447.51s, 	Step: 5011, 	{'train/loss': 0.12904802611413993, 'validation/loss': 0.12994724269820293, 'validation/num_examples': 83274637, 'test/loss': 0.13235331593338817, 'test/num_examples': 95000000, 'score': 3516.81751871109, 'total_duration': 10447.511914730072, 'accumulated_submission_time': 3516.81751871109, 'accumulated_eval_time': 6929.828325033188, 'accumulated_logging_time': 0.7022745609283447}
I0306 02:58:54.657890 139645962680064 logging_writer.py:48] [5011] accumulated_eval_time=6929.828325, accumulated_logging_time=0.702275, accumulated_submission_time=3516.817519, global_step=5011, preemption_count=0, score=3516.817519, test/loss=0.132353, test/num_examples=95000000, total_duration=10447.511915, train/loss=0.129048, validation/loss=0.129947, validation/num_examples=83274637
I0306 03:00:54.806043 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:03:11.793698 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:03:18.064790 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:03:25.472085 139827085571904 submission_runner.py:413] Time since start: 10718.34s, 	Step: 5183, 	{'train/loss': 0.12825895513191163, 'validation/loss': 0.13013825856950298, 'validation/num_examples': 83274637, 'test/loss': 0.13252107764185855, 'test/num_examples': 95000000, 'score': 3636.9511404037476, 'total_duration': 10718.343326330185, 'accumulated_submission_time': 3636.9511404037476, 'accumulated_eval_time': 7080.494361877441, 'accumulated_logging_time': 0.728309154510498}
I0306 03:03:25.488396 139646180759296 logging_writer.py:48] [5183] accumulated_eval_time=7080.494362, accumulated_logging_time=0.728309, accumulated_submission_time=3636.951140, global_step=5183, preemption_count=0, score=3636.951140, test/loss=0.132521, test/num_examples=95000000, total_duration=10718.343326, train/loss=0.128259, validation/loss=0.130138, validation/num_examples=83274637
I0306 03:05:25.983213 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:07:46.418642 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:07:52.704703 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:08:00.077446 139827085571904 submission_runner.py:413] Time since start: 10992.95s, 	Step: 5357, 	{'train/loss': 0.1300322749423531, 'validation/loss': 0.12997396846015372, 'validation/num_examples': 83274637, 'test/loss': 0.1323541123149671, 'test/num_examples': 95000000, 'score': 3757.4322624206543, 'total_duration': 10992.948665618896, 'accumulated_submission_time': 3757.4322624206543, 'accumulated_eval_time': 7234.588553190231, 'accumulated_logging_time': 0.7525970935821533}
I0306 03:08:00.092537 139645962680064 logging_writer.py:48] [5357] accumulated_eval_time=7234.588553, accumulated_logging_time=0.752597, accumulated_submission_time=3757.432262, global_step=5357, preemption_count=0, score=3757.432262, test/loss=0.132354, test/num_examples=95000000, total_duration=10992.948666, train/loss=0.130032, validation/loss=0.129974, validation/num_examples=83274637
I0306 03:09:39.496128 139646180759296 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.010643321089446545, loss=0.1281191110610962
I0306 03:10:00.764848 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:12:17.631618 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:12:23.904292 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:12:31.263893 139827085571904 submission_runner.py:413] Time since start: 11264.14s, 	Step: 5527, 	{'train/loss': 0.1288842977311626, 'validation/loss': 0.1300954086848046, 'validation/num_examples': 83274637, 'test/loss': 0.13250781140008225, 'test/num_examples': 95000000, 'score': 3878.0917840003967, 'total_duration': 11264.135138750076, 'accumulated_submission_time': 3878.0917840003967, 'accumulated_eval_time': 7385.087574720383, 'accumulated_logging_time': 0.7748117446899414}
I0306 03:12:31.278055 139645962680064 logging_writer.py:48] [5527] accumulated_eval_time=7385.087575, accumulated_logging_time=0.774812, accumulated_submission_time=3878.091784, global_step=5527, preemption_count=0, score=3878.091784, test/loss=0.132508, test/num_examples=95000000, total_duration=11264.135139, train/loss=0.128884, validation/loss=0.130095, validation/num_examples=83274637
I0306 03:14:31.295620 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:16:47.353935 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:16:53.679658 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:17:01.041007 139827085571904 submission_runner.py:413] Time since start: 11533.91s, 	Step: 5696, 	{'train/loss': 0.12639998635218577, 'validation/loss': 0.12985476401341142, 'validation/num_examples': 83274637, 'test/loss': 0.13228717486636513, 'test/num_examples': 95000000, 'score': 3998.095972299576, 'total_duration': 11533.912237644196, 'accumulated_submission_time': 3998.095972299576, 'accumulated_eval_time': 7534.83292889595, 'accumulated_logging_time': 0.7966806888580322}
I0306 03:17:01.057680 139646180759296 logging_writer.py:48] [5696] accumulated_eval_time=7534.832929, accumulated_logging_time=0.796681, accumulated_submission_time=3998.095972, global_step=5696, preemption_count=0, score=3998.095972, test/loss=0.132287, test/num_examples=95000000, total_duration=11533.912238, train/loss=0.126400, validation/loss=0.129855, validation/num_examples=83274637
I0306 03:19:01.540513 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:21:14.246322 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:21:20.624605 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:21:27.971543 139827085571904 submission_runner.py:413] Time since start: 11800.84s, 	Step: 5872, 	{'train/loss': 0.1278943569405274, 'validation/loss': 0.1298379614596819, 'validation/num_examples': 83274637, 'test/loss': 0.13224980531455593, 'test/num_examples': 95000000, 'score': 4118.5652804374695, 'total_duration': 11800.842785358429, 'accumulated_submission_time': 4118.5652804374695, 'accumulated_eval_time': 7681.263945817947, 'accumulated_logging_time': 0.8210937976837158}
I0306 03:21:27.986161 139645962680064 logging_writer.py:48] [5872] accumulated_eval_time=7681.263946, accumulated_logging_time=0.821094, accumulated_submission_time=4118.565280, global_step=5872, preemption_count=0, score=4118.565280, test/loss=0.132250, test/num_examples=95000000, total_duration=11800.842785, train/loss=0.127894, validation/loss=0.129838, validation/num_examples=83274637
I0306 03:22:55.212059 139646180759296 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.0036536867264658213, loss=0.13516981899738312
I0306 03:23:28.049411 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:25:40.935716 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:25:47.210330 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:25:54.601348 139827085571904 submission_runner.py:413] Time since start: 12067.47s, 	Step: 6041, 	{'train/loss': 0.12892879672207921, 'validation/loss': 0.12981573962009585, 'validation/num_examples': 83274637, 'test/loss': 0.13214697192639802, 'test/num_examples': 95000000, 'score': 4238.614892244339, 'total_duration': 12067.472588300705, 'accumulated_submission_time': 4238.614892244339, 'accumulated_eval_time': 7827.815846443176, 'accumulated_logging_time': 0.843940258026123}
I0306 03:25:54.618100 139645962680064 logging_writer.py:48] [6041] accumulated_eval_time=7827.815846, accumulated_logging_time=0.843940, accumulated_submission_time=4238.614892, global_step=6041, preemption_count=0, score=4238.614892, test/loss=0.132147, test/num_examples=95000000, total_duration=12067.472588, train/loss=0.128929, validation/loss=0.129816, validation/num_examples=83274637
I0306 03:27:54.762357 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:30:07.500776 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:30:13.827639 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:30:21.211785 139827085571904 submission_runner.py:413] Time since start: 12334.08s, 	Step: 6210, 	{'train/loss': 0.128617396097888, 'validation/loss': 0.13005727573188042, 'validation/num_examples': 83274637, 'test/loss': 0.13254092358141448, 'test/num_examples': 95000000, 'score': 4358.745446205139, 'total_duration': 12334.08301281929, 'accumulated_submission_time': 4358.745446205139, 'accumulated_eval_time': 7974.265251874924, 'accumulated_logging_time': 0.868908166885376}
I0306 03:30:21.229147 139646180759296 logging_writer.py:48] [6210] accumulated_eval_time=7974.265252, accumulated_logging_time=0.868908, accumulated_submission_time=4358.745446, global_step=6210, preemption_count=0, score=4358.745446, test/loss=0.132541, test/num_examples=95000000, total_duration=12334.083013, train/loss=0.128617, validation/loss=0.130057, validation/num_examples=83274637
I0306 03:32:22.207504 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:34:36.180727 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:34:42.494885 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:34:49.915806 139827085571904 submission_runner.py:413] Time since start: 12602.79s, 	Step: 6379, 	{'train/loss': 0.12790960809157328, 'validation/loss': 0.12991972480018135, 'validation/num_examples': 83274637, 'test/loss': 0.1323423482113487, 'test/num_examples': 95000000, 'score': 4479.70954990387, 'total_duration': 12602.78704380989, 'accumulated_submission_time': 4479.70954990387, 'accumulated_eval_time': 8121.973530769348, 'accumulated_logging_time': 0.89485764503479}
I0306 03:34:49.931464 139645962680064 logging_writer.py:48] [6379] accumulated_eval_time=8121.973531, accumulated_logging_time=0.894858, accumulated_submission_time=4479.709550, global_step=6379, preemption_count=0, score=4479.709550, test/loss=0.132342, test/num_examples=95000000, total_duration=12602.787044, train/loss=0.127910, validation/loss=0.129920, validation/num_examples=83274637
I0306 03:36:08.189263 139646180759296 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.004176459275186062, loss=0.12885692715644836
I0306 03:36:50.485254 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:39:03.822730 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:39:10.121761 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:39:17.546491 139827085571904 submission_runner.py:413] Time since start: 12870.42s, 	Step: 6552, 	{'train/loss': 0.13030627763496255, 'validation/loss': 0.1302447102212376, 'validation/num_examples': 83274637, 'test/loss': 0.13273242744654606, 'test/num_examples': 95000000, 'score': 4600.250163555145, 'total_duration': 12870.417716026306, 'accumulated_submission_time': 4600.250163555145, 'accumulated_eval_time': 8269.034720659256, 'accumulated_logging_time': 0.9180853366851807}
I0306 03:39:17.562264 139645962680064 logging_writer.py:48] [6552] accumulated_eval_time=8269.034721, accumulated_logging_time=0.918085, accumulated_submission_time=4600.250164, global_step=6552, preemption_count=0, score=4600.250164, test/loss=0.132732, test/num_examples=95000000, total_duration=12870.417716, train/loss=0.130306, validation/loss=0.130245, validation/num_examples=83274637
I0306 03:41:18.095318 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:43:35.796144 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:43:42.103743 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:43:49.537978 139827085571904 submission_runner.py:413] Time since start: 13142.41s, 	Step: 6720, 	{'train/loss': 0.12841027155049942, 'validation/loss': 0.1297639618219681, 'validation/num_examples': 83274637, 'test/loss': 0.13214559021381578, 'test/num_examples': 95000000, 'score': 4720.76885509491, 'total_duration': 13142.409147262573, 'accumulated_submission_time': 4720.76885509491, 'accumulated_eval_time': 8420.47728729248, 'accumulated_logging_time': 0.9425745010375977}
I0306 03:43:49.566970 139646180759296 logging_writer.py:48] [6720] accumulated_eval_time=8420.477287, accumulated_logging_time=0.942575, accumulated_submission_time=4720.768855, global_step=6720, preemption_count=0, score=4720.768855, test/loss=0.132146, test/num_examples=95000000, total_duration=13142.409147, train/loss=0.128410, validation/loss=0.129764, validation/num_examples=83274637
I0306 03:45:49.825804 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:48:04.947521 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:48:11.276653 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:48:18.741633 139827085571904 submission_runner.py:413] Time since start: 13411.61s, 	Step: 6896, 	{'train/loss': 0.12687208334792335, 'validation/loss': 0.12979370503740534, 'validation/num_examples': 83274637, 'test/loss': 0.13210701903782895, 'test/num_examples': 95000000, 'score': 4841.014019012451, 'total_duration': 13411.612874031067, 'accumulated_submission_time': 4841.014019012451, 'accumulated_eval_time': 8569.393094301224, 'accumulated_logging_time': 0.979358434677124}
I0306 03:48:18.757911 139645962680064 logging_writer.py:48] [6896] accumulated_eval_time=8569.393094, accumulated_logging_time=0.979358, accumulated_submission_time=4841.014019, global_step=6896, preemption_count=0, score=4841.014019, test/loss=0.132107, test/num_examples=95000000, total_duration=13411.612874, train/loss=0.126872, validation/loss=0.129794, validation/num_examples=83274637
I0306 03:49:25.778957 139646180759296 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.05359688028693199, loss=0.12996776401996613
I0306 03:50:19.469623 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:52:33.366525 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:52:39.640731 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:52:47.088505 139827085571904 submission_runner.py:413] Time since start: 13679.96s, 	Step: 7067, 	{'train/loss': 0.13029275867361692, 'validation/loss': 0.12980142070635806, 'validation/num_examples': 83274637, 'test/loss': 0.1321848359375, 'test/num_examples': 95000000, 'score': 4961.712739467621, 'total_duration': 13679.959724903107, 'accumulated_submission_time': 4961.712739467621, 'accumulated_eval_time': 8717.011936903, 'accumulated_logging_time': 1.0031108856201172}
I0306 03:52:47.106393 139645962680064 logging_writer.py:48] [7067] accumulated_eval_time=8717.011937, accumulated_logging_time=1.003111, accumulated_submission_time=4961.712739, global_step=7067, preemption_count=0, score=4961.712739, test/loss=0.132185, test/num_examples=95000000, total_duration=13679.959725, train/loss=0.130293, validation/loss=0.129801, validation/num_examples=83274637
I0306 03:54:47.180193 139827085571904 spec.py:321] Evaluating on the training split.
I0306 03:57:04.540149 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 03:57:10.862074 139827085571904 spec.py:349] Evaluating on the test split.
I0306 03:57:18.282393 139827085571904 submission_runner.py:413] Time since start: 13951.15s, 	Step: 7237, 	{'train/loss': 0.12764344767392058, 'validation/loss': 0.12966503764412987, 'validation/num_examples': 83274637, 'test/loss': 0.13198324111842105, 'test/num_examples': 95000000, 'score': 5081.772540807724, 'total_duration': 13951.153629541397, 'accumulated_submission_time': 5081.772540807724, 'accumulated_eval_time': 8868.114108800888, 'accumulated_logging_time': 1.0293889045715332}
I0306 03:57:18.300603 139646180759296 logging_writer.py:48] [7237] accumulated_eval_time=8868.114109, accumulated_logging_time=1.029389, accumulated_submission_time=5081.772541, global_step=7237, preemption_count=0, score=5081.772541, test/loss=0.131983, test/num_examples=95000000, total_duration=13951.153630, train/loss=0.127643, validation/loss=0.129665, validation/num_examples=83274637
I0306 03:59:18.515285 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:01:31.741733 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:01:38.037584 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:01:45.462702 139827085571904 submission_runner.py:413] Time since start: 14218.33s, 	Step: 7406, 	{'train/loss': 0.12736902643674575, 'validation/loss': 0.12972282773955532, 'validation/num_examples': 83274637, 'test/loss': 0.1319949220497533, 'test/num_examples': 95000000, 'score': 5201.973747730255, 'total_duration': 14218.333938837051, 'accumulated_submission_time': 5201.973747730255, 'accumulated_eval_time': 9015.061503648758, 'accumulated_logging_time': 1.0553011894226074}
I0306 04:01:45.477743 139645962680064 logging_writer.py:48] [7406] accumulated_eval_time=9015.061504, accumulated_logging_time=1.055301, accumulated_submission_time=5201.973748, global_step=7406, preemption_count=0, score=5201.973748, test/loss=0.131995, test/num_examples=95000000, total_duration=14218.333939, train/loss=0.127369, validation/loss=0.129723, validation/num_examples=83274637
I0306 04:02:40.421260 139646180759296 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.01376275159418583, loss=0.1301851123571396
I0306 04:03:45.652367 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:06:00.806177 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:06:07.135776 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:06:14.543142 139827085571904 submission_runner.py:413] Time since start: 14487.41s, 	Step: 7580, 	{'train/loss': 0.12958810197294884, 'validation/loss': 0.1296612333082731, 'validation/num_examples': 83274637, 'test/loss': 0.13196664583675988, 'test/num_examples': 95000000, 'score': 5322.135422706604, 'total_duration': 14487.41438627243, 'accumulated_submission_time': 5322.135422706604, 'accumulated_eval_time': 9163.952250003815, 'accumulated_logging_time': 1.0776252746582031}
I0306 04:06:14.558183 139645962680064 logging_writer.py:48] [7580] accumulated_eval_time=9163.952250, accumulated_logging_time=1.077625, accumulated_submission_time=5322.135423, global_step=7580, preemption_count=0, score=5322.135423, test/loss=0.131967, test/num_examples=95000000, total_duration=14487.414386, train/loss=0.129588, validation/loss=0.129661, validation/num_examples=83274637
I0306 04:08:16.142898 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:10:27.935877 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:10:34.245972 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:10:41.623406 139827085571904 submission_runner.py:413] Time since start: 14754.49s, 	Step: 7750, 	{'train/loss': 0.12697161331116777, 'validation/loss': 0.1296560050319553, 'validation/num_examples': 83274637, 'test/loss': 0.13196843414884868, 'test/num_examples': 95000000, 'score': 5443.70708322525, 'total_duration': 14754.494647026062, 'accumulated_submission_time': 5443.70708322525, 'accumulated_eval_time': 9309.432745933533, 'accumulated_logging_time': 1.1001296043395996}
I0306 04:10:41.639004 139646180759296 logging_writer.py:48] [7750] accumulated_eval_time=9309.432746, accumulated_logging_time=1.100130, accumulated_submission_time=5443.707083, global_step=7750, preemption_count=0, score=5443.707083, test/loss=0.131968, test/num_examples=95000000, total_duration=14754.494647, train/loss=0.126972, validation/loss=0.129656, validation/num_examples=83274637
I0306 04:12:42.007666 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:14:58.616235 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:15:04.942228 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:15:12.344793 139827085571904 submission_runner.py:413] Time since start: 15025.22s, 	Step: 7925, 	{'train/loss': 0.1293157176963938, 'validation/loss': 0.1297070415423276, 'validation/num_examples': 83274637, 'test/loss': 0.13207495669202302, 'test/num_examples': 95000000, 'score': 5564.062667131424, 'total_duration': 15025.216032981873, 'accumulated_submission_time': 5564.062667131424, 'accumulated_eval_time': 9459.76985168457, 'accumulated_logging_time': 1.1230103969573975}
I0306 04:15:12.360213 139645962680064 logging_writer.py:48] [7925] accumulated_eval_time=9459.769852, accumulated_logging_time=1.123010, accumulated_submission_time=5564.062667, global_step=7925, preemption_count=0, score=5564.062667, test/loss=0.132075, test/num_examples=95000000, total_duration=15025.216033, train/loss=0.129316, validation/loss=0.129707, validation/num_examples=83274637
I0306 04:15:55.828971 139646180759296 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.0179985873401165, loss=0.1238919347524643
I0306 04:17:13.308013 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:19:26.839225 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:19:33.163324 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:19:40.530917 139827085571904 submission_runner.py:413] Time since start: 15293.40s, 	Step: 8094, 	{'train/loss': 0.129429170873555, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5684.995863676071, 'total_duration': 15293.402150630951, 'accumulated_submission_time': 5684.995863676071, 'accumulated_eval_time': 9606.992738962173, 'accumulated_logging_time': 1.147623062133789}
I0306 04:19:40.547305 139645962680064 logging_writer.py:48] [8094] accumulated_eval_time=9606.992739, accumulated_logging_time=1.147623, accumulated_submission_time=5684.995864, global_step=8094, preemption_count=0, score=5684.995864, test/loss=0.132065, test/num_examples=95000000, total_duration=15293.402151, train/loss=0.129429, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:21:41.482052 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:23:47.045865 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:23:53.334541 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:24:00.754637 139827085571904 submission_runner.py:413] Time since start: 15553.63s, 	Step: 8267, 	{'train/loss': 0.12804579950353634, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5805.917500972748, 'total_duration': 15553.625880718231, 'accumulated_submission_time': 5805.917500972748, 'accumulated_eval_time': 9746.265315294266, 'accumulated_logging_time': 1.171464204788208}
I0306 04:24:00.769640 139646180759296 logging_writer.py:48] [8267] accumulated_eval_time=9746.265315, accumulated_logging_time=1.171464, accumulated_submission_time=5805.917501, global_step=8267, preemption_count=0, score=5805.917501, test/loss=0.132065, test/num_examples=95000000, total_duration=15553.625881, train/loss=0.128046, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:26:01.104875 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:28:14.267180 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:28:20.632053 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:28:28.083656 139827085571904 submission_runner.py:413] Time since start: 15820.95s, 	Step: 8437, 	{'train/loss': 0.12877348243440473, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5926.237798452377, 'total_duration': 15820.95489358902, 'accumulated_submission_time': 5926.237798452377, 'accumulated_eval_time': 9893.24407339096, 'accumulated_logging_time': 1.1957948207855225}
I0306 04:28:28.100162 139645962680064 logging_writer.py:48] [8437] accumulated_eval_time=9893.244073, accumulated_logging_time=1.195795, accumulated_submission_time=5926.237798, global_step=8437, preemption_count=0, score=5926.237798, test/loss=0.132065, test/num_examples=95000000, total_duration=15820.954894, train/loss=0.128773, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:29:02.154946 139646180759296 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.0108815748244524, loss=0.1340843141078949
I0306 04:30:28.560783 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:32:37.972483 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:32:44.319067 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:32:51.755307 139827085571904 submission_runner.py:413] Time since start: 16084.63s, 	Step: 8605, 	{'train/loss': 0.13002369707485414, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6046.685829162598, 'total_duration': 16084.626545190811, 'accumulated_submission_time': 6046.685829162598, 'accumulated_eval_time': 10036.438574790955, 'accumulated_logging_time': 1.2192978858947754}
I0306 04:32:51.770317 139645962680064 logging_writer.py:48] [8605] accumulated_eval_time=10036.438575, accumulated_logging_time=1.219298, accumulated_submission_time=6046.685829, global_step=8605, preemption_count=0, score=6046.685829, test/loss=0.132065, test/num_examples=95000000, total_duration=16084.626545, train/loss=0.130024, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:34:52.358461 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:37:10.267981 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:37:16.611121 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:37:24.105573 139827085571904 submission_runner.py:413] Time since start: 16356.98s, 	Step: 8775, 	{'train/loss': 0.12782398639422543, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6167.259372472763, 'total_duration': 16356.976807832718, 'accumulated_submission_time': 6167.259372472763, 'accumulated_eval_time': 10188.185682058334, 'accumulated_logging_time': 1.243321180343628}
I0306 04:37:24.128555 139646180759296 logging_writer.py:48] [8775] accumulated_eval_time=10188.185682, accumulated_logging_time=1.243321, accumulated_submission_time=6167.259372, global_step=8775, preemption_count=0, score=6167.259372, test/loss=0.132065, test/num_examples=95000000, total_duration=16356.976808, train/loss=0.127824, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:39:24.361176 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:41:42.057144 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:41:48.439243 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:41:55.881907 139827085571904 submission_runner.py:413] Time since start: 16628.75s, 	Step: 8943, 	{'train/loss': 0.1289729635295628, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6287.479074716568, 'total_duration': 16628.75314092636, 'accumulated_submission_time': 6287.479074716568, 'accumulated_eval_time': 10339.706386566162, 'accumulated_logging_time': 1.273768424987793}
I0306 04:41:55.898980 139645962680064 logging_writer.py:48] [8943] accumulated_eval_time=10339.706387, accumulated_logging_time=1.273768, accumulated_submission_time=6287.479075, global_step=8943, preemption_count=0, score=6287.479075, test/loss=0.132065, test/num_examples=95000000, total_duration=16628.753141, train/loss=0.128973, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:42:24.317687 139646180759296 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.016460096463561058, loss=0.12656481564044952
I0306 04:43:56.070237 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:46:13.504395 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:46:19.896076 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:46:27.338546 139827085571904 submission_runner.py:413] Time since start: 16900.21s, 	Step: 9111, 	{'train/loss': 0.12821222813624256, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6407.637455701828, 'total_duration': 16900.20977807045, 'accumulated_submission_time': 6407.637455701828, 'accumulated_eval_time': 10490.974660634995, 'accumulated_logging_time': 1.2982261180877686}
I0306 04:46:27.355605 139645962680064 logging_writer.py:48] [9111] accumulated_eval_time=10490.974661, accumulated_logging_time=1.298226, accumulated_submission_time=6407.637456, global_step=9111, preemption_count=0, score=6407.637456, test/loss=0.132065, test/num_examples=95000000, total_duration=16900.209778, train/loss=0.128212, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:48:27.401201 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:50:40.192749 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:50:46.543605 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:50:54.034137 139827085571904 submission_runner.py:413] Time since start: 17166.91s, 	Step: 9280, 	{'train/loss': 0.12863390649077278, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6527.667032718658, 'total_duration': 17166.905377149582, 'accumulated_submission_time': 6527.667032718658, 'accumulated_eval_time': 10637.607573270798, 'accumulated_logging_time': 1.325711727142334}
I0306 04:50:54.053135 139646180759296 logging_writer.py:48] [9280] accumulated_eval_time=10637.607573, accumulated_logging_time=1.325712, accumulated_submission_time=6527.667033, global_step=9280, preemption_count=0, score=6527.667033, test/loss=0.132065, test/num_examples=95000000, total_duration=17166.905377, train/loss=0.128634, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:52:54.596465 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:55:15.153033 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:55:21.517490 139827085571904 spec.py:349] Evaluating on the test split.
I0306 04:55:29.076831 139827085571904 submission_runner.py:413] Time since start: 17441.95s, 	Step: 9453, 	{'train/loss': 0.1278467817501452, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6648.197132349014, 'total_duration': 17441.948035001755, 'accumulated_submission_time': 6648.197132349014, 'accumulated_eval_time': 10792.087891101837, 'accumulated_logging_time': 1.3522124290466309}
I0306 04:55:29.106784 139645962680064 logging_writer.py:48] [9453] accumulated_eval_time=10792.087891, accumulated_logging_time=1.352212, accumulated_submission_time=6648.197132, global_step=9453, preemption_count=0, score=6648.197132, test/loss=0.132065, test/num_examples=95000000, total_duration=17441.948035, train/loss=0.127847, validation/loss=0.129700, validation/num_examples=83274637
I0306 04:55:49.277279 139646180759296 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.00897638127207756, loss=0.13062170147895813
I0306 04:57:29.523470 139827085571904 spec.py:321] Evaluating on the training split.
I0306 04:59:46.739895 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 04:59:53.120302 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:00:00.587965 139827085571904 submission_runner.py:413] Time since start: 17713.46s, 	Step: 9622, 	{'train/loss': 0.12962097107614362, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6768.595697641373, 'total_duration': 17713.459176540375, 'accumulated_submission_time': 6768.595697641373, 'accumulated_eval_time': 10943.152333021164, 'accumulated_logging_time': 1.3946888446807861}
I0306 05:00:00.610185 139645962680064 logging_writer.py:48] [9622] accumulated_eval_time=10943.152333, accumulated_logging_time=1.394689, accumulated_submission_time=6768.595698, global_step=9622, preemption_count=0, score=6768.595698, test/loss=0.132065, test/num_examples=95000000, total_duration=17713.459177, train/loss=0.129621, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:02:01.091691 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:04:14.365668 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:04:20.770667 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:04:28.279537 139827085571904 submission_runner.py:413] Time since start: 17981.15s, 	Step: 9795, 	{'train/loss': 0.12907600880793804, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6889.0643355846405, 'total_duration': 17981.150763750076, 'accumulated_submission_time': 6889.0643355846405, 'accumulated_eval_time': 11090.340146064758, 'accumulated_logging_time': 1.4239428043365479}
I0306 05:04:28.297380 139646180759296 logging_writer.py:48] [9795] accumulated_eval_time=11090.340146, accumulated_logging_time=1.423943, accumulated_submission_time=6889.064336, global_step=9795, preemption_count=0, score=6889.064336, test/loss=0.132065, test/num_examples=95000000, total_duration=17981.150764, train/loss=0.129076, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:06:29.170414 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:08:42.538233 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:08:48.918172 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:08:56.348703 139827085571904 submission_runner.py:413] Time since start: 18249.22s, 	Step: 9968, 	{'train/loss': 0.12683945167926872, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7009.923266887665, 'total_duration': 18249.219930887222, 'accumulated_submission_time': 7009.923266887665, 'accumulated_eval_time': 11237.51840376854, 'accumulated_logging_time': 1.4502079486846924}
I0306 05:08:56.364650 139645962680064 logging_writer.py:48] [9968] accumulated_eval_time=11237.518404, accumulated_logging_time=1.450208, accumulated_submission_time=7009.923267, global_step=9968, preemption_count=0, score=7009.923267, test/loss=0.132065, test/num_examples=95000000, total_duration=18249.219931, train/loss=0.126839, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:09:02.695719 139646180759296 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.014751309528946877, loss=0.12516407668590546
I0306 05:10:56.883882 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:13:09.644026 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:13:16.019344 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:13:23.482197 139827085571904 submission_runner.py:413] Time since start: 18516.35s, 	Step: 10139, 	{'train/loss': 0.13129427424579296, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7130.429570674896, 'total_duration': 18516.353434562683, 'accumulated_submission_time': 7130.429570674896, 'accumulated_eval_time': 11384.116703271866, 'accumulated_logging_time': 1.4732162952423096}
I0306 05:13:23.497698 139645962680064 logging_writer.py:48] [10139] accumulated_eval_time=11384.116703, accumulated_logging_time=1.473216, accumulated_submission_time=7130.429571, global_step=10139, preemption_count=0, score=7130.429571, test/loss=0.132065, test/num_examples=95000000, total_duration=18516.353435, train/loss=0.131294, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:15:23.557919 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:17:38.315552 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:17:44.731330 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:17:52.296820 139827085571904 submission_runner.py:413] Time since start: 18785.17s, 	Step: 10306, 	{'train/loss': 0.12823956619081256, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7250.475865602493, 'total_duration': 18785.168044805527, 'accumulated_submission_time': 7250.475865602493, 'accumulated_eval_time': 11532.855570793152, 'accumulated_logging_time': 1.4970321655273438}
I0306 05:17:52.315000 139646180759296 logging_writer.py:48] [10306] accumulated_eval_time=11532.855571, accumulated_logging_time=1.497032, accumulated_submission_time=7250.475866, global_step=10306, preemption_count=0, score=7250.475866, test/loss=0.132065, test/num_examples=95000000, total_duration=18785.168045, train/loss=0.128240, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:19:52.572244 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:22:07.019548 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:22:13.379309 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:22:20.861098 139827085571904 submission_runner.py:413] Time since start: 19053.73s, 	Step: 10476, 	{'train/loss': 0.12600934899078226, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7370.720200300217, 'total_duration': 19053.732333660126, 'accumulated_submission_time': 7370.720200300217, 'accumulated_eval_time': 11681.144396066666, 'accumulated_logging_time': 1.5223846435546875}
I0306 05:22:20.880782 139645962680064 logging_writer.py:48] [10476] accumulated_eval_time=11681.144396, accumulated_logging_time=1.522385, accumulated_submission_time=7370.720200, global_step=10476, preemption_count=0, score=7370.720200, test/loss=0.132065, test/num_examples=95000000, total_duration=19053.732334, train/loss=0.126009, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:22:23.259544 139646180759296 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.014951208606362343, loss=0.12195929139852524
I0306 05:24:20.953387 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:26:34.812789 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:26:41.206398 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:26:48.703611 139827085571904 submission_runner.py:413] Time since start: 19321.57s, 	Step: 10648, 	{'train/loss': 0.12598176876891334, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7490.779628753662, 'total_duration': 19321.574851989746, 'accumulated_submission_time': 7490.779628753662, 'accumulated_eval_time': 11828.894605636597, 'accumulated_logging_time': 1.5495703220367432}
I0306 05:26:48.719120 139645962680064 logging_writer.py:48] [10648] accumulated_eval_time=11828.894606, accumulated_logging_time=1.549570, accumulated_submission_time=7490.779629, global_step=10648, preemption_count=0, score=7490.779629, test/loss=0.132065, test/num_examples=95000000, total_duration=19321.574852, train/loss=0.125982, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:26:50.353481 139827085571904 spec.py:321] Evaluating on the training split.
I0306 05:31:01.369568 139827085571904 spec.py:333] Evaluating on the validation split.
I0306 05:31:07.603614 139827085571904 spec.py:349] Evaluating on the test split.
I0306 05:31:15.139382 139827085571904 submission_runner.py:413] Time since start: 19588.01s, 	Step: 10666, 	{'train/loss': 0.12536793839444155, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7492.406150817871, 'total_duration': 19588.010620117188, 'accumulated_submission_time': 7492.406150817871, 'accumulated_eval_time': 12093.680482625961, 'accumulated_logging_time': 1.5720419883728027}
I0306 05:31:15.156825 139646180759296 logging_writer.py:48] [10666] accumulated_eval_time=12093.680483, accumulated_logging_time=1.572042, accumulated_submission_time=7492.406151, global_step=10666, preemption_count=0, score=7492.406151, test/loss=0.132065, test/num_examples=95000000, total_duration=19588.010620, train/loss=0.125368, validation/loss=0.129700, validation/num_examples=83274637
I0306 05:31:15.173591 139645962680064 logging_writer.py:48] [10666] global_step=10666, preemption_count=0, score=7492.406151
I0306 05:31:18.080273 139827085571904 checkpoints.py:490] Saving checkpoint at step: 10666
I0306 05:31:42.967938 139827085571904 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1/checkpoint_10666
I0306 05:31:43.399462 139827085571904 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/criteo1tb_embed_init_jax/trial_1/checkpoint_10666.
I0306 05:31:43.546828 139827085571904 submission_runner.py:588] Tuning trial 1/1
I0306 05:31:43.547078 139827085571904 submission_runner.py:589] Hyperparameters: Hyperparameters(learning_rate=0.002517072211464665, beta1=0.9908351643533544, beta2=0.9859568907533993, warmup_steps=799, weight_decay=0.12274552870237089)
I0306 05:31:43.549617 139827085571904 submission_runner.py:590] Metrics: {'eval_results': [(1, {'train/loss': 6.109228727952489, 'validation/loss': 6.167542957887646, 'validation/num_examples': 83274637, 'test/loss': 6.0549652388157895, 'test/num_examples': 95000000, 'score': 20.095224142074585, 'total_duration': 802.123473405838, 'accumulated_submission_time': 20.095224142074585, 'accumulated_eval_time': 782.0281999111176, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (181, {'train/loss': 1.0292331924978293, 'validation/loss': 1.0355964892257652, 'validation/num_examples': 83274637, 'test/loss': 1.0667826981085526, 'test/num_examples': 95000000, 'score': 140.2082736492157, 'total_duration': 1478.591975927353, 'accumulated_submission_time': 140.2082736492157, 'accumulated_eval_time': 1338.3536128997803, 'accumulated_logging_time': 0.025177478790283203, 'global_step': 181, 'preemption_count': 0}), (360, {'train/loss': 0.14613674374871283, 'validation/loss': 0.14416453528041198, 'validation/num_examples': 83274637, 'test/loss': 0.1475941744037829, 'test/num_examples': 95000000, 'score': 260.5102393627167, 'total_duration': 2143.8023307323456, 'accumulated_submission_time': 260.5102393627167, 'accumulated_eval_time': 1883.2365686893463, 'accumulated_logging_time': 0.0453038215637207, 'global_step': 360, 'preemption_count': 0}), (543, {'train/loss': 0.1408584550866541, 'validation/loss': 0.1370924884480433, 'validation/num_examples': 83274637, 'test/loss': 0.14047363409745064, 'test/num_examples': 95000000, 'score': 381.20074915885925, 'total_duration': 2795.7803695201874, 'accumulated_submission_time': 381.20074915885925, 'accumulated_eval_time': 2414.4990158081055, 'accumulated_logging_time': 0.06494522094726562, 'global_step': 543, 'preemption_count': 0}), (719, {'train/loss': 0.1346092497777639, 'validation/loss': 0.13442303210670256, 'validation/num_examples': 83274637, 'test/loss': 0.1371794584189967, 'test/num_examples': 95000000, 'score': 501.219598531723, 'total_duration': 3421.111014842987, 'accumulated_submission_time': 501.219598531723, 'accumulated_eval_time': 2919.7799072265625, 'accumulated_logging_time': 0.0905008316040039, 'global_step': 719, 'preemption_count': 0}), (898, {'train/loss': 0.13271532685689205, 'validation/loss': 0.13345795828866838, 'validation/num_examples': 83274637, 'test/loss': 0.13580814927014803, 'test/num_examples': 95000000, 'score': 621.8137724399567, 'total_duration': 3981.2682223320007, 'accumulated_submission_time': 621.8137724399567, 'accumulated_eval_time': 3359.313163995743, 'accumulated_logging_time': 0.1148374080657959, 'global_step': 898, 'preemption_count': 0}), (1075, {'train/loss': 0.134810209133715, 'validation/loss': 0.13302400807072867, 'validation/num_examples': 83274637, 'test/loss': 0.13570753902138158, 'test/num_examples': 95000000, 'score': 742.4888572692871, 'total_duration': 4426.727645158768, 'accumulated_submission_time': 742.4888572692871, 'accumulated_eval_time': 3684.0718517303467, 'accumulated_logging_time': 0.13515233993530273, 'global_step': 1075, 'preemption_count': 0}), (1246, {'train/loss': 0.1316567547853638, 'validation/loss': 0.1324533089078491, 'validation/num_examples': 83274637, 'test/loss': 0.13509689385279605, 'test/num_examples': 95000000, 'score': 862.8673768043518, 'total_duration': 4673.351754188538, 'accumulated_submission_time': 862.8673768043518, 'accumulated_eval_time': 3810.291472196579, 'accumulated_logging_time': 0.15576720237731934, 'global_step': 1246, 'preemption_count': 0}), (1420, {'train/loss': 0.13107645994274872, 'validation/loss': 0.13247138904895497, 'validation/num_examples': 83274637, 'test/loss': 0.13497659274259868, 'test/num_examples': 95000000, 'score': 983.6590650081635, 'total_duration': 4917.13800907135, 'accumulated_submission_time': 983.6590650081635, 'accumulated_eval_time': 3933.256739139557, 'accumulated_logging_time': 0.17933344841003418, 'global_step': 1420, 'preemption_count': 0}), (1593, {'train/loss': 0.1317302388308933, 'validation/loss': 0.1320736700381834, 'validation/num_examples': 83274637, 'test/loss': 0.1345820564555921, 'test/num_examples': 95000000, 'score': 1104.4129085540771, 'total_duration': 5160.142123937607, 'accumulated_submission_time': 1104.4129085540771, 'accumulated_eval_time': 4055.4788019657135, 'accumulated_logging_time': 0.20142126083374023, 'global_step': 1593, 'preemption_count': 0}), (1763, {'train/loss': 0.13105140546770216, 'validation/loss': 0.13217193276575015, 'validation/num_examples': 83274637, 'test/loss': 0.13481217767269738, 'test/num_examples': 95000000, 'score': 1225.1209287643433, 'total_duration': 5401.911085367203, 'accumulated_submission_time': 1225.1209287643433, 'accumulated_eval_time': 4176.51301908493, 'accumulated_logging_time': 0.22223329544067383, 'global_step': 1763, 'preemption_count': 0}), (1937, {'train/loss': 0.13002524792023426, 'validation/loss': 0.13151014367751013, 'validation/num_examples': 83274637, 'test/loss': 0.13409731219161183, 'test/num_examples': 95000000, 'score': 1345.2244369983673, 'total_duration': 5643.257565021515, 'accumulated_submission_time': 1345.2244369983673, 'accumulated_eval_time': 4297.729638576508, 'accumulated_logging_time': 0.2428886890411377, 'global_step': 1937, 'preemption_count': 0}), (2106, {'train/loss': 0.13063489149014154, 'validation/loss': 0.13158152448626104, 'validation/num_examples': 83274637, 'test/loss': 0.13406168797286183, 'test/num_examples': 95000000, 'score': 1465.9347670078278, 'total_duration': 5901.933885574341, 'accumulated_submission_time': 1465.9347670078278, 'accumulated_eval_time': 4435.667479753494, 'accumulated_logging_time': 0.2652931213378906, 'global_step': 2106, 'preemption_count': 0}), (2280, {'train/loss': 0.12992139915062947, 'validation/loss': 0.1314656815165703, 'validation/num_examples': 83274637, 'test/loss': 0.1339436931743421, 'test/num_examples': 95000000, 'score': 1586.92808842659, 'total_duration': 6166.037005186081, 'accumulated_submission_time': 1586.92808842659, 'accumulated_eval_time': 4578.74246764183, 'accumulated_logging_time': 0.29433465003967285, 'global_step': 2280, 'preemption_count': 0}), (2452, {'train/loss': 0.1282057983320464, 'validation/loss': 0.1313638672405741, 'validation/num_examples': 83274637, 'test/loss': 0.1339249580180921, 'test/num_examples': 95000000, 'score': 1707.3107225894928, 'total_duration': 6429.408533811569, 'accumulated_submission_time': 1707.3107225894928, 'accumulated_eval_time': 4721.699376344681, 'accumulated_logging_time': 0.32056307792663574, 'global_step': 2452, 'preemption_count': 0}), (2629, {'train/loss': 0.12998447534423205, 'validation/loss': 0.13116356826816608, 'validation/num_examples': 83274637, 'test/loss': 0.13356058246299343, 'test/num_examples': 95000000, 'score': 1827.946754693985, 'total_duration': 6696.769212245941, 'accumulated_submission_time': 1827.946754693985, 'accumulated_eval_time': 4868.3942856788635, 'accumulated_logging_time': 0.3444957733154297, 'global_step': 2629, 'preemption_count': 0}), (2797, {'train/loss': 0.1297653577050323, 'validation/loss': 0.1309964910707146, 'validation/num_examples': 83274637, 'test/loss': 0.13345417218338815, 'test/num_examples': 95000000, 'score': 1949.261926651001, 'total_duration': 6960.97970700264, 'accumulated_submission_time': 1949.261926651001, 'accumulated_eval_time': 5011.2578637599945, 'accumulated_logging_time': 0.3702840805053711, 'global_step': 2797, 'preemption_count': 0}), (2967, {'train/loss': 0.1275362218232275, 'validation/loss': 0.13100985742288496, 'validation/num_examples': 83274637, 'test/loss': 0.1332381970703125, 'test/num_examples': 95000000, 'score': 2070.1923229694366, 'total_duration': 7229.499065876007, 'accumulated_submission_time': 2070.1923229694366, 'accumulated_eval_time': 5158.819734811783, 'accumulated_logging_time': 0.3914461135864258, 'global_step': 2967, 'preemption_count': 0}), (3136, {'train/loss': 0.12966926681732982, 'validation/loss': 0.13062459062040102, 'validation/num_examples': 83274637, 'test/loss': 0.1330101122944079, 'test/num_examples': 95000000, 'score': 2190.217220544815, 'total_duration': 7495.405162334442, 'accumulated_submission_time': 2190.217220544815, 'accumulated_eval_time': 5304.670695304871, 'accumulated_logging_time': 0.4160161018371582, 'global_step': 3136, 'preemption_count': 0}), (3305, {'train/loss': 0.1304276871418803, 'validation/loss': 0.13068166306972315, 'validation/num_examples': 83274637, 'test/loss': 0.1332013373046875, 'test/num_examples': 95000000, 'score': 2310.7342343330383, 'total_duration': 7761.510757923126, 'accumulated_submission_time': 2310.7342343330383, 'accumulated_eval_time': 5450.231810331345, 'accumulated_logging_time': 0.437877893447876, 'global_step': 3305, 'preemption_count': 0}), (3478, {'train/loss': 0.1300596429866815, 'validation/loss': 0.13057972373689242, 'validation/num_examples': 83274637, 'test/loss': 0.13286286328125, 'test/num_examples': 95000000, 'score': 2430.834977388382, 'total_duration': 8027.666455030441, 'accumulated_submission_time': 2430.834977388382, 'accumulated_eval_time': 5596.258558034897, 'accumulated_logging_time': 0.46037936210632324, 'global_step': 3478, 'preemption_count': 0}), (3649, {'train/loss': 0.1285871615012487, 'validation/loss': 0.13035082751246338, 'validation/num_examples': 83274637, 'test/loss': 0.13268681461759868, 'test/num_examples': 95000000, 'score': 2551.807795524597, 'total_duration': 8292.085990667343, 'accumulated_submission_time': 2551.807795524597, 'accumulated_eval_time': 5739.673795938492, 'accumulated_logging_time': 0.4860258102416992, 'global_step': 3649, 'preemption_count': 0}), (3819, {'train/loss': 0.1275556819900027, 'validation/loss': 0.13032559703810237, 'validation/num_examples': 83274637, 'test/loss': 0.13265292453741775, 'test/num_examples': 95000000, 'score': 2673.0149159431458, 'total_duration': 8559.199102163315, 'accumulated_submission_time': 2673.0149159431458, 'accumulated_eval_time': 5885.547197341919, 'accumulated_logging_time': 0.5128910541534424, 'global_step': 3819, 'preemption_count': 0}), (3989, {'train/loss': 0.12926367576579628, 'validation/loss': 0.13040773695634664, 'validation/num_examples': 83274637, 'test/loss': 0.13273741698190789, 'test/num_examples': 95000000, 'score': 2793.950444459915, 'total_duration': 8827.959662914276, 'accumulated_submission_time': 2793.950444459915, 'accumulated_eval_time': 6033.336914777756, 'accumulated_logging_time': 0.5424618721008301, 'global_step': 3989, 'preemption_count': 0}), (4161, {'train/loss': 0.1298518533226829, 'validation/loss': 0.13055444278948042, 'validation/num_examples': 83274637, 'test/loss': 0.13287225047286183, 'test/num_examples': 95000000, 'score': 2914.198286294937, 'total_duration': 9095.024054288864, 'accumulated_submission_time': 2914.198286294937, 'accumulated_eval_time': 6180.116861343384, 'accumulated_logging_time': 0.5731680393218994, 'global_step': 4161, 'preemption_count': 0}), (4335, {'train/loss': 0.12814454279793133, 'validation/loss': 0.13028338416458662, 'validation/num_examples': 83274637, 'test/loss': 0.13254378745888157, 'test/num_examples': 95000000, 'score': 3034.7467846870422, 'total_duration': 9368.880550384521, 'accumulated_submission_time': 3034.7467846870422, 'accumulated_eval_time': 6333.396206855774, 'accumulated_logging_time': 0.5960559844970703, 'global_step': 4335, 'preemption_count': 0}), (4505, {'train/loss': 0.12964003481580028, 'validation/loss': 0.13045328682091703, 'validation/num_examples': 83274637, 'test/loss': 0.13275666548108553, 'test/num_examples': 95000000, 'score': 3155.732577085495, 'total_duration': 9640.360978126526, 'accumulated_submission_time': 3155.732577085495, 'accumulated_eval_time': 6483.859271764755, 'accumulated_logging_time': 0.6221106052398682, 'global_step': 4505, 'preemption_count': 0}), (4674, {'train/loss': 0.12741434199255217, 'validation/loss': 0.1302821550801236, 'validation/num_examples': 83274637, 'test/loss': 0.13259115851151315, 'test/num_examples': 95000000, 'score': 3276.329290866852, 'total_duration': 9911.314411640167, 'accumulated_submission_time': 3276.329290866852, 'accumulated_eval_time': 6634.179695606232, 'accumulated_logging_time': 0.6527330875396729, 'global_step': 4674, 'preemption_count': 0}), (4842, {'train/loss': 0.13040790589725446, 'validation/loss': 0.13007074959727835, 'validation/num_examples': 83274637, 'test/loss': 0.13234405121299342, 'test/num_examples': 95000000, 'score': 3396.4643602371216, 'total_duration': 10174.89155459404, 'accumulated_submission_time': 3396.4643602371216, 'accumulated_eval_time': 6777.589445590973, 'accumulated_logging_time': 0.6794803142547607, 'global_step': 4842, 'preemption_count': 0}), (5011, {'train/loss': 0.12904802611413993, 'validation/loss': 0.12994724269820293, 'validation/num_examples': 83274637, 'test/loss': 0.13235331593338817, 'test/num_examples': 95000000, 'score': 3516.81751871109, 'total_duration': 10447.511914730072, 'accumulated_submission_time': 3516.81751871109, 'accumulated_eval_time': 6929.828325033188, 'accumulated_logging_time': 0.7022745609283447, 'global_step': 5011, 'preemption_count': 0}), (5183, {'train/loss': 0.12825895513191163, 'validation/loss': 0.13013825856950298, 'validation/num_examples': 83274637, 'test/loss': 0.13252107764185855, 'test/num_examples': 95000000, 'score': 3636.9511404037476, 'total_duration': 10718.343326330185, 'accumulated_submission_time': 3636.9511404037476, 'accumulated_eval_time': 7080.494361877441, 'accumulated_logging_time': 0.728309154510498, 'global_step': 5183, 'preemption_count': 0}), (5357, {'train/loss': 0.1300322749423531, 'validation/loss': 0.12997396846015372, 'validation/num_examples': 83274637, 'test/loss': 0.1323541123149671, 'test/num_examples': 95000000, 'score': 3757.4322624206543, 'total_duration': 10992.948665618896, 'accumulated_submission_time': 3757.4322624206543, 'accumulated_eval_time': 7234.588553190231, 'accumulated_logging_time': 0.7525970935821533, 'global_step': 5357, 'preemption_count': 0}), (5527, {'train/loss': 0.1288842977311626, 'validation/loss': 0.1300954086848046, 'validation/num_examples': 83274637, 'test/loss': 0.13250781140008225, 'test/num_examples': 95000000, 'score': 3878.0917840003967, 'total_duration': 11264.135138750076, 'accumulated_submission_time': 3878.0917840003967, 'accumulated_eval_time': 7385.087574720383, 'accumulated_logging_time': 0.7748117446899414, 'global_step': 5527, 'preemption_count': 0}), (5696, {'train/loss': 0.12639998635218577, 'validation/loss': 0.12985476401341142, 'validation/num_examples': 83274637, 'test/loss': 0.13228717486636513, 'test/num_examples': 95000000, 'score': 3998.095972299576, 'total_duration': 11533.912237644196, 'accumulated_submission_time': 3998.095972299576, 'accumulated_eval_time': 7534.83292889595, 'accumulated_logging_time': 0.7966806888580322, 'global_step': 5696, 'preemption_count': 0}), (5872, {'train/loss': 0.1278943569405274, 'validation/loss': 0.1298379614596819, 'validation/num_examples': 83274637, 'test/loss': 0.13224980531455593, 'test/num_examples': 95000000, 'score': 4118.5652804374695, 'total_duration': 11800.842785358429, 'accumulated_submission_time': 4118.5652804374695, 'accumulated_eval_time': 7681.263945817947, 'accumulated_logging_time': 0.8210937976837158, 'global_step': 5872, 'preemption_count': 0}), (6041, {'train/loss': 0.12892879672207921, 'validation/loss': 0.12981573962009585, 'validation/num_examples': 83274637, 'test/loss': 0.13214697192639802, 'test/num_examples': 95000000, 'score': 4238.614892244339, 'total_duration': 12067.472588300705, 'accumulated_submission_time': 4238.614892244339, 'accumulated_eval_time': 7827.815846443176, 'accumulated_logging_time': 0.843940258026123, 'global_step': 6041, 'preemption_count': 0}), (6210, {'train/loss': 0.128617396097888, 'validation/loss': 0.13005727573188042, 'validation/num_examples': 83274637, 'test/loss': 0.13254092358141448, 'test/num_examples': 95000000, 'score': 4358.745446205139, 'total_duration': 12334.08301281929, 'accumulated_submission_time': 4358.745446205139, 'accumulated_eval_time': 7974.265251874924, 'accumulated_logging_time': 0.868908166885376, 'global_step': 6210, 'preemption_count': 0}), (6379, {'train/loss': 0.12790960809157328, 'validation/loss': 0.12991972480018135, 'validation/num_examples': 83274637, 'test/loss': 0.1323423482113487, 'test/num_examples': 95000000, 'score': 4479.70954990387, 'total_duration': 12602.78704380989, 'accumulated_submission_time': 4479.70954990387, 'accumulated_eval_time': 8121.973530769348, 'accumulated_logging_time': 0.89485764503479, 'global_step': 6379, 'preemption_count': 0}), (6552, {'train/loss': 0.13030627763496255, 'validation/loss': 0.1302447102212376, 'validation/num_examples': 83274637, 'test/loss': 0.13273242744654606, 'test/num_examples': 95000000, 'score': 4600.250163555145, 'total_duration': 12870.417716026306, 'accumulated_submission_time': 4600.250163555145, 'accumulated_eval_time': 8269.034720659256, 'accumulated_logging_time': 0.9180853366851807, 'global_step': 6552, 'preemption_count': 0}), (6720, {'train/loss': 0.12841027155049942, 'validation/loss': 0.1297639618219681, 'validation/num_examples': 83274637, 'test/loss': 0.13214559021381578, 'test/num_examples': 95000000, 'score': 4720.76885509491, 'total_duration': 13142.409147262573, 'accumulated_submission_time': 4720.76885509491, 'accumulated_eval_time': 8420.47728729248, 'accumulated_logging_time': 0.9425745010375977, 'global_step': 6720, 'preemption_count': 0}), (6896, {'train/loss': 0.12687208334792335, 'validation/loss': 0.12979370503740534, 'validation/num_examples': 83274637, 'test/loss': 0.13210701903782895, 'test/num_examples': 95000000, 'score': 4841.014019012451, 'total_duration': 13411.612874031067, 'accumulated_submission_time': 4841.014019012451, 'accumulated_eval_time': 8569.393094301224, 'accumulated_logging_time': 0.979358434677124, 'global_step': 6896, 'preemption_count': 0}), (7067, {'train/loss': 0.13029275867361692, 'validation/loss': 0.12980142070635806, 'validation/num_examples': 83274637, 'test/loss': 0.1321848359375, 'test/num_examples': 95000000, 'score': 4961.712739467621, 'total_duration': 13679.959724903107, 'accumulated_submission_time': 4961.712739467621, 'accumulated_eval_time': 8717.011936903, 'accumulated_logging_time': 1.0031108856201172, 'global_step': 7067, 'preemption_count': 0}), (7237, {'train/loss': 0.12764344767392058, 'validation/loss': 0.12966503764412987, 'validation/num_examples': 83274637, 'test/loss': 0.13198324111842105, 'test/num_examples': 95000000, 'score': 5081.772540807724, 'total_duration': 13951.153629541397, 'accumulated_submission_time': 5081.772540807724, 'accumulated_eval_time': 8868.114108800888, 'accumulated_logging_time': 1.0293889045715332, 'global_step': 7237, 'preemption_count': 0}), (7406, {'train/loss': 0.12736902643674575, 'validation/loss': 0.12972282773955532, 'validation/num_examples': 83274637, 'test/loss': 0.1319949220497533, 'test/num_examples': 95000000, 'score': 5201.973747730255, 'total_duration': 14218.333938837051, 'accumulated_submission_time': 5201.973747730255, 'accumulated_eval_time': 9015.061503648758, 'accumulated_logging_time': 1.0553011894226074, 'global_step': 7406, 'preemption_count': 0}), (7580, {'train/loss': 0.12958810197294884, 'validation/loss': 0.1296612333082731, 'validation/num_examples': 83274637, 'test/loss': 0.13196664583675988, 'test/num_examples': 95000000, 'score': 5322.135422706604, 'total_duration': 14487.41438627243, 'accumulated_submission_time': 5322.135422706604, 'accumulated_eval_time': 9163.952250003815, 'accumulated_logging_time': 1.0776252746582031, 'global_step': 7580, 'preemption_count': 0}), (7750, {'train/loss': 0.12697161331116777, 'validation/loss': 0.1296560050319553, 'validation/num_examples': 83274637, 'test/loss': 0.13196843414884868, 'test/num_examples': 95000000, 'score': 5443.70708322525, 'total_duration': 14754.494647026062, 'accumulated_submission_time': 5443.70708322525, 'accumulated_eval_time': 9309.432745933533, 'accumulated_logging_time': 1.1001296043395996, 'global_step': 7750, 'preemption_count': 0}), (7925, {'train/loss': 0.1293157176963938, 'validation/loss': 0.1297070415423276, 'validation/num_examples': 83274637, 'test/loss': 0.13207495669202302, 'test/num_examples': 95000000, 'score': 5564.062667131424, 'total_duration': 15025.216032981873, 'accumulated_submission_time': 5564.062667131424, 'accumulated_eval_time': 9459.76985168457, 'accumulated_logging_time': 1.1230103969573975, 'global_step': 7925, 'preemption_count': 0}), (8094, {'train/loss': 0.129429170873555, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5684.995863676071, 'total_duration': 15293.402150630951, 'accumulated_submission_time': 5684.995863676071, 'accumulated_eval_time': 9606.992738962173, 'accumulated_logging_time': 1.147623062133789, 'global_step': 8094, 'preemption_count': 0}), (8267, {'train/loss': 0.12804579950353634, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5805.917500972748, 'total_duration': 15553.625880718231, 'accumulated_submission_time': 5805.917500972748, 'accumulated_eval_time': 9746.265315294266, 'accumulated_logging_time': 1.171464204788208, 'global_step': 8267, 'preemption_count': 0}), (8437, {'train/loss': 0.12877348243440473, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 5926.237798452377, 'total_duration': 15820.95489358902, 'accumulated_submission_time': 5926.237798452377, 'accumulated_eval_time': 9893.24407339096, 'accumulated_logging_time': 1.1957948207855225, 'global_step': 8437, 'preemption_count': 0}), (8605, {'train/loss': 0.13002369707485414, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6046.685829162598, 'total_duration': 16084.626545190811, 'accumulated_submission_time': 6046.685829162598, 'accumulated_eval_time': 10036.438574790955, 'accumulated_logging_time': 1.2192978858947754, 'global_step': 8605, 'preemption_count': 0}), (8775, {'train/loss': 0.12782398639422543, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6167.259372472763, 'total_duration': 16356.976807832718, 'accumulated_submission_time': 6167.259372472763, 'accumulated_eval_time': 10188.185682058334, 'accumulated_logging_time': 1.243321180343628, 'global_step': 8775, 'preemption_count': 0}), (8943, {'train/loss': 0.1289729635295628, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6287.479074716568, 'total_duration': 16628.75314092636, 'accumulated_submission_time': 6287.479074716568, 'accumulated_eval_time': 10339.706386566162, 'accumulated_logging_time': 1.273768424987793, 'global_step': 8943, 'preemption_count': 0}), (9111, {'train/loss': 0.12821222813624256, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6407.637455701828, 'total_duration': 16900.20977807045, 'accumulated_submission_time': 6407.637455701828, 'accumulated_eval_time': 10490.974660634995, 'accumulated_logging_time': 1.2982261180877686, 'global_step': 9111, 'preemption_count': 0}), (9280, {'train/loss': 0.12863390649077278, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6527.667032718658, 'total_duration': 17166.905377149582, 'accumulated_submission_time': 6527.667032718658, 'accumulated_eval_time': 10637.607573270798, 'accumulated_logging_time': 1.325711727142334, 'global_step': 9280, 'preemption_count': 0}), (9453, {'train/loss': 0.1278467817501452, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6648.197132349014, 'total_duration': 17441.948035001755, 'accumulated_submission_time': 6648.197132349014, 'accumulated_eval_time': 10792.087891101837, 'accumulated_logging_time': 1.3522124290466309, 'global_step': 9453, 'preemption_count': 0}), (9622, {'train/loss': 0.12962097107614362, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6768.595697641373, 'total_duration': 17713.459176540375, 'accumulated_submission_time': 6768.595697641373, 'accumulated_eval_time': 10943.152333021164, 'accumulated_logging_time': 1.3946888446807861, 'global_step': 9622, 'preemption_count': 0}), (9795, {'train/loss': 0.12907600880793804, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 6889.0643355846405, 'total_duration': 17981.150763750076, 'accumulated_submission_time': 6889.0643355846405, 'accumulated_eval_time': 11090.340146064758, 'accumulated_logging_time': 1.4239428043365479, 'global_step': 9795, 'preemption_count': 0}), (9968, {'train/loss': 0.12683945167926872, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7009.923266887665, 'total_duration': 18249.219930887222, 'accumulated_submission_time': 7009.923266887665, 'accumulated_eval_time': 11237.51840376854, 'accumulated_logging_time': 1.4502079486846924, 'global_step': 9968, 'preemption_count': 0}), (10139, {'train/loss': 0.13129427424579296, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7130.429570674896, 'total_duration': 18516.353434562683, 'accumulated_submission_time': 7130.429570674896, 'accumulated_eval_time': 11384.116703271866, 'accumulated_logging_time': 1.4732162952423096, 'global_step': 10139, 'preemption_count': 0}), (10306, {'train/loss': 0.12823956619081256, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7250.475865602493, 'total_duration': 18785.168044805527, 'accumulated_submission_time': 7250.475865602493, 'accumulated_eval_time': 11532.855570793152, 'accumulated_logging_time': 1.4970321655273438, 'global_step': 10306, 'preemption_count': 0}), (10476, {'train/loss': 0.12600934899078226, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7370.720200300217, 'total_duration': 19053.732333660126, 'accumulated_submission_time': 7370.720200300217, 'accumulated_eval_time': 11681.144396066666, 'accumulated_logging_time': 1.5223846435546875, 'global_step': 10476, 'preemption_count': 0}), (10648, {'train/loss': 0.12598176876891334, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7490.779628753662, 'total_duration': 19321.574851989746, 'accumulated_submission_time': 7490.779628753662, 'accumulated_eval_time': 11828.894605636597, 'accumulated_logging_time': 1.5495703220367432, 'global_step': 10648, 'preemption_count': 0}), (10666, {'train/loss': 0.12536793839444155, 'validation/loss': 0.12970039608030653, 'validation/num_examples': 83274637, 'test/loss': 0.13206532890625, 'test/num_examples': 95000000, 'score': 7492.406150817871, 'total_duration': 19588.010620117188, 'accumulated_submission_time': 7492.406150817871, 'accumulated_eval_time': 12093.680482625961, 'accumulated_logging_time': 1.5720419883728027, 'global_step': 10666, 'preemption_count': 0})], 'global_step': 10666}
I0306 05:31:43.549802 139827085571904 submission_runner.py:591] Timing: 7492.406150817871
I0306 05:31:43.549864 139827085571904 submission_runner.py:593] Total number of evals: 64
I0306 05:31:43.549915 139827085571904 submission_runner.py:594] ====================
I0306 05:31:43.550134 139827085571904 submission_runner.py:678] Final criteo1tb_embed_init score: 7492.406150817871

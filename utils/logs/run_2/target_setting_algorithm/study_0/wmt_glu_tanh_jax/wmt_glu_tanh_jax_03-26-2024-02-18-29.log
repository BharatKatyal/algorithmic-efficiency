python3 submission_runner.py --framework=jax --workload=wmt_glu_tanh --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/wmt --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=505220837 --max_global_steps=133333 --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/wmt_glu_tanh/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/wmt_glu_tanh_jax_03-26-2024-02-18-29.log
I0326 02:18:52.400885 139718155032384 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax.
I0326 02:18:53.447655 139718155032384 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Interpreter Host
I0326 02:18:53.448479 139718155032384 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0326 02:18:53.448612 139718155032384 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0326 02:18:53.455463 139718155032384 submission_runner.py:554] Using RNG seed 505220837
I0326 02:18:54.625909 139718155032384 submission_runner.py:563] --- Tuning run 1/1 ---
I0326 02:18:54.626116 139718155032384 submission_runner.py:568] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1.
I0326 02:18:54.626283 139718155032384 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1/hparams.json.
I0326 02:18:54.828019 139718155032384 submission_runner.py:209] Initializing dataset.
I0326 02:18:54.839175 139718155032384 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0326 02:18:54.842896 139718155032384 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0326 02:18:55.006391 139718155032384 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0326 02:18:56.979602 139718155032384 submission_runner.py:220] Initializing model.
I0326 02:19:07.000296 139718155032384 submission_runner.py:262] Initializing optimizer.
I0326 02:19:08.029541 139718155032384 submission_runner.py:269] Initializing metrics bundle.
I0326 02:19:08.029739 139718155032384 submission_runner.py:287] Initializing checkpoint and logger.
I0326 02:19:08.030743 139718155032384 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1 with prefix checkpoint_
I0326 02:19:08.030876 139718155032384 submission_runner.py:307] Saving meta data to /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1/meta_data_0.json.
I0326 02:19:08.031066 139718155032384 logger_utils.py:257] Unable to record workload.train_mean information. Continuing without it.
I0326 02:19:08.031124 139718155032384 logger_utils.py:257] Unable to record workload.train_stddev information. Continuing without it.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0326 02:19:08.327714 139718155032384 logger_utils.py:220] Unable to record git information. Continuing without it.
I0326 02:19:08.606911 139718155032384 submission_runner.py:311] Saving flags to /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1/flags_0.json.
I0326 02:19:08.616819 139718155032384 submission_runner.py:321] Starting training loop.
I0326 02:19:49.065747 139553067226880 logging_writer.py:48] [0] global_step=0, grad_norm=4.8918280601501465, loss=11.333498001098633
I0326 02:19:49.082022 139718155032384 spec.py:321] Evaluating on the training split.
I0326 02:19:49.085318 139718155032384 dataset_info.py:578] Load dataset info from /data/wmt/wmt17_translate/de-en/1.0.0
I0326 02:19:49.087972 139718155032384 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0326 02:19:49.123761 139718155032384 logging_logger.py:49] Constructing tf.data.Dataset wmt17_translate for split train, from /data/wmt/wmt17_translate/de-en/1.0.0
I0326 02:19:57.085210 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 02:24:56.917853 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 02:24:56.921278 139718155032384 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0326 02:24:56.924790 139718155032384 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0326 02:24:56.957578 139718155032384 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split validation, from /data/wmt/wmt14_translate/de-en/1.0.0
I0326 02:25:04.178850 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 02:29:54.994634 139718155032384 spec.py:349] Evaluating on the test split.
I0326 02:29:54.997170 139718155032384 dataset_info.py:578] Load dataset info from /data/wmt/wmt14_translate/de-en/1.0.0
I0326 02:29:55.000148 139718155032384 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0326 02:29:55.032409 139718155032384 logging_logger.py:49] Constructing tf.data.Dataset wmt14_translate for split test, from /data/wmt/wmt14_translate/de-en/1.0.0
I0326 02:29:58.101046 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 02:34:48.952302 139718155032384 submission_runner.py:420] Time since start: 940.34s, 	Step: 1, 	{'train/accuracy': 0.0006544577772729099, 'train/loss': 11.358758926391602, 'train/bleu': 5.226550070522235e-11, 'validation/accuracy': 0.0004835649742744863, 'validation/loss': 11.346352577209473, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489946909249, 'test/loss': 11.35776138305664, 'test/bleu': 5.348545640066251e-10, 'test/num_examples': 3003, 'score': 40.46516227722168, 'total_duration': 940.3353931903839, 'accumulated_submission_time': 40.46516227722168, 'accumulated_eval_time': 899.8701910972595, 'accumulated_logging_time': 0}
I0326 02:34:48.970160 139548485990144 logging_writer.py:48] [1] accumulated_eval_time=899.870191, accumulated_logging_time=0, accumulated_submission_time=40.465162, global_step=1, preemption_count=0, score=40.465162, test/accuracy=0.000709, test/bleu=0.000000, test/loss=11.357761, test/num_examples=3003, total_duration=940.335393, train/accuracy=0.000654, train/bleu=0.000000, train/loss=11.358759, validation/accuracy=0.000484, validation/bleu=0.000000, validation/loss=11.346353, validation/num_examples=3000
I0326 02:34:49.380004 139548477597440 logging_writer.py:48] [1] global_step=1, grad_norm=4.9288530349731445, loss=11.349410057067871
I0326 02:34:49.786355 139548485990144 logging_writer.py:48] [2] global_step=2, grad_norm=4.956803321838379, loss=11.347359657287598
I0326 02:34:50.190822 139548477597440 logging_writer.py:48] [3] global_step=3, grad_norm=4.952202320098877, loss=11.348328590393066
I0326 02:34:50.596398 139548485990144 logging_writer.py:48] [4] global_step=4, grad_norm=4.851202011108398, loss=11.342730522155762
I0326 02:34:51.006967 139548477597440 logging_writer.py:48] [5] global_step=5, grad_norm=4.935704231262207, loss=11.34131908416748
I0326 02:34:51.416776 139548485990144 logging_writer.py:48] [6] global_step=6, grad_norm=5.059800148010254, loss=11.338921546936035
I0326 02:34:51.827189 139548477597440 logging_writer.py:48] [7] global_step=7, grad_norm=4.937539100646973, loss=11.348922729492188
I0326 02:34:52.233909 139548485990144 logging_writer.py:48] [8] global_step=8, grad_norm=4.960869312286377, loss=11.32913589477539
I0326 02:34:52.642562 139548477597440 logging_writer.py:48] [9] global_step=9, grad_norm=4.946764945983887, loss=11.321492195129395
I0326 02:34:53.053007 139548485990144 logging_writer.py:48] [10] global_step=10, grad_norm=5.000360012054443, loss=11.317741394042969
I0326 02:34:53.462776 139548477597440 logging_writer.py:48] [11] global_step=11, grad_norm=4.938836574554443, loss=11.313531875610352
I0326 02:34:53.874815 139548485990144 logging_writer.py:48] [12] global_step=12, grad_norm=4.959664821624756, loss=11.326831817626953
I0326 02:34:54.284283 139548477597440 logging_writer.py:48] [13] global_step=13, grad_norm=4.93353796005249, loss=11.315605163574219
I0326 02:34:54.693885 139548485990144 logging_writer.py:48] [14] global_step=14, grad_norm=4.931574821472168, loss=11.301753044128418
I0326 02:34:55.099287 139548477597440 logging_writer.py:48] [15] global_step=15, grad_norm=4.954270362854004, loss=11.28873348236084
I0326 02:34:55.509295 139548485990144 logging_writer.py:48] [16] global_step=16, grad_norm=4.888193607330322, loss=11.268339157104492
I0326 02:34:55.918222 139548477597440 logging_writer.py:48] [17] global_step=17, grad_norm=4.857300758361816, loss=11.281706809997559
I0326 02:34:56.334851 139548485990144 logging_writer.py:48] [18] global_step=18, grad_norm=4.931527614593506, loss=11.265698432922363
I0326 02:34:56.744015 139548477597440 logging_writer.py:48] [19] global_step=19, grad_norm=4.916079998016357, loss=11.249104499816895
I0326 02:34:57.151661 139548485990144 logging_writer.py:48] [20] global_step=20, grad_norm=4.838977813720703, loss=11.2501220703125
I0326 02:34:57.559997 139548477597440 logging_writer.py:48] [21] global_step=21, grad_norm=4.931962490081787, loss=11.228232383728027
I0326 02:34:57.966586 139548485990144 logging_writer.py:48] [22] global_step=22, grad_norm=4.8144707679748535, loss=11.223453521728516
I0326 02:34:58.373398 139548477597440 logging_writer.py:48] [23] global_step=23, grad_norm=4.900473594665527, loss=11.224019050598145
I0326 02:34:58.779659 139548485990144 logging_writer.py:48] [24] global_step=24, grad_norm=4.855391502380371, loss=11.19737434387207
I0326 02:34:59.184319 139548477597440 logging_writer.py:48] [25] global_step=25, grad_norm=4.860446453094482, loss=11.19091510772705
I0326 02:34:59.592934 139548485990144 logging_writer.py:48] [26] global_step=26, grad_norm=4.810262680053711, loss=11.174149513244629
I0326 02:34:59.997979 139548477597440 logging_writer.py:48] [27] global_step=27, grad_norm=4.834320068359375, loss=11.170419692993164
I0326 02:35:00.407950 139548485990144 logging_writer.py:48] [28] global_step=28, grad_norm=4.724492073059082, loss=11.161096572875977
I0326 02:35:00.812938 139548477597440 logging_writer.py:48] [29] global_step=29, grad_norm=4.800130367279053, loss=11.146551132202148
I0326 02:35:01.220525 139548485990144 logging_writer.py:48] [30] global_step=30, grad_norm=4.800124645233154, loss=11.124098777770996
I0326 02:35:01.626265 139548477597440 logging_writer.py:48] [31] global_step=31, grad_norm=4.767818927764893, loss=11.104072570800781
I0326 02:35:02.034769 139548485990144 logging_writer.py:48] [32] global_step=32, grad_norm=4.8009233474731445, loss=11.08846378326416
I0326 02:35:02.438309 139548477597440 logging_writer.py:48] [33] global_step=33, grad_norm=4.74006462097168, loss=11.077942848205566
I0326 02:35:02.842032 139548485990144 logging_writer.py:48] [34] global_step=34, grad_norm=4.673195838928223, loss=11.056445121765137
I0326 02:35:03.248548 139548477597440 logging_writer.py:48] [35] global_step=35, grad_norm=4.660492897033691, loss=11.046880722045898
I0326 02:35:03.652285 139548485990144 logging_writer.py:48] [36] global_step=36, grad_norm=4.658013820648193, loss=11.023341178894043
I0326 02:35:04.056515 139548477597440 logging_writer.py:48] [37] global_step=37, grad_norm=4.599600791931152, loss=11.027149200439453
I0326 02:35:04.463481 139548485990144 logging_writer.py:48] [38] global_step=38, grad_norm=4.592247009277344, loss=11.001836776733398
I0326 02:35:04.870214 139548477597440 logging_writer.py:48] [39] global_step=39, grad_norm=4.601369380950928, loss=10.980297088623047
I0326 02:35:05.279690 139548485990144 logging_writer.py:48] [40] global_step=40, grad_norm=4.5860161781311035, loss=10.965605735778809
I0326 02:35:05.685683 139548477597440 logging_writer.py:48] [41] global_step=41, grad_norm=4.434516906738281, loss=10.9364595413208
I0326 02:35:06.096422 139548485990144 logging_writer.py:48] [42] global_step=42, grad_norm=4.488582134246826, loss=10.922060012817383
I0326 02:35:06.502980 139548477597440 logging_writer.py:48] [43] global_step=43, grad_norm=4.483691692352295, loss=10.896871566772461
I0326 02:35:06.909135 139548485990144 logging_writer.py:48] [44] global_step=44, grad_norm=4.448193073272705, loss=10.883013725280762
I0326 02:35:07.315203 139548477597440 logging_writer.py:48] [45] global_step=45, grad_norm=4.3444952964782715, loss=10.848219871520996
I0326 02:35:07.720676 139548485990144 logging_writer.py:48] [46] global_step=46, grad_norm=4.243570804595947, loss=10.861102104187012
I0326 02:35:08.128322 139548477597440 logging_writer.py:48] [47] global_step=47, grad_norm=4.263733386993408, loss=10.802031517028809
I0326 02:35:08.539023 139548485990144 logging_writer.py:48] [48] global_step=48, grad_norm=4.166590213775635, loss=10.80445384979248
I0326 02:35:08.941064 139548477597440 logging_writer.py:48] [49] global_step=49, grad_norm=4.1642045974731445, loss=10.789913177490234
I0326 02:35:09.350643 139548485990144 logging_writer.py:48] [50] global_step=50, grad_norm=4.247448921203613, loss=10.75676155090332
I0326 02:35:09.750981 139548477597440 logging_writer.py:48] [51] global_step=51, grad_norm=4.144619464874268, loss=10.741448402404785
I0326 02:35:10.157450 139548485990144 logging_writer.py:48] [52] global_step=52, grad_norm=4.0478668212890625, loss=10.70218276977539
I0326 02:35:10.562007 139548477597440 logging_writer.py:48] [53] global_step=53, grad_norm=3.9308767318725586, loss=10.70831298828125
I0326 02:35:10.967579 139548485990144 logging_writer.py:48] [54] global_step=54, grad_norm=3.9335153102874756, loss=10.683754920959473
I0326 02:35:11.372333 139548477597440 logging_writer.py:48] [55] global_step=55, grad_norm=3.869332790374756, loss=10.670069694519043
I0326 02:35:11.774761 139548485990144 logging_writer.py:48] [56] global_step=56, grad_norm=3.875614881515503, loss=10.620833396911621
I0326 02:35:12.183645 139548477597440 logging_writer.py:48] [57] global_step=57, grad_norm=3.756046772003174, loss=10.621612548828125
I0326 02:35:12.587760 139548485990144 logging_writer.py:48] [58] global_step=58, grad_norm=3.7659871578216553, loss=10.582074165344238
I0326 02:35:12.993658 139548477597440 logging_writer.py:48] [59] global_step=59, grad_norm=3.657392978668213, loss=10.566436767578125
I0326 02:35:13.398354 139548485990144 logging_writer.py:48] [60] global_step=60, grad_norm=3.6158599853515625, loss=10.550176620483398
I0326 02:35:13.802682 139548477597440 logging_writer.py:48] [61] global_step=61, grad_norm=3.620814561843872, loss=10.518013954162598
I0326 02:35:14.209605 139548485990144 logging_writer.py:48] [62] global_step=62, grad_norm=3.537635087966919, loss=10.491479873657227
I0326 02:35:14.614667 139548477597440 logging_writer.py:48] [63] global_step=63, grad_norm=3.4885005950927734, loss=10.477941513061523
I0326 02:35:15.020277 139548485990144 logging_writer.py:48] [64] global_step=64, grad_norm=3.4404006004333496, loss=10.447710037231445
I0326 02:35:15.423551 139548477597440 logging_writer.py:48] [65] global_step=65, grad_norm=3.414992332458496, loss=10.434617042541504
I0326 02:35:15.828573 139548485990144 logging_writer.py:48] [66] global_step=66, grad_norm=3.3419699668884277, loss=10.415788650512695
I0326 02:35:16.232382 139548477597440 logging_writer.py:48] [67] global_step=67, grad_norm=3.3193163871765137, loss=10.378748893737793
I0326 02:35:16.637556 139548485990144 logging_writer.py:48] [68] global_step=68, grad_norm=3.2712996006011963, loss=10.354728698730469
I0326 02:35:17.041168 139548477597440 logging_writer.py:48] [69] global_step=69, grad_norm=3.2138402462005615, loss=10.332632064819336
I0326 02:35:17.447849 139548485990144 logging_writer.py:48] [70] global_step=70, grad_norm=3.160440444946289, loss=10.322365760803223
I0326 02:35:17.851876 139548477597440 logging_writer.py:48] [71] global_step=71, grad_norm=3.090421676635742, loss=10.293693542480469
I0326 02:35:18.259913 139548485990144 logging_writer.py:48] [72] global_step=72, grad_norm=3.069307804107666, loss=10.269302368164062
I0326 02:35:18.666003 139548477597440 logging_writer.py:48] [73] global_step=73, grad_norm=3.0460853576660156, loss=10.24727725982666
I0326 02:35:19.072282 139548485990144 logging_writer.py:48] [74] global_step=74, grad_norm=3.0002307891845703, loss=10.212928771972656
I0326 02:35:19.478702 139548477597440 logging_writer.py:48] [75] global_step=75, grad_norm=2.925297737121582, loss=10.194172859191895
I0326 02:35:19.881493 139548485990144 logging_writer.py:48] [76] global_step=76, grad_norm=2.9017369747161865, loss=10.166895866394043
I0326 02:35:20.285549 139548477597440 logging_writer.py:48] [77] global_step=77, grad_norm=2.8691141605377197, loss=10.156018257141113
I0326 02:35:20.691918 139548485990144 logging_writer.py:48] [78] global_step=78, grad_norm=2.7776083946228027, loss=10.154060363769531
I0326 02:35:21.097065 139548477597440 logging_writer.py:48] [79] global_step=79, grad_norm=2.7198781967163086, loss=10.121976852416992
I0326 02:35:21.500991 139548485990144 logging_writer.py:48] [80] global_step=80, grad_norm=2.7154459953308105, loss=10.070884704589844
I0326 02:35:21.903060 139548477597440 logging_writer.py:48] [81] global_step=81, grad_norm=2.6817800998687744, loss=10.066719055175781
I0326 02:35:22.310580 139548485990144 logging_writer.py:48] [82] global_step=82, grad_norm=2.6293904781341553, loss=10.036456108093262
I0326 02:35:22.718800 139548477597440 logging_writer.py:48] [83] global_step=83, grad_norm=2.5653092861175537, loss=10.02784252166748
I0326 02:35:23.123783 139548485990144 logging_writer.py:48] [84] global_step=84, grad_norm=2.5007011890411377, loss=10.015625
I0326 02:35:23.531095 139548477597440 logging_writer.py:48] [85] global_step=85, grad_norm=2.496293067932129, loss=9.968263626098633
I0326 02:35:23.936181 139548485990144 logging_writer.py:48] [86] global_step=86, grad_norm=2.4398765563964844, loss=9.958873748779297
I0326 02:35:24.343020 139548477597440 logging_writer.py:48] [87] global_step=87, grad_norm=2.4185714721679688, loss=9.941146850585938
I0326 02:35:24.749113 139548485990144 logging_writer.py:48] [88] global_step=88, grad_norm=2.390775442123413, loss=9.897234916687012
I0326 02:35:25.155390 139548477597440 logging_writer.py:48] [89] global_step=89, grad_norm=2.3351800441741943, loss=9.886873245239258
I0326 02:35:25.560938 139548485990144 logging_writer.py:48] [90] global_step=90, grad_norm=2.254530429840088, loss=9.888428688049316
I0326 02:35:25.966156 139548477597440 logging_writer.py:48] [91] global_step=91, grad_norm=2.243774890899658, loss=9.853008270263672
I0326 02:35:26.375723 139548485990144 logging_writer.py:48] [92] global_step=92, grad_norm=2.1995198726654053, loss=9.814516067504883
I0326 02:35:26.781333 139548477597440 logging_writer.py:48] [93] global_step=93, grad_norm=2.137249708175659, loss=9.813844680786133
I0326 02:35:27.187282 139548485990144 logging_writer.py:48] [94] global_step=94, grad_norm=2.1371371746063232, loss=9.786354064941406
I0326 02:35:27.594898 139548477597440 logging_writer.py:48] [95] global_step=95, grad_norm=2.112314224243164, loss=9.76413631439209
I0326 02:35:27.999650 139548485990144 logging_writer.py:48] [96] global_step=96, grad_norm=2.038958787918091, loss=9.757519721984863
I0326 02:35:28.408125 139548477597440 logging_writer.py:48] [97] global_step=97, grad_norm=1.9952300786972046, loss=9.725933074951172
I0326 02:35:28.813566 139548485990144 logging_writer.py:48] [98] global_step=98, grad_norm=1.946071743965149, loss=9.709466934204102
I0326 02:35:29.220102 139548477597440 logging_writer.py:48] [99] global_step=99, grad_norm=1.923295021057129, loss=9.704102516174316
I0326 02:35:29.626882 139548485990144 logging_writer.py:48] [100] global_step=100, grad_norm=1.8872144222259521, loss=9.675518989562988
I0326 02:38:07.189714 139548477597440 logging_writer.py:48] [500] global_step=500, grad_norm=0.45642325282096863, loss=7.7986369132995605
I0326 02:41:24.423243 139548485990144 logging_writer.py:48] [1000] global_step=1000, grad_norm=0.4146191477775574, loss=7.10896110534668
I0326 02:44:41.511996 139548477597440 logging_writer.py:48] [1500] global_step=1500, grad_norm=0.47362151741981506, loss=6.5545148849487305
I0326 02:47:58.760795 139548485990144 logging_writer.py:48] [2000] global_step=2000, grad_norm=0.42026254534721375, loss=6.105531692504883
I0326 02:48:49.306332 139718155032384 spec.py:321] Evaluating on the training split.
I0326 02:48:52.584570 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 02:53:34.544559 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 02:53:37.478364 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 02:58:17.859642 139718155032384 spec.py:349] Evaluating on the test split.
I0326 02:58:20.800498 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:02:56.073490 139718155032384 submission_runner.py:420] Time since start: 2627.46s, 	Step: 2130, 	{'train/accuracy': 0.27093955874443054, 'train/loss': 5.799288272857666, 'train/bleu': 4.126816278480495, 'validation/accuracy': 0.25389641523361206, 'validation/loss': 6.011801242828369, 'validation/bleu': 2.116802980749451, 'validation/num_examples': 3000, 'test/accuracy': 0.23444309830665588, 'test/loss': 6.295222759246826, 'test/bleu': 1.4699774535962755, 'test/num_examples': 3003, 'score': 880.7291378974915, 'total_duration': 2627.456573486328, 'accumulated_submission_time': 880.7291378974915, 'accumulated_eval_time': 1746.6372668743134, 'accumulated_logging_time': 0.027021169662475586}
I0326 03:02:56.091279 139548477597440 logging_writer.py:48] [2130] accumulated_eval_time=1746.637267, accumulated_logging_time=0.027021, accumulated_submission_time=880.729138, global_step=2130, preemption_count=0, score=880.729138, test/accuracy=0.234443, test/bleu=1.469977, test/loss=6.295223, test/num_examples=3003, total_duration=2627.456573, train/accuracy=0.270940, train/bleu=4.126816, train/loss=5.799288, validation/accuracy=0.253896, validation/bleu=2.116803, validation/loss=6.011801, validation/num_examples=3000
I0326 03:05:22.059180 139548485990144 logging_writer.py:48] [2500] global_step=2500, grad_norm=0.4485568404197693, loss=5.563992023468018
I0326 03:08:39.175326 139548477597440 logging_writer.py:48] [3000] global_step=3000, grad_norm=0.4583470821380615, loss=5.256716728210449
I0326 03:11:56.379036 139548485990144 logging_writer.py:48] [3500] global_step=3500, grad_norm=0.43923333287239075, loss=4.8927459716796875
I0326 03:15:13.649040 139548477597440 logging_writer.py:48] [4000] global_step=4000, grad_norm=0.4740467667579651, loss=4.696597099304199
I0326 03:16:56.281909 139718155032384 spec.py:321] Evaluating on the training split.
I0326 03:16:59.566192 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:21:27.309653 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 03:21:30.274362 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:26:10.896445 139718155032384 spec.py:349] Evaluating on the test split.
I0326 03:26:13.852563 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:30:43.794381 139718155032384 submission_runner.py:420] Time since start: 4295.18s, 	Step: 4262, 	{'train/accuracy': 0.37573936581611633, 'train/loss': 4.322761535644531, 'train/bleu': 10.870818743029048, 'validation/accuracy': 0.35269245505332947, 'validation/loss': 4.538534641265869, 'validation/bleu': 6.342824093268732, 'validation/num_examples': 3000, 'test/accuracy': 0.3332636058330536, 'test/loss': 4.799701690673828, 'test/bleu': 4.822614706678366, 'test/num_examples': 3003, 'score': 1720.8505008220673, 'total_duration': 4295.177495479584, 'accumulated_submission_time': 1720.8505008220673, 'accumulated_eval_time': 2574.149696111679, 'accumulated_logging_time': 0.0551455020904541}
I0326 03:30:43.809095 139548485990144 logging_writer.py:48] [4262] accumulated_eval_time=2574.149696, accumulated_logging_time=0.055146, accumulated_submission_time=1720.850501, global_step=4262, preemption_count=0, score=1720.850501, test/accuracy=0.333264, test/bleu=4.822615, test/loss=4.799702, test/num_examples=3003, total_duration=4295.177495, train/accuracy=0.375739, train/bleu=10.870819, train/loss=4.322762, validation/accuracy=0.352692, validation/bleu=6.342824, validation/loss=4.538535, validation/num_examples=3000
I0326 03:32:17.784893 139548477597440 logging_writer.py:48] [4500] global_step=4500, grad_norm=0.5666569471359253, loss=4.335622787475586
I0326 03:35:34.869138 139548485990144 logging_writer.py:48] [5000] global_step=5000, grad_norm=0.6725122332572937, loss=4.076854228973389
I0326 03:38:52.191536 139548477597440 logging_writer.py:48] [5500] global_step=5500, grad_norm=0.6890478134155273, loss=3.8519861698150635
I0326 03:42:09.673059 139548485990144 logging_writer.py:48] [6000] global_step=6000, grad_norm=0.5611665844917297, loss=3.59275221824646
I0326 03:44:44.070402 139718155032384 spec.py:321] Evaluating on the training split.
I0326 03:44:47.350828 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:47:41.745699 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 03:47:44.676514 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:50:27.300177 139718155032384 spec.py:349] Evaluating on the test split.
I0326 03:50:30.248153 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 03:53:04.629876 139718155032384 submission_runner.py:420] Time since start: 5636.01s, 	Step: 6393, 	{'train/accuracy': 0.4912654459476471, 'train/loss': 3.2222611904144287, 'train/bleu': 19.697797928721243, 'validation/accuracy': 0.4758775532245636, 'validation/loss': 3.3509387969970703, 'validation/bleu': 14.410022052107662, 'validation/num_examples': 3000, 'test/accuracy': 0.46889781951904297, 'test/loss': 3.47405743598938, 'test/bleu': 12.481687483932063, 'test/num_examples': 3003, 'score': 2561.0418226718903, 'total_duration': 5636.012998342514, 'accumulated_submission_time': 2561.0418226718903, 'accumulated_eval_time': 3074.7091352939606, 'accumulated_logging_time': 0.07852911949157715}
I0326 03:53:04.644393 139548477597440 logging_writer.py:48] [6393] accumulated_eval_time=3074.709135, accumulated_logging_time=0.078529, accumulated_submission_time=2561.041823, global_step=6393, preemption_count=0, score=2561.041823, test/accuracy=0.468898, test/bleu=12.481687, test/loss=3.474057, test/num_examples=3003, total_duration=5636.012998, train/accuracy=0.491265, train/bleu=19.697798, train/loss=3.222261, validation/accuracy=0.475878, validation/bleu=14.410022, validation/loss=3.350939, validation/num_examples=3000
I0326 03:53:47.106736 139548485990144 logging_writer.py:48] [6500] global_step=6500, grad_norm=0.5206888914108276, loss=3.4094207286834717
I0326 03:57:04.399629 139548477597440 logging_writer.py:48] [7000] global_step=7000, grad_norm=0.5125343799591064, loss=3.345003843307495
I0326 04:00:21.766313 139548485990144 logging_writer.py:48] [7500] global_step=7500, grad_norm=0.5049811601638794, loss=3.0355677604675293
I0326 04:03:39.033024 139548477597440 logging_writer.py:48] [8000] global_step=8000, grad_norm=0.5047627687454224, loss=3.074596881866455
I0326 04:06:56.364083 139548485990144 logging_writer.py:48] [8500] global_step=8500, grad_norm=0.46742936968803406, loss=2.8674590587615967
I0326 04:07:04.766211 139718155032384 spec.py:321] Evaluating on the training split.
I0326 04:07:08.069362 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:09:52.996176 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 04:09:55.927445 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:12:30.729167 139718155032384 spec.py:349] Evaluating on the test split.
I0326 04:12:33.676812 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:15:00.886900 139718155032384 submission_runner.py:420] Time since start: 6952.27s, 	Step: 8523, 	{'train/accuracy': 0.5403037667274475, 'train/loss': 2.743696689605713, 'train/bleu': 24.398100648381433, 'validation/accuracy': 0.5407124757766724, 'validation/loss': 2.7186522483825684, 'validation/bleu': 19.91883313495568, 'validation/num_examples': 3000, 'test/accuracy': 0.5433734655380249, 'test/loss': 2.743574380874634, 'test/bleu': 18.425026303901944, 'test/num_examples': 3003, 'score': 3401.0938029289246, 'total_duration': 6952.270023345947, 'accumulated_submission_time': 3401.0938029289246, 'accumulated_eval_time': 3550.829785823822, 'accumulated_logging_time': 0.10245394706726074}
I0326 04:15:00.902076 139548477597440 logging_writer.py:48] [8523] accumulated_eval_time=3550.829786, accumulated_logging_time=0.102454, accumulated_submission_time=3401.093803, global_step=8523, preemption_count=0, score=3401.093803, test/accuracy=0.543373, test/bleu=18.425026, test/loss=2.743574, test/num_examples=3003, total_duration=6952.270023, train/accuracy=0.540304, train/bleu=24.398101, train/loss=2.743697, validation/accuracy=0.540712, validation/bleu=19.918833, validation/loss=2.718652, validation/num_examples=3000
I0326 04:18:09.353358 139548485990144 logging_writer.py:48] [9000] global_step=9000, grad_norm=0.47307416796684265, loss=2.798811435699463
I0326 04:21:26.798253 139548477597440 logging_writer.py:48] [9500] global_step=9500, grad_norm=0.45385780930519104, loss=2.768221616744995
I0326 04:24:44.309322 139548485990144 logging_writer.py:48] [10000] global_step=10000, grad_norm=0.4579337537288666, loss=2.609726905822754
I0326 04:28:01.662671 139548477597440 logging_writer.py:48] [10500] global_step=10500, grad_norm=0.44566214084625244, loss=2.6394174098968506
I0326 04:29:00.931597 139718155032384 spec.py:321] Evaluating on the training split.
I0326 04:29:04.219455 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:31:45.684750 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 04:31:48.628108 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:34:15.473759 139718155032384 spec.py:349] Evaluating on the test split.
I0326 04:34:18.421748 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:36:34.206101 139718155032384 submission_runner.py:420] Time since start: 8245.59s, 	Step: 10652, 	{'train/accuracy': 0.5709224939346313, 'train/loss': 2.4608547687530518, 'train/bleu': 26.78267087982707, 'validation/accuracy': 0.5760746598243713, 'validation/loss': 2.3768019676208496, 'validation/bleu': 22.404282535661746, 'validation/num_examples': 3000, 'test/accuracy': 0.577189028263092, 'test/loss': 2.3795788288116455, 'test/bleu': 20.701841781692146, 'test/num_examples': 3003, 'score': 4241.0500638484955, 'total_duration': 8245.589230537415, 'accumulated_submission_time': 4241.0500638484955, 'accumulated_eval_time': 4004.104261159897, 'accumulated_logging_time': 0.1272284984588623}
I0326 04:36:34.220610 139548485990144 logging_writer.py:48] [10652] accumulated_eval_time=4004.104261, accumulated_logging_time=0.127228, accumulated_submission_time=4241.050064, global_step=10652, preemption_count=0, score=4241.050064, test/accuracy=0.577189, test/bleu=20.701842, test/loss=2.379579, test/num_examples=3003, total_duration=8245.589231, train/accuracy=0.570922, train/bleu=26.782671, train/loss=2.460855, validation/accuracy=0.576075, validation/bleu=22.404283, validation/loss=2.376802, validation/num_examples=3000
I0326 04:38:51.811142 139548477597440 logging_writer.py:48] [11000] global_step=11000, grad_norm=0.4543222188949585, loss=2.600963830947876
I0326 04:42:09.288026 139548485990144 logging_writer.py:48] [11500] global_step=11500, grad_norm=0.4137777090072632, loss=2.4983532428741455
I0326 04:45:26.750321 139548477597440 logging_writer.py:48] [12000] global_step=12000, grad_norm=0.4201701879501343, loss=2.447700262069702
I0326 04:48:44.156491 139548485990144 logging_writer.py:48] [12500] global_step=12500, grad_norm=0.4233691394329071, loss=2.4033639430999756
I0326 04:50:34.377827 139718155032384 spec.py:321] Evaluating on the training split.
I0326 04:50:37.661592 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:53:12.815659 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 04:53:15.775971 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:55:54.735518 139718155032384 spec.py:349] Evaluating on the test split.
I0326 04:55:57.694854 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 04:58:41.768316 139718155032384 submission_runner.py:420] Time since start: 9573.15s, 	Step: 12781, 	{'train/accuracy': 0.6009242534637451, 'train/loss': 2.167930841445923, 'train/bleu': 28.771511285120063, 'validation/accuracy': 0.5995337963104248, 'validation/loss': 2.179979085922241, 'validation/bleu': 23.8841132813885, 'validation/num_examples': 3000, 'test/accuracy': 0.6030445694923401, 'test/loss': 2.157670497894287, 'test/bleu': 22.521304631100403, 'test/num_examples': 3003, 'score': 5081.135403871536, 'total_duration': 9573.15140914917, 'accumulated_submission_time': 5081.135403871536, 'accumulated_eval_time': 4491.494679689407, 'accumulated_logging_time': 0.1515347957611084}
I0326 04:58:41.786615 139548477597440 logging_writer.py:48] [12781] accumulated_eval_time=4491.494680, accumulated_logging_time=0.151535, accumulated_submission_time=5081.135404, global_step=12781, preemption_count=0, score=5081.135404, test/accuracy=0.603045, test/bleu=22.521305, test/loss=2.157670, test/num_examples=3003, total_duration=9573.151409, train/accuracy=0.600924, train/bleu=28.771511, train/loss=2.167931, validation/accuracy=0.599534, validation/bleu=23.884113, validation/loss=2.179979, validation/num_examples=3000
I0326 05:00:08.516814 139548485990144 logging_writer.py:48] [13000] global_step=13000, grad_norm=0.395283043384552, loss=2.257044792175293
I0326 05:03:25.789210 139548477597440 logging_writer.py:48] [13500] global_step=13500, grad_norm=0.38166943192481995, loss=2.4049875736236572
I0326 05:06:43.263528 139548485990144 logging_writer.py:48] [14000] global_step=14000, grad_norm=0.3823276460170746, loss=2.3295071125030518
I0326 05:10:00.656408 139548477597440 logging_writer.py:48] [14500] global_step=14500, grad_norm=0.38495880365371704, loss=2.380690336227417
I0326 05:12:41.813360 139718155032384 spec.py:321] Evaluating on the training split.
I0326 05:12:45.096854 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:15:45.259198 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 05:15:48.192436 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:18:15.419056 139718155032384 spec.py:349] Evaluating on the test split.
I0326 05:18:18.357213 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:20:29.082128 139718155032384 submission_runner.py:420] Time since start: 10880.47s, 	Step: 14910, 	{'train/accuracy': 0.6043392419815063, 'train/loss': 2.13118577003479, 'train/bleu': 28.635248460338257, 'validation/accuracy': 0.6131603717803955, 'validation/loss': 2.0572800636291504, 'validation/bleu': 25.154799526881114, 'validation/num_examples': 3000, 'test/accuracy': 0.6177677512168884, 'test/loss': 2.023928165435791, 'test/bleu': 23.771131765689905, 'test/num_examples': 3003, 'score': 5921.088765621185, 'total_duration': 10880.465248346329, 'accumulated_submission_time': 5921.088765621185, 'accumulated_eval_time': 4958.763414859772, 'accumulated_logging_time': 0.18037986755371094}
I0326 05:20:29.098875 139548485990144 logging_writer.py:48] [14910] accumulated_eval_time=4958.763415, accumulated_logging_time=0.180380, accumulated_submission_time=5921.088766, global_step=14910, preemption_count=0, score=5921.088766, test/accuracy=0.617768, test/bleu=23.771132, test/loss=2.023928, test/num_examples=3003, total_duration=10880.465248, train/accuracy=0.604339, train/bleu=28.635248, train/loss=2.131186, validation/accuracy=0.613160, validation/bleu=25.154800, validation/loss=2.057280, validation/num_examples=3000
I0326 05:21:04.875835 139548477597440 logging_writer.py:48] [15000] global_step=15000, grad_norm=0.37677592039108276, loss=2.1618287563323975
I0326 05:24:22.118993 139548485990144 logging_writer.py:48] [15500] global_step=15500, grad_norm=0.3749646246433258, loss=2.220957040786743
I0326 05:27:39.538723 139548477597440 logging_writer.py:48] [16000] global_step=16000, grad_norm=0.3873737156391144, loss=2.230886220932007
I0326 05:30:57.053254 139548485990144 logging_writer.py:48] [16500] global_step=16500, grad_norm=0.3739008605480194, loss=2.2168023586273193
I0326 05:34:14.548545 139548477597440 logging_writer.py:48] [17000] global_step=17000, grad_norm=0.36747175455093384, loss=2.277879238128662
I0326 05:34:29.260372 139718155032384 spec.py:321] Evaluating on the training split.
I0326 05:34:32.551859 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:36:56.078028 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 05:36:59.012394 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:39:24.314763 139718155032384 spec.py:349] Evaluating on the test split.
I0326 05:39:27.251824 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:41:37.809755 139718155032384 submission_runner.py:420] Time since start: 12149.19s, 	Step: 17039, 	{'train/accuracy': 0.6120966672897339, 'train/loss': 2.068455219268799, 'train/bleu': 29.216168855040227, 'validation/accuracy': 0.6225464940071106, 'validation/loss': 1.9765042066574097, 'validation/bleu': 25.518672138926608, 'validation/num_examples': 3000, 'test/accuracy': 0.6296903491020203, 'test/loss': 1.925389289855957, 'test/bleu': 24.463759083185852, 'test/num_examples': 3003, 'score': 6761.183487892151, 'total_duration': 12149.19287109375, 'accumulated_submission_time': 6761.183487892151, 'accumulated_eval_time': 5387.312738418579, 'accumulated_logging_time': 0.20620489120483398}
I0326 05:41:37.825123 139548485990144 logging_writer.py:48] [17039] accumulated_eval_time=5387.312738, accumulated_logging_time=0.206205, accumulated_submission_time=6761.183488, global_step=17039, preemption_count=0, score=6761.183488, test/accuracy=0.629690, test/bleu=24.463759, test/loss=1.925389, test/num_examples=3003, total_duration=12149.192871, train/accuracy=0.612097, train/bleu=29.216169, train/loss=2.068455, validation/accuracy=0.622546, validation/bleu=25.518672, validation/loss=1.976504, validation/num_examples=3000
I0326 05:44:39.957292 139548477597440 logging_writer.py:48] [17500] global_step=17500, grad_norm=0.3694772720336914, loss=2.216339111328125
I0326 05:47:57.421746 139548485990144 logging_writer.py:48] [18000] global_step=18000, grad_norm=0.3600142002105713, loss=2.1834006309509277
I0326 05:51:15.065213 139548477597440 logging_writer.py:48] [18500] global_step=18500, grad_norm=0.37040165066719055, loss=2.136942148208618
I0326 05:54:32.565825 139548485990144 logging_writer.py:48] [19000] global_step=19000, grad_norm=0.3762645721435547, loss=2.0708296298980713
I0326 05:55:37.832878 139718155032384 spec.py:321] Evaluating on the training split.
I0326 05:55:41.125724 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 05:58:06.111843 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 05:58:09.059770 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:00:44.857147 139718155032384 spec.py:349] Evaluating on the test split.
I0326 06:00:47.799368 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:03:00.728767 139718155032384 submission_runner.py:420] Time since start: 13432.11s, 	Step: 19167, 	{'train/accuracy': 0.6214902400970459, 'train/loss': 1.972712516784668, 'train/bleu': 30.248103803089382, 'validation/accuracy': 0.6296387910842896, 'validation/loss': 1.9145017862319946, 'validation/bleu': 26.026892612448364, 'validation/num_examples': 3000, 'test/accuracy': 0.6362559199333191, 'test/loss': 1.864668846130371, 'test/bleu': 24.60783481856993, 'test/num_examples': 3003, 'score': 7601.048940181732, 'total_duration': 13432.111891508102, 'accumulated_submission_time': 7601.048940181732, 'accumulated_eval_time': 5830.208584308624, 'accumulated_logging_time': 0.30353426933288574}
I0326 06:03:00.744135 139548477597440 logging_writer.py:48] [19167] accumulated_eval_time=5830.208584, accumulated_logging_time=0.303534, accumulated_submission_time=7601.048940, global_step=19167, preemption_count=0, score=7601.048940, test/accuracy=0.636256, test/bleu=24.607835, test/loss=1.864669, test/num_examples=3003, total_duration=13432.111892, train/accuracy=0.621490, train/bleu=30.248104, train/loss=1.972713, validation/accuracy=0.629639, validation/bleu=26.026893, validation/loss=1.914502, validation/num_examples=3000
I0326 06:05:12.355282 139548485990144 logging_writer.py:48] [19500] global_step=19500, grad_norm=0.36189794540405273, loss=2.0845389366149902
I0326 06:08:29.717099 139548477597440 logging_writer.py:48] [20000] global_step=20000, grad_norm=0.35817334055900574, loss=2.186063289642334
I0326 06:11:47.257035 139548485990144 logging_writer.py:48] [20500] global_step=20500, grad_norm=0.3428620994091034, loss=2.0040528774261475
I0326 06:15:04.883712 139548477597440 logging_writer.py:48] [21000] global_step=21000, grad_norm=0.3369828462600708, loss=2.07651686668396
I0326 06:17:01.049490 139718155032384 spec.py:321] Evaluating on the training split.
I0326 06:17:04.330847 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:20:12.502102 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 06:20:15.440512 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:22:41.885076 139718155032384 spec.py:349] Evaluating on the test split.
I0326 06:22:44.844372 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:25:00.766113 139718155032384 submission_runner.py:420] Time since start: 14752.15s, 	Step: 21296, 	{'train/accuracy': 0.6231822967529297, 'train/loss': 1.967400074005127, 'train/bleu': 30.22888892093484, 'validation/accuracy': 0.6353424191474915, 'validation/loss': 1.863579273223877, 'validation/bleu': 26.392238692451198, 'validation/num_examples': 3000, 'test/accuracy': 0.6427633762359619, 'test/loss': 1.8073633909225464, 'test/bleu': 25.819944823884317, 'test/num_examples': 3003, 'score': 8441.285067796707, 'total_duration': 14752.149206638336, 'accumulated_submission_time': 8441.285067796707, 'accumulated_eval_time': 6309.925147533417, 'accumulated_logging_time': 0.32774877548217773}
I0326 06:25:00.784457 139548485990144 logging_writer.py:48] [21296] accumulated_eval_time=6309.925148, accumulated_logging_time=0.327749, accumulated_submission_time=8441.285068, global_step=21296, preemption_count=0, score=8441.285068, test/accuracy=0.642763, test/bleu=25.819945, test/loss=1.807363, test/num_examples=3003, total_duration=14752.149207, train/accuracy=0.623182, train/bleu=30.228889, train/loss=1.967400, validation/accuracy=0.635342, validation/bleu=26.392239, validation/loss=1.863579, validation/num_examples=3000
I0326 06:26:21.487706 139548477597440 logging_writer.py:48] [21500] global_step=21500, grad_norm=0.3392501473426819, loss=2.065347909927368
I0326 06:29:38.812689 139548485990144 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.3462519943714142, loss=2.095747709274292
I0326 06:32:56.394553 139548477597440 logging_writer.py:48] [22500] global_step=22500, grad_norm=0.3416007459163666, loss=2.038780689239502
I0326 06:36:13.950223 139548485990144 logging_writer.py:48] [23000] global_step=23000, grad_norm=0.3513588607311249, loss=2.0867440700531006
I0326 06:39:00.937973 139718155032384 spec.py:321] Evaluating on the training split.
I0326 06:39:04.247092 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:41:45.041168 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 06:41:47.989139 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:44:10.427134 139718155032384 spec.py:349] Evaluating on the test split.
I0326 06:44:13.375545 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 06:46:24.181788 139718155032384 submission_runner.py:420] Time since start: 16035.56s, 	Step: 23424, 	{'train/accuracy': 0.6224754452705383, 'train/loss': 1.9595882892608643, 'train/bleu': 30.77939013267566, 'validation/accuracy': 0.6388761401176453, 'validation/loss': 1.8288156986236572, 'validation/bleu': 26.847944393006056, 'validation/num_examples': 3000, 'test/accuracy': 0.6475858688354492, 'test/loss': 1.766526699066162, 'test/bleu': 25.693952740584837, 'test/num_examples': 3003, 'score': 9281.366070508957, 'total_duration': 16035.564885139465, 'accumulated_submission_time': 9281.366070508957, 'accumulated_eval_time': 6753.168920993805, 'accumulated_logging_time': 0.3561251163482666}
I0326 06:46:24.199465 139548477597440 logging_writer.py:48] [23424] accumulated_eval_time=6753.168921, accumulated_logging_time=0.356125, accumulated_submission_time=9281.366071, global_step=23424, preemption_count=0, score=9281.366071, test/accuracy=0.647586, test/bleu=25.693953, test/loss=1.766527, test/num_examples=3003, total_duration=16035.564885, train/accuracy=0.622475, train/bleu=30.779390, train/loss=1.959588, validation/accuracy=0.638876, validation/bleu=26.847944, validation/loss=1.828816, validation/num_examples=3000
I0326 06:46:54.543242 139548485990144 logging_writer.py:48] [23500] global_step=23500, grad_norm=0.33914729952812195, loss=1.9754644632339478
I0326 06:50:11.916344 139548477597440 logging_writer.py:48] [24000] global_step=24000, grad_norm=0.3394595980644226, loss=2.0102856159210205
I0326 06:53:29.632939 139548485990144 logging_writer.py:48] [24500] global_step=24500, grad_norm=0.3416055738925934, loss=2.044205665588379
I0326 06:56:47.557882 139548477597440 logging_writer.py:48] [25000] global_step=25000, grad_norm=0.3487623333930969, loss=2.0139477252960205
I0326 07:00:05.330723 139548485990144 logging_writer.py:48] [25500] global_step=25500, grad_norm=0.33790042996406555, loss=2.000793933868408
I0326 07:00:24.438437 139718155032384 spec.py:321] Evaluating on the training split.
I0326 07:00:27.732708 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:03:12.194315 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 07:03:15.150721 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:05:49.509944 139718155032384 spec.py:349] Evaluating on the test split.
I0326 07:05:52.462785 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:08:05.865915 139718155032384 submission_runner.py:420] Time since start: 17337.25s, 	Step: 25550, 	{'train/accuracy': 0.6397817730903625, 'train/loss': 1.8352636098861694, 'train/bleu': 31.42415285207092, 'validation/accuracy': 0.6423974633216858, 'validation/loss': 1.796883463859558, 'validation/bleu': 26.894833345855076, 'validation/num_examples': 3000, 'test/accuracy': 0.6520829796791077, 'test/loss': 1.7320581674575806, 'test/bleu': 26.013254802832883, 'test/num_examples': 3003, 'score': 10121.52901339531, 'total_duration': 17337.24902200699, 'accumulated_submission_time': 10121.52901339531, 'accumulated_eval_time': 7214.59633231163, 'accumulated_logging_time': 0.38266491889953613}
I0326 07:08:05.882391 139548477597440 logging_writer.py:48] [25550] accumulated_eval_time=7214.596332, accumulated_logging_time=0.382665, accumulated_submission_time=10121.529013, global_step=25550, preemption_count=0, score=10121.529013, test/accuracy=0.652083, test/bleu=26.013255, test/loss=1.732058, test/num_examples=3003, total_duration=17337.249022, train/accuracy=0.639782, train/bleu=31.424153, train/loss=1.835264, validation/accuracy=0.642397, validation/bleu=26.894833, validation/loss=1.796883, validation/num_examples=3000
I0326 07:11:03.811884 139548485990144 logging_writer.py:48] [26000] global_step=26000, grad_norm=0.33695855736732483, loss=2.001786708831787
I0326 07:14:21.315222 139548477597440 logging_writer.py:48] [26500] global_step=26500, grad_norm=0.3290652334690094, loss=1.955199956893921
I0326 07:17:38.758119 139548485990144 logging_writer.py:48] [27000] global_step=27000, grad_norm=0.3336627185344696, loss=1.9981732368469238
I0326 07:20:56.223312 139548477597440 logging_writer.py:48] [27500] global_step=27500, grad_norm=0.35198771953582764, loss=2.059438705444336
I0326 07:22:06.194422 139718155032384 spec.py:321] Evaluating on the training split.
I0326 07:22:09.483040 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:24:43.072587 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 07:24:46.011500 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:27:14.315719 139718155032384 spec.py:349] Evaluating on the test split.
I0326 07:27:17.265038 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:29:32.323951 139718155032384 submission_runner.py:420] Time since start: 18623.71s, 	Step: 27679, 	{'train/accuracy': 0.6318906545639038, 'train/loss': 1.885514736175537, 'train/bleu': 31.369597983481885, 'validation/accuracy': 0.6466875672340393, 'validation/loss': 1.7673922777175903, 'validation/bleu': 27.38267513672947, 'validation/num_examples': 3000, 'test/accuracy': 0.6565917134284973, 'test/loss': 1.7026907205581665, 'test/bleu': 26.53402928627849, 'test/num_examples': 3003, 'score': 10961.76893544197, 'total_duration': 18623.707042217255, 'accumulated_submission_time': 10961.76893544197, 'accumulated_eval_time': 7660.725780248642, 'accumulated_logging_time': 0.4088447093963623}
I0326 07:29:32.343315 139548485990144 logging_writer.py:48] [27679] accumulated_eval_time=7660.725780, accumulated_logging_time=0.408845, accumulated_submission_time=10961.768935, global_step=27679, preemption_count=0, score=10961.768935, test/accuracy=0.656592, test/bleu=26.534029, test/loss=1.702691, test/num_examples=3003, total_duration=18623.707042, train/accuracy=0.631891, train/bleu=31.369598, train/loss=1.885515, validation/accuracy=0.646688, validation/bleu=27.382675, validation/loss=1.767392, validation/num_examples=3000
I0326 07:31:39.403462 139548477597440 logging_writer.py:48] [28000] global_step=28000, grad_norm=0.3390682637691498, loss=1.9926388263702393
I0326 07:34:56.742094 139548485990144 logging_writer.py:48] [28500] global_step=28500, grad_norm=0.3402983546257019, loss=1.9426085948944092
I0326 07:38:14.278164 139548477597440 logging_writer.py:48] [29000] global_step=29000, grad_norm=0.33610883355140686, loss=1.962882161140442
I0326 07:41:31.828209 139548485990144 logging_writer.py:48] [29500] global_step=29500, grad_norm=0.32286569476127625, loss=1.8879609107971191
I0326 07:43:32.411435 139718155032384 spec.py:321] Evaluating on the training split.
I0326 07:43:35.707844 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:46:34.168050 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 07:46:37.108799 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:49:03.223809 139718155032384 spec.py:349] Evaluating on the test split.
I0326 07:49:06.164741 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 07:51:13.287145 139718155032384 submission_runner.py:420] Time since start: 19924.67s, 	Step: 29807, 	{'train/accuracy': 0.6316201090812683, 'train/loss': 1.8734259605407715, 'train/bleu': 30.95687173447356, 'validation/accuracy': 0.6486714482307434, 'validation/loss': 1.7478152513504028, 'validation/bleu': 27.44764531779654, 'validation/num_examples': 3000, 'test/accuracy': 0.6579513549804688, 'test/loss': 1.683772087097168, 'test/bleu': 26.680195484452824, 'test/num_examples': 3003, 'score': 11801.76305937767, 'total_duration': 19924.670253753662, 'accumulated_submission_time': 11801.76305937767, 'accumulated_eval_time': 8121.601450204849, 'accumulated_logging_time': 0.43807554244995117}
I0326 07:51:13.304709 139548477597440 logging_writer.py:48] [29807] accumulated_eval_time=8121.601450, accumulated_logging_time=0.438076, accumulated_submission_time=11801.763059, global_step=29807, preemption_count=0, score=11801.763059, test/accuracy=0.657951, test/bleu=26.680195, test/loss=1.683772, test/num_examples=3003, total_duration=19924.670254, train/accuracy=0.631620, train/bleu=30.956872, train/loss=1.873426, validation/accuracy=0.648671, validation/bleu=27.447645, validation/loss=1.747815, validation/num_examples=3000
I0326 07:52:29.706377 139548485990144 logging_writer.py:48] [30000] global_step=30000, grad_norm=0.3256012797355652, loss=1.9996064901351929
I0326 07:55:46.931693 139548477597440 logging_writer.py:48] [30500] global_step=30500, grad_norm=0.33762356638908386, loss=1.951438069343567
I0326 07:59:04.479332 139548485990144 logging_writer.py:48] [31000] global_step=31000, grad_norm=0.32368162274360657, loss=1.9266177415847778
I0326 08:02:21.838652 139548477597440 logging_writer.py:48] [31500] global_step=31500, grad_norm=0.32750681042671204, loss=1.9870907068252563
I0326 08:05:13.413189 139718155032384 spec.py:321] Evaluating on the training split.
I0326 08:05:16.732164 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:08:17.683095 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 08:08:20.623125 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:10:43.157903 139718155032384 spec.py:349] Evaluating on the test split.
I0326 08:10:46.125215 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:12:59.118599 139718155032384 submission_runner.py:420] Time since start: 21230.50s, 	Step: 31936, 	{'train/accuracy': 0.6406065225601196, 'train/loss': 1.814473271369934, 'train/bleu': 31.776392800461746, 'validation/accuracy': 0.6511388421058655, 'validation/loss': 1.7287027835845947, 'validation/bleu': 27.869752885143885, 'validation/num_examples': 3000, 'test/accuracy': 0.6602870225906372, 'test/loss': 1.662176489830017, 'test/bleu': 27.129149538184063, 'test/num_examples': 3003, 'score': 12641.800742864609, 'total_duration': 21230.501709222794, 'accumulated_submission_time': 12641.800742864609, 'accumulated_eval_time': 8587.306821346283, 'accumulated_logging_time': 0.465712308883667}
I0326 08:12:59.135887 139548485990144 logging_writer.py:48] [31936] accumulated_eval_time=8587.306821, accumulated_logging_time=0.465712, accumulated_submission_time=12641.800743, global_step=31936, preemption_count=0, score=12641.800743, test/accuracy=0.660287, test/bleu=27.129150, test/loss=1.662176, test/num_examples=3003, total_duration=21230.501709, train/accuracy=0.640607, train/bleu=31.776393, train/loss=1.814473, validation/accuracy=0.651139, validation/bleu=27.869753, validation/loss=1.728703, validation/num_examples=3000
I0326 08:13:24.693278 139548477597440 logging_writer.py:48] [32000] global_step=32000, grad_norm=0.3348948657512665, loss=1.9210501909255981
I0326 08:16:41.870546 139548485990144 logging_writer.py:48] [32500] global_step=32500, grad_norm=0.3245267868041992, loss=1.9209076166152954
I0326 08:19:59.350606 139548477597440 logging_writer.py:48] [33000] global_step=33000, grad_norm=0.3261640667915344, loss=1.9391483068466187
I0326 08:23:16.880557 139548485990144 logging_writer.py:48] [33500] global_step=33500, grad_norm=0.33707839250564575, loss=1.9399077892303467
I0326 08:26:34.446849 139548477597440 logging_writer.py:48] [34000] global_step=34000, grad_norm=0.32713887095451355, loss=1.851590871810913
I0326 08:26:59.420728 139718155032384 spec.py:321] Evaluating on the training split.
I0326 08:27:02.722736 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:29:31.275557 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 08:29:34.227771 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:32:05.406118 139718155032384 spec.py:349] Evaluating on the test split.
I0326 08:32:08.362673 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:34:18.466804 139718155032384 submission_runner.py:420] Time since start: 22509.85s, 	Step: 34065, 	{'train/accuracy': 0.640739381313324, 'train/loss': 1.8135218620300293, 'train/bleu': 31.720892098633595, 'validation/accuracy': 0.6525523662567139, 'validation/loss': 1.7109779119491577, 'validation/bleu': 27.501888843338417, 'validation/num_examples': 3000, 'test/accuracy': 0.6620417237281799, 'test/loss': 1.6420912742614746, 'test/bleu': 26.674599913045167, 'test/num_examples': 3003, 'score': 13482.01640677452, 'total_duration': 22509.849905252457, 'accumulated_submission_time': 13482.01640677452, 'accumulated_eval_time': 9026.352849721909, 'accumulated_logging_time': 0.49149322509765625}
I0326 08:34:18.485723 139548485990144 logging_writer.py:48] [34065] accumulated_eval_time=9026.352850, accumulated_logging_time=0.491493, accumulated_submission_time=13482.016407, global_step=34065, preemption_count=0, score=13482.016407, test/accuracy=0.662042, test/bleu=26.674600, test/loss=1.642091, test/num_examples=3003, total_duration=22509.849905, train/accuracy=0.640739, train/bleu=31.720892, train/loss=1.813522, validation/accuracy=0.652552, validation/bleu=27.501889, validation/loss=1.710978, validation/num_examples=3000
I0326 08:37:10.331050 139548477597440 logging_writer.py:48] [34500] global_step=34500, grad_norm=0.32867079973220825, loss=2.008326292037964
I0326 08:40:27.696559 139548485990144 logging_writer.py:48] [35000] global_step=35000, grad_norm=0.32683631777763367, loss=1.8914967775344849
I0326 08:43:45.178725 139548477597440 logging_writer.py:48] [35500] global_step=35500, grad_norm=0.33435025811195374, loss=1.946733832359314
I0326 08:47:02.676593 139548485990144 logging_writer.py:48] [36000] global_step=36000, grad_norm=0.32210221886634827, loss=1.8090567588806152
I0326 08:48:18.594250 139718155032384 spec.py:321] Evaluating on the training split.
I0326 08:48:21.883114 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:51:34.206632 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 08:51:37.131036 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:54:05.223746 139718155032384 spec.py:349] Evaluating on the test split.
I0326 08:54:08.176512 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 08:56:21.588166 139718155032384 submission_runner.py:420] Time since start: 23832.97s, 	Step: 36194, 	{'train/accuracy': 0.6364485025405884, 'train/loss': 1.8419629335403442, 'train/bleu': 31.526890861422114, 'validation/accuracy': 0.6544741988182068, 'validation/loss': 1.6928914785385132, 'validation/bleu': 27.82994853418911, 'validation/num_examples': 3000, 'test/accuracy': 0.6642612218856812, 'test/loss': 1.6232562065124512, 'test/bleu': 26.890337681174856, 'test/num_examples': 3003, 'score': 14322.055265665054, 'total_duration': 23832.97128868103, 'accumulated_submission_time': 14322.055265665054, 'accumulated_eval_time': 9509.346721887589, 'accumulated_logging_time': 0.5204513072967529}
I0326 08:56:21.604622 139548477597440 logging_writer.py:48] [36194] accumulated_eval_time=9509.346722, accumulated_logging_time=0.520451, accumulated_submission_time=14322.055266, global_step=36194, preemption_count=0, score=14322.055266, test/accuracy=0.664261, test/bleu=26.890338, test/loss=1.623256, test/num_examples=3003, total_duration=23832.971289, train/accuracy=0.636449, train/bleu=31.526891, train/loss=1.841963, validation/accuracy=0.654474, validation/bleu=27.829949, validation/loss=1.692891, validation/num_examples=3000
I0326 08:58:22.518569 139548485990144 logging_writer.py:48] [36500] global_step=36500, grad_norm=0.33432072401046753, loss=1.9313011169433594
I0326 09:01:39.851040 139548477597440 logging_writer.py:48] [37000] global_step=37000, grad_norm=0.3350442051887512, loss=1.9232239723205566
I0326 09:04:57.266060 139548485990144 logging_writer.py:48] [37500] global_step=37500, grad_norm=0.32539305090904236, loss=1.8536303043365479
I0326 09:08:14.752764 139548477597440 logging_writer.py:48] [38000] global_step=38000, grad_norm=0.32759323716163635, loss=1.9154406785964966
I0326 09:10:21.595110 139718155032384 spec.py:321] Evaluating on the training split.
I0326 09:10:24.886609 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:13:40.879755 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 09:13:43.817096 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:16:14.866168 139718155032384 spec.py:349] Evaluating on the test split.
I0326 09:16:17.817888 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:18:27.717499 139718155032384 submission_runner.py:420] Time since start: 25159.10s, 	Step: 38323, 	{'train/accuracy': 0.6442604660987854, 'train/loss': 1.7844679355621338, 'train/bleu': 32.063646108503356, 'validation/accuracy': 0.6566564440727234, 'validation/loss': 1.6798200607299805, 'validation/bleu': 27.93414196969954, 'validation/num_examples': 3000, 'test/accuracy': 0.667910099029541, 'test/loss': 1.6096643209457397, 'test/bleu': 27.240041752404643, 'test/num_examples': 3003, 'score': 15161.977427244186, 'total_duration': 25159.10061264038, 'accumulated_submission_time': 15161.977427244186, 'accumulated_eval_time': 9995.469063997269, 'accumulated_logging_time': 0.5457136631011963}
I0326 09:18:27.734052 139548485990144 logging_writer.py:48] [38323] accumulated_eval_time=9995.469064, accumulated_logging_time=0.545714, accumulated_submission_time=15161.977427, global_step=38323, preemption_count=0, score=15161.977427, test/accuracy=0.667910, test/bleu=27.240042, test/loss=1.609664, test/num_examples=3003, total_duration=25159.100613, train/accuracy=0.644260, train/bleu=32.063646, train/loss=1.784468, validation/accuracy=0.656656, validation/bleu=27.934142, validation/loss=1.679820, validation/num_examples=3000
I0326 09:19:37.779122 139548477597440 logging_writer.py:48] [38500] global_step=38500, grad_norm=0.33988046646118164, loss=1.908112645149231
I0326 09:22:55.135980 139548485990144 logging_writer.py:48] [39000] global_step=39000, grad_norm=0.33726492524147034, loss=1.901806116104126
I0326 09:26:12.659701 139548477597440 logging_writer.py:48] [39500] global_step=39500, grad_norm=0.3265392482280731, loss=1.8750030994415283
I0326 09:29:30.217747 139548485990144 logging_writer.py:48] [40000] global_step=40000, grad_norm=0.3318732678890228, loss=1.9024118185043335
I0326 09:32:27.888133 139718155032384 spec.py:321] Evaluating on the training split.
I0326 09:32:31.184856 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:35:30.442274 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 09:35:33.384332 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:37:52.076437 139718155032384 spec.py:349] Evaluating on the test split.
I0326 09:37:55.035811 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:40:06.352173 139718155032384 submission_runner.py:420] Time since start: 26457.74s, 	Step: 40451, 	{'train/accuracy': 0.6461368799209595, 'train/loss': 1.7737420797348022, 'train/bleu': 31.586409143337253, 'validation/accuracy': 0.6585162878036499, 'validation/loss': 1.6680903434753418, 'validation/bleu': 27.95472627491304, 'validation/num_examples': 3000, 'test/accuracy': 0.6679449081420898, 'test/loss': 1.5970640182495117, 'test/bleu': 27.34817933096726, 'test/num_examples': 3003, 'score': 16002.063148498535, 'total_duration': 26457.735300302505, 'accumulated_submission_time': 16002.063148498535, 'accumulated_eval_time': 10453.933075904846, 'accumulated_logging_time': 0.5711174011230469}
I0326 09:40:06.368758 139548477597440 logging_writer.py:48] [40451] accumulated_eval_time=10453.933076, accumulated_logging_time=0.571117, accumulated_submission_time=16002.063148, global_step=40451, preemption_count=0, score=16002.063148, test/accuracy=0.667945, test/bleu=27.348179, test/loss=1.597064, test/num_examples=3003, total_duration=26457.735300, train/accuracy=0.646137, train/bleu=31.586409, train/loss=1.773742, validation/accuracy=0.658516, validation/bleu=27.954726, validation/loss=1.668090, validation/num_examples=3000
I0326 09:40:26.040695 139548485990144 logging_writer.py:48] [40500] global_step=40500, grad_norm=0.3331579864025116, loss=1.8576918840408325
I0326 09:43:43.378979 139548477597440 logging_writer.py:48] [41000] global_step=41000, grad_norm=0.32933151721954346, loss=1.870666265487671
I0326 09:47:01.056999 139548485990144 logging_writer.py:48] [41500] global_step=41500, grad_norm=0.33748623728752136, loss=1.845548152923584
I0326 09:50:18.696003 139548477597440 logging_writer.py:48] [42000] global_step=42000, grad_norm=0.3267800211906433, loss=1.8573591709136963
I0326 09:53:36.409438 139548485990144 logging_writer.py:48] [42500] global_step=42500, grad_norm=0.3270963728427887, loss=1.90006422996521
I0326 09:54:06.531244 139718155032384 spec.py:321] Evaluating on the training split.
I0326 09:54:09.825549 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:56:47.799111 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 09:56:50.764800 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 09:59:19.939468 139718155032384 spec.py:349] Evaluating on the test split.
I0326 09:59:22.902398 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:01:24.931448 139718155032384 submission_runner.py:420] Time since start: 27736.31s, 	Step: 42578, 	{'train/accuracy': 0.6419093608856201, 'train/loss': 1.7889466285705566, 'train/bleu': 31.450693100668254, 'validation/accuracy': 0.6579955816268921, 'validation/loss': 1.6585248708724976, 'validation/bleu': 28.07055937179989, 'validation/num_examples': 3000, 'test/accuracy': 0.6679217219352722, 'test/loss': 1.5884218215942383, 'test/bleu': 27.306791955348064, 'test/num_examples': 3003, 'score': 16842.15467786789, 'total_duration': 27736.314566135406, 'accumulated_submission_time': 16842.15467786789, 'accumulated_eval_time': 10892.333222389221, 'accumulated_logging_time': 0.596534252166748}
I0326 10:01:24.947686 139548477597440 logging_writer.py:48] [42578] accumulated_eval_time=10892.333222, accumulated_logging_time=0.596534, accumulated_submission_time=16842.154678, global_step=42578, preemption_count=0, score=16842.154678, test/accuracy=0.667922, test/bleu=27.306792, test/loss=1.588422, test/num_examples=3003, total_duration=27736.314566, train/accuracy=0.641909, train/bleu=31.450693, train/loss=1.788947, validation/accuracy=0.657996, validation/bleu=28.070559, validation/loss=1.658525, validation/num_examples=3000
I0326 10:04:11.737723 139548485990144 logging_writer.py:48] [43000] global_step=43000, grad_norm=0.3385810852050781, loss=1.8184406757354736
I0326 10:07:29.292606 139548477597440 logging_writer.py:48] [43500] global_step=43500, grad_norm=0.32088690996170044, loss=1.8353692293167114
I0326 10:10:46.952134 139548485990144 logging_writer.py:48] [44000] global_step=44000, grad_norm=0.33189094066619873, loss=1.8751375675201416
I0326 10:14:04.447884 139548477597440 logging_writer.py:48] [44500] global_step=44500, grad_norm=0.3226107954978943, loss=1.849348545074463
I0326 10:15:25.200597 139718155032384 spec.py:321] Evaluating on the training split.
I0326 10:15:28.512052 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:18:07.573184 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 10:18:10.511877 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:20:43.084622 139718155032384 spec.py:349] Evaluating on the test split.
I0326 10:20:46.031756 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:23:00.871421 139718155032384 submission_runner.py:420] Time since start: 29032.25s, 	Step: 44706, 	{'train/accuracy': 0.6493119597434998, 'train/loss': 1.7331675291061401, 'train/bleu': 32.19224109122431, 'validation/accuracy': 0.6602026224136353, 'validation/loss': 1.6442763805389404, 'validation/bleu': 28.252124841591026, 'validation/num_examples': 3000, 'test/accuracy': 0.6715589165687561, 'test/loss': 1.57472562789917, 'test/bleu': 27.47007836747885, 'test/num_examples': 3003, 'score': 17682.33544230461, 'total_duration': 29032.2545440197, 'accumulated_submission_time': 17682.33544230461, 'accumulated_eval_time': 11348.004050970078, 'accumulated_logging_time': 0.6215384006500244}
I0326 10:23:00.887946 139548485990144 logging_writer.py:48] [44706] accumulated_eval_time=11348.004051, accumulated_logging_time=0.621538, accumulated_submission_time=17682.335442, global_step=44706, preemption_count=0, score=17682.335442, test/accuracy=0.671559, test/bleu=27.470078, test/loss=1.574726, test/num_examples=3003, total_duration=29032.254544, train/accuracy=0.649312, train/bleu=32.192241, train/loss=1.733168, validation/accuracy=0.660203, validation/bleu=28.252125, validation/loss=1.644276, validation/num_examples=3000
I0326 10:24:57.114245 139548477597440 logging_writer.py:48] [45000] global_step=45000, grad_norm=0.3302944302558899, loss=1.8555364608764648
I0326 10:28:14.809387 139548485990144 logging_writer.py:48] [45500] global_step=45500, grad_norm=0.34369564056396484, loss=1.9308421611785889
I0326 10:31:32.457168 139548477597440 logging_writer.py:48] [46000] global_step=46000, grad_norm=0.3435148298740387, loss=1.852371096611023
I0326 10:34:50.058233 139548485990144 logging_writer.py:48] [46500] global_step=46500, grad_norm=0.3376462459564209, loss=1.9510940313339233
I0326 10:37:01.139582 139718155032384 spec.py:321] Evaluating on the training split.
I0326 10:37:04.435513 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:39:34.380521 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 10:39:37.320666 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:41:56.812076 139718155032384 spec.py:349] Evaluating on the test split.
I0326 10:41:59.763332 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 10:44:02.104231 139718155032384 submission_runner.py:420] Time since start: 30293.49s, 	Step: 46833, 	{'train/accuracy': 0.6459473967552185, 'train/loss': 1.7606253623962402, 'train/bleu': 31.742556163953207, 'validation/accuracy': 0.6623228192329407, 'validation/loss': 1.635831356048584, 'validation/bleu': 28.549222616070168, 'validation/num_examples': 3000, 'test/accuracy': 0.6732903718948364, 'test/loss': 1.5621764659881592, 'test/bleu': 27.84722431998512, 'test/num_examples': 3003, 'score': 18522.51437306404, 'total_duration': 30293.487340688705, 'accumulated_submission_time': 18522.51437306404, 'accumulated_eval_time': 11768.968646764755, 'accumulated_logging_time': 0.647925853729248}
I0326 10:44:02.121183 139548477597440 logging_writer.py:48] [46833] accumulated_eval_time=11768.968647, accumulated_logging_time=0.647926, accumulated_submission_time=18522.514373, global_step=46833, preemption_count=0, score=18522.514373, test/accuracy=0.673290, test/bleu=27.847224, test/loss=1.562176, test/num_examples=3003, total_duration=30293.487341, train/accuracy=0.645947, train/bleu=31.742556, train/loss=1.760625, validation/accuracy=0.662323, validation/bleu=28.549223, validation/loss=1.635831, validation/num_examples=3000
I0326 10:45:08.289031 139548485990144 logging_writer.py:48] [47000] global_step=47000, grad_norm=0.33851420879364014, loss=1.7743927240371704
I0326 10:48:25.886235 139548477597440 logging_writer.py:48] [47500] global_step=47500, grad_norm=0.3292568624019623, loss=1.776574969291687
I0326 10:51:43.508087 139548485990144 logging_writer.py:48] [48000] global_step=48000, grad_norm=0.33116385340690613, loss=1.7807271480560303
I0326 10:55:01.279498 139548477597440 logging_writer.py:48] [48500] global_step=48500, grad_norm=0.3220788538455963, loss=1.784435510635376
I0326 10:58:02.434567 139718155032384 spec.py:321] Evaluating on the training split.
I0326 10:58:05.723582 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:01:09.361150 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 11:01:12.305786 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:03:31.988134 139718155032384 spec.py:349] Evaluating on the test split.
I0326 11:03:34.924776 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:05:44.726305 139718155032384 submission_runner.py:420] Time since start: 31596.11s, 	Step: 48960, 	{'train/accuracy': 0.6494240164756775, 'train/loss': 1.741469144821167, 'train/bleu': 31.711329570898744, 'validation/accuracy': 0.6627815961837769, 'validation/loss': 1.6288464069366455, 'validation/bleu': 28.454221701958485, 'validation/num_examples': 3000, 'test/accuracy': 0.6730579733848572, 'test/loss': 1.554472804069519, 'test/bleu': 27.65920033246138, 'test/num_examples': 3003, 'score': 19362.75937628746, 'total_duration': 31596.109431028366, 'accumulated_submission_time': 19362.75937628746, 'accumulated_eval_time': 12231.260348558426, 'accumulated_logging_time': 0.6742384433746338}
I0326 11:05:44.743531 139548485990144 logging_writer.py:48] [48960] accumulated_eval_time=12231.260349, accumulated_logging_time=0.674238, accumulated_submission_time=19362.759376, global_step=48960, preemption_count=0, score=19362.759376, test/accuracy=0.673058, test/bleu=27.659200, test/loss=1.554473, test/num_examples=3003, total_duration=31596.109431, train/accuracy=0.649424, train/bleu=31.711330, train/loss=1.741469, validation/accuracy=0.662782, validation/bleu=28.454222, validation/loss=1.628846, validation/num_examples=3000
I0326 11:06:00.819295 139548477597440 logging_writer.py:48] [49000] global_step=49000, grad_norm=0.3318726122379303, loss=1.8745193481445312
I0326 11:09:18.019626 139548485990144 logging_writer.py:48] [49500] global_step=49500, grad_norm=0.32635626196861267, loss=1.7742819786071777
I0326 11:12:35.644984 139548477597440 logging_writer.py:48] [50000] global_step=50000, grad_norm=0.3343364894390106, loss=1.8621429204940796
I0326 11:15:53.298096 139548485990144 logging_writer.py:48] [50500] global_step=50500, grad_norm=0.33746537566185, loss=1.7735769748687744
I0326 11:19:10.975595 139548477597440 logging_writer.py:48] [51000] global_step=51000, grad_norm=0.337973952293396, loss=1.819943904876709
I0326 11:19:45.066875 139718155032384 spec.py:321] Evaluating on the training split.
I0326 11:19:48.363880 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:22:23.801790 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 11:22:26.748808 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:24:49.258955 139718155032384 spec.py:349] Evaluating on the test split.
I0326 11:24:52.197535 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:26:56.077013 139718155032384 submission_runner.py:420] Time since start: 32867.46s, 	Step: 51088, 	{'train/accuracy': 0.6541247963905334, 'train/loss': 1.7044013738632202, 'train/bleu': 32.51463890372634, 'validation/accuracy': 0.6647034883499146, 'validation/loss': 1.6190812587738037, 'validation/bleu': 28.541555850264622, 'validation/num_examples': 3000, 'test/accuracy': 0.6759979128837585, 'test/loss': 1.5459054708480835, 'test/bleu': 27.81582596906202, 'test/num_examples': 3003, 'score': 20203.012866973877, 'total_duration': 32867.4601187706, 'accumulated_submission_time': 20203.012866973877, 'accumulated_eval_time': 12662.270419836044, 'accumulated_logging_time': 0.6999831199645996}
I0326 11:26:56.094094 139548485990144 logging_writer.py:48] [51088] accumulated_eval_time=12662.270420, accumulated_logging_time=0.699983, accumulated_submission_time=20203.012867, global_step=51088, preemption_count=0, score=20203.012867, test/accuracy=0.675998, test/bleu=27.815826, test/loss=1.545905, test/num_examples=3003, total_duration=32867.460119, train/accuracy=0.654125, train/bleu=32.514639, train/loss=1.704401, validation/accuracy=0.664703, validation/bleu=28.541556, validation/loss=1.619081, validation/num_examples=3000
I0326 11:29:38.917948 139548477597440 logging_writer.py:48] [51500] global_step=51500, grad_norm=0.3382979929447174, loss=1.8058865070343018
I0326 11:32:56.482294 139548485990144 logging_writer.py:48] [52000] global_step=52000, grad_norm=0.3365076780319214, loss=1.6867870092391968
I0326 11:36:14.251821 139548477597440 logging_writer.py:48] [52500] global_step=52500, grad_norm=0.33544883131980896, loss=1.752053141593933
I0326 11:39:31.873659 139548485990144 logging_writer.py:48] [53000] global_step=53000, grad_norm=0.34822142124176025, loss=1.8645473718643188
I0326 11:40:56.204359 139718155032384 spec.py:321] Evaluating on the training split.
I0326 11:40:59.537551 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:43:40.211461 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 11:43:43.149383 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:46:06.049528 139718155032384 spec.py:349] Evaluating on the test split.
I0326 11:46:08.989751 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 11:48:10.232903 139718155032384 submission_runner.py:420] Time since start: 34141.62s, 	Step: 53215, 	{'train/accuracy': 0.6503514647483826, 'train/loss': 1.7199337482452393, 'train/bleu': 32.20614601646499, 'validation/accuracy': 0.6664889454841614, 'validation/loss': 1.605893850326538, 'validation/bleu': 28.80111518885052, 'validation/num_examples': 3000, 'test/accuracy': 0.6767997145652771, 'test/loss': 1.5347919464111328, 'test/bleu': 28.064821292902458, 'test/num_examples': 3003, 'score': 21043.053194999695, 'total_duration': 34141.61603355408, 'accumulated_submission_time': 21043.053194999695, 'accumulated_eval_time': 13096.298949480057, 'accumulated_logging_time': 0.7257065773010254}
I0326 11:48:10.249910 139548477597440 logging_writer.py:48] [53215] accumulated_eval_time=13096.298949, accumulated_logging_time=0.725707, accumulated_submission_time=21043.053195, global_step=53215, preemption_count=0, score=21043.053195, test/accuracy=0.676800, test/bleu=28.064821, test/loss=1.534792, test/num_examples=3003, total_duration=34141.616034, train/accuracy=0.650351, train/bleu=32.206146, train/loss=1.719934, validation/accuracy=0.666489, validation/bleu=28.801115, validation/loss=1.605894, validation/num_examples=3000
I0326 11:50:03.071659 139548485990144 logging_writer.py:48] [53500] global_step=53500, grad_norm=0.34122082591056824, loss=1.9090595245361328
I0326 11:53:20.475819 139548477597440 logging_writer.py:48] [54000] global_step=54000, grad_norm=0.3345998227596283, loss=1.7636313438415527
I0326 11:56:37.909842 139548485990144 logging_writer.py:48] [54500] global_step=54500, grad_norm=0.33752307295799255, loss=1.7642375230789185
I0326 11:59:55.579103 139548477597440 logging_writer.py:48] [55000] global_step=55000, grad_norm=0.32943493127822876, loss=1.8168367147445679
I0326 12:02:10.444008 139718155032384 spec.py:321] Evaluating on the training split.
I0326 12:02:13.739604 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:05:17.026372 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 12:05:19.968857 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:07:46.802318 139718155032384 spec.py:349] Evaluating on the test split.
I0326 12:07:49.728670 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:09:50.708866 139718155032384 submission_runner.py:420] Time since start: 35442.09s, 	Step: 55343, 	{'train/accuracy': 0.6536936163902283, 'train/loss': 1.7110180854797363, 'train/bleu': 32.08206514099033, 'validation/accuracy': 0.6651126146316528, 'validation/loss': 1.605336308479309, 'validation/bleu': 28.597463512538503, 'validation/num_examples': 3000, 'test/accuracy': 0.6763349175453186, 'test/loss': 1.5295848846435547, 'test/bleu': 27.94065320305915, 'test/num_examples': 3003, 'score': 21883.17886543274, 'total_duration': 35442.09198188782, 'accumulated_submission_time': 21883.17886543274, 'accumulated_eval_time': 13556.563753604889, 'accumulated_logging_time': 0.7513151168823242}
I0326 12:09:50.725968 139548485990144 logging_writer.py:48] [55343] accumulated_eval_time=13556.563754, accumulated_logging_time=0.751315, accumulated_submission_time=21883.178865, global_step=55343, preemption_count=0, score=21883.178865, test/accuracy=0.676335, test/bleu=27.940653, test/loss=1.529585, test/num_examples=3003, total_duration=35442.091982, train/accuracy=0.653694, train/bleu=32.082065, train/loss=1.711018, validation/accuracy=0.665113, validation/bleu=28.597464, validation/loss=1.605336, validation/num_examples=3000
I0326 12:10:52.969638 139548477597440 logging_writer.py:48] [55500] global_step=55500, grad_norm=0.3365153968334198, loss=1.7350643873214722
I0326 12:14:10.478905 139548485990144 logging_writer.py:48] [56000] global_step=56000, grad_norm=0.3355340361595154, loss=1.7282568216323853
I0326 12:17:28.291261 139548477597440 logging_writer.py:48] [56500] global_step=56500, grad_norm=0.3410855233669281, loss=1.748106837272644
I0326 12:20:45.923305 139548485990144 logging_writer.py:48] [57000] global_step=57000, grad_norm=0.3403259217739105, loss=1.7483899593353271
I0326 12:23:50.959786 139718155032384 spec.py:321] Evaluating on the training split.
I0326 12:23:54.257829 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:27:00.709142 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 12:27:03.642383 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:29:36.563260 139718155032384 spec.py:349] Evaluating on the test split.
I0326 12:29:39.502622 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:31:42.141233 139718155032384 submission_runner.py:420] Time since start: 36753.52s, 	Step: 57470, 	{'train/accuracy': 0.6590781807899475, 'train/loss': 1.677270531654358, 'train/bleu': 32.61833773293062, 'validation/accuracy': 0.6678776144981384, 'validation/loss': 1.5970656871795654, 'validation/bleu': 29.095836433525825, 'validation/num_examples': 3000, 'test/accuracy': 0.6785776615142822, 'test/loss': 1.5185816287994385, 'test/bleu': 28.22648016703368, 'test/num_examples': 3003, 'score': 22723.339594364166, 'total_duration': 36753.524359464645, 'accumulated_submission_time': 22723.339594364166, 'accumulated_eval_time': 14027.745198726654, 'accumulated_logging_time': 0.7782564163208008}
I0326 12:31:42.158633 139548477597440 logging_writer.py:48] [57470] accumulated_eval_time=14027.745199, accumulated_logging_time=0.778256, accumulated_submission_time=22723.339594, global_step=57470, preemption_count=0, score=22723.339594, test/accuracy=0.678578, test/bleu=28.226480, test/loss=1.518582, test/num_examples=3003, total_duration=36753.524359, train/accuracy=0.659078, train/bleu=32.618338, train/loss=1.677271, validation/accuracy=0.667878, validation/bleu=29.095836, validation/loss=1.597066, validation/num_examples=3000
I0326 12:31:54.335458 139548485990144 logging_writer.py:48] [57500] global_step=57500, grad_norm=0.34326305985450745, loss=1.8172913789749146
I0326 12:35:11.510854 139548477597440 logging_writer.py:48] [58000] global_step=58000, grad_norm=0.3412209749221802, loss=1.7228754758834839
I0326 12:38:28.970929 139548485990144 logging_writer.py:48] [58500] global_step=58500, grad_norm=0.34050413966178894, loss=1.7590622901916504
I0326 12:41:46.738789 139548477597440 logging_writer.py:48] [59000] global_step=59000, grad_norm=0.3473344147205353, loss=1.7838568687438965
I0326 12:45:04.632529 139548485990144 logging_writer.py:48] [59500] global_step=59500, grad_norm=0.3505284786224365, loss=1.7915903329849243
I0326 12:45:42.293714 139718155032384 spec.py:321] Evaluating on the training split.
I0326 12:45:45.596053 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:48:28.424539 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 12:48:31.369799 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:50:56.739542 139718155032384 spec.py:349] Evaluating on the test split.
I0326 12:50:59.676285 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 12:53:05.232497 139718155032384 submission_runner.py:420] Time since start: 38036.62s, 	Step: 59597, 	{'train/accuracy': 0.6529233455657959, 'train/loss': 1.7106753587722778, 'train/bleu': 32.56478568134917, 'validation/accuracy': 0.6675800681114197, 'validation/loss': 1.5873774290084839, 'validation/bleu': 29.03362858652503, 'validation/num_examples': 3000, 'test/accuracy': 0.6792516708374023, 'test/loss': 1.5106875896453857, 'test/bleu': 28.122545885080353, 'test/num_examples': 3003, 'score': 23563.399985313416, 'total_duration': 38036.61562204361, 'accumulated_submission_time': 23563.399985313416, 'accumulated_eval_time': 14470.683942556381, 'accumulated_logging_time': 0.8043756484985352}
I0326 12:53:05.250245 139548477597440 logging_writer.py:48] [59597] accumulated_eval_time=14470.683943, accumulated_logging_time=0.804376, accumulated_submission_time=23563.399985, global_step=59597, preemption_count=0, score=23563.399985, test/accuracy=0.679252, test/bleu=28.122546, test/loss=1.510688, test/num_examples=3003, total_duration=38036.615622, train/accuracy=0.652923, train/bleu=32.564786, train/loss=1.710675, validation/accuracy=0.667580, validation/bleu=29.033629, validation/loss=1.587377, validation/num_examples=3000
I0326 12:55:44.426504 139548485990144 logging_writer.py:48] [60000] global_step=60000, grad_norm=0.3535154461860657, loss=1.768568754196167
I0326 12:59:02.016087 139548477597440 logging_writer.py:48] [60500] global_step=60500, grad_norm=0.3442268967628479, loss=1.795394778251648
I0326 13:02:19.616597 139548485990144 logging_writer.py:48] [61000] global_step=61000, grad_norm=0.3419112265110016, loss=1.7684918642044067
I0326 13:05:37.164782 139548477597440 logging_writer.py:48] [61500] global_step=61500, grad_norm=0.34757617115974426, loss=1.8078986406326294
I0326 13:07:05.397973 139718155032384 spec.py:321] Evaluating on the training split.
I0326 13:07:08.702046 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:10:15.186543 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 13:10:18.148941 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:12:42.767953 139718155032384 spec.py:349] Evaluating on the test split.
I0326 13:12:45.724344 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:14:51.234660 139718155032384 submission_runner.py:420] Time since start: 39342.62s, 	Step: 61725, 	{'train/accuracy': 0.6515601277351379, 'train/loss': 1.7172927856445312, 'train/bleu': 32.24904633656718, 'validation/accuracy': 0.6682124137878418, 'validation/loss': 1.5838459730148315, 'validation/bleu': 29.214943493682032, 'validation/num_examples': 3000, 'test/accuracy': 0.6800883412361145, 'test/loss': 1.5061928033828735, 'test/bleu': 28.285435608132758, 'test/num_examples': 3003, 'score': 24403.476749181747, 'total_duration': 39342.61774158478, 'accumulated_submission_time': 24403.476749181747, 'accumulated_eval_time': 14936.520565748215, 'accumulated_logging_time': 0.8307778835296631}
I0326 13:14:51.257563 139548485990144 logging_writer.py:48] [61725] accumulated_eval_time=14936.520566, accumulated_logging_time=0.830778, accumulated_submission_time=24403.476749, global_step=61725, preemption_count=0, score=24403.476749, test/accuracy=0.680088, test/bleu=28.285436, test/loss=1.506193, test/num_examples=3003, total_duration=39342.617742, train/accuracy=0.651560, train/bleu=32.249046, train/loss=1.717293, validation/accuracy=0.668212, validation/bleu=29.214943, validation/loss=1.583846, validation/num_examples=3000
I0326 13:16:40.072314 139548477597440 logging_writer.py:48] [62000] global_step=62000, grad_norm=0.3409040868282318, loss=1.7490116357803345
I0326 13:19:57.470426 139548485990144 logging_writer.py:48] [62500] global_step=62500, grad_norm=0.3432629108428955, loss=1.7286781072616577
I0326 13:23:15.024110 139548477597440 logging_writer.py:48] [63000] global_step=63000, grad_norm=0.35547110438346863, loss=1.8064320087432861
I0326 13:26:32.572269 139548485990144 logging_writer.py:48] [63500] global_step=63500, grad_norm=0.3473890423774719, loss=1.7735308408737183
I0326 13:28:51.329286 139718155032384 spec.py:321] Evaluating on the training split.
I0326 13:28:54.626538 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:32:13.484725 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 13:32:16.422302 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:34:39.883101 139718155032384 spec.py:349] Evaluating on the test split.
I0326 13:34:42.825475 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:36:54.325216 139718155032384 submission_runner.py:420] Time since start: 40665.71s, 	Step: 63853, 	{'train/accuracy': 0.6600537300109863, 'train/loss': 1.669567584991455, 'train/bleu': 32.36535878181648, 'validation/accuracy': 0.6685224175453186, 'validation/loss': 1.5804531574249268, 'validation/bleu': 29.0512194690786, 'validation/num_examples': 3000, 'test/accuracy': 0.6814014315605164, 'test/loss': 1.5003212690353394, 'test/bleu': 28.46243019918655, 'test/num_examples': 3003, 'score': 25243.47717642784, 'total_duration': 40665.70834302902, 'accumulated_submission_time': 25243.47717642784, 'accumulated_eval_time': 15419.516457080841, 'accumulated_logging_time': 0.8640763759613037}
I0326 13:36:54.342935 139548477597440 logging_writer.py:48] [63853] accumulated_eval_time=15419.516457, accumulated_logging_time=0.864076, accumulated_submission_time=25243.477176, global_step=63853, preemption_count=0, score=25243.477176, test/accuracy=0.681401, test/bleu=28.462430, test/loss=1.500321, test/num_examples=3003, total_duration=40665.708343, train/accuracy=0.660054, train/bleu=32.365359, train/loss=1.669568, validation/accuracy=0.668522, validation/bleu=29.051219, validation/loss=1.580453, validation/num_examples=3000
I0326 13:37:52.572085 139548485990144 logging_writer.py:48] [64000] global_step=64000, grad_norm=0.34702974557876587, loss=1.8070707321166992
I0326 13:41:09.929805 139548477597440 logging_writer.py:48] [64500] global_step=64500, grad_norm=0.3522385358810425, loss=1.8468422889709473
I0326 13:44:27.579513 139548485990144 logging_writer.py:48] [65000] global_step=65000, grad_norm=0.3620254099369049, loss=1.8025310039520264
I0326 13:47:45.308637 139548477597440 logging_writer.py:48] [65500] global_step=65500, grad_norm=0.35810795426368713, loss=1.7814807891845703
I0326 13:50:54.684027 139718155032384 spec.py:321] Evaluating on the training split.
I0326 13:50:57.982228 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:54:09.977455 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 13:54:12.912547 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:56:28.563268 139718155032384 spec.py:349] Evaluating on the test split.
I0326 13:56:31.523753 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 13:58:33.497544 139718155032384 submission_runner.py:420] Time since start: 41964.88s, 	Step: 65981, 	{'train/accuracy': 0.6564612984657288, 'train/loss': 1.6870346069335938, 'train/bleu': 32.40155219027495, 'validation/accuracy': 0.6705682277679443, 'validation/loss': 1.5727699995040894, 'validation/bleu': 29.21382812854247, 'validation/num_examples': 3000, 'test/accuracy': 0.6818662881851196, 'test/loss': 1.4934130907058716, 'test/bleu': 28.418446160435852, 'test/num_examples': 3003, 'score': 26083.749479055405, 'total_duration': 41964.88067674637, 'accumulated_submission_time': 26083.749479055405, 'accumulated_eval_time': 15878.329960823059, 'accumulated_logging_time': 0.8912930488586426}
I0326 13:58:33.514889 139548485990144 logging_writer.py:48] [65981] accumulated_eval_time=15878.329961, accumulated_logging_time=0.891293, accumulated_submission_time=26083.749479, global_step=65981, preemption_count=0, score=26083.749479, test/accuracy=0.681866, test/bleu=28.418446, test/loss=1.493413, test/num_examples=3003, total_duration=41964.880677, train/accuracy=0.656461, train/bleu=32.401552, train/loss=1.687035, validation/accuracy=0.670568, validation/bleu=29.213828, validation/loss=1.572770, validation/num_examples=3000
I0326 13:58:41.380858 139548477597440 logging_writer.py:48] [66000] global_step=66000, grad_norm=0.3555716276168823, loss=1.7827566862106323
I0326 14:01:58.543957 139548485990144 logging_writer.py:48] [66500] global_step=66500, grad_norm=0.3933876156806946, loss=1.824615478515625
I0326 14:05:16.137715 139548477597440 logging_writer.py:48] [67000] global_step=67000, grad_norm=0.35556861758232117, loss=1.7229180335998535
I0326 14:08:33.607597 139548485990144 logging_writer.py:48] [67500] global_step=67500, grad_norm=0.3421711027622223, loss=1.6865973472595215
I0326 14:11:51.128333 139548477597440 logging_writer.py:48] [68000] global_step=68000, grad_norm=0.36298704147338867, loss=1.6888034343719482
I0326 14:12:33.866157 139718155032384 spec.py:321] Evaluating on the training split.
I0326 14:12:37.159783 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:15:58.754584 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 14:16:01.702328 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:18:27.676715 139718155032384 spec.py:349] Evaluating on the test split.
I0326 14:18:30.652209 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:20:35.135301 139718155032384 submission_runner.py:420] Time since start: 43286.52s, 	Step: 68110, 	{'train/accuracy': 0.6591756343841553, 'train/loss': 1.6740998029708862, 'train/bleu': 33.13587460529193, 'validation/accuracy': 0.670741856098175, 'validation/loss': 1.5643101930618286, 'validation/bleu': 29.045543532175397, 'validation/num_examples': 3000, 'test/accuracy': 0.6835512518882751, 'test/loss': 1.4830164909362793, 'test/bleu': 28.349632841069347, 'test/num_examples': 3003, 'score': 26924.032155513763, 'total_duration': 43286.51839852333, 'accumulated_submission_time': 26924.032155513763, 'accumulated_eval_time': 16359.599029064178, 'accumulated_logging_time': 0.9174084663391113}
I0326 14:20:35.155841 139548485990144 logging_writer.py:48] [68110] accumulated_eval_time=16359.599029, accumulated_logging_time=0.917408, accumulated_submission_time=26924.032156, global_step=68110, preemption_count=0, score=26924.032156, test/accuracy=0.683551, test/bleu=28.349633, test/loss=1.483016, test/num_examples=3003, total_duration=43286.518399, train/accuracy=0.659176, train/bleu=33.135875, train/loss=1.674100, validation/accuracy=0.670742, validation/bleu=29.045544, validation/loss=1.564310, validation/num_examples=3000
I0326 14:23:09.314405 139548477597440 logging_writer.py:48] [68500] global_step=68500, grad_norm=0.3581923544406891, loss=1.7188334465026855
I0326 14:26:26.675200 139548485990144 logging_writer.py:48] [69000] global_step=69000, grad_norm=0.3639312982559204, loss=1.733720302581787
I0326 14:29:44.433004 139548477597440 logging_writer.py:48] [69500] global_step=69500, grad_norm=0.35311105847358704, loss=1.688861608505249
I0326 14:33:02.104154 139548485990144 logging_writer.py:48] [70000] global_step=70000, grad_norm=0.34655123949050903, loss=1.6696563959121704
I0326 14:34:35.469236 139718155032384 spec.py:321] Evaluating on the training split.
I0326 14:34:38.786072 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:37:31.634068 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 14:37:34.590844 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:39:56.110528 139718155032384 spec.py:349] Evaluating on the test split.
I0326 14:39:59.043664 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:42:05.472460 139718155032384 submission_runner.py:420] Time since start: 44576.86s, 	Step: 70238, 	{'train/accuracy': 0.6604442000389099, 'train/loss': 1.6657711267471313, 'train/bleu': 32.65748161790169, 'validation/accuracy': 0.6725025177001953, 'validation/loss': 1.5626001358032227, 'validation/bleu': 29.17193255350609, 'validation/num_examples': 3000, 'test/accuracy': 0.6855034828186035, 'test/loss': 1.4803154468536377, 'test/bleu': 28.661273966831658, 'test/num_examples': 3003, 'score': 27764.273996829987, 'total_duration': 44576.85558485985, 'accumulated_submission_time': 27764.273996829987, 'accumulated_eval_time': 16809.602218151093, 'accumulated_logging_time': 0.9473400115966797}
I0326 14:42:05.490361 139548477597440 logging_writer.py:48] [70238] accumulated_eval_time=16809.602218, accumulated_logging_time=0.947340, accumulated_submission_time=27764.273997, global_step=70238, preemption_count=0, score=27764.273997, test/accuracy=0.685503, test/bleu=28.661274, test/loss=1.480315, test/num_examples=3003, total_duration=44576.855585, train/accuracy=0.660444, train/bleu=32.657482, train/loss=1.665771, validation/accuracy=0.672503, validation/bleu=29.171933, validation/loss=1.562600, validation/num_examples=3000
I0326 14:43:49.100299 139548485990144 logging_writer.py:48] [70500] global_step=70500, grad_norm=0.3675205707550049, loss=1.7094155550003052
I0326 14:47:06.784985 139548477597440 logging_writer.py:48] [71000] global_step=71000, grad_norm=0.36306920647621155, loss=1.7205560207366943
I0326 14:50:24.311753 139548485990144 logging_writer.py:48] [71500] global_step=71500, grad_norm=0.3605809807777405, loss=1.7204296588897705
I0326 14:53:41.956335 139548477597440 logging_writer.py:48] [72000] global_step=72000, grad_norm=0.36692923307418823, loss=1.7493889331817627
I0326 14:56:05.573340 139718155032384 spec.py:321] Evaluating on the training split.
I0326 14:56:08.869277 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 14:59:23.771846 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 14:59:26.710168 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:01:45.697066 139718155032384 spec.py:349] Evaluating on the test split.
I0326 15:01:48.660931 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:03:50.720875 139718155032384 submission_runner.py:420] Time since start: 45882.10s, 	Step: 72365, 	{'train/accuracy': 0.6582271456718445, 'train/loss': 1.6727216243743896, 'train/bleu': 32.4629981081095, 'validation/accuracy': 0.6732092499732971, 'validation/loss': 1.5576822757720947, 'validation/bleu': 29.288366297309235, 'validation/num_examples': 3000, 'test/accuracy': 0.6850502490997314, 'test/loss': 1.4750444889068604, 'test/bleu': 28.69783471709986, 'test/num_examples': 3003, 'score': 28604.286732912064, 'total_duration': 45882.10397315025, 'accumulated_submission_time': 28604.286732912064, 'accumulated_eval_time': 17274.74968957901, 'accumulated_logging_time': 0.9748327732086182}
I0326 15:03:50.742359 139548485990144 logging_writer.py:48] [72365] accumulated_eval_time=17274.749690, accumulated_logging_time=0.974833, accumulated_submission_time=28604.286733, global_step=72365, preemption_count=0, score=28604.286733, test/accuracy=0.685050, test/bleu=28.697835, test/loss=1.475044, test/num_examples=3003, total_duration=45882.103973, train/accuracy=0.658227, train/bleu=32.462998, train/loss=1.672722, validation/accuracy=0.673209, validation/bleu=29.288366, validation/loss=1.557682, validation/num_examples=3000
I0326 15:04:44.357039 139548477597440 logging_writer.py:48] [72500] global_step=72500, grad_norm=0.37063971161842346, loss=1.6941049098968506
I0326 15:08:01.851985 139548485990144 logging_writer.py:48] [73000] global_step=73000, grad_norm=0.35575851798057556, loss=1.6955980062484741
I0326 15:11:19.636968 139548477597440 logging_writer.py:48] [73500] global_step=73500, grad_norm=0.3591764569282532, loss=1.637294054031372
I0326 15:14:37.297713 139548485990144 logging_writer.py:48] [74000] global_step=74000, grad_norm=0.36198732256889343, loss=1.687414526939392
I0326 15:17:50.745496 139718155032384 spec.py:321] Evaluating on the training split.
I0326 15:17:54.048621 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:21:04.481539 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 15:21:07.419760 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:23:28.552717 139718155032384 spec.py:349] Evaluating on the test split.
I0326 15:23:31.487037 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:25:34.572127 139718155032384 submission_runner.py:420] Time since start: 47185.96s, 	Step: 74491, 	{'train/accuracy': 0.6647081971168518, 'train/loss': 1.6393332481384277, 'train/bleu': 33.07062489449608, 'validation/accuracy': 0.673568844795227, 'validation/loss': 1.5542222261428833, 'validation/bleu': 29.364483972398364, 'validation/num_examples': 3000, 'test/accuracy': 0.6867004036903381, 'test/loss': 1.4691143035888672, 'test/bleu': 28.949947187398234, 'test/num_examples': 3003, 'score': 29444.215552568436, 'total_duration': 47185.95525050163, 'accumulated_submission_time': 29444.215552568436, 'accumulated_eval_time': 17738.5762860775, 'accumulated_logging_time': 1.00701904296875}
I0326 15:25:34.590339 139548477597440 logging_writer.py:48] [74491] accumulated_eval_time=17738.576286, accumulated_logging_time=1.007019, accumulated_submission_time=29444.215553, global_step=74491, preemption_count=0, score=29444.215553, test/accuracy=0.686700, test/bleu=28.949947, test/loss=1.469114, test/num_examples=3003, total_duration=47185.955251, train/accuracy=0.664708, train/bleu=33.070625, train/loss=1.639333, validation/accuracy=0.673569, validation/bleu=29.364484, validation/loss=1.554222, validation/num_examples=3000
I0326 15:25:38.541864 139548485990144 logging_writer.py:48] [74500] global_step=74500, grad_norm=0.3618231415748596, loss=1.7529332637786865
I0326 15:28:55.978917 139548477597440 logging_writer.py:48] [75000] global_step=75000, grad_norm=0.36606043577194214, loss=1.6682904958724976
I0326 15:32:13.660212 139548485990144 logging_writer.py:48] [75500] global_step=75500, grad_norm=0.3719983696937561, loss=1.7160247564315796
I0326 15:35:31.207189 139548477597440 logging_writer.py:48] [76000] global_step=76000, grad_norm=0.3715173900127411, loss=1.7391382455825806
I0326 15:38:48.978859 139548485990144 logging_writer.py:48] [76500] global_step=76500, grad_norm=0.3717317283153534, loss=1.74233877658844
I0326 15:39:34.590673 139718155032384 spec.py:321] Evaluating on the training split.
I0326 15:39:37.883028 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:42:42.614753 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 15:42:45.553882 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:45:18.771722 139718155032384 spec.py:349] Evaluating on the test split.
I0326 15:45:21.718899 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 15:47:23.304557 139718155032384 submission_runner.py:420] Time since start: 48494.69s, 	Step: 76617, 	{'train/accuracy': 0.6620994210243225, 'train/loss': 1.6539947986602783, 'train/bleu': 33.319546257429636, 'validation/accuracy': 0.6737052202224731, 'validation/loss': 1.5505098104476929, 'validation/bleu': 29.241776418280704, 'validation/num_examples': 3000, 'test/accuracy': 0.6865260601043701, 'test/loss': 1.4673891067504883, 'test/bleu': 28.681083122730616, 'test/num_examples': 3003, 'score': 30284.14289712906, 'total_duration': 48494.68763375282, 'accumulated_submission_time': 30284.14289712906, 'accumulated_eval_time': 18207.290071249008, 'accumulated_logging_time': 1.0347270965576172}
I0326 15:47:23.327455 139548477597440 logging_writer.py:48] [76617] accumulated_eval_time=18207.290071, accumulated_logging_time=1.034727, accumulated_submission_time=30284.142897, global_step=76617, preemption_count=0, score=30284.142897, test/accuracy=0.686526, test/bleu=28.681083, test/loss=1.467389, test/num_examples=3003, total_duration=48494.687634, train/accuracy=0.662099, train/bleu=33.319546, train/loss=1.653995, validation/accuracy=0.673705, validation/bleu=29.241776, validation/loss=1.550510, validation/num_examples=3000
I0326 15:49:54.880370 139548485990144 logging_writer.py:48] [77000] global_step=77000, grad_norm=0.37304240465164185, loss=1.7057240009307861
I0326 15:53:12.492065 139548477597440 logging_writer.py:48] [77500] global_step=77500, grad_norm=0.3747982382774353, loss=1.7243043184280396
I0326 15:56:30.177829 139548485990144 logging_writer.py:48] [78000] global_step=78000, grad_norm=0.3807087242603302, loss=1.8031871318817139
I0326 15:59:48.064369 139548477597440 logging_writer.py:48] [78500] global_step=78500, grad_norm=0.3749241232872009, loss=1.7071655988693237
I0326 16:01:23.443631 139718155032384 spec.py:321] Evaluating on the training split.
I0326 16:01:26.735011 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:04:27.807647 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 16:04:30.746471 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:06:45.201564 139718155032384 spec.py:349] Evaluating on the test split.
I0326 16:06:48.142930 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:08:53.341782 139718155032384 submission_runner.py:420] Time since start: 49784.72s, 	Step: 78743, 	{'train/accuracy': 0.6623937487602234, 'train/loss': 1.6457419395446777, 'train/bleu': 33.11086571288778, 'validation/accuracy': 0.6740400195121765, 'validation/loss': 1.5491384267807007, 'validation/bleu': 29.40327698765743, 'validation/num_examples': 3000, 'test/accuracy': 0.6872814297676086, 'test/loss': 1.462404489517212, 'test/bleu': 28.759189457182835, 'test/num_examples': 3003, 'score': 31124.188576698303, 'total_duration': 49784.72490167618, 'accumulated_submission_time': 31124.188576698303, 'accumulated_eval_time': 18657.18817090988, 'accumulated_logging_time': 1.067159652709961}
I0326 16:08:53.359977 139548485990144 logging_writer.py:48] [78743] accumulated_eval_time=18657.188171, accumulated_logging_time=1.067160, accumulated_submission_time=31124.188577, global_step=78743, preemption_count=0, score=31124.188577, test/accuracy=0.687281, test/bleu=28.759189, test/loss=1.462404, test/num_examples=3003, total_duration=49784.724902, train/accuracy=0.662394, train/bleu=33.110866, train/loss=1.645742, validation/accuracy=0.674040, validation/bleu=29.403277, validation/loss=1.549138, validation/num_examples=3000
I0326 16:10:35.091763 139548477597440 logging_writer.py:48] [79000] global_step=79000, grad_norm=0.3704359531402588, loss=1.7126343250274658
I0326 16:13:52.650693 139548485990144 logging_writer.py:48] [79500] global_step=79500, grad_norm=0.3735623061656952, loss=1.7021900415420532
I0326 16:17:10.309117 139548477597440 logging_writer.py:48] [80000] global_step=80000, grad_norm=0.38384029269218445, loss=1.7154912948608398
I0326 16:20:28.065001 139548485990144 logging_writer.py:48] [80500] global_step=80500, grad_norm=0.38113465905189514, loss=1.7427339553833008
I0326 16:22:53.722407 139718155032384 spec.py:321] Evaluating on the training split.
I0326 16:22:57.029200 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:26:12.788603 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 16:26:15.731233 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:28:40.525749 139718155032384 spec.py:349] Evaluating on the test split.
I0326 16:28:43.468810 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:30:50.493130 139718155032384 submission_runner.py:420] Time since start: 51101.88s, 	Step: 80870, 	{'train/accuracy': 0.6644508242607117, 'train/loss': 1.6332341432571411, 'train/bleu': 32.893763265093995, 'validation/accuracy': 0.6743375658988953, 'validation/loss': 1.5437225103378296, 'validation/bleu': 29.453807960036432, 'validation/num_examples': 3000, 'test/accuracy': 0.6885480284690857, 'test/loss': 1.4589591026306152, 'test/bleu': 28.845884887866404, 'test/num_examples': 3003, 'score': 31964.482553243637, 'total_duration': 51101.87626194954, 'accumulated_submission_time': 31964.482553243637, 'accumulated_eval_time': 19133.958903074265, 'accumulated_logging_time': 1.094712257385254}
I0326 16:30:50.511192 139548477597440 logging_writer.py:48] [80870] accumulated_eval_time=19133.958903, accumulated_logging_time=1.094712, accumulated_submission_time=31964.482553, global_step=80870, preemption_count=0, score=31964.482553, test/accuracy=0.688548, test/bleu=28.845885, test/loss=1.458959, test/num_examples=3003, total_duration=51101.876262, train/accuracy=0.664451, train/bleu=32.893763, train/loss=1.633234, validation/accuracy=0.674338, validation/bleu=29.453808, validation/loss=1.543723, validation/num_examples=3000
I0326 16:31:42.063043 139548485990144 logging_writer.py:48] [81000] global_step=81000, grad_norm=0.3755921423435211, loss=1.7086085081100464
I0326 16:34:59.458389 139548477597440 logging_writer.py:48] [81500] global_step=81500, grad_norm=0.3602820932865143, loss=1.6395604610443115
I0326 16:38:17.047558 139548485990144 logging_writer.py:48] [82000] global_step=82000, grad_norm=0.36767828464508057, loss=1.674126148223877
I0326 16:41:34.642204 139548477597440 logging_writer.py:48] [82500] global_step=82500, grad_norm=0.386234849691391, loss=1.7657208442687988
I0326 16:44:50.743255 139718155032384 spec.py:321] Evaluating on the training split.
I0326 16:44:54.040800 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:48:06.864114 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 16:48:09.812541 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:50:25.829200 139718155032384 spec.py:349] Evaluating on the test split.
I0326 16:50:28.780478 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 16:52:26.718685 139718155032384 submission_runner.py:420] Time since start: 52398.10s, 	Step: 82998, 	{'train/accuracy': 0.6658928990364075, 'train/loss': 1.624880075454712, 'train/bleu': 33.05402801387831, 'validation/accuracy': 0.6750319004058838, 'validation/loss': 1.5423458814620972, 'validation/bleu': 29.53866290463432, 'validation/num_examples': 3000, 'test/accuracy': 0.6881529688835144, 'test/loss': 1.4548407793045044, 'test/bleu': 28.883922822385834, 'test/num_examples': 3003, 'score': 32804.644961595535, 'total_duration': 52398.10178756714, 'accumulated_submission_time': 32804.644961595535, 'accumulated_eval_time': 19589.93427681923, 'accumulated_logging_time': 1.1223857402801514}
I0326 16:52:26.738132 139548485990144 logging_writer.py:48] [82998] accumulated_eval_time=19589.934277, accumulated_logging_time=1.122386, accumulated_submission_time=32804.644962, global_step=82998, preemption_count=0, score=32804.644962, test/accuracy=0.688153, test/bleu=28.883923, test/loss=1.454841, test/num_examples=3003, total_duration=52398.101788, train/accuracy=0.665893, train/bleu=33.054028, train/loss=1.624880, validation/accuracy=0.675032, validation/bleu=29.538663, validation/loss=1.542346, validation/num_examples=3000
I0326 16:52:27.933185 139548477597440 logging_writer.py:48] [83000] global_step=83000, grad_norm=0.38209614157676697, loss=1.7128148078918457
I0326 16:55:45.234480 139548485990144 logging_writer.py:48] [83500] global_step=83500, grad_norm=0.38183432817459106, loss=1.7221157550811768
I0326 16:59:02.940194 139548477597440 logging_writer.py:48] [84000] global_step=84000, grad_norm=0.36917829513549805, loss=1.6347174644470215
I0326 17:02:20.687030 139548485990144 logging_writer.py:48] [84500] global_step=84500, grad_norm=0.38994595408439636, loss=1.7558590173721313
I0326 17:05:38.357136 139548477597440 logging_writer.py:48] [85000] global_step=85000, grad_norm=0.3726802468299866, loss=1.7118579149246216
I0326 17:06:27.019056 139718155032384 spec.py:321] Evaluating on the training split.
I0326 17:06:30.315898 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:09:33.754295 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 17:09:36.722481 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:12:04.006365 139718155032384 spec.py:349] Evaluating on the test split.
I0326 17:12:06.959131 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:14:07.647075 139718155032384 submission_runner.py:420] Time since start: 53699.03s, 	Step: 85125, 	{'train/accuracy': 0.6661605834960938, 'train/loss': 1.6293845176696777, 'train/bleu': 33.031410263553745, 'validation/accuracy': 0.6757510900497437, 'validation/loss': 1.5391515493392944, 'validation/bleu': 29.399125439669973, 'validation/num_examples': 3000, 'test/accuracy': 0.6895125508308411, 'test/loss': 1.4517813920974731, 'test/bleu': 29.014955500067032, 'test/num_examples': 3003, 'score': 33644.85697507858, 'total_duration': 53699.03018069267, 'accumulated_submission_time': 33644.85697507858, 'accumulated_eval_time': 20050.562247276306, 'accumulated_logging_time': 1.1508526802062988}
I0326 17:14:07.666114 139548485990144 logging_writer.py:48] [85125] accumulated_eval_time=20050.562247, accumulated_logging_time=1.150853, accumulated_submission_time=33644.856975, global_step=85125, preemption_count=0, score=33644.856975, test/accuracy=0.689513, test/bleu=29.014956, test/loss=1.451781, test/num_examples=3003, total_duration=53699.030181, train/accuracy=0.666161, train/bleu=33.031410, train/loss=1.629385, validation/accuracy=0.675751, validation/bleu=29.399125, validation/loss=1.539152, validation/num_examples=3000
I0326 17:16:35.920385 139548477597440 logging_writer.py:48] [85500] global_step=85500, grad_norm=0.3778022229671478, loss=1.6694954633712769
I0326 17:19:53.349407 139548485990144 logging_writer.py:48] [86000] global_step=86000, grad_norm=0.3786219656467438, loss=1.747328519821167
I0326 17:23:11.016712 139548477597440 logging_writer.py:48] [86500] global_step=86500, grad_norm=0.37637263536453247, loss=1.7277404069900513
I0326 17:26:28.626733 139548485990144 logging_writer.py:48] [87000] global_step=87000, grad_norm=0.38175269961357117, loss=1.701564073562622
I0326 17:28:07.651515 139718155032384 spec.py:321] Evaluating on the training split.
I0326 17:28:10.966221 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:31:15.622087 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 17:31:18.577513 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:33:45.135512 139718155032384 spec.py:349] Evaluating on the test split.
I0326 17:33:48.081663 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:35:49.999503 139718155032384 submission_runner.py:420] Time since start: 55001.38s, 	Step: 87252, 	{'train/accuracy': 0.6625667214393616, 'train/loss': 1.6439590454101562, 'train/bleu': 33.311455593985066, 'validation/accuracy': 0.674821138381958, 'validation/loss': 1.539188265800476, 'validation/bleu': 29.55347587368749, 'validation/num_examples': 3000, 'test/accuracy': 0.6889199018478394, 'test/loss': 1.4510725736618042, 'test/bleu': 28.87610983946514, 'test/num_examples': 3003, 'score': 34484.774285793304, 'total_duration': 55001.382620573044, 'accumulated_submission_time': 34484.774285793304, 'accumulated_eval_time': 20512.910196065903, 'accumulated_logging_time': 1.1787753105163574}
I0326 17:35:50.017354 139548477597440 logging_writer.py:48] [87252] accumulated_eval_time=20512.910196, accumulated_logging_time=1.178775, accumulated_submission_time=34484.774286, global_step=87252, preemption_count=0, score=34484.774286, test/accuracy=0.688920, test/bleu=28.876110, test/loss=1.451073, test/num_examples=3003, total_duration=55001.382621, train/accuracy=0.662567, train/bleu=33.311456, train/loss=1.643959, validation/accuracy=0.674821, validation/bleu=29.553476, validation/loss=1.539188, validation/num_examples=3000
I0326 17:37:28.254339 139548485990144 logging_writer.py:48] [87500] global_step=87500, grad_norm=0.36659136414527893, loss=1.5854188203811646
I0326 17:40:45.766220 139548477597440 logging_writer.py:48] [88000] global_step=88000, grad_norm=0.3772886097431183, loss=1.6479511260986328
I0326 17:44:03.673909 139548485990144 logging_writer.py:48] [88500] global_step=88500, grad_norm=0.3776131570339203, loss=1.669356346130371
I0326 17:47:21.474984 139548477597440 logging_writer.py:48] [89000] global_step=89000, grad_norm=0.3753182291984558, loss=1.6489070653915405
I0326 17:49:50.391284 139718155032384 spec.py:321] Evaluating on the training split.
I0326 17:49:53.706060 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:52:50.878973 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 17:52:53.823135 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:55:21.266246 139718155032384 spec.py:349] Evaluating on the test split.
I0326 17:55:24.215615 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 17:57:28.425661 139718155032384 submission_runner.py:420] Time since start: 56299.81s, 	Step: 89378, 	{'train/accuracy': 0.6678431630134583, 'train/loss': 1.6093648672103882, 'train/bleu': 33.74220844567571, 'validation/accuracy': 0.67549067735672, 'validation/loss': 1.5368748903274536, 'validation/bleu': 29.518225547546326, 'validation/num_examples': 3000, 'test/accuracy': 0.6893033981323242, 'test/loss': 1.4499191045761108, 'test/bleu': 28.961180953632965, 'test/num_examples': 3003, 'score': 35325.074748039246, 'total_duration': 56299.808768987656, 'accumulated_submission_time': 35325.074748039246, 'accumulated_eval_time': 20970.944540262222, 'accumulated_logging_time': 1.2054882049560547}
I0326 17:57:28.444860 139548485990144 logging_writer.py:48] [89378] accumulated_eval_time=20970.944540, accumulated_logging_time=1.205488, accumulated_submission_time=35325.074748, global_step=89378, preemption_count=0, score=35325.074748, test/accuracy=0.689303, test/bleu=28.961181, test/loss=1.449919, test/num_examples=3003, total_duration=56299.808769, train/accuracy=0.667843, train/bleu=33.742208, train/loss=1.609365, validation/accuracy=0.675491, validation/bleu=29.518226, validation/loss=1.536875, validation/num_examples=3000
I0326 17:58:16.872717 139548477597440 logging_writer.py:48] [89500] global_step=89500, grad_norm=0.37291648983955383, loss=1.6479679346084595
I0326 18:01:34.233163 139548485990144 logging_writer.py:48] [90000] global_step=90000, grad_norm=0.37766724824905396, loss=1.7221065759658813
I0326 18:04:52.148814 139548477597440 logging_writer.py:48] [90500] global_step=90500, grad_norm=0.38043561577796936, loss=1.6296747922897339
I0326 18:08:09.804300 139548485990144 logging_writer.py:48] [91000] global_step=91000, grad_norm=0.3775660991668701, loss=1.6529511213302612
I0326 18:11:27.478458 139548477597440 logging_writer.py:48] [91500] global_step=91500, grad_norm=0.38023772835731506, loss=1.6605528593063354
I0326 18:11:28.747591 139718155032384 spec.py:321] Evaluating on the training split.
I0326 18:11:32.036080 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:14:43.457449 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 18:14:46.392997 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:17:14.262649 139718155032384 spec.py:349] Evaluating on the test split.
I0326 18:17:17.201990 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:19:24.031240 139718155032384 submission_runner.py:420] Time since start: 57615.41s, 	Step: 91505, 	{'train/accuracy': 0.6692007184028625, 'train/loss': 1.606384515762329, 'train/bleu': 33.270068291106114, 'validation/accuracy': 0.6759494543075562, 'validation/loss': 1.5350228548049927, 'validation/bleu': 29.44206848437146, 'validation/num_examples': 3000, 'test/accuracy': 0.6895822882652283, 'test/loss': 1.4467785358428955, 'test/bleu': 28.96231016820202, 'test/num_examples': 3003, 'score': 36165.305540561676, 'total_duration': 57615.41436624527, 'accumulated_submission_time': 36165.305540561676, 'accumulated_eval_time': 21446.22813630104, 'accumulated_logging_time': 1.2337958812713623}
I0326 18:19:24.050386 139548485990144 logging_writer.py:48] [91505] accumulated_eval_time=21446.228136, accumulated_logging_time=1.233796, accumulated_submission_time=36165.305541, global_step=91505, preemption_count=0, score=36165.305541, test/accuracy=0.689582, test/bleu=28.962310, test/loss=1.446779, test/num_examples=3003, total_duration=57615.414366, train/accuracy=0.669201, train/bleu=33.270068, train/loss=1.606385, validation/accuracy=0.675949, validation/bleu=29.442068, validation/loss=1.535023, validation/num_examples=3000
I0326 18:22:39.882131 139548477597440 logging_writer.py:48] [92000] global_step=92000, grad_norm=0.38118764758110046, loss=1.740409255027771
I0326 18:25:57.486225 139548485990144 logging_writer.py:48] [92500] global_step=92500, grad_norm=0.3736850321292877, loss=1.7143324613571167
I0326 18:29:15.293253 139548477597440 logging_writer.py:48] [93000] global_step=93000, grad_norm=0.3947431445121765, loss=1.7532974481582642
I0326 18:32:33.078288 139548485990144 logging_writer.py:48] [93500] global_step=93500, grad_norm=0.3787881135940552, loss=1.7090059518814087
I0326 18:33:24.152469 139718155032384 spec.py:321] Evaluating on the training split.
I0326 18:33:27.459431 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:36:43.461851 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 18:36:46.401412 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:39:05.444411 139718155032384 spec.py:349] Evaluating on the test split.
I0326 18:39:08.390370 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:41:13.334408 139718155032384 submission_runner.py:420] Time since start: 58924.72s, 	Step: 93631, 	{'train/accuracy': 0.6643207669258118, 'train/loss': 1.6307904720306396, 'train/bleu': 33.39272267403271, 'validation/accuracy': 0.675899863243103, 'validation/loss': 1.534496784210205, 'validation/bleu': 29.569689804946833, 'validation/num_examples': 3000, 'test/accuracy': 0.6896984577178955, 'test/loss': 1.4462283849716187, 'test/bleu': 28.92526570522043, 'test/num_examples': 3003, 'score': 37005.33549666405, 'total_duration': 58924.71753025055, 'accumulated_submission_time': 37005.33549666405, 'accumulated_eval_time': 21915.410023212433, 'accumulated_logging_time': 1.2617874145507812}
I0326 18:41:13.354506 139548477597440 logging_writer.py:48] [93631] accumulated_eval_time=21915.410023, accumulated_logging_time=1.261787, accumulated_submission_time=37005.335497, global_step=93631, preemption_count=0, score=37005.335497, test/accuracy=0.689698, test/bleu=28.925266, test/loss=1.446228, test/num_examples=3003, total_duration=58924.717530, train/accuracy=0.664321, train/bleu=33.392723, train/loss=1.630790, validation/accuracy=0.675900, validation/bleu=29.569690, validation/loss=1.534497, validation/num_examples=3000
I0326 18:43:39.265587 139548485990144 logging_writer.py:48] [94000] global_step=94000, grad_norm=0.37475597858428955, loss=1.6286401748657227
I0326 18:46:56.884909 139548477597440 logging_writer.py:48] [94500] global_step=94500, grad_norm=0.38981226086616516, loss=1.7319421768188477
I0326 18:50:14.631837 139548485990144 logging_writer.py:48] [95000] global_step=95000, grad_norm=0.3869932293891907, loss=1.6610420942306519
I0326 18:53:32.494138 139548477597440 logging_writer.py:48] [95500] global_step=95500, grad_norm=0.371480256319046, loss=1.7065004110336304
I0326 18:55:13.369075 139718155032384 spec.py:321] Evaluating on the training split.
I0326 18:55:16.671537 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 18:58:21.827992 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 18:58:24.770632 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:00:40.026669 139718155032384 spec.py:349] Evaluating on the test split.
I0326 19:00:42.973337 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:02:49.210176 139718155032384 submission_runner.py:420] Time since start: 60220.59s, 	Step: 95757, 	{'train/accuracy': 0.6658026576042175, 'train/loss': 1.6256057024002075, 'train/bleu': 33.14538555477715, 'validation/accuracy': 0.6764454245567322, 'validation/loss': 1.5338702201843262, 'validation/bleu': 29.651743492832765, 'validation/num_examples': 3000, 'test/accuracy': 0.6897565722465515, 'test/loss': 1.446224331855774, 'test/bleu': 28.982792991548262, 'test/num_examples': 3003, 'score': 37845.279463768005, 'total_duration': 60220.593296051025, 'accumulated_submission_time': 37845.279463768005, 'accumulated_eval_time': 22371.251089334488, 'accumulated_logging_time': 1.2910687923431396}
I0326 19:02:49.230614 139548485990144 logging_writer.py:48] [95757] accumulated_eval_time=22371.251089, accumulated_logging_time=1.291069, accumulated_submission_time=37845.279464, global_step=95757, preemption_count=0, score=37845.279464, test/accuracy=0.689757, test/bleu=28.982793, test/loss=1.446224, test/num_examples=3003, total_duration=60220.593296, train/accuracy=0.665803, train/bleu=33.145386, train/loss=1.625606, validation/accuracy=0.676445, validation/bleu=29.651743, validation/loss=1.533870, validation/num_examples=3000
I0326 19:04:25.434811 139548477597440 logging_writer.py:48] [96000] global_step=96000, grad_norm=0.36719515919685364, loss=1.6089115142822266
I0326 19:07:42.887563 139548485990144 logging_writer.py:48] [96500] global_step=96500, grad_norm=0.38070249557495117, loss=1.6915972232818604
I0326 19:11:00.429378 139548477597440 logging_writer.py:48] [97000] global_step=97000, grad_norm=0.39301931858062744, loss=1.7522616386413574
I0326 19:14:18.213095 139548485990144 logging_writer.py:48] [97500] global_step=97500, grad_norm=0.3908011317253113, loss=1.6978031396865845
I0326 19:16:49.456273 139718155032384 spec.py:321] Evaluating on the training split.
I0326 19:16:52.769080 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:19:46.189429 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 19:19:49.139457 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:22:07.441691 139718155032384 spec.py:349] Evaluating on the test split.
I0326 19:22:10.379506 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:24:12.291016 139718155032384 submission_runner.py:420] Time since start: 61503.67s, 	Step: 97884, 	{'train/accuracy': 0.6647250056266785, 'train/loss': 1.6299571990966797, 'train/bleu': 33.119370066979, 'validation/accuracy': 0.676482617855072, 'validation/loss': 1.5336493253707886, 'validation/bleu': 29.644226766928973, 'validation/num_examples': 3000, 'test/accuracy': 0.6896170973777771, 'test/loss': 1.4458106756210327, 'test/bleu': 29.05153768728049, 'test/num_examples': 3003, 'score': 38685.433634996414, 'total_duration': 61503.6741437912, 'accumulated_submission_time': 38685.433634996414, 'accumulated_eval_time': 22814.085819721222, 'accumulated_logging_time': 1.3211243152618408}
I0326 19:24:12.311823 139548477597440 logging_writer.py:48] [97884] accumulated_eval_time=22814.085820, accumulated_logging_time=1.321124, accumulated_submission_time=38685.433635, global_step=97884, preemption_count=0, score=38685.433635, test/accuracy=0.689617, test/bleu=29.051538, test/loss=1.445811, test/num_examples=3003, total_duration=61503.674144, train/accuracy=0.664725, train/bleu=33.119370, train/loss=1.629957, validation/accuracy=0.676483, validation/bleu=29.644227, validation/loss=1.533649, validation/num_examples=3000
I0326 19:24:58.391664 139548485990144 logging_writer.py:48] [98000] global_step=98000, grad_norm=0.4028650224208832, loss=1.7232309579849243
I0326 19:28:15.879847 139548477597440 logging_writer.py:48] [98500] global_step=98500, grad_norm=0.3710169494152069, loss=1.6262242794036865
I0326 19:31:33.370579 139548485990144 logging_writer.py:48] [99000] global_step=99000, grad_norm=0.3791137933731079, loss=1.689691424369812
I0326 19:34:51.098382 139548477597440 logging_writer.py:48] [99500] global_step=99500, grad_norm=0.37705904245376587, loss=1.6187622547149658
I0326 19:38:08.928117 139548485990144 logging_writer.py:48] [100000] global_step=100000, grad_norm=0.39024215936660767, loss=1.6973010301589966
I0326 19:38:12.569687 139718155032384 spec.py:321] Evaluating on the training split.
I0326 19:38:15.868119 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:41:21.982271 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 19:41:24.909083 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:43:42.844240 139718155032384 spec.py:349] Evaluating on the test split.
I0326 19:43:45.782272 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 19:45:49.209151 139718155032384 submission_runner.py:420] Time since start: 62800.59s, 	Step: 100011, 	{'train/accuracy': 0.6631566882133484, 'train/loss': 1.6354643106460571, 'train/bleu': 33.22771341830227, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 39525.62224817276, 'total_duration': 62800.5922498703, 'accumulated_submission_time': 39525.62224817276, 'accumulated_eval_time': 23270.725203990936, 'accumulated_logging_time': 1.350602388381958}
I0326 19:45:49.233935 139548477597440 logging_writer.py:48] [100011] accumulated_eval_time=23270.725204, accumulated_logging_time=1.350602, accumulated_submission_time=39525.622248, global_step=100011, preemption_count=0, score=39525.622248, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=62800.592250, train/accuracy=0.663157, train/bleu=33.227713, train/loss=1.635464, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 19:49:02.679456 139548485990144 logging_writer.py:48] [100500] global_step=100500, grad_norm=0.3847329020500183, loss=1.661086916923523
I0326 19:52:20.318207 139548477597440 logging_writer.py:48] [101000] global_step=101000, grad_norm=0.39074409008026123, loss=1.7175127267837524
I0326 19:55:37.993522 139548485990144 logging_writer.py:48] [101500] global_step=101500, grad_norm=0.389235258102417, loss=1.7411117553710938
I0326 19:58:55.669074 139548477597440 logging_writer.py:48] [102000] global_step=102000, grad_norm=0.3790470361709595, loss=1.6904467344284058
I0326 19:59:49.490428 139718155032384 spec.py:321] Evaluating on the training split.
I0326 19:59:52.785456 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:03:00.164785 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 20:03:03.106372 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:05:21.083872 139718155032384 spec.py:349] Evaluating on the test split.
I0326 20:05:24.039027 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:07:27.919250 139718155032384 submission_runner.py:420] Time since start: 64099.30s, 	Step: 102138, 	{'train/accuracy': 0.6662063002586365, 'train/loss': 1.6252217292785645, 'train/bleu': 33.41859247781274, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 40365.80884718895, 'total_duration': 64099.30232620239, 'accumulated_submission_time': 40365.80884718895, 'accumulated_eval_time': 23729.153928041458, 'accumulated_logging_time': 1.3860681056976318}
I0326 20:07:27.943698 139548485990144 logging_writer.py:48] [102138] accumulated_eval_time=23729.153928, accumulated_logging_time=1.386068, accumulated_submission_time=40365.808847, global_step=102138, preemption_count=0, score=40365.808847, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=64099.302326, train/accuracy=0.666206, train/bleu=33.418592, train/loss=1.625222, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 20:09:51.117998 139548477597440 logging_writer.py:48] [102500] global_step=102500, grad_norm=0.38005489110946655, loss=1.6477071046829224
I0326 20:13:08.895444 139548485990144 logging_writer.py:48] [103000] global_step=103000, grad_norm=0.386613130569458, loss=1.7096047401428223
I0326 20:16:26.492252 139548477597440 logging_writer.py:48] [103500] global_step=103500, grad_norm=0.36897802352905273, loss=1.6027300357818604
I0326 20:19:44.195008 139548485990144 logging_writer.py:48] [104000] global_step=104000, grad_norm=0.38551294803619385, loss=1.6920024156570435
I0326 20:21:28.208573 139718155032384 spec.py:321] Evaluating on the training split.
I0326 20:21:31.499711 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:24:44.539367 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 20:24:47.481966 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:27:05.332821 139718155032384 spec.py:349] Evaluating on the test split.
I0326 20:27:08.273928 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:29:10.281505 139718155032384 submission_runner.py:420] Time since start: 65401.66s, 	Step: 104265, 	{'train/accuracy': 0.6637135744094849, 'train/loss': 1.642957091331482, 'train/bleu': 33.476828274495745, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 41206.000952243805, 'total_duration': 65401.66462135315, 'accumulated_submission_time': 41206.000952243805, 'accumulated_eval_time': 24191.22681427002, 'accumulated_logging_time': 1.4201257228851318}
I0326 20:29:10.301431 139548477597440 logging_writer.py:48] [104265] accumulated_eval_time=24191.226814, accumulated_logging_time=1.420126, accumulated_submission_time=41206.000952, global_step=104265, preemption_count=0, score=41206.000952, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=65401.664621, train/accuracy=0.663714, train/bleu=33.476828, train/loss=1.642957, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 20:30:43.327090 139548485990144 logging_writer.py:48] [104500] global_step=104500, grad_norm=0.3898465931415558, loss=1.6866546869277954
I0326 20:34:01.028320 139548477597440 logging_writer.py:48] [105000] global_step=105000, grad_norm=0.39143797755241394, loss=1.6568032503128052
I0326 20:37:18.673933 139548485990144 logging_writer.py:48] [105500] global_step=105500, grad_norm=0.38017261028289795, loss=1.662122130393982
I0326 20:40:36.489820 139548477597440 logging_writer.py:48] [106000] global_step=106000, grad_norm=0.3765835762023926, loss=1.7123491764068604
I0326 20:43:10.374045 139718155032384 spec.py:321] Evaluating on the training split.
I0326 20:43:13.696344 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:46:32.631887 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 20:46:35.600789 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:48:54.228911 139718155032384 spec.py:349] Evaluating on the test split.
I0326 20:48:57.183338 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 20:50:59.146176 139718155032384 submission_runner.py:420] Time since start: 66710.53s, 	Step: 106391, 	{'train/accuracy': 0.663641631603241, 'train/loss': 1.6413278579711914, 'train/bleu': 33.06173071784763, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 42046.00037717819, 'total_duration': 66710.52930140495, 'accumulated_submission_time': 42046.00037717819, 'accumulated_eval_time': 24659.998909950256, 'accumulated_logging_time': 1.4497294425964355}
I0326 20:50:59.165863 139548485990144 logging_writer.py:48] [106391] accumulated_eval_time=24659.998910, accumulated_logging_time=1.449729, accumulated_submission_time=42046.000377, global_step=106391, preemption_count=0, score=42046.000377, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=66710.529301, train/accuracy=0.663642, train/bleu=33.061731, train/loss=1.641328, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 20:51:42.456410 139548477597440 logging_writer.py:48] [106500] global_step=106500, grad_norm=0.37232497334480286, loss=1.6564754247665405
I0326 20:54:59.887898 139548485990144 logging_writer.py:48] [107000] global_step=107000, grad_norm=0.3866763114929199, loss=1.7157453298568726
I0326 20:58:17.424289 139548477597440 logging_writer.py:48] [107500] global_step=107500, grad_norm=0.3801087737083435, loss=1.6580898761749268
I0326 21:01:35.086034 139548485990144 logging_writer.py:48] [108000] global_step=108000, grad_norm=0.4077056348323822, loss=1.7557549476623535
I0326 21:04:52.670669 139548477597440 logging_writer.py:48] [108500] global_step=108500, grad_norm=0.3808760643005371, loss=1.5836530923843384
I0326 21:04:59.475800 139718155032384 spec.py:321] Evaluating on the training split.
I0326 21:05:02.781302 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:08:14.742251 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 21:08:17.708721 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:10:37.618531 139718155032384 spec.py:349] Evaluating on the test split.
I0326 21:10:40.584529 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:12:43.859693 139718155032384 submission_runner.py:420] Time since start: 68015.24s, 	Step: 108519, 	{'train/accuracy': 0.6635457277297974, 'train/loss': 1.6351522207260132, 'train/bleu': 33.36698995555973, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 42886.24218392372, 'total_duration': 68015.24281430244, 'accumulated_submission_time': 42886.24218392372, 'accumulated_eval_time': 25124.382752656937, 'accumulated_logging_time': 1.4777867794036865}
I0326 21:12:43.879529 139548485990144 logging_writer.py:48] [108519] accumulated_eval_time=25124.382753, accumulated_logging_time=1.477787, accumulated_submission_time=42886.242184, global_step=108519, preemption_count=0, score=42886.242184, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=68015.242814, train/accuracy=0.663546, train/bleu=33.366990, train/loss=1.635152, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 21:15:54.071839 139548477597440 logging_writer.py:48] [109000] global_step=109000, grad_norm=0.3978510797023773, loss=1.7792037725448608
I0326 21:19:11.742129 139548485990144 logging_writer.py:48] [109500] global_step=109500, grad_norm=0.3769576847553253, loss=1.6300891637802124
I0326 21:22:29.359454 139548477597440 logging_writer.py:48] [110000] global_step=110000, grad_norm=0.3767913579940796, loss=1.6874186992645264
I0326 21:25:47.107090 139548485990144 logging_writer.py:48] [110500] global_step=110500, grad_norm=0.3872009217739105, loss=1.754995346069336
I0326 21:26:44.118336 139718155032384 spec.py:321] Evaluating on the training split.
I0326 21:26:47.430729 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:30:01.668748 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 21:30:04.617805 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:32:22.525480 139718155032384 spec.py:349] Evaluating on the test split.
I0326 21:32:25.463202 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:34:27.907193 139718155032384 submission_runner.py:420] Time since start: 69319.29s, 	Step: 110646, 	{'train/accuracy': 0.6649230122566223, 'train/loss': 1.6328346729278564, 'train/bleu': 33.09319428318106, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 43726.40936732292, 'total_duration': 69319.29031658173, 'accumulated_submission_time': 43726.40936732292, 'accumulated_eval_time': 25588.171586751938, 'accumulated_logging_time': 1.5061218738555908}
I0326 21:34:27.927471 139548477597440 logging_writer.py:48] [110646] accumulated_eval_time=25588.171587, accumulated_logging_time=1.506122, accumulated_submission_time=43726.409367, global_step=110646, preemption_count=0, score=43726.409367, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=69319.290317, train/accuracy=0.664923, train/bleu=33.093194, train/loss=1.632835, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 21:36:47.917745 139548485990144 logging_writer.py:48] [111000] global_step=111000, grad_norm=0.384103387594223, loss=1.6626334190368652
I0326 21:40:05.506098 139548477597440 logging_writer.py:48] [111500] global_step=111500, grad_norm=0.38382166624069214, loss=1.7121268510818481
I0326 21:43:23.275137 139548485990144 logging_writer.py:48] [112000] global_step=112000, grad_norm=0.3803076446056366, loss=1.640498161315918
I0326 21:46:41.035878 139548477597440 logging_writer.py:48] [112500] global_step=112500, grad_norm=0.38726767897605896, loss=1.7481738328933716
I0326 21:48:27.920084 139718155032384 spec.py:321] Evaluating on the training split.
I0326 21:48:31.223075 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:51:41.441502 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 21:51:44.388573 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:54:02.374179 139718155032384 spec.py:349] Evaluating on the test split.
I0326 21:54:05.315995 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 21:56:07.230114 139718155032384 submission_runner.py:420] Time since start: 70618.61s, 	Step: 112772, 	{'train/accuracy': 0.6653245687484741, 'train/loss': 1.629243016242981, 'train/bleu': 33.114112733533155, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 44566.33202266693, 'total_duration': 70618.61324000359, 'accumulated_submission_time': 44566.33202266693, 'accumulated_eval_time': 26047.481578588486, 'accumulated_logging_time': 1.5354969501495361}
I0326 21:56:07.250042 139548485990144 logging_writer.py:48] [112772] accumulated_eval_time=26047.481579, accumulated_logging_time=1.535497, accumulated_submission_time=44566.332023, global_step=112772, preemption_count=0, score=44566.332023, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=70618.613240, train/accuracy=0.665325, train/bleu=33.114113, train/loss=1.629243, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 21:57:37.460879 139548477597440 logging_writer.py:48] [113000] global_step=113000, grad_norm=0.3860386610031128, loss=1.7031898498535156
I0326 22:00:55.038271 139548485990144 logging_writer.py:48] [113500] global_step=113500, grad_norm=0.3850071430206299, loss=1.7302663326263428
I0326 22:04:12.754735 139548477597440 logging_writer.py:48] [114000] global_step=114000, grad_norm=0.38742801547050476, loss=1.7020314931869507
I0326 22:07:30.705746 139548485990144 logging_writer.py:48] [114500] global_step=114500, grad_norm=0.373188316822052, loss=1.6820381879806519
I0326 22:10:07.326827 139718155032384 spec.py:321] Evaluating on the training split.
I0326 22:10:10.619480 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:13:09.664888 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 22:13:12.610677 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:15:32.237805 139718155032384 spec.py:349] Evaluating on the test split.
I0326 22:15:35.197729 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:17:37.210836 139718155032384 submission_runner.py:420] Time since start: 71908.59s, 	Step: 114898, 	{'train/accuracy': 0.6667666435241699, 'train/loss': 1.620067834854126, 'train/bleu': 33.17930205843212, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 45406.33263897896, 'total_duration': 71908.59395694733, 'accumulated_submission_time': 45406.33263897896, 'accumulated_eval_time': 26497.36556339264, 'accumulated_logging_time': 1.564969539642334}
I0326 22:17:37.231291 139548477597440 logging_writer.py:48] [114898] accumulated_eval_time=26497.365563, accumulated_logging_time=1.564970, accumulated_submission_time=45406.332639, global_step=114898, preemption_count=0, score=45406.332639, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=71908.593957, train/accuracy=0.666767, train/bleu=33.179302, train/loss=1.620068, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 22:18:17.758363 139548485990144 logging_writer.py:48] [115000] global_step=115000, grad_norm=0.3743087947368622, loss=1.6114230155944824
I0326 22:21:35.336972 139548477597440 logging_writer.py:48] [115500] global_step=115500, grad_norm=0.38891538977622986, loss=1.7568720579147339
I0326 22:24:53.007479 139548485990144 logging_writer.py:48] [116000] global_step=116000, grad_norm=0.39402472972869873, loss=1.6637824773788452
I0326 22:28:10.662217 139548477597440 logging_writer.py:48] [116500] global_step=116500, grad_norm=0.37876468896865845, loss=1.6574786901474
I0326 22:31:28.284732 139548485990144 logging_writer.py:48] [117000] global_step=117000, grad_norm=0.3977900445461273, loss=1.7107102870941162
I0326 22:31:37.454798 139718155032384 spec.py:321] Evaluating on the training split.
I0326 22:31:40.757560 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:34:56.840787 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 22:34:59.792364 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:37:17.617106 139718155032384 spec.py:349] Evaluating on the test split.
I0326 22:37:20.555687 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:39:22.494842 139718155032384 submission_runner.py:420] Time since start: 73213.88s, 	Step: 117025, 	{'train/accuracy': 0.6684821844100952, 'train/loss': 1.6118019819259644, 'train/bleu': 33.24876625146544, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 46246.48472690582, 'total_duration': 73213.87795639038, 'accumulated_submission_time': 46246.48472690582, 'accumulated_eval_time': 26962.40554356575, 'accumulated_logging_time': 1.5938818454742432}
I0326 22:39:22.515020 139548477597440 logging_writer.py:48] [117025] accumulated_eval_time=26962.405544, accumulated_logging_time=1.593882, accumulated_submission_time=46246.484727, global_step=117025, preemption_count=0, score=46246.484727, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=73213.877956, train/accuracy=0.668482, train/bleu=33.248766, train/loss=1.611802, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 22:42:30.373627 139548485990144 logging_writer.py:48] [117500] global_step=117500, grad_norm=0.5024528503417969, loss=1.7863953113555908
I0326 22:45:47.931547 139548477597440 logging_writer.py:48] [118000] global_step=118000, grad_norm=0.37368035316467285, loss=1.673683762550354
I0326 22:49:05.534006 139548485990144 logging_writer.py:48] [118500] global_step=118500, grad_norm=0.3827672302722931, loss=1.60848867893219
I0326 22:52:23.286099 139548477597440 logging_writer.py:48] [119000] global_step=119000, grad_norm=0.3768508732318878, loss=1.6908035278320312
I0326 22:53:22.736474 139718155032384 spec.py:321] Evaluating on the training split.
I0326 22:53:26.031241 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:56:33.422334 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 22:56:36.355117 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 22:58:54.186782 139718155032384 spec.py:349] Evaluating on the test split.
I0326 22:58:57.126898 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 23:00:59.018948 139718155032384 submission_runner.py:420] Time since start: 74510.40s, 	Step: 119152, 	{'train/accuracy': 0.6632609963417053, 'train/loss': 1.6398509740829468, 'train/bleu': 32.862805290297274, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 47086.6354162693, 'total_duration': 74510.4020717144, 'accumulated_submission_time': 47086.6354162693, 'accumulated_eval_time': 27418.68799138069, 'accumulated_logging_time': 1.6234221458435059}
I0326 23:00:59.039615 139548485990144 logging_writer.py:48] [119152] accumulated_eval_time=27418.687991, accumulated_logging_time=1.623422, accumulated_submission_time=47086.635416, global_step=119152, preemption_count=0, score=47086.635416, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=74510.402072, train/accuracy=0.663261, train/bleu=32.862805, train/loss=1.639851, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 23:03:16.674313 139548477597440 logging_writer.py:48] [119500] global_step=119500, grad_norm=0.3790127635002136, loss=1.7012802362442017
I0326 23:06:34.156792 139548485990144 logging_writer.py:48] [120000] global_step=120000, grad_norm=0.3841155469417572, loss=1.7036978006362915
I0326 23:09:51.707294 139548477597440 logging_writer.py:48] [120500] global_step=120500, grad_norm=0.39010733366012573, loss=1.7315688133239746
I0326 23:13:09.320669 139548485990144 logging_writer.py:48] [121000] global_step=121000, grad_norm=0.392963171005249, loss=1.76723313331604
I0326 23:14:59.326618 139718155032384 spec.py:321] Evaluating on the training split.
I0326 23:15:02.639445 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 23:18:04.634126 139718155032384 spec.py:333] Evaluating on the validation split.
I0326 23:18:07.578863 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 23:20:25.565625 139718155032384 spec.py:349] Evaluating on the test split.
I0326 23:20:28.519736 139718155032384 workload.py:181] Translating evaluation dataset.
I0326 23:22:30.443581 139718155032384 submission_runner.py:420] Time since start: 75801.83s, 	Step: 121280, 	{'train/accuracy': 0.6646860837936401, 'train/loss': 1.6378016471862793, 'train/bleu': 33.552819755735264, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 47926.85423922539, 'total_duration': 75801.82671022415, 'accumulated_submission_time': 47926.85423922539, 'accumulated_eval_time': 27869.80495786667, 'accumulated_logging_time': 1.6523303985595703}
I0326 23:22:30.464450 139548477597440 logging_writer.py:48] [121280] accumulated_eval_time=27869.804958, accumulated_logging_time=1.652330, accumulated_submission_time=47926.854239, global_step=121280, preemption_count=0, score=47926.854239, test/accuracy=0.689629, test/bleu=29.010196, test/loss=1.445760, test/num_examples=3003, total_duration=75801.826710, train/accuracy=0.664686, train/bleu=33.552820, train/loss=1.637802, validation/accuracy=0.676321, validation/bleu=29.625025, validation/loss=1.533691, validation/num_examples=3000
I0326 23:23:57.563045 139548485990144 logging_writer.py:48] [121500] global_step=121500, grad_norm=0.3829863667488098, loss=1.7082818746566772
I0326 23:26:15.038798 139548477597440 logging_writer.py:48] [121850] global_step=121850, preemption_count=0, score=48151.390808
I0326 23:26:16.706034 139718155032384 checkpoints.py:490] Saving checkpoint at step: 121850
I0326 23:26:21.140610 139718155032384 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1/checkpoint_121850
I0326 23:26:21.146072 139718155032384 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/wmt_glu_tanh_jax/trial_1/checkpoint_121850.
I0326 23:26:21.185547 139718155032384 submission_runner.py:593] Tuning trial 1/1
I0326 23:26:21.185693 139718155032384 submission_runner.py:594] Hyperparameters: Hyperparameters(learning_rate=0.0002111193022461917, beta1=0.8748186204170956, beta2=0.8576876516215266, warmup_steps=9999, weight_decay=0.18033280763289028, label_smoothing=0.0)
I0326 23:26:21.187434 139718155032384 submission_runner.py:595] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0006544577772729099, 'train/loss': 11.358758926391602, 'train/bleu': 5.226550070522235e-11, 'validation/accuracy': 0.0004835649742744863, 'validation/loss': 11.346352577209473, 'validation/bleu': 0.0, 'validation/num_examples': 3000, 'test/accuracy': 0.0007088489946909249, 'test/loss': 11.35776138305664, 'test/bleu': 5.348545640066251e-10, 'test/num_examples': 3003, 'score': 40.46516227722168, 'total_duration': 940.3353931903839, 'accumulated_submission_time': 40.46516227722168, 'accumulated_eval_time': 899.8701910972595, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (2130, {'train/accuracy': 0.27093955874443054, 'train/loss': 5.799288272857666, 'train/bleu': 4.126816278480495, 'validation/accuracy': 0.25389641523361206, 'validation/loss': 6.011801242828369, 'validation/bleu': 2.116802980749451, 'validation/num_examples': 3000, 'test/accuracy': 0.23444309830665588, 'test/loss': 6.295222759246826, 'test/bleu': 1.4699774535962755, 'test/num_examples': 3003, 'score': 880.7291378974915, 'total_duration': 2627.456573486328, 'accumulated_submission_time': 880.7291378974915, 'accumulated_eval_time': 1746.6372668743134, 'accumulated_logging_time': 0.027021169662475586, 'global_step': 2130, 'preemption_count': 0}), (4262, {'train/accuracy': 0.37573936581611633, 'train/loss': 4.322761535644531, 'train/bleu': 10.870818743029048, 'validation/accuracy': 0.35269245505332947, 'validation/loss': 4.538534641265869, 'validation/bleu': 6.342824093268732, 'validation/num_examples': 3000, 'test/accuracy': 0.3332636058330536, 'test/loss': 4.799701690673828, 'test/bleu': 4.822614706678366, 'test/num_examples': 3003, 'score': 1720.8505008220673, 'total_duration': 4295.177495479584, 'accumulated_submission_time': 1720.8505008220673, 'accumulated_eval_time': 2574.149696111679, 'accumulated_logging_time': 0.0551455020904541, 'global_step': 4262, 'preemption_count': 0}), (6393, {'train/accuracy': 0.4912654459476471, 'train/loss': 3.2222611904144287, 'train/bleu': 19.697797928721243, 'validation/accuracy': 0.4758775532245636, 'validation/loss': 3.3509387969970703, 'validation/bleu': 14.410022052107662, 'validation/num_examples': 3000, 'test/accuracy': 0.46889781951904297, 'test/loss': 3.47405743598938, 'test/bleu': 12.481687483932063, 'test/num_examples': 3003, 'score': 2561.0418226718903, 'total_duration': 5636.012998342514, 'accumulated_submission_time': 2561.0418226718903, 'accumulated_eval_time': 3074.7091352939606, 'accumulated_logging_time': 0.07852911949157715, 'global_step': 6393, 'preemption_count': 0}), (8523, {'train/accuracy': 0.5403037667274475, 'train/loss': 2.743696689605713, 'train/bleu': 24.398100648381433, 'validation/accuracy': 0.5407124757766724, 'validation/loss': 2.7186522483825684, 'validation/bleu': 19.91883313495568, 'validation/num_examples': 3000, 'test/accuracy': 0.5433734655380249, 'test/loss': 2.743574380874634, 'test/bleu': 18.425026303901944, 'test/num_examples': 3003, 'score': 3401.0938029289246, 'total_duration': 6952.270023345947, 'accumulated_submission_time': 3401.0938029289246, 'accumulated_eval_time': 3550.829785823822, 'accumulated_logging_time': 0.10245394706726074, 'global_step': 8523, 'preemption_count': 0}), (10652, {'train/accuracy': 0.5709224939346313, 'train/loss': 2.4608547687530518, 'train/bleu': 26.78267087982707, 'validation/accuracy': 0.5760746598243713, 'validation/loss': 2.3768019676208496, 'validation/bleu': 22.404282535661746, 'validation/num_examples': 3000, 'test/accuracy': 0.577189028263092, 'test/loss': 2.3795788288116455, 'test/bleu': 20.701841781692146, 'test/num_examples': 3003, 'score': 4241.0500638484955, 'total_duration': 8245.589230537415, 'accumulated_submission_time': 4241.0500638484955, 'accumulated_eval_time': 4004.104261159897, 'accumulated_logging_time': 0.1272284984588623, 'global_step': 10652, 'preemption_count': 0}), (12781, {'train/accuracy': 0.6009242534637451, 'train/loss': 2.167930841445923, 'train/bleu': 28.771511285120063, 'validation/accuracy': 0.5995337963104248, 'validation/loss': 2.179979085922241, 'validation/bleu': 23.8841132813885, 'validation/num_examples': 3000, 'test/accuracy': 0.6030445694923401, 'test/loss': 2.157670497894287, 'test/bleu': 22.521304631100403, 'test/num_examples': 3003, 'score': 5081.135403871536, 'total_duration': 9573.15140914917, 'accumulated_submission_time': 5081.135403871536, 'accumulated_eval_time': 4491.494679689407, 'accumulated_logging_time': 0.1515347957611084, 'global_step': 12781, 'preemption_count': 0}), (14910, {'train/accuracy': 0.6043392419815063, 'train/loss': 2.13118577003479, 'train/bleu': 28.635248460338257, 'validation/accuracy': 0.6131603717803955, 'validation/loss': 2.0572800636291504, 'validation/bleu': 25.154799526881114, 'validation/num_examples': 3000, 'test/accuracy': 0.6177677512168884, 'test/loss': 2.023928165435791, 'test/bleu': 23.771131765689905, 'test/num_examples': 3003, 'score': 5921.088765621185, 'total_duration': 10880.465248346329, 'accumulated_submission_time': 5921.088765621185, 'accumulated_eval_time': 4958.763414859772, 'accumulated_logging_time': 0.18037986755371094, 'global_step': 14910, 'preemption_count': 0}), (17039, {'train/accuracy': 0.6120966672897339, 'train/loss': 2.068455219268799, 'train/bleu': 29.216168855040227, 'validation/accuracy': 0.6225464940071106, 'validation/loss': 1.9765042066574097, 'validation/bleu': 25.518672138926608, 'validation/num_examples': 3000, 'test/accuracy': 0.6296903491020203, 'test/loss': 1.925389289855957, 'test/bleu': 24.463759083185852, 'test/num_examples': 3003, 'score': 6761.183487892151, 'total_duration': 12149.19287109375, 'accumulated_submission_time': 6761.183487892151, 'accumulated_eval_time': 5387.312738418579, 'accumulated_logging_time': 0.20620489120483398, 'global_step': 17039, 'preemption_count': 0}), (19167, {'train/accuracy': 0.6214902400970459, 'train/loss': 1.972712516784668, 'train/bleu': 30.248103803089382, 'validation/accuracy': 0.6296387910842896, 'validation/loss': 1.9145017862319946, 'validation/bleu': 26.026892612448364, 'validation/num_examples': 3000, 'test/accuracy': 0.6362559199333191, 'test/loss': 1.864668846130371, 'test/bleu': 24.60783481856993, 'test/num_examples': 3003, 'score': 7601.048940181732, 'total_duration': 13432.111891508102, 'accumulated_submission_time': 7601.048940181732, 'accumulated_eval_time': 5830.208584308624, 'accumulated_logging_time': 0.30353426933288574, 'global_step': 19167, 'preemption_count': 0}), (21296, {'train/accuracy': 0.6231822967529297, 'train/loss': 1.967400074005127, 'train/bleu': 30.22888892093484, 'validation/accuracy': 0.6353424191474915, 'validation/loss': 1.863579273223877, 'validation/bleu': 26.392238692451198, 'validation/num_examples': 3000, 'test/accuracy': 0.6427633762359619, 'test/loss': 1.8073633909225464, 'test/bleu': 25.819944823884317, 'test/num_examples': 3003, 'score': 8441.285067796707, 'total_duration': 14752.149206638336, 'accumulated_submission_time': 8441.285067796707, 'accumulated_eval_time': 6309.925147533417, 'accumulated_logging_time': 0.32774877548217773, 'global_step': 21296, 'preemption_count': 0}), (23424, {'train/accuracy': 0.6224754452705383, 'train/loss': 1.9595882892608643, 'train/bleu': 30.77939013267566, 'validation/accuracy': 0.6388761401176453, 'validation/loss': 1.8288156986236572, 'validation/bleu': 26.847944393006056, 'validation/num_examples': 3000, 'test/accuracy': 0.6475858688354492, 'test/loss': 1.766526699066162, 'test/bleu': 25.693952740584837, 'test/num_examples': 3003, 'score': 9281.366070508957, 'total_duration': 16035.564885139465, 'accumulated_submission_time': 9281.366070508957, 'accumulated_eval_time': 6753.168920993805, 'accumulated_logging_time': 0.3561251163482666, 'global_step': 23424, 'preemption_count': 0}), (25550, {'train/accuracy': 0.6397817730903625, 'train/loss': 1.8352636098861694, 'train/bleu': 31.42415285207092, 'validation/accuracy': 0.6423974633216858, 'validation/loss': 1.796883463859558, 'validation/bleu': 26.894833345855076, 'validation/num_examples': 3000, 'test/accuracy': 0.6520829796791077, 'test/loss': 1.7320581674575806, 'test/bleu': 26.013254802832883, 'test/num_examples': 3003, 'score': 10121.52901339531, 'total_duration': 17337.24902200699, 'accumulated_submission_time': 10121.52901339531, 'accumulated_eval_time': 7214.59633231163, 'accumulated_logging_time': 0.38266491889953613, 'global_step': 25550, 'preemption_count': 0}), (27679, {'train/accuracy': 0.6318906545639038, 'train/loss': 1.885514736175537, 'train/bleu': 31.369597983481885, 'validation/accuracy': 0.6466875672340393, 'validation/loss': 1.7673922777175903, 'validation/bleu': 27.38267513672947, 'validation/num_examples': 3000, 'test/accuracy': 0.6565917134284973, 'test/loss': 1.7026907205581665, 'test/bleu': 26.53402928627849, 'test/num_examples': 3003, 'score': 10961.76893544197, 'total_duration': 18623.707042217255, 'accumulated_submission_time': 10961.76893544197, 'accumulated_eval_time': 7660.725780248642, 'accumulated_logging_time': 0.4088447093963623, 'global_step': 27679, 'preemption_count': 0}), (29807, {'train/accuracy': 0.6316201090812683, 'train/loss': 1.8734259605407715, 'train/bleu': 30.95687173447356, 'validation/accuracy': 0.6486714482307434, 'validation/loss': 1.7478152513504028, 'validation/bleu': 27.44764531779654, 'validation/num_examples': 3000, 'test/accuracy': 0.6579513549804688, 'test/loss': 1.683772087097168, 'test/bleu': 26.680195484452824, 'test/num_examples': 3003, 'score': 11801.76305937767, 'total_duration': 19924.670253753662, 'accumulated_submission_time': 11801.76305937767, 'accumulated_eval_time': 8121.601450204849, 'accumulated_logging_time': 0.43807554244995117, 'global_step': 29807, 'preemption_count': 0}), (31936, {'train/accuracy': 0.6406065225601196, 'train/loss': 1.814473271369934, 'train/bleu': 31.776392800461746, 'validation/accuracy': 0.6511388421058655, 'validation/loss': 1.7287027835845947, 'validation/bleu': 27.869752885143885, 'validation/num_examples': 3000, 'test/accuracy': 0.6602870225906372, 'test/loss': 1.662176489830017, 'test/bleu': 27.129149538184063, 'test/num_examples': 3003, 'score': 12641.800742864609, 'total_duration': 21230.501709222794, 'accumulated_submission_time': 12641.800742864609, 'accumulated_eval_time': 8587.306821346283, 'accumulated_logging_time': 0.465712308883667, 'global_step': 31936, 'preemption_count': 0}), (34065, {'train/accuracy': 0.640739381313324, 'train/loss': 1.8135218620300293, 'train/bleu': 31.720892098633595, 'validation/accuracy': 0.6525523662567139, 'validation/loss': 1.7109779119491577, 'validation/bleu': 27.501888843338417, 'validation/num_examples': 3000, 'test/accuracy': 0.6620417237281799, 'test/loss': 1.6420912742614746, 'test/bleu': 26.674599913045167, 'test/num_examples': 3003, 'score': 13482.01640677452, 'total_duration': 22509.849905252457, 'accumulated_submission_time': 13482.01640677452, 'accumulated_eval_time': 9026.352849721909, 'accumulated_logging_time': 0.49149322509765625, 'global_step': 34065, 'preemption_count': 0}), (36194, {'train/accuracy': 0.6364485025405884, 'train/loss': 1.8419629335403442, 'train/bleu': 31.526890861422114, 'validation/accuracy': 0.6544741988182068, 'validation/loss': 1.6928914785385132, 'validation/bleu': 27.82994853418911, 'validation/num_examples': 3000, 'test/accuracy': 0.6642612218856812, 'test/loss': 1.6232562065124512, 'test/bleu': 26.890337681174856, 'test/num_examples': 3003, 'score': 14322.055265665054, 'total_duration': 23832.97128868103, 'accumulated_submission_time': 14322.055265665054, 'accumulated_eval_time': 9509.346721887589, 'accumulated_logging_time': 0.5204513072967529, 'global_step': 36194, 'preemption_count': 0}), (38323, {'train/accuracy': 0.6442604660987854, 'train/loss': 1.7844679355621338, 'train/bleu': 32.063646108503356, 'validation/accuracy': 0.6566564440727234, 'validation/loss': 1.6798200607299805, 'validation/bleu': 27.93414196969954, 'validation/num_examples': 3000, 'test/accuracy': 0.667910099029541, 'test/loss': 1.6096643209457397, 'test/bleu': 27.240041752404643, 'test/num_examples': 3003, 'score': 15161.977427244186, 'total_duration': 25159.10061264038, 'accumulated_submission_time': 15161.977427244186, 'accumulated_eval_time': 9995.469063997269, 'accumulated_logging_time': 0.5457136631011963, 'global_step': 38323, 'preemption_count': 0}), (40451, {'train/accuracy': 0.6461368799209595, 'train/loss': 1.7737420797348022, 'train/bleu': 31.586409143337253, 'validation/accuracy': 0.6585162878036499, 'validation/loss': 1.6680903434753418, 'validation/bleu': 27.95472627491304, 'validation/num_examples': 3000, 'test/accuracy': 0.6679449081420898, 'test/loss': 1.5970640182495117, 'test/bleu': 27.34817933096726, 'test/num_examples': 3003, 'score': 16002.063148498535, 'total_duration': 26457.735300302505, 'accumulated_submission_time': 16002.063148498535, 'accumulated_eval_time': 10453.933075904846, 'accumulated_logging_time': 0.5711174011230469, 'global_step': 40451, 'preemption_count': 0}), (42578, {'train/accuracy': 0.6419093608856201, 'train/loss': 1.7889466285705566, 'train/bleu': 31.450693100668254, 'validation/accuracy': 0.6579955816268921, 'validation/loss': 1.6585248708724976, 'validation/bleu': 28.07055937179989, 'validation/num_examples': 3000, 'test/accuracy': 0.6679217219352722, 'test/loss': 1.5884218215942383, 'test/bleu': 27.306791955348064, 'test/num_examples': 3003, 'score': 16842.15467786789, 'total_duration': 27736.314566135406, 'accumulated_submission_time': 16842.15467786789, 'accumulated_eval_time': 10892.333222389221, 'accumulated_logging_time': 0.596534252166748, 'global_step': 42578, 'preemption_count': 0}), (44706, {'train/accuracy': 0.6493119597434998, 'train/loss': 1.7331675291061401, 'train/bleu': 32.19224109122431, 'validation/accuracy': 0.6602026224136353, 'validation/loss': 1.6442763805389404, 'validation/bleu': 28.252124841591026, 'validation/num_examples': 3000, 'test/accuracy': 0.6715589165687561, 'test/loss': 1.57472562789917, 'test/bleu': 27.47007836747885, 'test/num_examples': 3003, 'score': 17682.33544230461, 'total_duration': 29032.2545440197, 'accumulated_submission_time': 17682.33544230461, 'accumulated_eval_time': 11348.004050970078, 'accumulated_logging_time': 0.6215384006500244, 'global_step': 44706, 'preemption_count': 0}), (46833, {'train/accuracy': 0.6459473967552185, 'train/loss': 1.7606253623962402, 'train/bleu': 31.742556163953207, 'validation/accuracy': 0.6623228192329407, 'validation/loss': 1.635831356048584, 'validation/bleu': 28.549222616070168, 'validation/num_examples': 3000, 'test/accuracy': 0.6732903718948364, 'test/loss': 1.5621764659881592, 'test/bleu': 27.84722431998512, 'test/num_examples': 3003, 'score': 18522.51437306404, 'total_duration': 30293.487340688705, 'accumulated_submission_time': 18522.51437306404, 'accumulated_eval_time': 11768.968646764755, 'accumulated_logging_time': 0.647925853729248, 'global_step': 46833, 'preemption_count': 0}), (48960, {'train/accuracy': 0.6494240164756775, 'train/loss': 1.741469144821167, 'train/bleu': 31.711329570898744, 'validation/accuracy': 0.6627815961837769, 'validation/loss': 1.6288464069366455, 'validation/bleu': 28.454221701958485, 'validation/num_examples': 3000, 'test/accuracy': 0.6730579733848572, 'test/loss': 1.554472804069519, 'test/bleu': 27.65920033246138, 'test/num_examples': 3003, 'score': 19362.75937628746, 'total_duration': 31596.109431028366, 'accumulated_submission_time': 19362.75937628746, 'accumulated_eval_time': 12231.260348558426, 'accumulated_logging_time': 0.6742384433746338, 'global_step': 48960, 'preemption_count': 0}), (51088, {'train/accuracy': 0.6541247963905334, 'train/loss': 1.7044013738632202, 'train/bleu': 32.51463890372634, 'validation/accuracy': 0.6647034883499146, 'validation/loss': 1.6190812587738037, 'validation/bleu': 28.541555850264622, 'validation/num_examples': 3000, 'test/accuracy': 0.6759979128837585, 'test/loss': 1.5459054708480835, 'test/bleu': 27.81582596906202, 'test/num_examples': 3003, 'score': 20203.012866973877, 'total_duration': 32867.4601187706, 'accumulated_submission_time': 20203.012866973877, 'accumulated_eval_time': 12662.270419836044, 'accumulated_logging_time': 0.6999831199645996, 'global_step': 51088, 'preemption_count': 0}), (53215, {'train/accuracy': 0.6503514647483826, 'train/loss': 1.7199337482452393, 'train/bleu': 32.20614601646499, 'validation/accuracy': 0.6664889454841614, 'validation/loss': 1.605893850326538, 'validation/bleu': 28.80111518885052, 'validation/num_examples': 3000, 'test/accuracy': 0.6767997145652771, 'test/loss': 1.5347919464111328, 'test/bleu': 28.064821292902458, 'test/num_examples': 3003, 'score': 21043.053194999695, 'total_duration': 34141.61603355408, 'accumulated_submission_time': 21043.053194999695, 'accumulated_eval_time': 13096.298949480057, 'accumulated_logging_time': 0.7257065773010254, 'global_step': 53215, 'preemption_count': 0}), (55343, {'train/accuracy': 0.6536936163902283, 'train/loss': 1.7110180854797363, 'train/bleu': 32.08206514099033, 'validation/accuracy': 0.6651126146316528, 'validation/loss': 1.605336308479309, 'validation/bleu': 28.597463512538503, 'validation/num_examples': 3000, 'test/accuracy': 0.6763349175453186, 'test/loss': 1.5295848846435547, 'test/bleu': 27.94065320305915, 'test/num_examples': 3003, 'score': 21883.17886543274, 'total_duration': 35442.09198188782, 'accumulated_submission_time': 21883.17886543274, 'accumulated_eval_time': 13556.563753604889, 'accumulated_logging_time': 0.7513151168823242, 'global_step': 55343, 'preemption_count': 0}), (57470, {'train/accuracy': 0.6590781807899475, 'train/loss': 1.677270531654358, 'train/bleu': 32.61833773293062, 'validation/accuracy': 0.6678776144981384, 'validation/loss': 1.5970656871795654, 'validation/bleu': 29.095836433525825, 'validation/num_examples': 3000, 'test/accuracy': 0.6785776615142822, 'test/loss': 1.5185816287994385, 'test/bleu': 28.22648016703368, 'test/num_examples': 3003, 'score': 22723.339594364166, 'total_duration': 36753.524359464645, 'accumulated_submission_time': 22723.339594364166, 'accumulated_eval_time': 14027.745198726654, 'accumulated_logging_time': 0.7782564163208008, 'global_step': 57470, 'preemption_count': 0}), (59597, {'train/accuracy': 0.6529233455657959, 'train/loss': 1.7106753587722778, 'train/bleu': 32.56478568134917, 'validation/accuracy': 0.6675800681114197, 'validation/loss': 1.5873774290084839, 'validation/bleu': 29.03362858652503, 'validation/num_examples': 3000, 'test/accuracy': 0.6792516708374023, 'test/loss': 1.5106875896453857, 'test/bleu': 28.122545885080353, 'test/num_examples': 3003, 'score': 23563.399985313416, 'total_duration': 38036.61562204361, 'accumulated_submission_time': 23563.399985313416, 'accumulated_eval_time': 14470.683942556381, 'accumulated_logging_time': 0.8043756484985352, 'global_step': 59597, 'preemption_count': 0}), (61725, {'train/accuracy': 0.6515601277351379, 'train/loss': 1.7172927856445312, 'train/bleu': 32.24904633656718, 'validation/accuracy': 0.6682124137878418, 'validation/loss': 1.5838459730148315, 'validation/bleu': 29.214943493682032, 'validation/num_examples': 3000, 'test/accuracy': 0.6800883412361145, 'test/loss': 1.5061928033828735, 'test/bleu': 28.285435608132758, 'test/num_examples': 3003, 'score': 24403.476749181747, 'total_duration': 39342.61774158478, 'accumulated_submission_time': 24403.476749181747, 'accumulated_eval_time': 14936.520565748215, 'accumulated_logging_time': 0.8307778835296631, 'global_step': 61725, 'preemption_count': 0}), (63853, {'train/accuracy': 0.6600537300109863, 'train/loss': 1.669567584991455, 'train/bleu': 32.36535878181648, 'validation/accuracy': 0.6685224175453186, 'validation/loss': 1.5804531574249268, 'validation/bleu': 29.0512194690786, 'validation/num_examples': 3000, 'test/accuracy': 0.6814014315605164, 'test/loss': 1.5003212690353394, 'test/bleu': 28.46243019918655, 'test/num_examples': 3003, 'score': 25243.47717642784, 'total_duration': 40665.70834302902, 'accumulated_submission_time': 25243.47717642784, 'accumulated_eval_time': 15419.516457080841, 'accumulated_logging_time': 0.8640763759613037, 'global_step': 63853, 'preemption_count': 0}), (65981, {'train/accuracy': 0.6564612984657288, 'train/loss': 1.6870346069335938, 'train/bleu': 32.40155219027495, 'validation/accuracy': 0.6705682277679443, 'validation/loss': 1.5727699995040894, 'validation/bleu': 29.21382812854247, 'validation/num_examples': 3000, 'test/accuracy': 0.6818662881851196, 'test/loss': 1.4934130907058716, 'test/bleu': 28.418446160435852, 'test/num_examples': 3003, 'score': 26083.749479055405, 'total_duration': 41964.88067674637, 'accumulated_submission_time': 26083.749479055405, 'accumulated_eval_time': 15878.329960823059, 'accumulated_logging_time': 0.8912930488586426, 'global_step': 65981, 'preemption_count': 0}), (68110, {'train/accuracy': 0.6591756343841553, 'train/loss': 1.6740998029708862, 'train/bleu': 33.13587460529193, 'validation/accuracy': 0.670741856098175, 'validation/loss': 1.5643101930618286, 'validation/bleu': 29.045543532175397, 'validation/num_examples': 3000, 'test/accuracy': 0.6835512518882751, 'test/loss': 1.4830164909362793, 'test/bleu': 28.349632841069347, 'test/num_examples': 3003, 'score': 26924.032155513763, 'total_duration': 43286.51839852333, 'accumulated_submission_time': 26924.032155513763, 'accumulated_eval_time': 16359.599029064178, 'accumulated_logging_time': 0.9174084663391113, 'global_step': 68110, 'preemption_count': 0}), (70238, {'train/accuracy': 0.6604442000389099, 'train/loss': 1.6657711267471313, 'train/bleu': 32.65748161790169, 'validation/accuracy': 0.6725025177001953, 'validation/loss': 1.5626001358032227, 'validation/bleu': 29.17193255350609, 'validation/num_examples': 3000, 'test/accuracy': 0.6855034828186035, 'test/loss': 1.4803154468536377, 'test/bleu': 28.661273966831658, 'test/num_examples': 3003, 'score': 27764.273996829987, 'total_duration': 44576.85558485985, 'accumulated_submission_time': 27764.273996829987, 'accumulated_eval_time': 16809.602218151093, 'accumulated_logging_time': 0.9473400115966797, 'global_step': 70238, 'preemption_count': 0}), (72365, {'train/accuracy': 0.6582271456718445, 'train/loss': 1.6727216243743896, 'train/bleu': 32.4629981081095, 'validation/accuracy': 0.6732092499732971, 'validation/loss': 1.5576822757720947, 'validation/bleu': 29.288366297309235, 'validation/num_examples': 3000, 'test/accuracy': 0.6850502490997314, 'test/loss': 1.4750444889068604, 'test/bleu': 28.69783471709986, 'test/num_examples': 3003, 'score': 28604.286732912064, 'total_duration': 45882.10397315025, 'accumulated_submission_time': 28604.286732912064, 'accumulated_eval_time': 17274.74968957901, 'accumulated_logging_time': 0.9748327732086182, 'global_step': 72365, 'preemption_count': 0}), (74491, {'train/accuracy': 0.6647081971168518, 'train/loss': 1.6393332481384277, 'train/bleu': 33.07062489449608, 'validation/accuracy': 0.673568844795227, 'validation/loss': 1.5542222261428833, 'validation/bleu': 29.364483972398364, 'validation/num_examples': 3000, 'test/accuracy': 0.6867004036903381, 'test/loss': 1.4691143035888672, 'test/bleu': 28.949947187398234, 'test/num_examples': 3003, 'score': 29444.215552568436, 'total_duration': 47185.95525050163, 'accumulated_submission_time': 29444.215552568436, 'accumulated_eval_time': 17738.5762860775, 'accumulated_logging_time': 1.00701904296875, 'global_step': 74491, 'preemption_count': 0}), (76617, {'train/accuracy': 0.6620994210243225, 'train/loss': 1.6539947986602783, 'train/bleu': 33.319546257429636, 'validation/accuracy': 0.6737052202224731, 'validation/loss': 1.5505098104476929, 'validation/bleu': 29.241776418280704, 'validation/num_examples': 3000, 'test/accuracy': 0.6865260601043701, 'test/loss': 1.4673891067504883, 'test/bleu': 28.681083122730616, 'test/num_examples': 3003, 'score': 30284.14289712906, 'total_duration': 48494.68763375282, 'accumulated_submission_time': 30284.14289712906, 'accumulated_eval_time': 18207.290071249008, 'accumulated_logging_time': 1.0347270965576172, 'global_step': 76617, 'preemption_count': 0}), (78743, {'train/accuracy': 0.6623937487602234, 'train/loss': 1.6457419395446777, 'train/bleu': 33.11086571288778, 'validation/accuracy': 0.6740400195121765, 'validation/loss': 1.5491384267807007, 'validation/bleu': 29.40327698765743, 'validation/num_examples': 3000, 'test/accuracy': 0.6872814297676086, 'test/loss': 1.462404489517212, 'test/bleu': 28.759189457182835, 'test/num_examples': 3003, 'score': 31124.188576698303, 'total_duration': 49784.72490167618, 'accumulated_submission_time': 31124.188576698303, 'accumulated_eval_time': 18657.18817090988, 'accumulated_logging_time': 1.067159652709961, 'global_step': 78743, 'preemption_count': 0}), (80870, {'train/accuracy': 0.6644508242607117, 'train/loss': 1.6332341432571411, 'train/bleu': 32.893763265093995, 'validation/accuracy': 0.6743375658988953, 'validation/loss': 1.5437225103378296, 'validation/bleu': 29.453807960036432, 'validation/num_examples': 3000, 'test/accuracy': 0.6885480284690857, 'test/loss': 1.4589591026306152, 'test/bleu': 28.845884887866404, 'test/num_examples': 3003, 'score': 31964.482553243637, 'total_duration': 51101.87626194954, 'accumulated_submission_time': 31964.482553243637, 'accumulated_eval_time': 19133.958903074265, 'accumulated_logging_time': 1.094712257385254, 'global_step': 80870, 'preemption_count': 0}), (82998, {'train/accuracy': 0.6658928990364075, 'train/loss': 1.624880075454712, 'train/bleu': 33.05402801387831, 'validation/accuracy': 0.6750319004058838, 'validation/loss': 1.5423458814620972, 'validation/bleu': 29.53866290463432, 'validation/num_examples': 3000, 'test/accuracy': 0.6881529688835144, 'test/loss': 1.4548407793045044, 'test/bleu': 28.883922822385834, 'test/num_examples': 3003, 'score': 32804.644961595535, 'total_duration': 52398.10178756714, 'accumulated_submission_time': 32804.644961595535, 'accumulated_eval_time': 19589.93427681923, 'accumulated_logging_time': 1.1223857402801514, 'global_step': 82998, 'preemption_count': 0}), (85125, {'train/accuracy': 0.6661605834960938, 'train/loss': 1.6293845176696777, 'train/bleu': 33.031410263553745, 'validation/accuracy': 0.6757510900497437, 'validation/loss': 1.5391515493392944, 'validation/bleu': 29.399125439669973, 'validation/num_examples': 3000, 'test/accuracy': 0.6895125508308411, 'test/loss': 1.4517813920974731, 'test/bleu': 29.014955500067032, 'test/num_examples': 3003, 'score': 33644.85697507858, 'total_duration': 53699.03018069267, 'accumulated_submission_time': 33644.85697507858, 'accumulated_eval_time': 20050.562247276306, 'accumulated_logging_time': 1.1508526802062988, 'global_step': 85125, 'preemption_count': 0}), (87252, {'train/accuracy': 0.6625667214393616, 'train/loss': 1.6439590454101562, 'train/bleu': 33.311455593985066, 'validation/accuracy': 0.674821138381958, 'validation/loss': 1.539188265800476, 'validation/bleu': 29.55347587368749, 'validation/num_examples': 3000, 'test/accuracy': 0.6889199018478394, 'test/loss': 1.4510725736618042, 'test/bleu': 28.87610983946514, 'test/num_examples': 3003, 'score': 34484.774285793304, 'total_duration': 55001.382620573044, 'accumulated_submission_time': 34484.774285793304, 'accumulated_eval_time': 20512.910196065903, 'accumulated_logging_time': 1.1787753105163574, 'global_step': 87252, 'preemption_count': 0}), (89378, {'train/accuracy': 0.6678431630134583, 'train/loss': 1.6093648672103882, 'train/bleu': 33.74220844567571, 'validation/accuracy': 0.67549067735672, 'validation/loss': 1.5368748903274536, 'validation/bleu': 29.518225547546326, 'validation/num_examples': 3000, 'test/accuracy': 0.6893033981323242, 'test/loss': 1.4499191045761108, 'test/bleu': 28.961180953632965, 'test/num_examples': 3003, 'score': 35325.074748039246, 'total_duration': 56299.808768987656, 'accumulated_submission_time': 35325.074748039246, 'accumulated_eval_time': 20970.944540262222, 'accumulated_logging_time': 1.2054882049560547, 'global_step': 89378, 'preemption_count': 0}), (91505, {'train/accuracy': 0.6692007184028625, 'train/loss': 1.606384515762329, 'train/bleu': 33.270068291106114, 'validation/accuracy': 0.6759494543075562, 'validation/loss': 1.5350228548049927, 'validation/bleu': 29.44206848437146, 'validation/num_examples': 3000, 'test/accuracy': 0.6895822882652283, 'test/loss': 1.4467785358428955, 'test/bleu': 28.96231016820202, 'test/num_examples': 3003, 'score': 36165.305540561676, 'total_duration': 57615.41436624527, 'accumulated_submission_time': 36165.305540561676, 'accumulated_eval_time': 21446.22813630104, 'accumulated_logging_time': 1.2337958812713623, 'global_step': 91505, 'preemption_count': 0}), (93631, {'train/accuracy': 0.6643207669258118, 'train/loss': 1.6307904720306396, 'train/bleu': 33.39272267403271, 'validation/accuracy': 0.675899863243103, 'validation/loss': 1.534496784210205, 'validation/bleu': 29.569689804946833, 'validation/num_examples': 3000, 'test/accuracy': 0.6896984577178955, 'test/loss': 1.4462283849716187, 'test/bleu': 28.92526570522043, 'test/num_examples': 3003, 'score': 37005.33549666405, 'total_duration': 58924.71753025055, 'accumulated_submission_time': 37005.33549666405, 'accumulated_eval_time': 21915.410023212433, 'accumulated_logging_time': 1.2617874145507812, 'global_step': 93631, 'preemption_count': 0}), (95757, {'train/accuracy': 0.6658026576042175, 'train/loss': 1.6256057024002075, 'train/bleu': 33.14538555477715, 'validation/accuracy': 0.6764454245567322, 'validation/loss': 1.5338702201843262, 'validation/bleu': 29.651743492832765, 'validation/num_examples': 3000, 'test/accuracy': 0.6897565722465515, 'test/loss': 1.446224331855774, 'test/bleu': 28.982792991548262, 'test/num_examples': 3003, 'score': 37845.279463768005, 'total_duration': 60220.593296051025, 'accumulated_submission_time': 37845.279463768005, 'accumulated_eval_time': 22371.251089334488, 'accumulated_logging_time': 1.2910687923431396, 'global_step': 95757, 'preemption_count': 0}), (97884, {'train/accuracy': 0.6647250056266785, 'train/loss': 1.6299571990966797, 'train/bleu': 33.119370066979, 'validation/accuracy': 0.676482617855072, 'validation/loss': 1.5336493253707886, 'validation/bleu': 29.644226766928973, 'validation/num_examples': 3000, 'test/accuracy': 0.6896170973777771, 'test/loss': 1.4458106756210327, 'test/bleu': 29.05153768728049, 'test/num_examples': 3003, 'score': 38685.433634996414, 'total_duration': 61503.6741437912, 'accumulated_submission_time': 38685.433634996414, 'accumulated_eval_time': 22814.085819721222, 'accumulated_logging_time': 1.3211243152618408, 'global_step': 97884, 'preemption_count': 0}), (100011, {'train/accuracy': 0.6631566882133484, 'train/loss': 1.6354643106460571, 'train/bleu': 33.22771341830227, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 39525.62224817276, 'total_duration': 62800.5922498703, 'accumulated_submission_time': 39525.62224817276, 'accumulated_eval_time': 23270.725203990936, 'accumulated_logging_time': 1.350602388381958, 'global_step': 100011, 'preemption_count': 0}), (102138, {'train/accuracy': 0.6662063002586365, 'train/loss': 1.6252217292785645, 'train/bleu': 33.41859247781274, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 40365.80884718895, 'total_duration': 64099.30232620239, 'accumulated_submission_time': 40365.80884718895, 'accumulated_eval_time': 23729.153928041458, 'accumulated_logging_time': 1.3860681056976318, 'global_step': 102138, 'preemption_count': 0}), (104265, {'train/accuracy': 0.6637135744094849, 'train/loss': 1.642957091331482, 'train/bleu': 33.476828274495745, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 41206.000952243805, 'total_duration': 65401.66462135315, 'accumulated_submission_time': 41206.000952243805, 'accumulated_eval_time': 24191.22681427002, 'accumulated_logging_time': 1.4201257228851318, 'global_step': 104265, 'preemption_count': 0}), (106391, {'train/accuracy': 0.663641631603241, 'train/loss': 1.6413278579711914, 'train/bleu': 33.06173071784763, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 42046.00037717819, 'total_duration': 66710.52930140495, 'accumulated_submission_time': 42046.00037717819, 'accumulated_eval_time': 24659.998909950256, 'accumulated_logging_time': 1.4497294425964355, 'global_step': 106391, 'preemption_count': 0}), (108519, {'train/accuracy': 0.6635457277297974, 'train/loss': 1.6351522207260132, 'train/bleu': 33.36698995555973, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 42886.24218392372, 'total_duration': 68015.24281430244, 'accumulated_submission_time': 42886.24218392372, 'accumulated_eval_time': 25124.382752656937, 'accumulated_logging_time': 1.4777867794036865, 'global_step': 108519, 'preemption_count': 0}), (110646, {'train/accuracy': 0.6649230122566223, 'train/loss': 1.6328346729278564, 'train/bleu': 33.09319428318106, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 43726.40936732292, 'total_duration': 69319.29031658173, 'accumulated_submission_time': 43726.40936732292, 'accumulated_eval_time': 25588.171586751938, 'accumulated_logging_time': 1.5061218738555908, 'global_step': 110646, 'preemption_count': 0}), (112772, {'train/accuracy': 0.6653245687484741, 'train/loss': 1.629243016242981, 'train/bleu': 33.114112733533155, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 44566.33202266693, 'total_duration': 70618.61324000359, 'accumulated_submission_time': 44566.33202266693, 'accumulated_eval_time': 26047.481578588486, 'accumulated_logging_time': 1.5354969501495361, 'global_step': 112772, 'preemption_count': 0}), (114898, {'train/accuracy': 0.6667666435241699, 'train/loss': 1.620067834854126, 'train/bleu': 33.17930205843212, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 45406.33263897896, 'total_duration': 71908.59395694733, 'accumulated_submission_time': 45406.33263897896, 'accumulated_eval_time': 26497.36556339264, 'accumulated_logging_time': 1.564969539642334, 'global_step': 114898, 'preemption_count': 0}), (117025, {'train/accuracy': 0.6684821844100952, 'train/loss': 1.6118019819259644, 'train/bleu': 33.24876625146544, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 46246.48472690582, 'total_duration': 73213.87795639038, 'accumulated_submission_time': 46246.48472690582, 'accumulated_eval_time': 26962.40554356575, 'accumulated_logging_time': 1.5938818454742432, 'global_step': 117025, 'preemption_count': 0}), (119152, {'train/accuracy': 0.6632609963417053, 'train/loss': 1.6398509740829468, 'train/bleu': 32.862805290297274, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 47086.6354162693, 'total_duration': 74510.4020717144, 'accumulated_submission_time': 47086.6354162693, 'accumulated_eval_time': 27418.68799138069, 'accumulated_logging_time': 1.6234221458435059, 'global_step': 119152, 'preemption_count': 0}), (121280, {'train/accuracy': 0.6646860837936401, 'train/loss': 1.6378016471862793, 'train/bleu': 33.552819755735264, 'validation/accuracy': 0.6763214468955994, 'validation/loss': 1.5336906909942627, 'validation/bleu': 29.625024680132437, 'validation/num_examples': 3000, 'test/accuracy': 0.6896287202835083, 'test/loss': 1.4457597732543945, 'test/bleu': 29.01019585406551, 'test/num_examples': 3003, 'score': 47926.85423922539, 'total_duration': 75801.82671022415, 'accumulated_submission_time': 47926.85423922539, 'accumulated_eval_time': 27869.80495786667, 'accumulated_logging_time': 1.6523303985595703, 'global_step': 121280, 'preemption_count': 0})], 'global_step': 121850}
I0326 23:26:21.187568 139718155032384 submission_runner.py:596] Timing: 48151.39080834389
I0326 23:26:21.187618 139718155032384 submission_runner.py:598] Total number of evals: 58
I0326 23:26:21.187659 139718155032384 submission_runner.py:599] ====================
I0326 23:26:21.187803 139718155032384 submission_runner.py:683] Final wmt_glu_tanh score: 0

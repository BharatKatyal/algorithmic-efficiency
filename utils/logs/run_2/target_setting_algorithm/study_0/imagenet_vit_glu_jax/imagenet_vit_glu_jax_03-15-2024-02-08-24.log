python3 submission_runner.py --framework=jax --workload=imagenet_vit_glu --submission_path=reference_algorithms/target_setting_algorithms/jax_nadamw.py --data_dir=/data/imagenet/jax --num_tuning_trials=1 --experiment_dir=/experiment_runs --experiment_name=variants_target_setting/study_0 --overwrite=true --save_checkpoints=false --rng_seed=3173852236 --max_global_steps=186666 --imagenet_v2_data_dir=/data/imagenet/jax --tuning_ruleset=external --tuning_search_space=reference_algorithms/target_setting_algorithms/imagenet_vit_glu/tuning_search_space.json --num_tuning_trials=1 2>&1 | tee -a /logs/imagenet_vit_glu_jax_03-15-2024-02-08-24.log
/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: 

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). 

For more information see: https://github.com/tensorflow/addons/issues/2807 

  warnings.warn(
I0315 02:08:45.669540 139734377899840 logger_utils.py:61] Removing existing experiment directory /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax because --overwrite was set.
I0315 02:08:45.756103 139734377899840 logger_utils.py:76] Creating experiment directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax.
I0315 02:08:46.757130 139734377899840 xla_bridge.py:455] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: Interpreter Host CUDA
I0315 02:08:46.758102 139734377899840 xla_bridge.py:455] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I0315 02:08:46.758320 139734377899840 xla_bridge.py:455] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
I0315 02:08:46.765617 139734377899840 submission_runner.py:554] Using RNG seed 3173852236
I0315 02:08:47.842159 139734377899840 submission_runner.py:563] --- Tuning run 1/1 ---
I0315 02:08:47.842392 139734377899840 submission_runner.py:568] Creating tuning directory at /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1.
I0315 02:08:47.842612 139734377899840 logger_utils.py:92] Saving hparams to /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1/hparams.json.
I0315 02:08:48.027202 139734377899840 submission_runner.py:209] Initializing dataset.
I0315 02:08:48.045138 139734377899840 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:08:48.056195 139734377899840 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 02:08:48.434599 139734377899840 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:08:56.633332 139734377899840 submission_runner.py:220] Initializing model.
I0315 02:09:07.073847 139734377899840 submission_runner.py:262] Initializing optimizer.
I0315 02:09:08.166441 139734377899840 submission_runner.py:269] Initializing metrics bundle.
I0315 02:09:08.166634 139734377899840 submission_runner.py:287] Initializing checkpoint and logger.
I0315 02:09:08.167830 139734377899840 checkpoints.py:915] Found no checkpoint files in /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1 with prefix checkpoint_
I0315 02:09:08.167978 139734377899840 submission_runner.py:307] Saving meta data to /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1/meta_data_0.json.
fatal: detected dubious ownership in repository at '/algorithmic-efficiency'
To add an exception for this directory, call:

	git config --global --add safe.directory /algorithmic-efficiency
I0315 02:09:08.477446 139734377899840 logger_utils.py:220] Unable to record git information. Continuing without it.
I0315 02:09:08.765326 139734377899840 submission_runner.py:311] Saving flags to /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1/flags_0.json.
I0315 02:09:08.774861 139734377899840 submission_runner.py:321] Starting training loop.
I0315 02:09:50.483139 139571329804032 logging_writer.py:48] [0] global_step=0, grad_norm=0.5307573080062866, loss=6.9077558517456055
I0315 02:09:50.504673 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:09:50.513321 139734377899840 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:09:50.524517 139734377899840 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 02:09:50.614871 139734377899840 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split train, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:10:13.686451 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:10:13.693243 139734377899840 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:10:13.702243 139734377899840 dataset_info.py:669] Fields info.[splits, supervised_keys] from disk and from code do not match. Keeping the one from code.
I0315 02:10:13.743460 139734377899840 logging_logger.py:49] Constructing tf.data.Dataset imagenet2012 for split validation, from /data/imagenet/jax/imagenet2012/5.1.0
I0315 02:10:32.408287 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:10:32.414434 139734377899840 dataset_info.py:578] Load dataset info from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0315 02:10:32.419719 139734377899840 dataset_builder.py:528] Reusing dataset imagenet_v2 (/data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0)
I0315 02:10:32.458554 139734377899840 logging_logger.py:49] Constructing tf.data.Dataset imagenet_v2 for split test, from /data/imagenet/jax/imagenet_v2/matched-frequency/3.0.0
I0315 02:10:37.332284 139734377899840 submission_runner.py:420] Time since start: 88.56s, 	Step: 1, 	{'train/accuracy': 0.0007617187220603228, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 41.72967982292175, 'total_duration': 88.55736303329468, 'accumulated_submission_time': 41.72967982292175, 'accumulated_eval_time': 46.82756495475769, 'accumulated_logging_time': 0}
I0315 02:10:37.349327 139540526262016 logging_writer.py:48] [1] accumulated_eval_time=46.827565, accumulated_logging_time=0, accumulated_submission_time=41.729680, global_step=1, preemption_count=0, score=41.729680, test/accuracy=0.001000, test/loss=6.907757, test/num_examples=10000, total_duration=88.557363, train/accuracy=0.000762, train/loss=6.907756, validation/accuracy=0.001000, validation/loss=6.907756, validation/num_examples=50000
I0315 02:11:02.855166 139572084180736 logging_writer.py:48] [1] global_step=1, grad_norm=0.5041911005973816, loss=6.9077558517456055
I0315 02:11:03.249323 139572092573440 logging_writer.py:48] [2] global_step=2, grad_norm=0.5009155869483948, loss=6.907754421234131
I0315 02:11:03.652349 139572084180736 logging_writer.py:48] [3] global_step=3, grad_norm=0.5373414158821106, loss=6.907753944396973
I0315 02:11:04.050383 139572092573440 logging_writer.py:48] [4] global_step=4, grad_norm=0.5251891613006592, loss=6.907753944396973
I0315 02:11:04.449930 139572084180736 logging_writer.py:48] [5] global_step=5, grad_norm=0.5463772416114807, loss=6.907748699188232
I0315 02:11:04.851207 139572092573440 logging_writer.py:48] [6] global_step=6, grad_norm=0.5320554375648499, loss=6.907755374908447
I0315 02:11:05.247620 139572084180736 logging_writer.py:48] [7] global_step=7, grad_norm=0.5104211568832397, loss=6.907754898071289
I0315 02:11:05.650196 139572092573440 logging_writer.py:48] [8] global_step=8, grad_norm=0.5261605381965637, loss=6.907758712768555
I0315 02:11:06.047730 139572084180736 logging_writer.py:48] [9] global_step=9, grad_norm=0.5298463702201843, loss=6.9077558517456055
I0315 02:11:06.455126 139572092573440 logging_writer.py:48] [10] global_step=10, grad_norm=0.5196107029914856, loss=6.907746315002441
I0315 02:11:06.855761 139572084180736 logging_writer.py:48] [11] global_step=11, grad_norm=0.5344832539558411, loss=6.907720565795898
I0315 02:11:07.256018 139572092573440 logging_writer.py:48] [12] global_step=12, grad_norm=0.5248831510543823, loss=6.907711505889893
I0315 02:11:07.655832 139572084180736 logging_writer.py:48] [13] global_step=13, grad_norm=0.5335619449615479, loss=6.907750129699707
I0315 02:11:08.058988 139572092573440 logging_writer.py:48] [14] global_step=14, grad_norm=0.5051091313362122, loss=6.907732963562012
I0315 02:11:08.468805 139572084180736 logging_writer.py:48] [15] global_step=15, grad_norm=0.5338996052742004, loss=6.9077043533325195
I0315 02:11:08.868137 139572092573440 logging_writer.py:48] [16] global_step=16, grad_norm=0.5274432301521301, loss=6.907743453979492
I0315 02:11:09.267062 139572084180736 logging_writer.py:48] [17] global_step=17, grad_norm=0.50190669298172, loss=6.907754898071289
I0315 02:11:09.668472 139572092573440 logging_writer.py:48] [18] global_step=18, grad_norm=0.5315636396408081, loss=6.907712936401367
I0315 02:11:10.073906 139572084180736 logging_writer.py:48] [19] global_step=19, grad_norm=0.5177652835845947, loss=6.907763481140137
I0315 02:11:10.474039 139572092573440 logging_writer.py:48] [20] global_step=20, grad_norm=0.5308244228363037, loss=6.907661437988281
I0315 02:11:10.883112 139572084180736 logging_writer.py:48] [21] global_step=21, grad_norm=0.531620979309082, loss=6.907760143280029
I0315 02:11:11.291833 139572092573440 logging_writer.py:48] [22] global_step=22, grad_norm=0.5159053206443787, loss=6.907660007476807
I0315 02:11:11.702849 139572084180736 logging_writer.py:48] [23] global_step=23, grad_norm=0.5269493460655212, loss=6.907676696777344
I0315 02:11:12.101455 139572092573440 logging_writer.py:48] [24] global_step=24, grad_norm=0.5108689665794373, loss=6.907668590545654
I0315 02:11:12.511092 139572084180736 logging_writer.py:48] [25] global_step=25, grad_norm=0.5199300050735474, loss=6.90773868560791
I0315 02:11:12.915811 139572092573440 logging_writer.py:48] [26] global_step=26, grad_norm=0.5363524556159973, loss=6.90787410736084
I0315 02:11:13.314524 139572084180736 logging_writer.py:48] [27] global_step=27, grad_norm=0.5335282683372498, loss=6.907605171203613
I0315 02:11:13.714871 139572092573440 logging_writer.py:48] [28] global_step=28, grad_norm=0.5432417392730713, loss=6.907597541809082
I0315 02:11:14.115473 139572084180736 logging_writer.py:48] [29] global_step=29, grad_norm=0.5366165041923523, loss=6.907697677612305
I0315 02:11:14.518582 139572092573440 logging_writer.py:48] [30] global_step=30, grad_norm=0.5139583945274353, loss=6.9076948165893555
I0315 02:11:14.928998 139572084180736 logging_writer.py:48] [31] global_step=31, grad_norm=0.5376412272453308, loss=6.907628536224365
I0315 02:11:15.330366 139572092573440 logging_writer.py:48] [32] global_step=32, grad_norm=0.5384430885314941, loss=6.9076714515686035
I0315 02:11:15.732796 139572084180736 logging_writer.py:48] [33] global_step=33, grad_norm=0.5328580141067505, loss=6.90759801864624
I0315 02:11:16.141433 139572092573440 logging_writer.py:48] [34] global_step=34, grad_norm=0.5288012623786926, loss=6.907697677612305
I0315 02:11:16.552107 139572084180736 logging_writer.py:48] [35] global_step=35, grad_norm=0.5378218293190002, loss=6.907585144042969
I0315 02:11:16.954596 139572092573440 logging_writer.py:48] [36] global_step=36, grad_norm=0.5389828085899353, loss=6.907578945159912
I0315 02:11:17.366882 139572084180736 logging_writer.py:48] [37] global_step=37, grad_norm=0.5423193573951721, loss=6.907535552978516
I0315 02:11:17.767166 139572092573440 logging_writer.py:48] [38] global_step=38, grad_norm=0.546565592288971, loss=6.907485485076904
I0315 02:11:18.167933 139572084180736 logging_writer.py:48] [39] global_step=39, grad_norm=0.5201254487037659, loss=6.907655239105225
I0315 02:11:18.568886 139572092573440 logging_writer.py:48] [40] global_step=40, grad_norm=0.5362823605537415, loss=6.907584190368652
I0315 02:11:18.976239 139572084180736 logging_writer.py:48] [41] global_step=41, grad_norm=0.5365371108055115, loss=6.9076151847839355
I0315 02:11:19.377526 139572092573440 logging_writer.py:48] [42] global_step=42, grad_norm=0.540345311164856, loss=6.907419204711914
I0315 02:11:19.779304 139572084180736 logging_writer.py:48] [43] global_step=43, grad_norm=0.5222604870796204, loss=6.907512187957764
I0315 02:11:20.179548 139572092573440 logging_writer.py:48] [44] global_step=44, grad_norm=0.5249215364456177, loss=6.907504081726074
I0315 02:11:20.583906 139572084180736 logging_writer.py:48] [45] global_step=45, grad_norm=0.50869220495224, loss=6.907347202301025
I0315 02:11:20.988956 139572092573440 logging_writer.py:48] [46] global_step=46, grad_norm=0.5085911750793457, loss=6.907633304595947
I0315 02:11:21.391722 139572084180736 logging_writer.py:48] [47] global_step=47, grad_norm=0.5548086762428284, loss=6.9075117111206055
I0315 02:11:21.795552 139572092573440 logging_writer.py:48] [48] global_step=48, grad_norm=0.5120053291320801, loss=6.9072651863098145
I0315 02:11:22.197029 139572084180736 logging_writer.py:48] [49] global_step=49, grad_norm=0.5505667924880981, loss=6.90715217590332
I0315 02:11:22.600215 139572092573440 logging_writer.py:48] [50] global_step=50, grad_norm=0.5209596753120422, loss=6.907524108886719
I0315 02:11:23.003343 139572084180736 logging_writer.py:48] [51] global_step=51, grad_norm=0.5282770991325378, loss=6.907393455505371
I0315 02:11:23.403306 139572092573440 logging_writer.py:48] [52] global_step=52, grad_norm=0.5568780899047852, loss=6.907466888427734
I0315 02:11:23.805323 139572084180736 logging_writer.py:48] [53] global_step=53, grad_norm=0.5702890157699585, loss=6.907219409942627
I0315 02:11:24.208237 139572092573440 logging_writer.py:48] [54] global_step=54, grad_norm=0.5241471529006958, loss=6.907388687133789
I0315 02:11:24.618331 139572084180736 logging_writer.py:48] [55] global_step=55, grad_norm=0.5264887809753418, loss=6.907207489013672
I0315 02:11:25.019658 139572092573440 logging_writer.py:48] [56] global_step=56, grad_norm=0.5742861032485962, loss=6.907376289367676
I0315 02:11:25.429030 139572084180736 logging_writer.py:48] [57] global_step=57, grad_norm=0.5117960572242737, loss=6.9072394371032715
I0315 02:11:25.832105 139572092573440 logging_writer.py:48] [58] global_step=58, grad_norm=0.5775144696235657, loss=6.907611846923828
I0315 02:11:26.242734 139572084180736 logging_writer.py:48] [59] global_step=59, grad_norm=0.5778195858001709, loss=6.907045364379883
I0315 02:11:26.654523 139572092573440 logging_writer.py:48] [60] global_step=60, grad_norm=0.5643145442008972, loss=6.907299041748047
I0315 02:11:27.057746 139572084180736 logging_writer.py:48] [61] global_step=61, grad_norm=0.5724794268608093, loss=6.907100200653076
I0315 02:11:27.458144 139572092573440 logging_writer.py:48] [62] global_step=62, grad_norm=0.5688766241073608, loss=6.907193183898926
I0315 02:11:27.861320 139572084180736 logging_writer.py:48] [63] global_step=63, grad_norm=0.5138192772865295, loss=6.9071173667907715
I0315 02:11:28.266837 139572092573440 logging_writer.py:48] [64] global_step=64, grad_norm=0.5727827548980713, loss=6.90718936920166
I0315 02:11:28.679458 139572084180736 logging_writer.py:48] [65] global_step=65, grad_norm=0.5697337985038757, loss=6.906526565551758
I0315 02:11:29.090843 139572092573440 logging_writer.py:48] [66] global_step=66, grad_norm=0.5351661443710327, loss=6.906723499298096
I0315 02:11:29.499794 139572084180736 logging_writer.py:48] [67] global_step=67, grad_norm=0.5804935693740845, loss=6.90706729888916
I0315 02:11:29.908855 139572092573440 logging_writer.py:48] [68] global_step=68, grad_norm=0.5803072452545166, loss=6.90621280670166
I0315 02:11:30.309415 139572084180736 logging_writer.py:48] [69] global_step=69, grad_norm=0.5413700938224792, loss=6.9069108963012695
I0315 02:11:30.709349 139572092573440 logging_writer.py:48] [70] global_step=70, grad_norm=0.5674182176589966, loss=6.906997203826904
I0315 02:11:31.109624 139572084180736 logging_writer.py:48] [71] global_step=71, grad_norm=0.5843185782432556, loss=6.906281471252441
I0315 02:11:31.515871 139572092573440 logging_writer.py:48] [72] global_step=72, grad_norm=0.5791357159614563, loss=6.906310081481934
I0315 02:11:31.908235 139572084180736 logging_writer.py:48] [73] global_step=73, grad_norm=0.5281173586845398, loss=6.906891345977783
I0315 02:11:32.311659 139572092573440 logging_writer.py:48] [74] global_step=74, grad_norm=0.5980189442634583, loss=6.905635356903076
I0315 02:11:32.714745 139572084180736 logging_writer.py:48] [75] global_step=75, grad_norm=0.5475173592567444, loss=6.906324863433838
I0315 02:11:33.115169 139572092573440 logging_writer.py:48] [76] global_step=76, grad_norm=0.6212153434753418, loss=6.906015872955322
I0315 02:11:33.517678 139572084180736 logging_writer.py:48] [77] global_step=77, grad_norm=0.5692836046218872, loss=6.906474590301514
I0315 02:11:33.924123 139572092573440 logging_writer.py:48] [78] global_step=78, grad_norm=0.6110038757324219, loss=6.906562805175781
I0315 02:11:34.337191 139572084180736 logging_writer.py:48] [79] global_step=79, grad_norm=0.5391314625740051, loss=6.9069061279296875
I0315 02:11:34.751643 139572092573440 logging_writer.py:48] [80] global_step=80, grad_norm=0.6064813137054443, loss=6.9055280685424805
I0315 02:11:35.155819 139572084180736 logging_writer.py:48] [81] global_step=81, grad_norm=0.5420058965682983, loss=6.9061408042907715
I0315 02:11:35.560580 139572092573440 logging_writer.py:48] [82] global_step=82, grad_norm=0.5989406704902649, loss=6.905233383178711
I0315 02:11:35.963463 139572084180736 logging_writer.py:48] [83] global_step=83, grad_norm=0.6122555136680603, loss=6.905228137969971
I0315 02:11:36.367789 139572092573440 logging_writer.py:48] [84] global_step=84, grad_norm=0.6275452971458435, loss=6.905660629272461
I0315 02:11:36.782590 139572084180736 logging_writer.py:48] [85] global_step=85, grad_norm=0.6134295463562012, loss=6.9055376052856445
I0315 02:11:37.186264 139572092573440 logging_writer.py:48] [86] global_step=86, grad_norm=0.5739029049873352, loss=6.906043529510498
I0315 02:11:37.591597 139572084180736 logging_writer.py:48] [87] global_step=87, grad_norm=0.5890687704086304, loss=6.905226230621338
I0315 02:11:37.995319 139572092573440 logging_writer.py:48] [88] global_step=88, grad_norm=0.5771254897117615, loss=6.905930519104004
I0315 02:11:38.404215 139572084180736 logging_writer.py:48] [89] global_step=89, grad_norm=0.63279128074646, loss=6.904442310333252
I0315 02:11:38.812557 139572092573440 logging_writer.py:48] [90] global_step=90, grad_norm=0.6109787821769714, loss=6.905089378356934
I0315 02:11:39.222962 139572084180736 logging_writer.py:48] [91] global_step=91, grad_norm=0.566017210483551, loss=6.905187606811523
I0315 02:11:39.626970 139572092573440 logging_writer.py:48] [92] global_step=92, grad_norm=0.5415021777153015, loss=6.905953884124756
I0315 02:11:40.035296 139572084180736 logging_writer.py:48] [93] global_step=93, grad_norm=0.6384474635124207, loss=6.9036149978637695
I0315 02:11:40.438132 139572092573440 logging_writer.py:48] [94] global_step=94, grad_norm=0.630422055721283, loss=6.904491424560547
I0315 02:11:40.853664 139572084180736 logging_writer.py:48] [95] global_step=95, grad_norm=0.5528135895729065, loss=6.905203819274902
I0315 02:11:41.263297 139572092573440 logging_writer.py:48] [96] global_step=96, grad_norm=0.5569827556610107, loss=6.905895709991455
I0315 02:11:41.666977 139572084180736 logging_writer.py:48] [97] global_step=97, grad_norm=0.6806199550628662, loss=6.90319299697876
I0315 02:11:42.080193 139572092573440 logging_writer.py:48] [98] global_step=98, grad_norm=0.5561826825141907, loss=6.906522274017334
I0315 02:11:42.494559 139572084180736 logging_writer.py:48] [99] global_step=99, grad_norm=0.6682014465332031, loss=6.901872158050537
I0315 02:11:42.900886 139572092573440 logging_writer.py:48] [100] global_step=100, grad_norm=0.6470574736595154, loss=6.9035162925720215
I0315 02:14:18.582134 139572084180736 logging_writer.py:48] [500] global_step=500, grad_norm=0.8001306056976318, loss=6.726842880249023
I0315 02:17:33.296069 139572092573440 logging_writer.py:48] [1000] global_step=1000, grad_norm=1.3564724922180176, loss=6.701887130737305
I0315 02:17:37.668662 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:17:49.586136 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:18:01.853374 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:18:04.567717 139734377899840 submission_runner.py:420] Time since start: 535.79s, 	Step: 1013, 	{'train/accuracy': 0.016718748956918716, 'train/loss': 6.275478363037109, 'validation/accuracy': 0.016419999301433563, 'validation/loss': 6.287055492401123, 'validation/num_examples': 50000, 'test/accuracy': 0.012900000438094139, 'test/loss': 6.35337495803833, 'test/num_examples': 10000, 'score': 462.00606775283813, 'total_duration': 535.7927763462067, 'accumulated_submission_time': 462.00606775283813, 'accumulated_eval_time': 73.72658395767212, 'accumulated_logging_time': 0.026311874389648438}
I0315 02:18:04.584361 139540534654720 logging_writer.py:48] [1013] accumulated_eval_time=73.726584, accumulated_logging_time=0.026312, accumulated_submission_time=462.006068, global_step=1013, preemption_count=0, score=462.006068, test/accuracy=0.012900, test/loss=6.353375, test/num_examples=10000, total_duration=535.792776, train/accuracy=0.016719, train/loss=6.275478, validation/accuracy=0.016420, validation/loss=6.287055, validation/num_examples=50000
I0315 02:21:14.812748 139540685625088 logging_writer.py:48] [1500] global_step=1500, grad_norm=1.817136526107788, loss=6.147366046905518
I0315 02:24:29.812269 139540534654720 logging_writer.py:48] [2000] global_step=2000, grad_norm=1.4875191450119019, loss=6.18885612487793
I0315 02:25:04.608890 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:25:16.554798 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:25:29.075652 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:25:31.775314 139734377899840 submission_runner.py:420] Time since start: 983.00s, 	Step: 2091, 	{'train/accuracy': 0.04833984375, 'train/loss': 5.618739604949951, 'validation/accuracy': 0.04793999716639519, 'validation/loss': 5.6484575271606445, 'validation/num_examples': 50000, 'test/accuracy': 0.03760000318288803, 'test/loss': 5.799871921539307, 'test/num_examples': 10000, 'score': 881.9834010601044, 'total_duration': 983.0003850460052, 'accumulated_submission_time': 881.9834010601044, 'accumulated_eval_time': 100.89297294616699, 'accumulated_logging_time': 0.052314043045043945}
I0315 02:25:31.790125 139540685625088 logging_writer.py:48] [2091] accumulated_eval_time=100.892973, accumulated_logging_time=0.052314, accumulated_submission_time=881.983401, global_step=2091, preemption_count=0, score=881.983401, test/accuracy=0.037600, test/loss=5.799872, test/num_examples=10000, total_duration=983.000385, train/accuracy=0.048340, train/loss=5.618740, validation/accuracy=0.047940, validation/loss=5.648458, validation/num_examples=50000
I0315 02:28:11.734515 139540534654720 logging_writer.py:48] [2500] global_step=2500, grad_norm=1.57317316532135, loss=5.822188377380371
I0315 02:31:26.957753 139540685625088 logging_writer.py:48] [3000] global_step=3000, grad_norm=1.1374075412750244, loss=6.642941474914551
I0315 02:32:31.865585 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:32:43.803121 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:32:56.092084 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:32:58.781367 139734377899840 submission_runner.py:420] Time since start: 1430.01s, 	Step: 3168, 	{'train/accuracy': 0.08355468511581421, 'train/loss': 5.139497756958008, 'validation/accuracy': 0.07763999700546265, 'validation/loss': 5.19743013381958, 'validation/num_examples': 50000, 'test/accuracy': 0.06160000339150429, 'test/loss': 5.409333229064941, 'test/num_examples': 10000, 'score': 1302.0117499828339, 'total_duration': 1430.0064475536346, 'accumulated_submission_time': 1302.0117499828339, 'accumulated_eval_time': 127.80873513221741, 'accumulated_logging_time': 0.07586097717285156}
I0315 02:32:58.796372 139540534654720 logging_writer.py:48] [3168] accumulated_eval_time=127.808735, accumulated_logging_time=0.075861, accumulated_submission_time=1302.011750, global_step=3168, preemption_count=0, score=1302.011750, test/accuracy=0.061600, test/loss=5.409333, test/num_examples=10000, total_duration=1430.006448, train/accuracy=0.083555, train/loss=5.139498, validation/accuracy=0.077640, validation/loss=5.197430, validation/num_examples=50000
I0315 02:35:08.823077 139540685625088 logging_writer.py:48] [3500] global_step=3500, grad_norm=1.2912719249725342, loss=6.592289924621582
I0315 02:38:24.197530 139540534654720 logging_writer.py:48] [4000] global_step=4000, grad_norm=1.497870683670044, loss=5.478035926818848
I0315 02:39:58.848945 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:40:10.805915 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:40:23.363010 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:40:26.064890 139734377899840 submission_runner.py:420] Time since start: 1877.29s, 	Step: 4244, 	{'train/accuracy': 0.1238085925579071, 'train/loss': 4.724140644073486, 'validation/accuracy': 0.11699999868869781, 'validation/loss': 4.780978202819824, 'validation/num_examples': 50000, 'test/accuracy': 0.08860000222921371, 'test/loss': 5.077528953552246, 'test/num_examples': 10000, 'score': 1722.0173926353455, 'total_duration': 1877.2899487018585, 'accumulated_submission_time': 1722.0173926353455, 'accumulated_eval_time': 155.0246467590332, 'accumulated_logging_time': 0.09940552711486816}
I0315 02:40:26.082053 139540685625088 logging_writer.py:48] [4244] accumulated_eval_time=155.024647, accumulated_logging_time=0.099406, accumulated_submission_time=1722.017393, global_step=4244, preemption_count=0, score=1722.017393, test/accuracy=0.088600, test/loss=5.077529, test/num_examples=10000, total_duration=1877.289949, train/accuracy=0.123809, train/loss=4.724141, validation/accuracy=0.117000, validation/loss=4.780978, validation/num_examples=50000
I0315 02:42:06.569333 139540534654720 logging_writer.py:48] [4500] global_step=4500, grad_norm=1.2530654668807983, loss=6.389498233795166
I0315 02:45:22.084070 139540685625088 logging_writer.py:48] [5000] global_step=5000, grad_norm=1.2406799793243408, loss=6.340178966522217
I0315 02:47:26.103085 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:47:38.085884 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:47:50.404478 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:47:53.096426 139734377899840 submission_runner.py:420] Time since start: 2324.32s, 	Step: 5319, 	{'train/accuracy': 0.16015625, 'train/loss': 4.408839702606201, 'validation/accuracy': 0.1536400020122528, 'validation/loss': 4.4599199295043945, 'validation/num_examples': 50000, 'test/accuracy': 0.1153000071644783, 'test/loss': 4.801263332366943, 'test/num_examples': 10000, 'score': 2141.9897899627686, 'total_duration': 2324.321508169174, 'accumulated_submission_time': 2141.9897899627686, 'accumulated_eval_time': 182.01797032356262, 'accumulated_logging_time': 0.12645864486694336}
I0315 02:47:53.111253 139540534654720 logging_writer.py:48] [5319] accumulated_eval_time=182.017970, accumulated_logging_time=0.126459, accumulated_submission_time=2141.989790, global_step=5319, preemption_count=0, score=2141.989790, test/accuracy=0.115300, test/loss=4.801263, test/num_examples=10000, total_duration=2324.321508, train/accuracy=0.160156, train/loss=4.408840, validation/accuracy=0.153640, validation/loss=4.459920, validation/num_examples=50000
I0315 02:49:04.184600 139540685625088 logging_writer.py:48] [5500] global_step=5500, grad_norm=1.4554351568222046, loss=5.262969493865967
I0315 02:52:19.746797 139540534654720 logging_writer.py:48] [6000] global_step=6000, grad_norm=1.7961461544036865, loss=4.984524726867676
I0315 02:54:53.190440 139734377899840 spec.py:321] Evaluating on the training split.
I0315 02:55:05.164019 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 02:55:17.481731 139734377899840 spec.py:349] Evaluating on the test split.
I0315 02:55:20.180419 139734377899840 submission_runner.py:420] Time since start: 2771.41s, 	Step: 6394, 	{'train/accuracy': 0.20556640625, 'train/loss': 4.094365119934082, 'validation/accuracy': 0.18813998997211456, 'validation/loss': 4.188604831695557, 'validation/num_examples': 50000, 'test/accuracy': 0.14259999990463257, 'test/loss': 4.584964752197266, 'test/num_examples': 10000, 'score': 2562.018432378769, 'total_duration': 2771.4054958820343, 'accumulated_submission_time': 2562.018432378769, 'accumulated_eval_time': 209.00794339179993, 'accumulated_logging_time': 0.15285372734069824}
I0315 02:55:20.195358 139540685625088 logging_writer.py:48] [6394] accumulated_eval_time=209.007943, accumulated_logging_time=0.152854, accumulated_submission_time=2562.018432, global_step=6394, preemption_count=0, score=2562.018432, test/accuracy=0.142600, test/loss=4.584965, test/num_examples=10000, total_duration=2771.405496, train/accuracy=0.205566, train/loss=4.094365, validation/accuracy=0.188140, validation/loss=4.188605, validation/num_examples=50000
I0315 02:56:02.034039 139540534654720 logging_writer.py:48] [6500] global_step=6500, grad_norm=1.5026646852493286, loss=4.7927985191345215
I0315 02:59:17.646717 139540685625088 logging_writer.py:48] [7000] global_step=7000, grad_norm=1.2571167945861816, loss=5.463860511779785
I0315 03:02:20.464390 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:02:32.439407 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:02:44.781877 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:02:47.475460 139734377899840 submission_runner.py:420] Time since start: 3218.70s, 	Step: 7469, 	{'train/accuracy': 0.23644530773162842, 'train/loss': 3.8184990882873535, 'validation/accuracy': 0.2181599885225296, 'validation/loss': 3.9290621280670166, 'validation/num_examples': 50000, 'test/accuracy': 0.16510000824928284, 'test/loss': 4.373502731323242, 'test/num_examples': 10000, 'score': 2982.2403173446655, 'total_duration': 3218.7005162239075, 'accumulated_submission_time': 2982.2403173446655, 'accumulated_eval_time': 236.0189769268036, 'accumulated_logging_time': 0.1773977279663086}
I0315 03:02:47.493383 139540534654720 logging_writer.py:48] [7469] accumulated_eval_time=236.018977, accumulated_logging_time=0.177398, accumulated_submission_time=2982.240317, global_step=7469, preemption_count=0, score=2982.240317, test/accuracy=0.165100, test/loss=4.373503, test/num_examples=10000, total_duration=3218.700516, train/accuracy=0.236445, train/loss=3.818499, validation/accuracy=0.218160, validation/loss=3.929062, validation/num_examples=50000
I0315 03:03:00.034649 139540685625088 logging_writer.py:48] [7500] global_step=7500, grad_norm=1.3564484119415283, loss=4.539889335632324
I0315 03:06:15.693885 139540534654720 logging_writer.py:48] [8000] global_step=8000, grad_norm=1.3516931533813477, loss=4.389143943786621
I0315 03:09:31.383764 139540685625088 logging_writer.py:48] [8500] global_step=8500, grad_norm=1.2112529277801514, loss=4.200084686279297
I0315 03:09:47.512392 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:09:59.491769 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:10:11.833792 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:10:14.529074 139734377899840 submission_runner.py:420] Time since start: 3665.75s, 	Step: 8543, 	{'train/accuracy': 0.27927732467651367, 'train/loss': 3.5570497512817383, 'validation/accuracy': 0.24913999438285828, 'validation/loss': 3.730613946914673, 'validation/num_examples': 50000, 'test/accuracy': 0.1925000101327896, 'test/loss': 4.175887107849121, 'test/num_examples': 10000, 'score': 3402.2068305015564, 'total_duration': 3665.7541551589966, 'accumulated_submission_time': 3402.2068305015564, 'accumulated_eval_time': 263.0356225967407, 'accumulated_logging_time': 0.20886874198913574}
I0315 03:10:14.544134 139540534654720 logging_writer.py:48] [8543] accumulated_eval_time=263.035623, accumulated_logging_time=0.208869, accumulated_submission_time=3402.206831, global_step=8543, preemption_count=0, score=3402.206831, test/accuracy=0.192500, test/loss=4.175887, test/num_examples=10000, total_duration=3665.754155, train/accuracy=0.279277, train/loss=3.557050, validation/accuracy=0.249140, validation/loss=3.730614, validation/num_examples=50000
I0315 03:13:13.692011 139540685625088 logging_writer.py:48] [9000] global_step=9000, grad_norm=1.5538675785064697, loss=4.399210453033447
I0315 03:16:29.340260 139540534654720 logging_writer.py:48] [9500] global_step=9500, grad_norm=1.2267541885375977, loss=5.035673141479492
I0315 03:17:14.842765 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:17:26.805071 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:17:39.849051 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:17:42.529634 139734377899840 submission_runner.py:420] Time since start: 4113.75s, 	Step: 9618, 	{'train/accuracy': 0.30341795086860657, 'train/loss': 3.334085702896118, 'validation/accuracy': 0.2781600058078766, 'validation/loss': 3.4821395874023438, 'validation/num_examples': 50000, 'test/accuracy': 0.21800000965595245, 'test/loss': 3.977511405944824, 'test/num_examples': 10000, 'score': 3822.4579470157623, 'total_duration': 4113.754719257355, 'accumulated_submission_time': 3822.4579470157623, 'accumulated_eval_time': 290.722473859787, 'accumulated_logging_time': 0.23267745971679688}
I0315 03:17:42.544157 139540685625088 logging_writer.py:48] [9618] accumulated_eval_time=290.722474, accumulated_logging_time=0.232677, accumulated_submission_time=3822.457947, global_step=9618, preemption_count=0, score=3822.457947, test/accuracy=0.218000, test/loss=3.977511, test/num_examples=10000, total_duration=4113.754719, train/accuracy=0.303418, train/loss=3.334086, validation/accuracy=0.278160, validation/loss=3.482140, validation/num_examples=50000
I0315 03:20:12.317197 139540534654720 logging_writer.py:48] [10000] global_step=10000, grad_norm=1.3671916723251343, loss=4.407843589782715
I0315 03:23:27.936155 139540685625088 logging_writer.py:48] [10500] global_step=10500, grad_norm=1.3066256046295166, loss=4.58254861831665
I0315 03:24:42.759355 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:24:54.735753 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:25:07.078535 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:25:09.784319 139734377899840 submission_runner.py:420] Time since start: 4561.01s, 	Step: 10693, 	{'train/accuracy': 0.3306835889816284, 'train/loss': 3.1823666095733643, 'validation/accuracy': 0.30776000022888184, 'validation/loss': 3.304899215698242, 'validation/num_examples': 50000, 'test/accuracy': 0.23990000784397125, 'test/loss': 3.8208560943603516, 'test/num_examples': 10000, 'score': 4242.626497507095, 'total_duration': 4561.009375572205, 'accumulated_submission_time': 4242.626497507095, 'accumulated_eval_time': 317.747389793396, 'accumulated_logging_time': 0.25598788261413574}
I0315 03:25:09.802403 139540534654720 logging_writer.py:48] [10693] accumulated_eval_time=317.747390, accumulated_logging_time=0.255988, accumulated_submission_time=4242.626498, global_step=10693, preemption_count=0, score=4242.626498, test/accuracy=0.239900, test/loss=3.820856, test/num_examples=10000, total_duration=4561.009376, train/accuracy=0.330684, train/loss=3.182367, validation/accuracy=0.307760, validation/loss=3.304899, validation/num_examples=50000
I0315 03:27:10.274619 139540685625088 logging_writer.py:48] [11000] global_step=11000, grad_norm=1.0787835121154785, loss=5.348260879516602
I0315 03:30:25.937801 139540534654720 logging_writer.py:48] [11500] global_step=11500, grad_norm=1.3035991191864014, loss=4.117464065551758
I0315 03:32:10.093258 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:32:22.086795 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:32:34.432513 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:32:37.130735 139734377899840 submission_runner.py:420] Time since start: 5008.36s, 	Step: 11768, 	{'train/accuracy': 0.3617578148841858, 'train/loss': 3.022171974182129, 'validation/accuracy': 0.33142000436782837, 'validation/loss': 3.1789186000823975, 'validation/num_examples': 50000, 'test/accuracy': 0.25460001826286316, 'test/loss': 3.7280092239379883, 'test/num_examples': 10000, 'score': 4662.86850976944, 'total_duration': 5008.3557913303375, 'accumulated_submission_time': 4662.86850976944, 'accumulated_eval_time': 344.7848219871521, 'accumulated_logging_time': 0.2850813865661621}
I0315 03:32:37.147912 139540685625088 logging_writer.py:48] [11768] accumulated_eval_time=344.784822, accumulated_logging_time=0.285081, accumulated_submission_time=4662.868510, global_step=11768, preemption_count=0, score=4662.868510, test/accuracy=0.254600, test/loss=3.728009, test/num_examples=10000, total_duration=5008.355791, train/accuracy=0.361758, train/loss=3.022172, validation/accuracy=0.331420, validation/loss=3.178919, validation/num_examples=50000
I0315 03:34:08.184334 139540534654720 logging_writer.py:48] [12000] global_step=12000, grad_norm=1.4454689025878906, loss=3.932856321334839
I0315 03:37:23.756249 139540685625088 logging_writer.py:48] [12500] global_step=12500, grad_norm=1.0476773977279663, loss=4.9031805992126465
I0315 03:39:37.272284 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:39:49.273597 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:40:01.848737 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:40:04.554702 139734377899840 submission_runner.py:420] Time since start: 5455.78s, 	Step: 12843, 	{'train/accuracy': 0.3828710913658142, 'train/loss': 2.8559679985046387, 'validation/accuracy': 0.3553999960422516, 'validation/loss': 3.0134873390197754, 'validation/num_examples': 50000, 'test/accuracy': 0.2738000154495239, 'test/loss': 3.567352533340454, 'test/num_examples': 10000, 'score': 5082.946170091629, 'total_duration': 5455.77977514267, 'accumulated_submission_time': 5082.946170091629, 'accumulated_eval_time': 372.06721353530884, 'accumulated_logging_time': 0.31165504455566406}
I0315 03:40:04.569692 139540534654720 logging_writer.py:48] [12843] accumulated_eval_time=372.067214, accumulated_logging_time=0.311655, accumulated_submission_time=5082.946170, global_step=12843, preemption_count=0, score=5082.946170, test/accuracy=0.273800, test/loss=3.567353, test/num_examples=10000, total_duration=5455.779775, train/accuracy=0.382871, train/loss=2.855968, validation/accuracy=0.355400, validation/loss=3.013487, validation/num_examples=50000
I0315 03:41:06.386257 139540685625088 logging_writer.py:48] [13000] global_step=13000, grad_norm=1.4119195938110352, loss=3.778367042541504
I0315 03:44:22.011093 139540534654720 logging_writer.py:48] [13500] global_step=13500, grad_norm=1.2513253688812256, loss=3.647193670272827
I0315 03:47:04.873560 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:47:16.866313 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:47:29.184598 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:47:31.884845 139734377899840 submission_runner.py:420] Time since start: 5903.11s, 	Step: 13918, 	{'train/accuracy': 0.4347265660762787, 'train/loss': 2.5692591667175293, 'validation/accuracy': 0.37498000264167786, 'validation/loss': 2.8813555240631104, 'validation/num_examples': 50000, 'test/accuracy': 0.2930000126361847, 'test/loss': 3.458757162094116, 'test/num_examples': 10000, 'score': 5503.202824115753, 'total_duration': 5903.109926223755, 'accumulated_submission_time': 5503.202824115753, 'accumulated_eval_time': 399.0784823894501, 'accumulated_logging_time': 0.33634138107299805}
I0315 03:47:31.900372 139540685625088 logging_writer.py:48] [13918] accumulated_eval_time=399.078482, accumulated_logging_time=0.336341, accumulated_submission_time=5503.202824, global_step=13918, preemption_count=0, score=5503.202824, test/accuracy=0.293000, test/loss=3.458757, test/num_examples=10000, total_duration=5903.109926, train/accuracy=0.434727, train/loss=2.569259, validation/accuracy=0.374980, validation/loss=2.881356, validation/num_examples=50000
I0315 03:48:04.347374 139540534654720 logging_writer.py:48] [14000] global_step=14000, grad_norm=1.325408697128296, loss=3.7563562393188477
I0315 03:51:19.958441 139540685625088 logging_writer.py:48] [14500] global_step=14500, grad_norm=1.3704074621200562, loss=3.7537221908569336
I0315 03:54:32.101165 139734377899840 spec.py:321] Evaluating on the training split.
I0315 03:54:44.200083 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 03:54:56.527992 139734377899840 spec.py:349] Evaluating on the test split.
I0315 03:54:59.225848 139734377899840 submission_runner.py:420] Time since start: 6350.45s, 	Step: 14993, 	{'train/accuracy': 0.4290429651737213, 'train/loss': 2.589291572570801, 'validation/accuracy': 0.39593997597694397, 'validation/loss': 2.756913661956787, 'validation/num_examples': 50000, 'test/accuracy': 0.31070002913475037, 'test/loss': 3.3564560413360596, 'test/num_examples': 10000, 'score': 5923.3575963974, 'total_duration': 6350.450917482376, 'accumulated_submission_time': 5923.3575963974, 'accumulated_eval_time': 426.20317244529724, 'accumulated_logging_time': 0.3604750633239746}
I0315 03:54:59.242495 139540534654720 logging_writer.py:48] [14993] accumulated_eval_time=426.203172, accumulated_logging_time=0.360475, accumulated_submission_time=5923.357596, global_step=14993, preemption_count=0, score=5923.357596, test/accuracy=0.310700, test/loss=3.356456, test/num_examples=10000, total_duration=6350.450917, train/accuracy=0.429043, train/loss=2.589292, validation/accuracy=0.395940, validation/loss=2.756914, validation/num_examples=50000
I0315 03:55:02.385514 139540685625088 logging_writer.py:48] [15000] global_step=15000, grad_norm=1.4267404079437256, loss=3.8410685062408447
I0315 03:58:17.964566 139540534654720 logging_writer.py:48] [15500] global_step=15500, grad_norm=1.2699944972991943, loss=3.9859769344329834
I0315 04:01:33.588070 139540685625088 logging_writer.py:48] [16000] global_step=16000, grad_norm=1.286512017250061, loss=3.778228521347046
I0315 04:01:59.499680 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:02:11.659738 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:02:23.990767 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:02:26.695567 139734377899840 submission_runner.py:420] Time since start: 6797.92s, 	Step: 16068, 	{'train/accuracy': 0.4355859160423279, 'train/loss': 2.5344467163085938, 'validation/accuracy': 0.4030799865722656, 'validation/loss': 2.7032179832458496, 'validation/num_examples': 50000, 'test/accuracy': 0.3110000193119049, 'test/loss': 3.3090555667877197, 'test/num_examples': 10000, 'score': 6343.56699514389, 'total_duration': 6797.920631885529, 'accumulated_submission_time': 6343.56699514389, 'accumulated_eval_time': 453.39901423454285, 'accumulated_logging_time': 0.38715529441833496}
I0315 04:02:26.713188 139540534654720 logging_writer.py:48] [16068] accumulated_eval_time=453.399014, accumulated_logging_time=0.387155, accumulated_submission_time=6343.566995, global_step=16068, preemption_count=0, score=6343.566995, test/accuracy=0.311000, test/loss=3.309056, test/num_examples=10000, total_duration=6797.920632, train/accuracy=0.435586, train/loss=2.534447, validation/accuracy=0.403080, validation/loss=2.703218, validation/num_examples=50000
I0315 04:05:16.075947 139540685625088 logging_writer.py:48] [16500] global_step=16500, grad_norm=1.5307484865188599, loss=3.764101982116699
I0315 04:08:31.729563 139540534654720 logging_writer.py:48] [17000] global_step=17000, grad_norm=1.3549091815948486, loss=3.6605963706970215
I0315 04:09:26.997899 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:09:39.168061 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:09:51.498121 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:09:54.196581 139734377899840 submission_runner.py:420] Time since start: 7245.42s, 	Step: 17143, 	{'train/accuracy': 0.4674023389816284, 'train/loss': 2.382639169692993, 'validation/accuracy': 0.42239999771118164, 'validation/loss': 2.6041572093963623, 'validation/num_examples': 50000, 'test/accuracy': 0.32500001788139343, 'test/loss': 3.2311201095581055, 'test/num_examples': 10000, 'score': 6763.80282998085, 'total_duration': 7245.421663284302, 'accumulated_submission_time': 6763.80282998085, 'accumulated_eval_time': 480.5976753234863, 'accumulated_logging_time': 0.4140584468841553}
I0315 04:09:54.212590 139540685625088 logging_writer.py:48] [17143] accumulated_eval_time=480.597675, accumulated_logging_time=0.414058, accumulated_submission_time=6763.802830, global_step=17143, preemption_count=0, score=6763.802830, test/accuracy=0.325000, test/loss=3.231120, test/num_examples=10000, total_duration=7245.421663, train/accuracy=0.467402, train/loss=2.382639, validation/accuracy=0.422400, validation/loss=2.604157, validation/num_examples=50000
I0315 04:12:14.215460 139540534654720 logging_writer.py:48] [17500] global_step=17500, grad_norm=1.517822265625, loss=3.527923822402954
I0315 04:15:29.858630 139540685625088 logging_writer.py:48] [18000] global_step=18000, grad_norm=1.465299129486084, loss=3.312624931335449
I0315 04:16:54.429036 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:17:06.712616 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:17:19.307530 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:17:22.009025 139734377899840 submission_runner.py:420] Time since start: 7693.23s, 	Step: 18218, 	{'train/accuracy': 0.45326170325279236, 'train/loss': 2.457263946533203, 'validation/accuracy': 0.42010000348091125, 'validation/loss': 2.6309633255004883, 'validation/num_examples': 50000, 'test/accuracy': 0.3278000056743622, 'test/loss': 3.2264232635498047, 'test/num_examples': 10000, 'score': 7183.971779346466, 'total_duration': 7693.234092712402, 'accumulated_submission_time': 7183.971779346466, 'accumulated_eval_time': 508.1776280403137, 'accumulated_logging_time': 0.43997907638549805}
I0315 04:17:22.035209 139540534654720 logging_writer.py:48] [18218] accumulated_eval_time=508.177628, accumulated_logging_time=0.439979, accumulated_submission_time=7183.971779, global_step=18218, preemption_count=0, score=7183.971779, test/accuracy=0.327800, test/loss=3.226423, test/num_examples=10000, total_duration=7693.234093, train/accuracy=0.453262, train/loss=2.457264, validation/accuracy=0.420100, validation/loss=2.630963, validation/num_examples=50000
I0315 04:19:12.666936 139540685625088 logging_writer.py:48] [18500] global_step=18500, grad_norm=1.018446922302246, loss=4.672133922576904
I0315 04:22:28.320984 139540534654720 logging_writer.py:48] [19000] global_step=19000, grad_norm=1.324521780014038, loss=3.268667697906494
I0315 04:24:22.252798 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:24:34.668221 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:24:46.999702 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:24:49.683173 139734377899840 submission_runner.py:420] Time since start: 8140.91s, 	Step: 19293, 	{'train/accuracy': 0.4686523377895355, 'train/loss': 2.34665846824646, 'validation/accuracy': 0.43441998958587646, 'validation/loss': 2.5446348190307617, 'validation/num_examples': 50000, 'test/accuracy': 0.33560001850128174, 'test/loss': 3.165062665939331, 'test/num_examples': 10000, 'score': 7604.140007734299, 'total_duration': 8140.908233880997, 'accumulated_submission_time': 7604.140007734299, 'accumulated_eval_time': 535.6079642772675, 'accumulated_logging_time': 0.477703332901001}
I0315 04:24:49.705435 139540685625088 logging_writer.py:48] [19293] accumulated_eval_time=535.607964, accumulated_logging_time=0.477703, accumulated_submission_time=7604.140008, global_step=19293, preemption_count=0, score=7604.140008, test/accuracy=0.335600, test/loss=3.165063, test/num_examples=10000, total_duration=8140.908234, train/accuracy=0.468652, train/loss=2.346658, validation/accuracy=0.434420, validation/loss=2.544635, validation/num_examples=50000
I0315 04:26:11.083941 139540534654720 logging_writer.py:48] [19500] global_step=19500, grad_norm=1.4242116212844849, loss=3.3459787368774414
I0315 04:29:26.732925 139540685625088 logging_writer.py:48] [20000] global_step=20000, grad_norm=1.3919079303741455, loss=3.403391122817993
I0315 04:31:50.024222 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:32:02.545900 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:32:14.894119 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:32:17.593620 139734377899840 submission_runner.py:420] Time since start: 8588.82s, 	Step: 20368, 	{'train/accuracy': 0.48093748092651367, 'train/loss': 2.3270905017852783, 'validation/accuracy': 0.44312000274658203, 'validation/loss': 2.5323879718780518, 'validation/num_examples': 50000, 'test/accuracy': 0.34130001068115234, 'test/loss': 3.1465437412261963, 'test/num_examples': 10000, 'score': 8024.4110107421875, 'total_duration': 8588.818693876266, 'accumulated_submission_time': 8024.4110107421875, 'accumulated_eval_time': 563.1773550510406, 'accumulated_logging_time': 0.5101757049560547}
I0315 04:32:17.614573 139540534654720 logging_writer.py:48] [20368] accumulated_eval_time=563.177355, accumulated_logging_time=0.510176, accumulated_submission_time=8024.411011, global_step=20368, preemption_count=0, score=8024.411011, test/accuracy=0.341300, test/loss=3.146544, test/num_examples=10000, total_duration=8588.818694, train/accuracy=0.480937, train/loss=2.327091, validation/accuracy=0.443120, validation/loss=2.532388, validation/num_examples=50000
I0315 04:33:09.625445 139540685625088 logging_writer.py:48] [20500] global_step=20500, grad_norm=1.6173290014266968, loss=3.3567748069763184
I0315 04:36:25.235864 139540534654720 logging_writer.py:48] [21000] global_step=21000, grad_norm=1.1964716911315918, loss=4.229556083679199
I0315 04:39:17.860659 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:39:30.398723 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:39:42.753345 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:39:45.448778 139734377899840 submission_runner.py:420] Time since start: 9036.67s, 	Step: 21443, 	{'train/accuracy': 0.4955078065395355, 'train/loss': 2.2387301921844482, 'validation/accuracy': 0.4577399790287018, 'validation/loss': 2.429197311401367, 'validation/num_examples': 50000, 'test/accuracy': 0.35510000586509705, 'test/loss': 3.056088447570801, 'test/num_examples': 10000, 'score': 8444.608211994171, 'total_duration': 9036.673830986023, 'accumulated_submission_time': 8444.608211994171, 'accumulated_eval_time': 590.7654292583466, 'accumulated_logging_time': 0.5419635772705078}
I0315 04:39:45.472090 139540685625088 logging_writer.py:48] [21443] accumulated_eval_time=590.765429, accumulated_logging_time=0.541964, accumulated_submission_time=8444.608212, global_step=21443, preemption_count=0, score=8444.608212, test/accuracy=0.355100, test/loss=3.056088, test/num_examples=10000, total_duration=9036.673831, train/accuracy=0.495508, train/loss=2.238730, validation/accuracy=0.457740, validation/loss=2.429197, validation/num_examples=50000
I0315 04:40:08.188347 139540534654720 logging_writer.py:48] [21500] global_step=21500, grad_norm=1.273303747177124, loss=4.319124221801758
I0315 04:43:23.806453 139540685625088 logging_writer.py:48] [22000] global_step=22000, grad_norm=0.8925281167030334, loss=5.662242889404297
I0315 04:46:39.409244 139540534654720 logging_writer.py:48] [22500] global_step=22500, grad_norm=1.414578914642334, loss=3.4417500495910645
I0315 04:46:45.768043 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:46:58.337419 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:47:10.694912 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:47:13.389814 139734377899840 submission_runner.py:420] Time since start: 9484.61s, 	Step: 22518, 	{'train/accuracy': 0.5196679830551147, 'train/loss': 2.116511821746826, 'validation/accuracy': 0.46661999821662903, 'validation/loss': 2.3763182163238525, 'validation/num_examples': 50000, 'test/accuracy': 0.36330002546310425, 'test/loss': 3.0050151348114014, 'test/num_examples': 10000, 'score': 8864.854481458664, 'total_duration': 9484.614896535873, 'accumulated_submission_time': 8864.854481458664, 'accumulated_eval_time': 618.3871674537659, 'accumulated_logging_time': 0.5770328044891357}
I0315 04:47:13.407166 139540685625088 logging_writer.py:48] [22518] accumulated_eval_time=618.387167, accumulated_logging_time=0.577033, accumulated_submission_time=8864.854481, global_step=22518, preemption_count=0, score=8864.854481, test/accuracy=0.363300, test/loss=3.005015, test/num_examples=10000, total_duration=9484.614897, train/accuracy=0.519668, train/loss=2.116512, validation/accuracy=0.466620, validation/loss=2.376318, validation/num_examples=50000
I0315 04:50:22.287726 139540534654720 logging_writer.py:48] [23000] global_step=23000, grad_norm=1.6095772981643677, loss=3.21341609954834
I0315 04:53:37.944903 139540685625088 logging_writer.py:48] [23500] global_step=23500, grad_norm=1.4050495624542236, loss=3.106381893157959
I0315 04:54:13.633154 139734377899840 spec.py:321] Evaluating on the training split.
I0315 04:54:26.265429 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 04:54:39.546342 139734377899840 spec.py:349] Evaluating on the test split.
I0315 04:54:42.240339 139734377899840 submission_runner.py:420] Time since start: 9933.47s, 	Step: 23593, 	{'train/accuracy': 0.5162890553474426, 'train/loss': 2.1125574111938477, 'validation/accuracy': 0.4773399829864502, 'validation/loss': 2.3147103786468506, 'validation/num_examples': 50000, 'test/accuracy': 0.3775000274181366, 'test/loss': 2.9368526935577393, 'test/num_examples': 10000, 'score': 9285.034385204315, 'total_duration': 9933.46540260315, 'accumulated_submission_time': 9285.034385204315, 'accumulated_eval_time': 646.9943106174469, 'accumulated_logging_time': 0.6027960777282715}
I0315 04:54:42.259263 139540534654720 logging_writer.py:48] [23593] accumulated_eval_time=646.994311, accumulated_logging_time=0.602796, accumulated_submission_time=9285.034385, global_step=23593, preemption_count=0, score=9285.034385, test/accuracy=0.377500, test/loss=2.936853, test/num_examples=10000, total_duration=9933.465403, train/accuracy=0.516289, train/loss=2.112557, validation/accuracy=0.477340, validation/loss=2.314710, validation/num_examples=50000
I0315 04:57:21.853305 139540685625088 logging_writer.py:48] [24000] global_step=24000, grad_norm=1.4064462184906006, loss=3.4632930755615234
I0315 05:00:37.465527 139540534654720 logging_writer.py:48] [24500] global_step=24500, grad_norm=1.4874335527420044, loss=3.0855824947357178
I0315 05:01:42.508199 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:01:55.220388 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:02:07.687486 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:02:10.385368 139734377899840 submission_runner.py:420] Time since start: 10381.61s, 	Step: 24668, 	{'train/accuracy': 0.5253124833106995, 'train/loss': 2.0703892707824707, 'validation/accuracy': 0.483379989862442, 'validation/loss': 2.2770378589630127, 'validation/num_examples': 50000, 'test/accuracy': 0.3769000172615051, 'test/loss': 2.9155163764953613, 'test/num_examples': 10000, 'score': 9705.235731124878, 'total_duration': 10381.610446214676, 'accumulated_submission_time': 9705.235731124878, 'accumulated_eval_time': 674.871443271637, 'accumulated_logging_time': 0.6316502094268799}
I0315 05:02:10.404508 139540685625088 logging_writer.py:48] [24668] accumulated_eval_time=674.871443, accumulated_logging_time=0.631650, accumulated_submission_time=9705.235731, global_step=24668, preemption_count=0, score=9705.235731, test/accuracy=0.376900, test/loss=2.915516, test/num_examples=10000, total_duration=10381.610446, train/accuracy=0.525312, train/loss=2.070389, validation/accuracy=0.483380, validation/loss=2.277038, validation/num_examples=50000
I0315 05:04:20.608137 139540534654720 logging_writer.py:48] [25000] global_step=25000, grad_norm=1.17946195602417, loss=4.1683454513549805
I0315 05:07:36.248425 139540685625088 logging_writer.py:48] [25500] global_step=25500, grad_norm=1.5076134204864502, loss=2.9647960662841797
I0315 05:09:10.643514 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:09:23.361356 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:09:35.764328 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:09:38.471020 139734377899840 submission_runner.py:420] Time since start: 10829.70s, 	Step: 25743, 	{'train/accuracy': 0.5356835722923279, 'train/loss': 2.03143572807312, 'validation/accuracy': 0.48881998658180237, 'validation/loss': 2.2614190578460693, 'validation/num_examples': 50000, 'test/accuracy': 0.3850000202655792, 'test/loss': 2.894301176071167, 'test/num_examples': 10000, 'score': 10125.427013635635, 'total_duration': 10829.696096420288, 'accumulated_submission_time': 10125.427013635635, 'accumulated_eval_time': 702.6989147663116, 'accumulated_logging_time': 0.6608777046203613}
I0315 05:09:38.491961 139540534654720 logging_writer.py:48] [25743] accumulated_eval_time=702.698915, accumulated_logging_time=0.660878, accumulated_submission_time=10125.427014, global_step=25743, preemption_count=0, score=10125.427014, test/accuracy=0.385000, test/loss=2.894301, test/num_examples=10000, total_duration=10829.696096, train/accuracy=0.535684, train/loss=2.031436, validation/accuracy=0.488820, validation/loss=2.261419, validation/num_examples=50000
I0315 05:11:19.365757 139540685625088 logging_writer.py:48] [26000] global_step=26000, grad_norm=1.6059131622314453, loss=2.932236671447754
I0315 05:14:35.048522 139540534654720 logging_writer.py:48] [26500] global_step=26500, grad_norm=1.1204570531845093, loss=4.730834007263184
I0315 05:16:38.761167 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:16:51.449001 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:17:03.868184 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:17:06.559737 139734377899840 submission_runner.py:420] Time since start: 11277.78s, 	Step: 26818, 	{'train/accuracy': 0.5406249761581421, 'train/loss': 1.9762295484542847, 'validation/accuracy': 0.5010200142860413, 'validation/loss': 2.181331157684326, 'validation/num_examples': 50000, 'test/accuracy': 0.3930000066757202, 'test/loss': 2.834824562072754, 'test/num_examples': 10000, 'score': 10545.649332761765, 'total_duration': 11277.784814834595, 'accumulated_submission_time': 10545.649332761765, 'accumulated_eval_time': 730.4974730014801, 'accumulated_logging_time': 0.691148042678833}
I0315 05:17:06.583501 139540685625088 logging_writer.py:48] [26818] accumulated_eval_time=730.497473, accumulated_logging_time=0.691148, accumulated_submission_time=10545.649333, global_step=26818, preemption_count=0, score=10545.649333, test/accuracy=0.393000, test/loss=2.834825, test/num_examples=10000, total_duration=11277.784815, train/accuracy=0.540625, train/loss=1.976230, validation/accuracy=0.501020, validation/loss=2.181331, validation/num_examples=50000
I0315 05:18:18.191206 139540534654720 logging_writer.py:48] [27000] global_step=27000, grad_norm=1.3984990119934082, loss=3.0463614463806152
I0315 05:21:33.793140 139540685625088 logging_writer.py:48] [27500] global_step=27500, grad_norm=1.4275774955749512, loss=3.147226333618164
I0315 05:24:06.929706 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:24:19.651667 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:24:32.015974 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:24:34.710192 139734377899840 submission_runner.py:420] Time since start: 11725.94s, 	Step: 27893, 	{'train/accuracy': 0.570507824420929, 'train/loss': 1.8765980005264282, 'validation/accuracy': 0.5060799717903137, 'validation/loss': 2.1884729862213135, 'validation/num_examples': 50000, 'test/accuracy': 0.39590001106262207, 'test/loss': 2.8308162689208984, 'test/num_examples': 10000, 'score': 10965.946343421936, 'total_duration': 11725.935274362564, 'accumulated_submission_time': 10965.946343421936, 'accumulated_eval_time': 758.2779412269592, 'accumulated_logging_time': 0.7246453762054443}
I0315 05:24:34.727912 139540534654720 logging_writer.py:48] [27893] accumulated_eval_time=758.277941, accumulated_logging_time=0.724645, accumulated_submission_time=10965.946343, global_step=27893, preemption_count=0, score=10965.946343, test/accuracy=0.395900, test/loss=2.830816, test/num_examples=10000, total_duration=11725.935274, train/accuracy=0.570508, train/loss=1.876598, validation/accuracy=0.506080, validation/loss=2.188473, validation/num_examples=50000
I0315 05:25:16.992332 139540685625088 logging_writer.py:48] [28000] global_step=28000, grad_norm=1.511230707168579, loss=3.003877639770508
I0315 05:28:32.631262 139540534654720 logging_writer.py:48] [28500] global_step=28500, grad_norm=1.547078013420105, loss=2.7856204509735107
I0315 05:31:35.019662 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:31:47.838458 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:32:00.160133 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:32:02.865535 139734377899840 submission_runner.py:420] Time since start: 12174.09s, 	Step: 28968, 	{'train/accuracy': 0.5558984279632568, 'train/loss': 1.9142109155654907, 'validation/accuracy': 0.5089600086212158, 'validation/loss': 2.141429901123047, 'validation/num_examples': 50000, 'test/accuracy': 0.4043000340461731, 'test/loss': 2.7905051708221436, 'test/num_examples': 10000, 'score': 11386.19047832489, 'total_duration': 12174.090614080429, 'accumulated_submission_time': 11386.19047832489, 'accumulated_eval_time': 786.1237938404083, 'accumulated_logging_time': 0.7524659633636475}
I0315 05:32:02.892454 139540685625088 logging_writer.py:48] [28968] accumulated_eval_time=786.123794, accumulated_logging_time=0.752466, accumulated_submission_time=11386.190478, global_step=28968, preemption_count=0, score=11386.190478, test/accuracy=0.404300, test/loss=2.790505, test/num_examples=10000, total_duration=12174.090614, train/accuracy=0.555898, train/loss=1.914211, validation/accuracy=0.508960, validation/loss=2.141430, validation/num_examples=50000
I0315 05:32:15.802315 139540534654720 logging_writer.py:48] [29000] global_step=29000, grad_norm=1.2871079444885254, loss=3.84354829788208
I0315 05:35:31.374118 139540685625088 logging_writer.py:48] [29500] global_step=29500, grad_norm=1.1118342876434326, loss=4.416552543640137
I0315 05:38:47.001205 139540534654720 logging_writer.py:48] [30000] global_step=30000, grad_norm=1.8141131401062012, loss=3.0809974670410156
I0315 05:39:03.121969 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:39:16.057636 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:39:28.413980 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:39:31.116834 139734377899840 submission_runner.py:420] Time since start: 12622.34s, 	Step: 30043, 	{'train/accuracy': 0.5616406202316284, 'train/loss': 1.890612006187439, 'validation/accuracy': 0.5192800164222717, 'validation/loss': 2.092430353164673, 'validation/num_examples': 50000, 'test/accuracy': 0.40220001339912415, 'test/loss': 2.742039680480957, 'test/num_examples': 10000, 'score': 11806.372581005096, 'total_duration': 12622.341912984848, 'accumulated_submission_time': 11806.372581005096, 'accumulated_eval_time': 814.1186220645905, 'accumulated_logging_time': 0.788611888885498}
I0315 05:39:31.133675 139540685625088 logging_writer.py:48] [30043] accumulated_eval_time=814.118622, accumulated_logging_time=0.788612, accumulated_submission_time=11806.372581, global_step=30043, preemption_count=0, score=11806.372581, test/accuracy=0.402200, test/loss=2.742040, test/num_examples=10000, total_duration=12622.341913, train/accuracy=0.561641, train/loss=1.890612, validation/accuracy=0.519280, validation/loss=2.092430, validation/num_examples=50000
I0315 05:42:30.312177 139540534654720 logging_writer.py:48] [30500] global_step=30500, grad_norm=1.1083297729492188, loss=5.149762153625488
I0315 05:45:45.919135 139540685625088 logging_writer.py:48] [31000] global_step=31000, grad_norm=1.4378300905227661, loss=2.9291348457336426
I0315 05:46:31.401676 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:46:44.355014 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:46:56.719773 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:46:59.418516 139734377899840 submission_runner.py:420] Time since start: 13070.64s, 	Step: 31118, 	{'train/accuracy': 0.5644921660423279, 'train/loss': 1.891753911972046, 'validation/accuracy': 0.5156599879264832, 'validation/loss': 2.124831438064575, 'validation/num_examples': 50000, 'test/accuracy': 0.40310001373291016, 'test/loss': 2.7682459354400635, 'test/num_examples': 10000, 'score': 12226.592665433884, 'total_duration': 13070.643585920334, 'accumulated_submission_time': 12226.592665433884, 'accumulated_eval_time': 842.1354243755341, 'accumulated_logging_time': 0.8152530193328857}
I0315 05:46:59.435536 139540534654720 logging_writer.py:48] [31118] accumulated_eval_time=842.135424, accumulated_logging_time=0.815253, accumulated_submission_time=12226.592665, global_step=31118, preemption_count=0, score=12226.592665, test/accuracy=0.403100, test/loss=2.768246, test/num_examples=10000, total_duration=13070.643586, train/accuracy=0.564492, train/loss=1.891754, validation/accuracy=0.515660, validation/loss=2.124831, validation/num_examples=50000
I0315 05:49:29.221847 139540685625088 logging_writer.py:48] [31500] global_step=31500, grad_norm=1.7608283758163452, loss=3.0926730632781982
I0315 05:52:44.811150 139540534654720 logging_writer.py:48] [32000] global_step=32000, grad_norm=1.4091657400131226, loss=3.583808183670044
I0315 05:53:59.631438 139734377899840 spec.py:321] Evaluating on the training split.
I0315 05:54:12.624013 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 05:54:24.988815 139734377899840 spec.py:349] Evaluating on the test split.
I0315 05:54:27.692899 139734377899840 submission_runner.py:420] Time since start: 13518.92s, 	Step: 32193, 	{'train/accuracy': 0.5709765553474426, 'train/loss': 1.8355311155319214, 'validation/accuracy': 0.5263000130653381, 'validation/loss': 2.0540130138397217, 'validation/num_examples': 50000, 'test/accuracy': 0.41510000824928284, 'test/loss': 2.7045395374298096, 'test/num_examples': 10000, 'score': 12646.741933107376, 'total_duration': 13518.917974710464, 'accumulated_submission_time': 12646.741933107376, 'accumulated_eval_time': 870.1968598365784, 'accumulated_logging_time': 0.8407182693481445}
I0315 05:54:27.712813 139540685625088 logging_writer.py:48] [32193] accumulated_eval_time=870.196860, accumulated_logging_time=0.840718, accumulated_submission_time=12646.741933, global_step=32193, preemption_count=0, score=12646.741933, test/accuracy=0.415100, test/loss=2.704540, test/num_examples=10000, total_duration=13518.917975, train/accuracy=0.570977, train/loss=1.835531, validation/accuracy=0.526300, validation/loss=2.054013, validation/num_examples=50000
I0315 05:56:28.136900 139540534654720 logging_writer.py:48] [32500] global_step=32500, grad_norm=1.2040601968765259, loss=3.981557607650757
I0315 05:59:43.735477 139540685625088 logging_writer.py:48] [33000] global_step=33000, grad_norm=1.46912682056427, loss=2.777360439300537
I0315 06:01:27.902788 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:01:40.911629 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:01:53.500773 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:01:56.199161 139734377899840 submission_runner.py:420] Time since start: 13967.42s, 	Step: 33268, 	{'train/accuracy': 0.6173632740974426, 'train/loss': 1.6312971115112305, 'validation/accuracy': 0.5347200036048889, 'validation/loss': 2.0119359493255615, 'validation/num_examples': 50000, 'test/accuracy': 0.4172000288963318, 'test/loss': 2.6746208667755127, 'test/num_examples': 10000, 'score': 13066.884756326675, 'total_duration': 13967.424229860306, 'accumulated_submission_time': 13066.884756326675, 'accumulated_eval_time': 898.4931993484497, 'accumulated_logging_time': 0.8703837394714355}
I0315 06:01:56.217724 139540534654720 logging_writer.py:48] [33268] accumulated_eval_time=898.493199, accumulated_logging_time=0.870384, accumulated_submission_time=13066.884756, global_step=33268, preemption_count=0, score=13066.884756, test/accuracy=0.417200, test/loss=2.674621, test/num_examples=10000, total_duration=13967.424230, train/accuracy=0.617363, train/loss=1.631297, validation/accuracy=0.534720, validation/loss=2.011936, validation/num_examples=50000
I0315 06:03:27.303852 139540685625088 logging_writer.py:48] [33500] global_step=33500, grad_norm=1.4897115230560303, loss=2.4642715454101562
I0315 06:06:42.933701 139540534654720 logging_writer.py:48] [34000] global_step=34000, grad_norm=1.6533410549163818, loss=2.752943754196167
I0315 06:08:56.431912 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:09:09.501272 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:09:21.852896 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:09:24.541610 139734377899840 submission_runner.py:420] Time since start: 14415.77s, 	Step: 34343, 	{'train/accuracy': 0.5891015529632568, 'train/loss': 1.746524453163147, 'validation/accuracy': 0.5367000102996826, 'validation/loss': 1.9880625009536743, 'validation/num_examples': 50000, 'test/accuracy': 0.42170003056526184, 'test/loss': 2.6583588123321533, 'test/num_examples': 10000, 'score': 13487.050795793533, 'total_duration': 14415.766685247421, 'accumulated_submission_time': 13487.050795793533, 'accumulated_eval_time': 926.6028730869293, 'accumulated_logging_time': 0.8991312980651855}
I0315 06:09:24.560852 139540685625088 logging_writer.py:48] [34343] accumulated_eval_time=926.602873, accumulated_logging_time=0.899131, accumulated_submission_time=13487.050796, global_step=34343, preemption_count=0, score=13487.050796, test/accuracy=0.421700, test/loss=2.658359, test/num_examples=10000, total_duration=14415.766685, train/accuracy=0.589102, train/loss=1.746524, validation/accuracy=0.536700, validation/loss=1.988063, validation/num_examples=50000
I0315 06:10:26.332932 139540534654720 logging_writer.py:48] [34500] global_step=34500, grad_norm=1.2478786706924438, loss=3.4102232456207275
I0315 06:13:41.953227 139540685625088 logging_writer.py:48] [35000] global_step=35000, grad_norm=1.4170308113098145, loss=3.0827929973602295
I0315 06:16:24.813119 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:16:37.890708 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:16:50.255078 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:16:52.950915 139734377899840 submission_runner.py:420] Time since start: 14864.18s, 	Step: 35418, 	{'train/accuracy': 0.5856054425239563, 'train/loss': 1.7603331804275513, 'validation/accuracy': 0.542199969291687, 'validation/loss': 1.9779938459396362, 'validation/num_examples': 50000, 'test/accuracy': 0.41940000653266907, 'test/loss': 2.6502013206481934, 'test/num_examples': 10000, 'score': 13907.255617380142, 'total_duration': 14864.1759724617, 'accumulated_submission_time': 13907.255617380142, 'accumulated_eval_time': 954.7406280040741, 'accumulated_logging_time': 0.9276912212371826}
I0315 06:16:52.972206 139540534654720 logging_writer.py:48] [35418] accumulated_eval_time=954.740628, accumulated_logging_time=0.927691, accumulated_submission_time=13907.255617, global_step=35418, preemption_count=0, score=13907.255617, test/accuracy=0.419400, test/loss=2.650201, test/num_examples=10000, total_duration=14864.175972, train/accuracy=0.585605, train/loss=1.760333, validation/accuracy=0.542200, validation/loss=1.977994, validation/num_examples=50000
I0315 06:17:25.408836 139540685625088 logging_writer.py:48] [35500] global_step=35500, grad_norm=1.3513802289962769, loss=4.175752639770508
I0315 06:20:41.015274 139540534654720 logging_writer.py:48] [36000] global_step=36000, grad_norm=1.5264780521392822, loss=2.8280422687530518
I0315 06:23:53.185361 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:24:06.287317 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:24:18.631822 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:24:21.327489 139734377899840 submission_runner.py:420] Time since start: 15312.55s, 	Step: 36493, 	{'train/accuracy': 0.5997265577316284, 'train/loss': 1.7268105745315552, 'validation/accuracy': 0.5432999730110168, 'validation/loss': 1.9965629577636719, 'validation/num_examples': 50000, 'test/accuracy': 0.4263000190258026, 'test/loss': 2.640662908554077, 'test/num_examples': 10000, 'score': 14327.414219141006, 'total_duration': 15312.552569150925, 'accumulated_submission_time': 14327.414219141006, 'accumulated_eval_time': 982.8827528953552, 'accumulated_logging_time': 0.9647958278656006}
I0315 06:24:21.346251 139540685625088 logging_writer.py:48] [36493] accumulated_eval_time=982.882753, accumulated_logging_time=0.964796, accumulated_submission_time=14327.414219, global_step=36493, preemption_count=0, score=14327.414219, test/accuracy=0.426300, test/loss=2.640663, test/num_examples=10000, total_duration=15312.552569, train/accuracy=0.599727, train/loss=1.726811, validation/accuracy=0.543300, validation/loss=1.996563, validation/num_examples=50000
I0315 06:24:24.490943 139540534654720 logging_writer.py:48] [36500] global_step=36500, grad_norm=1.5612382888793945, loss=2.8598194122314453
I0315 06:27:40.034246 139540685625088 logging_writer.py:48] [37000] global_step=37000, grad_norm=1.440679907798767, loss=2.6924140453338623
I0315 06:30:55.709249 139540534654720 logging_writer.py:48] [37500] global_step=37500, grad_norm=1.6967270374298096, loss=2.5818216800689697
I0315 06:31:21.612540 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:31:34.790918 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:31:47.147533 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:31:49.850111 139734377899840 submission_runner.py:420] Time since start: 15761.08s, 	Step: 37568, 	{'train/accuracy': 0.6006640195846558, 'train/loss': 1.7108898162841797, 'validation/accuracy': 0.5539000034332275, 'validation/loss': 1.9328171014785767, 'validation/num_examples': 50000, 'test/accuracy': 0.43290001153945923, 'test/loss': 2.5919063091278076, 'test/num_examples': 10000, 'score': 14747.632803916931, 'total_duration': 15761.075187206268, 'accumulated_submission_time': 14747.632803916931, 'accumulated_eval_time': 1011.1202862262726, 'accumulated_logging_time': 0.9931976795196533}
I0315 06:31:49.867908 139540685625088 logging_writer.py:48] [37568] accumulated_eval_time=1011.120286, accumulated_logging_time=0.993198, accumulated_submission_time=14747.632804, global_step=37568, preemption_count=0, score=14747.632804, test/accuracy=0.432900, test/loss=2.591906, test/num_examples=10000, total_duration=15761.075187, train/accuracy=0.600664, train/loss=1.710890, validation/accuracy=0.553900, validation/loss=1.932817, validation/num_examples=50000
I0315 06:34:39.251667 139540534654720 logging_writer.py:48] [38000] global_step=38000, grad_norm=1.5445486307144165, loss=2.8152008056640625
I0315 06:37:54.901394 139540685625088 logging_writer.py:48] [38500] global_step=38500, grad_norm=1.2413313388824463, loss=5.373644828796387
I0315 06:38:50.170900 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:39:03.357867 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:39:15.741723 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:39:18.442179 139734377899840 submission_runner.py:420] Time since start: 16209.67s, 	Step: 38643, 	{'train/accuracy': 0.6182226538658142, 'train/loss': 1.598379135131836, 'validation/accuracy': 0.5583999752998352, 'validation/loss': 1.8778663873672485, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.5246849060058594, 'test/num_examples': 10000, 'score': 15167.889869451523, 'total_duration': 16209.667258501053, 'accumulated_submission_time': 15167.889869451523, 'accumulated_eval_time': 1039.3915419578552, 'accumulated_logging_time': 1.0191874504089355}
I0315 06:39:18.459581 139540534654720 logging_writer.py:48] [38643] accumulated_eval_time=1039.391542, accumulated_logging_time=1.019187, accumulated_submission_time=15167.889869, global_step=38643, preemption_count=0, score=15167.889869, test/accuracy=0.445800, test/loss=2.524685, test/num_examples=10000, total_duration=16209.667259, train/accuracy=0.618223, train/loss=1.598379, validation/accuracy=0.558400, validation/loss=1.877866, validation/num_examples=50000
I0315 06:41:38.483696 139540685625088 logging_writer.py:48] [39000] global_step=39000, grad_norm=1.56875741481781, loss=2.647437572479248
I0315 06:44:54.159506 139540534654720 logging_writer.py:48] [39500] global_step=39500, grad_norm=1.7270759344100952, loss=2.8796238899230957
I0315 06:46:18.735689 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:46:31.946325 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:46:44.309341 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:46:47.003118 139734377899840 submission_runner.py:420] Time since start: 16658.23s, 	Step: 39718, 	{'train/accuracy': 0.6103320121765137, 'train/loss': 1.6485371589660645, 'validation/accuracy': 0.562559962272644, 'validation/loss': 1.8861223459243774, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.535008430480957, 'test/num_examples': 10000, 'score': 15588.118755817413, 'total_duration': 16658.228201389313, 'accumulated_submission_time': 15588.118755817413, 'accumulated_eval_time': 1067.6589496135712, 'accumulated_logging_time': 1.0449261665344238}
I0315 06:46:47.022076 139540685625088 logging_writer.py:48] [39718] accumulated_eval_time=1067.658950, accumulated_logging_time=1.044926, accumulated_submission_time=15588.118756, global_step=39718, preemption_count=0, score=15588.118756, test/accuracy=0.445800, test/loss=2.535008, test/num_examples=10000, total_duration=16658.228201, train/accuracy=0.610332, train/loss=1.648537, validation/accuracy=0.562560, validation/loss=1.886122, validation/num_examples=50000
I0315 06:48:37.706911 139540534654720 logging_writer.py:48] [40000] global_step=40000, grad_norm=1.132718801498413, loss=4.5975341796875
I0315 06:51:53.338823 139540685625088 logging_writer.py:48] [40500] global_step=40500, grad_norm=1.232952356338501, loss=4.8414435386657715
I0315 06:53:47.318656 139734377899840 spec.py:321] Evaluating on the training split.
I0315 06:54:00.543763 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 06:54:12.909970 139734377899840 spec.py:349] Evaluating on the test split.
I0315 06:54:15.611430 139734377899840 submission_runner.py:420] Time since start: 17106.84s, 	Step: 40793, 	{'train/accuracy': 0.6161327958106995, 'train/loss': 1.6052472591400146, 'validation/accuracy': 0.5676400065422058, 'validation/loss': 1.839556097984314, 'validation/num_examples': 50000, 'test/accuracy': 0.44950002431869507, 'test/loss': 2.5017149448394775, 'test/num_examples': 10000, 'score': 16008.369101762772, 'total_duration': 17106.836500883102, 'accumulated_submission_time': 16008.369101762772, 'accumulated_eval_time': 1095.9517030715942, 'accumulated_logging_time': 1.072103500366211}
I0315 06:54:15.633431 139540534654720 logging_writer.py:48] [40793] accumulated_eval_time=1095.951703, accumulated_logging_time=1.072104, accumulated_submission_time=16008.369102, global_step=40793, preemption_count=0, score=16008.369102, test/accuracy=0.449500, test/loss=2.501715, test/num_examples=10000, total_duration=17106.836501, train/accuracy=0.616133, train/loss=1.605247, validation/accuracy=0.567640, validation/loss=1.839556, validation/num_examples=50000
I0315 06:55:36.950441 139540685625088 logging_writer.py:48] [41000] global_step=41000, grad_norm=1.423499584197998, loss=3.572190046310425
I0315 06:58:52.540458 139540534654720 logging_writer.py:48] [41500] global_step=41500, grad_norm=1.2483956813812256, loss=4.088946342468262
I0315 07:01:15.852923 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:01:29.070835 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:01:41.440702 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:01:44.129378 139734377899840 submission_runner.py:420] Time since start: 17555.35s, 	Step: 41868, 	{'train/accuracy': 0.6323046684265137, 'train/loss': 1.5458195209503174, 'validation/accuracy': 0.5681799650192261, 'validation/loss': 1.8447296619415283, 'validation/num_examples': 50000, 'test/accuracy': 0.4515000283718109, 'test/loss': 2.504584312438965, 'test/num_examples': 10000, 'score': 16428.54066300392, 'total_duration': 17555.354459047318, 'accumulated_submission_time': 16428.54066300392, 'accumulated_eval_time': 1124.2281475067139, 'accumulated_logging_time': 1.1044514179229736}
I0315 07:01:44.147629 139540685625088 logging_writer.py:48] [41868] accumulated_eval_time=1124.228148, accumulated_logging_time=1.104451, accumulated_submission_time=16428.540663, global_step=41868, preemption_count=0, score=16428.540663, test/accuracy=0.451500, test/loss=2.504584, test/num_examples=10000, total_duration=17555.354459, train/accuracy=0.632305, train/loss=1.545820, validation/accuracy=0.568180, validation/loss=1.844730, validation/num_examples=50000
I0315 07:02:36.200850 139540534654720 logging_writer.py:48] [42000] global_step=42000, grad_norm=1.6648588180541992, loss=3.0498878955841064
I0315 07:05:51.843266 139540685625088 logging_writer.py:48] [42500] global_step=42500, grad_norm=1.6311718225479126, loss=2.8486804962158203
I0315 07:08:44.453065 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:08:57.645894 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:09:09.989062 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:09:12.689472 139734377899840 submission_runner.py:420] Time since start: 18003.91s, 	Step: 42943, 	{'train/accuracy': 0.62109375, 'train/loss': 1.5963397026062012, 'validation/accuracy': 0.569379985332489, 'validation/loss': 1.8445096015930176, 'validation/num_examples': 50000, 'test/accuracy': 0.45570001006126404, 'test/loss': 2.490640640258789, 'test/num_examples': 10000, 'score': 16848.79888153076, 'total_duration': 18003.914548397064, 'accumulated_submission_time': 16848.79888153076, 'accumulated_eval_time': 1152.4645340442657, 'accumulated_logging_time': 1.1316595077514648}
I0315 07:09:12.711153 139540534654720 logging_writer.py:48] [42943] accumulated_eval_time=1152.464534, accumulated_logging_time=1.131660, accumulated_submission_time=16848.798882, global_step=42943, preemption_count=0, score=16848.798882, test/accuracy=0.455700, test/loss=2.490641, test/num_examples=10000, total_duration=18003.914548, train/accuracy=0.621094, train/loss=1.596340, validation/accuracy=0.569380, validation/loss=1.844510, validation/num_examples=50000
I0315 07:09:35.392391 139540685625088 logging_writer.py:48] [43000] global_step=43000, grad_norm=1.2915548086166382, loss=5.218034744262695
I0315 07:12:50.990433 139540534654720 logging_writer.py:48] [43500] global_step=43500, grad_norm=1.6371277570724487, loss=2.3473668098449707
I0315 07:16:06.654302 139540685625088 logging_writer.py:48] [44000] global_step=44000, grad_norm=1.6177006959915161, loss=2.3905344009399414
I0315 07:16:12.888734 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:16:26.122546 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:16:38.563774 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:16:41.253749 139734377899840 submission_runner.py:420] Time since start: 18452.48s, 	Step: 44017, 	{'train/accuracy': 0.6287695169448853, 'train/loss': 1.566895604133606, 'validation/accuracy': 0.576200008392334, 'validation/loss': 1.8047599792480469, 'validation/num_examples': 50000, 'test/accuracy': 0.45830002427101135, 'test/loss': 2.45627498626709, 'test/num_examples': 10000, 'score': 17268.929253578186, 'total_duration': 18452.478810548782, 'accumulated_submission_time': 17268.929253578186, 'accumulated_eval_time': 1180.829502105713, 'accumulated_logging_time': 1.1626203060150146}
I0315 07:16:41.278959 139540534654720 logging_writer.py:48] [44017] accumulated_eval_time=1180.829502, accumulated_logging_time=1.162620, accumulated_submission_time=17268.929254, global_step=44017, preemption_count=0, score=17268.929254, test/accuracy=0.458300, test/loss=2.456275, test/num_examples=10000, total_duration=18452.478811, train/accuracy=0.628770, train/loss=1.566896, validation/accuracy=0.576200, validation/loss=1.804760, validation/num_examples=50000
I0315 07:19:50.573555 139540685625088 logging_writer.py:48] [44500] global_step=44500, grad_norm=1.4763526916503906, loss=3.3210952281951904
I0315 07:23:06.212136 139540534654720 logging_writer.py:48] [45000] global_step=45000, grad_norm=1.62006413936615, loss=2.7039432525634766
I0315 07:23:41.503874 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:23:54.706337 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:24:07.154316 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:24:09.848686 139734377899840 submission_runner.py:420] Time since start: 18901.07s, 	Step: 45092, 	{'train/accuracy': 0.634960949420929, 'train/loss': 1.5245351791381836, 'validation/accuracy': 0.5781999826431274, 'validation/loss': 1.7938686609268188, 'validation/num_examples': 50000, 'test/accuracy': 0.45810002088546753, 'test/loss': 2.4540762901306152, 'test/num_examples': 10000, 'score': 17689.10785293579, 'total_duration': 18901.07377076149, 'accumulated_submission_time': 17689.10785293579, 'accumulated_eval_time': 1209.1742882728577, 'accumulated_logging_time': 1.1968097686767578}
I0315 07:24:09.872579 139540685625088 logging_writer.py:48] [45092] accumulated_eval_time=1209.174288, accumulated_logging_time=1.196810, accumulated_submission_time=17689.107853, global_step=45092, preemption_count=0, score=17689.107853, test/accuracy=0.458100, test/loss=2.454076, test/num_examples=10000, total_duration=18901.073771, train/accuracy=0.634961, train/loss=1.524535, validation/accuracy=0.578200, validation/loss=1.793869, validation/num_examples=50000
I0315 07:26:49.901673 139540534654720 logging_writer.py:48] [45500] global_step=45500, grad_norm=1.386151909828186, loss=4.440664291381836
I0315 07:30:05.530729 139540685625088 logging_writer.py:48] [46000] global_step=46000, grad_norm=1.3545628786087036, loss=3.8137898445129395
I0315 07:31:10.169634 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:31:23.336224 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:31:35.731089 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:31:38.427621 139734377899840 submission_runner.py:420] Time since start: 19349.65s, 	Step: 46167, 	{'train/accuracy': 0.6251757740974426, 'train/loss': 1.5695594549179077, 'validation/accuracy': 0.5769000053405762, 'validation/loss': 1.8058549165725708, 'validation/num_examples': 50000, 'test/accuracy': 0.460500031709671, 'test/loss': 2.470344305038452, 'test/num_examples': 10000, 'score': 18109.35847568512, 'total_duration': 19349.652705192566, 'accumulated_submission_time': 18109.35847568512, 'accumulated_eval_time': 1237.4322583675385, 'accumulated_logging_time': 1.2294011116027832}
I0315 07:31:38.447746 139540534654720 logging_writer.py:48] [46167] accumulated_eval_time=1237.432258, accumulated_logging_time=1.229401, accumulated_submission_time=18109.358476, global_step=46167, preemption_count=0, score=18109.358476, test/accuracy=0.460500, test/loss=2.470344, test/num_examples=10000, total_duration=19349.652705, train/accuracy=0.625176, train/loss=1.569559, validation/accuracy=0.576900, validation/loss=1.805855, validation/num_examples=50000
I0315 07:33:49.145439 139540685625088 logging_writer.py:48] [46500] global_step=46500, grad_norm=1.6831302642822266, loss=2.8473258018493652
I0315 07:37:04.715080 139540534654720 logging_writer.py:48] [47000] global_step=47000, grad_norm=1.464430809020996, loss=3.178185224533081
I0315 07:38:38.715345 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:38:51.871803 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:39:04.243445 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:39:06.945033 139734377899840 submission_runner.py:420] Time since start: 19798.17s, 	Step: 47242, 	{'train/accuracy': 0.6563280820846558, 'train/loss': 1.4442133903503418, 'validation/accuracy': 0.5828199982643127, 'validation/loss': 1.7790160179138184, 'validation/num_examples': 50000, 'test/accuracy': 0.46790000796318054, 'test/loss': 2.432217597961426, 'test/num_examples': 10000, 'score': 18529.57877254486, 'total_duration': 19798.17009449005, 'accumulated_submission_time': 18529.57877254486, 'accumulated_eval_time': 1265.6619102954865, 'accumulated_logging_time': 1.2582430839538574}
I0315 07:39:06.963191 139540685625088 logging_writer.py:48] [47242] accumulated_eval_time=1265.661910, accumulated_logging_time=1.258243, accumulated_submission_time=18529.578773, global_step=47242, preemption_count=0, score=18529.578773, test/accuracy=0.467900, test/loss=2.432218, test/num_examples=10000, total_duration=19798.170094, train/accuracy=0.656328, train/loss=1.444213, validation/accuracy=0.582820, validation/loss=1.779016, validation/num_examples=50000
I0315 07:40:48.238790 139540534654720 logging_writer.py:48] [47500] global_step=47500, grad_norm=1.5060529708862305, loss=2.5097687244415283
I0315 07:44:03.812561 139540685625088 logging_writer.py:48] [48000] global_step=48000, grad_norm=1.529831051826477, loss=2.6518514156341553
I0315 07:46:07.163815 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:46:20.260524 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:46:32.628401 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:46:35.319761 139734377899840 submission_runner.py:420] Time since start: 20246.54s, 	Step: 48317, 	{'train/accuracy': 0.6399804353713989, 'train/loss': 1.4858754873275757, 'validation/accuracy': 0.5850799679756165, 'validation/loss': 1.7439395189285278, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.4006543159484863, 'test/num_examples': 10000, 'score': 18949.731778621674, 'total_duration': 20246.544842243195, 'accumulated_submission_time': 18949.731778621674, 'accumulated_eval_time': 1293.817842245102, 'accumulated_logging_time': 1.2849884033203125}
I0315 07:46:35.338311 139540534654720 logging_writer.py:48] [48317] accumulated_eval_time=1293.817842, accumulated_logging_time=1.284988, accumulated_submission_time=18949.731779, global_step=48317, preemption_count=0, score=18949.731779, test/accuracy=0.467600, test/loss=2.400654, test/num_examples=10000, total_duration=20246.544842, train/accuracy=0.639980, train/loss=1.485875, validation/accuracy=0.585080, validation/loss=1.743940, validation/num_examples=50000
I0315 07:47:47.294552 139540685625088 logging_writer.py:48] [48500] global_step=48500, grad_norm=1.5535428524017334, loss=2.4890904426574707
I0315 07:51:02.902156 139540534654720 logging_writer.py:48] [49000] global_step=49000, grad_norm=1.7031978368759155, loss=3.0786359310150146
I0315 07:53:35.594481 139734377899840 spec.py:321] Evaluating on the training split.
I0315 07:53:48.732067 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 07:54:01.096248 139734377899840 spec.py:349] Evaluating on the test split.
I0315 07:54:03.796859 139734377899840 submission_runner.py:420] Time since start: 20695.02s, 	Step: 49392, 	{'train/accuracy': 0.6422656178474426, 'train/loss': 1.4632335901260376, 'validation/accuracy': 0.5943599939346313, 'validation/loss': 1.6997281312942505, 'validation/num_examples': 50000, 'test/accuracy': 0.48190003633499146, 'test/loss': 2.353092670440674, 'test/num_examples': 10000, 'score': 19369.939849853516, 'total_duration': 20695.021906375885, 'accumulated_submission_time': 19369.939849853516, 'accumulated_eval_time': 1322.0201544761658, 'accumulated_logging_time': 1.3136389255523682}
I0315 07:54:03.818448 139540685625088 logging_writer.py:48] [49392] accumulated_eval_time=1322.020154, accumulated_logging_time=1.313639, accumulated_submission_time=19369.939850, global_step=49392, preemption_count=0, score=19369.939850, test/accuracy=0.481900, test/loss=2.353093, test/num_examples=10000, total_duration=20695.021906, train/accuracy=0.642266, train/loss=1.463234, validation/accuracy=0.594360, validation/loss=1.699728, validation/num_examples=50000
I0315 07:54:46.406219 139540534654720 logging_writer.py:48] [49500] global_step=49500, grad_norm=1.4379246234893799, loss=3.6524417400360107
I0315 07:58:02.074453 139540685625088 logging_writer.py:48] [50000] global_step=50000, grad_norm=1.9029688835144043, loss=2.736003875732422
I0315 08:01:04.098595 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:01:17.224647 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:01:29.590193 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:01:32.287660 139734377899840 submission_runner.py:420] Time since start: 21143.51s, 	Step: 50467, 	{'train/accuracy': 0.655566394329071, 'train/loss': 1.4283013343811035, 'validation/accuracy': 0.5932799577713013, 'validation/loss': 1.7206931114196777, 'validation/num_examples': 50000, 'test/accuracy': 0.4756000339984894, 'test/loss': 2.3874094486236572, 'test/num_examples': 10000, 'score': 19790.172041893005, 'total_duration': 21143.512743234634, 'accumulated_submission_time': 19790.172041893005, 'accumulated_eval_time': 1350.2092118263245, 'accumulated_logging_time': 1.3454182147979736}
I0315 08:01:32.306716 139540534654720 logging_writer.py:48] [50467] accumulated_eval_time=1350.209212, accumulated_logging_time=1.345418, accumulated_submission_time=19790.172042, global_step=50467, preemption_count=0, score=19790.172042, test/accuracy=0.475600, test/loss=2.387409, test/num_examples=10000, total_duration=21143.512743, train/accuracy=0.655566, train/loss=1.428301, validation/accuracy=0.593280, validation/loss=1.720693, validation/num_examples=50000
I0315 08:01:45.624854 139540685625088 logging_writer.py:48] [50500] global_step=50500, grad_norm=1.3571887016296387, loss=5.234570503234863
I0315 08:05:01.191078 139540534654720 logging_writer.py:48] [51000] global_step=51000, grad_norm=1.5088672637939453, loss=5.149528503417969
I0315 08:08:16.852483 139540685625088 logging_writer.py:48] [51500] global_step=51500, grad_norm=1.6782110929489136, loss=2.525651216506958
I0315 08:08:32.593166 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:08:45.766731 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:08:58.429062 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:09:01.130068 139734377899840 submission_runner.py:420] Time since start: 21592.36s, 	Step: 51542, 	{'train/accuracy': 0.6568750143051147, 'train/loss': 1.4333698749542236, 'validation/accuracy': 0.6020399928092957, 'validation/loss': 1.684518814086914, 'validation/num_examples': 50000, 'test/accuracy': 0.4845000207424164, 'test/loss': 2.354658365249634, 'test/num_examples': 10000, 'score': 20210.40957069397, 'total_duration': 21592.355147123337, 'accumulated_submission_time': 20210.40957069397, 'accumulated_eval_time': 1378.7460765838623, 'accumulated_logging_time': 1.3763620853424072}
I0315 08:09:01.148204 139540534654720 logging_writer.py:48] [51542] accumulated_eval_time=1378.746077, accumulated_logging_time=1.376362, accumulated_submission_time=20210.409571, global_step=51542, preemption_count=0, score=20210.409571, test/accuracy=0.484500, test/loss=2.354658, test/num_examples=10000, total_duration=21592.355147, train/accuracy=0.656875, train/loss=1.433370, validation/accuracy=0.602040, validation/loss=1.684519, validation/num_examples=50000
I0315 08:12:00.675039 139540685625088 logging_writer.py:48] [52000] global_step=52000, grad_norm=1.3876268863677979, loss=3.360215425491333
I0315 08:15:16.335437 139540534654720 logging_writer.py:48] [52500] global_step=52500, grad_norm=1.383218765258789, loss=4.660170078277588
I0315 08:16:01.436707 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:16:14.499368 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:16:26.888284 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:16:29.581160 139734377899840 submission_runner.py:420] Time since start: 22040.81s, 	Step: 52617, 	{'train/accuracy': 0.6830663681030273, 'train/loss': 1.2850286960601807, 'validation/accuracy': 0.5993599891662598, 'validation/loss': 1.6752032041549683, 'validation/num_examples': 50000, 'test/accuracy': 0.4782000184059143, 'test/loss': 2.3473029136657715, 'test/num_examples': 10000, 'score': 20630.652017354965, 'total_duration': 22040.806235551834, 'accumulated_submission_time': 20630.652017354965, 'accumulated_eval_time': 1406.8904960155487, 'accumulated_logging_time': 1.4034199714660645}
I0315 08:16:29.601708 139540685625088 logging_writer.py:48] [52617] accumulated_eval_time=1406.890496, accumulated_logging_time=1.403420, accumulated_submission_time=20630.652017, global_step=52617, preemption_count=0, score=20630.652017, test/accuracy=0.478200, test/loss=2.347303, test/num_examples=10000, total_duration=22040.806236, train/accuracy=0.683066, train/loss=1.285029, validation/accuracy=0.599360, validation/loss=1.675203, validation/num_examples=50000
I0315 08:18:59.749732 139540534654720 logging_writer.py:48] [53000] global_step=53000, grad_norm=1.6680445671081543, loss=3.542807102203369
I0315 08:22:15.344986 139540685625088 logging_writer.py:48] [53500] global_step=53500, grad_norm=1.49372136592865, loss=3.1430726051330566
I0315 08:23:29.789801 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:23:42.801215 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:23:55.140436 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:23:57.842723 139734377899840 submission_runner.py:420] Time since start: 22489.07s, 	Step: 53692, 	{'train/accuracy': 0.6595507860183716, 'train/loss': 1.4042620658874512, 'validation/accuracy': 0.6054999828338623, 'validation/loss': 1.669420838356018, 'validation/num_examples': 50000, 'test/accuracy': 0.48570001125335693, 'test/loss': 2.336071252822876, 'test/num_examples': 10000, 'score': 21050.792801380157, 'total_duration': 22489.067804336548, 'accumulated_submission_time': 21050.792801380157, 'accumulated_eval_time': 1434.9433960914612, 'accumulated_logging_time': 1.4332911968231201}
I0315 08:23:57.864635 139540534654720 logging_writer.py:48] [53692] accumulated_eval_time=1434.943396, accumulated_logging_time=1.433291, accumulated_submission_time=21050.792801, global_step=53692, preemption_count=0, score=21050.792801, test/accuracy=0.485700, test/loss=2.336071, test/num_examples=10000, total_duration=22489.067804, train/accuracy=0.659551, train/loss=1.404262, validation/accuracy=0.605500, validation/loss=1.669421, validation/num_examples=50000
I0315 08:25:58.735969 139540685625088 logging_writer.py:48] [54000] global_step=54000, grad_norm=1.73190176486969, loss=2.6339521408081055
I0315 08:29:14.380485 139540534654720 logging_writer.py:48] [54500] global_step=54500, grad_norm=1.3644214868545532, loss=5.125448226928711
I0315 08:30:57.843540 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:31:10.899266 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:31:23.233980 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:31:25.925910 139734377899840 submission_runner.py:420] Time since start: 22937.15s, 	Step: 54766, 	{'train/accuracy': 0.6583788990974426, 'train/loss': 1.3919808864593506, 'validation/accuracy': 0.6048600077629089, 'validation/loss': 1.6459424495697021, 'validation/num_examples': 50000, 'test/accuracy': 0.48820000886917114, 'test/loss': 2.3061442375183105, 'test/num_examples': 10000, 'score': 21470.724470615387, 'total_duration': 22937.150980710983, 'accumulated_submission_time': 21470.724470615387, 'accumulated_eval_time': 1463.02574801445, 'accumulated_logging_time': 1.4640347957611084}
I0315 08:31:25.945854 139540685625088 logging_writer.py:48] [54766] accumulated_eval_time=1463.025748, accumulated_logging_time=1.464035, accumulated_submission_time=21470.724471, global_step=54766, preemption_count=0, score=21470.724471, test/accuracy=0.488200, test/loss=2.306144, test/num_examples=10000, total_duration=22937.150981, train/accuracy=0.658379, train/loss=1.391981, validation/accuracy=0.604860, validation/loss=1.645942, validation/num_examples=50000
I0315 08:32:57.917822 139540534654720 logging_writer.py:48] [55000] global_step=55000, grad_norm=1.7465051412582397, loss=2.3711764812469482
I0315 08:36:13.570129 139540685625088 logging_writer.py:48] [55500] global_step=55500, grad_norm=1.6863963603973389, loss=2.26660418510437
I0315 08:38:25.927582 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:38:39.116691 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:38:51.501056 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:38:54.201260 139734377899840 submission_runner.py:420] Time since start: 23385.43s, 	Step: 55840, 	{'train/accuracy': 0.67626953125, 'train/loss': 1.3267338275909424, 'validation/accuracy': 0.6133399605751038, 'validation/loss': 1.6220921277999878, 'validation/num_examples': 50000, 'test/accuracy': 0.492900013923645, 'test/loss': 2.2858996391296387, 'test/num_examples': 10000, 'score': 21890.660034418106, 'total_duration': 23385.426328659058, 'accumulated_submission_time': 21890.660034418106, 'accumulated_eval_time': 1491.2993965148926, 'accumulated_logging_time': 1.4927337169647217}
I0315 08:38:54.224262 139540534654720 logging_writer.py:48] [55840] accumulated_eval_time=1491.299397, accumulated_logging_time=1.492734, accumulated_submission_time=21890.660034, global_step=55840, preemption_count=0, score=21890.660034, test/accuracy=0.492900, test/loss=2.285900, test/num_examples=10000, total_duration=23385.426329, train/accuracy=0.676270, train/loss=1.326734, validation/accuracy=0.613340, validation/loss=1.622092, validation/num_examples=50000
I0315 08:39:57.151216 139540685625088 logging_writer.py:48] [56000] global_step=56000, grad_norm=1.7267329692840576, loss=2.526992082595825
I0315 08:43:12.835910 139540534654720 logging_writer.py:48] [56500] global_step=56500, grad_norm=1.393323540687561, loss=4.342477798461914
I0315 08:45:54.520153 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:46:07.672533 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:46:20.029357 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:46:22.727376 139734377899840 submission_runner.py:420] Time since start: 23833.95s, 	Step: 56915, 	{'train/accuracy': 0.6681054830551147, 'train/loss': 1.3655517101287842, 'validation/accuracy': 0.6129400134086609, 'validation/loss': 1.6313343048095703, 'validation/num_examples': 50000, 'test/accuracy': 0.48280003666877747, 'test/loss': 2.329977035522461, 'test/num_examples': 10000, 'score': 22310.907233953476, 'total_duration': 23833.952456712723, 'accumulated_submission_time': 22310.907233953476, 'accumulated_eval_time': 1519.506608247757, 'accumulated_logging_time': 1.5257229804992676}
I0315 08:46:22.750376 139540685625088 logging_writer.py:48] [56915] accumulated_eval_time=1519.506608, accumulated_logging_time=1.525723, accumulated_submission_time=22310.907234, global_step=56915, preemption_count=0, score=22310.907234, test/accuracy=0.482800, test/loss=2.329977, test/num_examples=10000, total_duration=23833.952457, train/accuracy=0.668105, train/loss=1.365552, validation/accuracy=0.612940, validation/loss=1.631334, validation/num_examples=50000
I0315 08:46:56.418359 139540534654720 logging_writer.py:48] [57000] global_step=57000, grad_norm=1.5357521772384644, loss=3.358410596847534
I0315 08:50:12.030302 139540685625088 logging_writer.py:48] [57500] global_step=57500, grad_norm=1.7453112602233887, loss=2.4974377155303955
I0315 08:53:23.043893 139734377899840 spec.py:321] Evaluating on the training split.
I0315 08:53:36.216867 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 08:53:48.582779 139734377899840 spec.py:349] Evaluating on the test split.
I0315 08:53:51.284760 139734377899840 submission_runner.py:420] Time since start: 24282.51s, 	Step: 57990, 	{'train/accuracy': 0.6885156035423279, 'train/loss': 1.3053981065750122, 'validation/accuracy': 0.6219599843025208, 'validation/loss': 1.5993369817733765, 'validation/num_examples': 50000, 'test/accuracy': 0.5071000456809998, 'test/loss': 2.248518943786621, 'test/num_examples': 10000, 'score': 22731.152432203293, 'total_duration': 24282.509819746017, 'accumulated_submission_time': 22731.152432203293, 'accumulated_eval_time': 1547.7474370002747, 'accumulated_logging_time': 1.5581462383270264}
I0315 08:53:51.309354 139540534654720 logging_writer.py:48] [57990] accumulated_eval_time=1547.747437, accumulated_logging_time=1.558146, accumulated_submission_time=22731.152432, global_step=57990, preemption_count=0, score=22731.152432, test/accuracy=0.507100, test/loss=2.248519, test/num_examples=10000, total_duration=24282.509820, train/accuracy=0.688516, train/loss=1.305398, validation/accuracy=0.621960, validation/loss=1.599337, validation/num_examples=50000
I0315 08:53:55.620806 139540685625088 logging_writer.py:48] [58000] global_step=58000, grad_norm=1.7024582624435425, loss=2.305302858352661
I0315 08:57:11.245801 139540534654720 logging_writer.py:48] [58500] global_step=58500, grad_norm=1.7621560096740723, loss=2.2694735527038574
I0315 09:00:26.877831 139540685625088 logging_writer.py:48] [59000] global_step=59000, grad_norm=1.709574818611145, loss=2.416853904724121
I0315 09:00:51.632642 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:01:04.834479 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:01:17.220064 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:01:19.918624 139734377899840 submission_runner.py:420] Time since start: 24731.14s, 	Step: 59065, 	{'train/accuracy': 0.6809374690055847, 'train/loss': 1.3111419677734375, 'validation/accuracy': 0.623199999332428, 'validation/loss': 1.5841891765594482, 'validation/num_examples': 50000, 'test/accuracy': 0.499500036239624, 'test/loss': 2.2402901649475098, 'test/num_examples': 10000, 'score': 23151.4269323349, 'total_duration': 24731.14370560646, 'accumulated_submission_time': 23151.4269323349, 'accumulated_eval_time': 1576.0334043502808, 'accumulated_logging_time': 1.5937366485595703}
I0315 09:01:19.938042 139540534654720 logging_writer.py:48] [59065] accumulated_eval_time=1576.033404, accumulated_logging_time=1.593737, accumulated_submission_time=23151.426932, global_step=59065, preemption_count=0, score=23151.426932, test/accuracy=0.499500, test/loss=2.240290, test/num_examples=10000, total_duration=24731.143706, train/accuracy=0.680937, train/loss=1.311142, validation/accuracy=0.623200, validation/loss=1.584189, validation/num_examples=50000
I0315 09:04:10.537064 139540685625088 logging_writer.py:48] [59500] global_step=59500, grad_norm=1.948801040649414, loss=2.6887032985687256
I0315 09:07:26.140900 139540534654720 logging_writer.py:48] [60000] global_step=60000, grad_norm=1.782922625541687, loss=2.273244857788086
I0315 09:08:20.219264 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:08:33.412943 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:08:45.801663 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:08:48.501399 139734377899840 submission_runner.py:420] Time since start: 25179.73s, 	Step: 60140, 	{'train/accuracy': 0.6778124570846558, 'train/loss': 1.3237377405166626, 'validation/accuracy': 0.6237999796867371, 'validation/loss': 1.5753084421157837, 'validation/num_examples': 50000, 'test/accuracy': 0.5049999952316284, 'test/loss': 2.238182544708252, 'test/num_examples': 10000, 'score': 23571.66185235977, 'total_duration': 25179.726477622986, 'accumulated_submission_time': 23571.66185235977, 'accumulated_eval_time': 1604.3155086040497, 'accumulated_logging_time': 1.621769666671753}
I0315 09:08:48.520557 139540685625088 logging_writer.py:48] [60140] accumulated_eval_time=1604.315509, accumulated_logging_time=1.621770, accumulated_submission_time=23571.661852, global_step=60140, preemption_count=0, score=23571.661852, test/accuracy=0.505000, test/loss=2.238183, test/num_examples=10000, total_duration=25179.726478, train/accuracy=0.677812, train/loss=1.323738, validation/accuracy=0.623800, validation/loss=1.575308, validation/num_examples=50000
I0315 09:11:09.765573 139540534654720 logging_writer.py:48] [60500] global_step=60500, grad_norm=1.803053379058838, loss=2.317401885986328
I0315 09:14:25.391104 139540685625088 logging_writer.py:48] [61000] global_step=61000, grad_norm=1.4423238039016724, loss=4.264876842498779
I0315 09:15:48.826674 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:16:02.063311 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:16:14.664315 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:16:17.355777 139734377899840 submission_runner.py:420] Time since start: 25628.58s, 	Step: 61215, 	{'train/accuracy': 0.6948632597923279, 'train/loss': 1.2332534790039062, 'validation/accuracy': 0.6238799691200256, 'validation/loss': 1.5658894777297974, 'validation/num_examples': 50000, 'test/accuracy': 0.5010000467300415, 'test/loss': 2.2323102951049805, 'test/num_examples': 10000, 'score': 23991.91918349266, 'total_duration': 25628.58084011078, 'accumulated_submission_time': 23991.91918349266, 'accumulated_eval_time': 1632.8445754051208, 'accumulated_logging_time': 1.650775671005249}
I0315 09:16:17.377368 139540534654720 logging_writer.py:48] [61215] accumulated_eval_time=1632.844575, accumulated_logging_time=1.650776, accumulated_submission_time=23991.919183, global_step=61215, preemption_count=0, score=23991.919183, test/accuracy=0.501000, test/loss=2.232310, test/num_examples=10000, total_duration=25628.580840, train/accuracy=0.694863, train/loss=1.233253, validation/accuracy=0.623880, validation/loss=1.565889, validation/num_examples=50000
I0315 09:18:09.246068 139540685625088 logging_writer.py:48] [61500] global_step=61500, grad_norm=1.7938159704208374, loss=2.6207120418548584
I0315 09:21:24.847506 139540534654720 logging_writer.py:48] [62000] global_step=62000, grad_norm=1.7746577262878418, loss=2.318211317062378
I0315 09:23:17.644921 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:23:30.812885 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:23:43.135503 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:23:45.839297 139734377899840 submission_runner.py:420] Time since start: 26077.06s, 	Step: 62290, 	{'train/accuracy': 0.6827734112739563, 'train/loss': 1.2909884452819824, 'validation/accuracy': 0.6261199712753296, 'validation/loss': 1.559798240661621, 'validation/num_examples': 50000, 'test/accuracy': 0.5069000124931335, 'test/loss': 2.2323246002197266, 'test/num_examples': 10000, 'score': 24412.13849759102, 'total_duration': 26077.064366340637, 'accumulated_submission_time': 24412.13849759102, 'accumulated_eval_time': 1661.038922548294, 'accumulated_logging_time': 1.6826434135437012}
I0315 09:23:45.860497 139540685625088 logging_writer.py:48] [62290] accumulated_eval_time=1661.038923, accumulated_logging_time=1.682643, accumulated_submission_time=24412.138498, global_step=62290, preemption_count=0, score=24412.138498, test/accuracy=0.506900, test/loss=2.232325, test/num_examples=10000, total_duration=26077.064366, train/accuracy=0.682773, train/loss=1.290988, validation/accuracy=0.626120, validation/loss=1.559798, validation/num_examples=50000
I0315 09:25:08.336898 139540534654720 logging_writer.py:48] [62500] global_step=62500, grad_norm=1.7962924242019653, loss=2.273927688598633
I0315 09:28:23.978172 139540685625088 logging_writer.py:48] [63000] global_step=63000, grad_norm=1.9399751424789429, loss=2.20538330078125
I0315 09:30:46.052176 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:30:59.210165 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:31:11.556607 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:31:14.253224 139734377899840 submission_runner.py:420] Time since start: 26525.48s, 	Step: 63365, 	{'train/accuracy': 0.6887109279632568, 'train/loss': 1.2545818090438843, 'validation/accuracy': 0.6304599642753601, 'validation/loss': 1.5248576402664185, 'validation/num_examples': 50000, 'test/accuracy': 0.5080000162124634, 'test/loss': 2.1767449378967285, 'test/num_examples': 10000, 'score': 24832.284222841263, 'total_duration': 26525.4783039093, 'accumulated_submission_time': 24832.284222841263, 'accumulated_eval_time': 1689.239952802658, 'accumulated_logging_time': 1.7124104499816895}
I0315 09:31:14.277464 139540534654720 logging_writer.py:48] [63365] accumulated_eval_time=1689.239953, accumulated_logging_time=1.712410, accumulated_submission_time=24832.284223, global_step=63365, preemption_count=0, score=24832.284223, test/accuracy=0.508000, test/loss=2.176745, test/num_examples=10000, total_duration=26525.478304, train/accuracy=0.688711, train/loss=1.254582, validation/accuracy=0.630460, validation/loss=1.524858, validation/num_examples=50000
I0315 09:32:07.479036 139540685625088 logging_writer.py:48] [63500] global_step=63500, grad_norm=1.8294626474380493, loss=2.2917346954345703
I0315 09:35:23.101515 139540534654720 logging_writer.py:48] [64000] global_step=64000, grad_norm=1.7175935506820679, loss=3.352571725845337
I0315 09:38:14.565943 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:38:27.713657 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:38:42.679317 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:38:45.363687 139734377899840 submission_runner.py:420] Time since start: 26976.59s, 	Step: 64440, 	{'train/accuracy': 0.6983984112739563, 'train/loss': 1.2290480136871338, 'validation/accuracy': 0.6302599906921387, 'validation/loss': 1.5308572053909302, 'validation/num_examples': 50000, 'test/accuracy': 0.5085000395774841, 'test/loss': 2.1962881088256836, 'test/num_examples': 10000, 'score': 25252.524570703506, 'total_duration': 26976.5887298584, 'accumulated_submission_time': 25252.524570703506, 'accumulated_eval_time': 1720.037649154663, 'accumulated_logging_time': 1.746248722076416}
I0315 09:38:45.388448 139540685625088 logging_writer.py:48] [64440] accumulated_eval_time=1720.037649, accumulated_logging_time=1.746249, accumulated_submission_time=25252.524571, global_step=64440, preemption_count=0, score=25252.524571, test/accuracy=0.508500, test/loss=2.196288, test/num_examples=10000, total_duration=26976.588730, train/accuracy=0.698398, train/loss=1.229048, validation/accuracy=0.630260, validation/loss=1.530857, validation/num_examples=50000
I0315 09:39:09.206901 139540534654720 logging_writer.py:48] [64500] global_step=64500, grad_norm=1.874125361442566, loss=2.3956854343414307
I0315 09:42:24.688485 139540685625088 logging_writer.py:48] [65000] global_step=65000, grad_norm=1.6529370546340942, loss=3.5566492080688477
I0315 09:45:40.261964 139540534654720 logging_writer.py:48] [65500] global_step=65500, grad_norm=1.5022474527359009, loss=4.786473274230957
I0315 09:45:45.424864 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:45:58.555784 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:46:10.995153 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:46:13.687485 139734377899840 submission_runner.py:420] Time since start: 27424.91s, 	Step: 65515, 	{'train/accuracy': 0.6917968392372131, 'train/loss': 1.2603040933609009, 'validation/accuracy': 0.6354599595069885, 'validation/loss': 1.5285406112670898, 'validation/num_examples': 50000, 'test/accuracy': 0.5040000081062317, 'test/loss': 2.2069759368896484, 'test/num_examples': 10000, 'score': 25672.51306271553, 'total_duration': 27424.912562847137, 'accumulated_submission_time': 25672.51306271553, 'accumulated_eval_time': 1748.3002469539642, 'accumulated_logging_time': 1.780982255935669}
I0315 09:46:13.708330 139540685625088 logging_writer.py:48] [65515] accumulated_eval_time=1748.300247, accumulated_logging_time=1.780982, accumulated_submission_time=25672.513063, global_step=65515, preemption_count=0, score=25672.513063, test/accuracy=0.504000, test/loss=2.206976, test/num_examples=10000, total_duration=27424.912563, train/accuracy=0.691797, train/loss=1.260304, validation/accuracy=0.635460, validation/loss=1.528541, validation/num_examples=50000
I0315 09:49:23.742015 139540534654720 logging_writer.py:48] [66000] global_step=66000, grad_norm=1.8589264154434204, loss=3.002372980117798
I0315 09:52:39.337500 139540685625088 logging_writer.py:48] [66500] global_step=66500, grad_norm=1.4804567098617554, loss=4.709360599517822
I0315 09:53:13.853258 139734377899840 spec.py:321] Evaluating on the training split.
I0315 09:53:26.958975 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 09:53:40.960639 139734377899840 spec.py:349] Evaluating on the test split.
I0315 09:53:43.644224 139734377899840 submission_runner.py:420] Time since start: 27874.87s, 	Step: 66590, 	{'train/accuracy': 0.7171093821525574, 'train/loss': 1.1421173810958862, 'validation/accuracy': 0.64028000831604, 'validation/loss': 1.4945441484451294, 'validation/num_examples': 50000, 'test/accuracy': 0.5195000171661377, 'test/loss': 2.15171217918396, 'test/num_examples': 10000, 'score': 26092.61092352867, 'total_duration': 27874.869310617447, 'accumulated_submission_time': 26092.61092352867, 'accumulated_eval_time': 1778.0911870002747, 'accumulated_logging_time': 1.8104863166809082}
I0315 09:53:43.663368 139540534654720 logging_writer.py:48] [66590] accumulated_eval_time=1778.091187, accumulated_logging_time=1.810486, accumulated_submission_time=26092.610924, global_step=66590, preemption_count=0, score=26092.610924, test/accuracy=0.519500, test/loss=2.151712, test/num_examples=10000, total_duration=27874.869311, train/accuracy=0.717109, train/loss=1.142117, validation/accuracy=0.640280, validation/loss=1.494544, validation/num_examples=50000
I0315 09:56:24.329177 139540685625088 logging_writer.py:48] [67000] global_step=67000, grad_norm=1.7711715698242188, loss=3.0030364990234375
I0315 09:59:39.952897 139540534654720 logging_writer.py:48] [67500] global_step=67500, grad_norm=1.9530588388442993, loss=2.6906657218933105
I0315 10:00:43.797594 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:00:56.844691 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:01:09.368088 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:01:12.067370 139734377899840 submission_runner.py:420] Time since start: 28323.29s, 	Step: 67665, 	{'train/accuracy': 0.7054101228713989, 'train/loss': 1.2118762731552124, 'validation/accuracy': 0.6391800045967102, 'validation/loss': 1.5081987380981445, 'validation/num_examples': 50000, 'test/accuracy': 0.5146999955177307, 'test/loss': 2.1746602058410645, 'test/num_examples': 10000, 'score': 26512.69844007492, 'total_duration': 28323.292452812195, 'accumulated_submission_time': 26512.69844007492, 'accumulated_eval_time': 1806.360939025879, 'accumulated_logging_time': 1.8380200862884521}
I0315 10:01:12.086913 139540685625088 logging_writer.py:48] [67665] accumulated_eval_time=1806.360939, accumulated_logging_time=1.838020, accumulated_submission_time=26512.698440, global_step=67665, preemption_count=0, score=26512.698440, test/accuracy=0.514700, test/loss=2.174660, test/num_examples=10000, total_duration=28323.292453, train/accuracy=0.705410, train/loss=1.211876, validation/accuracy=0.639180, validation/loss=1.508199, validation/num_examples=50000
I0315 10:03:23.552770 139540534654720 logging_writer.py:48] [68000] global_step=68000, grad_norm=1.6133095026016235, loss=3.2523910999298096
I0315 10:06:39.176902 139540685625088 logging_writer.py:48] [68500] global_step=68500, grad_norm=1.7369518280029297, loss=3.3900108337402344
I0315 10:08:12.414092 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:08:25.407094 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:08:37.909740 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:08:40.597076 139734377899840 submission_runner.py:420] Time since start: 28771.82s, 	Step: 68740, 	{'train/accuracy': 0.7085546851158142, 'train/loss': 1.1703555583953857, 'validation/accuracy': 0.6516799926757812, 'validation/loss': 1.4402635097503662, 'validation/num_examples': 50000, 'test/accuracy': 0.5311000347137451, 'test/loss': 2.0866637229919434, 'test/num_examples': 10000, 'score': 26932.97707104683, 'total_duration': 28771.82215476036, 'accumulated_submission_time': 26932.97707104683, 'accumulated_eval_time': 1834.5438992977142, 'accumulated_logging_time': 1.8677911758422852}
I0315 10:08:40.617434 139540534654720 logging_writer.py:48] [68740] accumulated_eval_time=1834.543899, accumulated_logging_time=1.867791, accumulated_submission_time=26932.977071, global_step=68740, preemption_count=0, score=26932.977071, test/accuracy=0.531100, test/loss=2.086664, test/num_examples=10000, total_duration=28771.822155, train/accuracy=0.708555, train/loss=1.170356, validation/accuracy=0.651680, validation/loss=1.440264, validation/num_examples=50000
I0315 10:10:22.651821 139540685625088 logging_writer.py:48] [69000] global_step=69000, grad_norm=1.8008339405059814, loss=2.4573893547058105
I0315 10:13:38.264409 139540534654720 logging_writer.py:48] [69500] global_step=69500, grad_norm=1.7298551797866821, loss=4.519472122192383
I0315 10:15:40.785075 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:15:53.777933 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:16:06.133596 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:16:08.835264 139734377899840 submission_runner.py:420] Time since start: 29220.06s, 	Step: 69815, 	{'train/accuracy': 0.7147460579872131, 'train/loss': 1.1490181684494019, 'validation/accuracy': 0.6469399929046631, 'validation/loss': 1.4612271785736084, 'validation/num_examples': 50000, 'test/accuracy': 0.5234000086784363, 'test/loss': 2.1238906383514404, 'test/num_examples': 10000, 'score': 27353.098613739014, 'total_duration': 29220.060346603394, 'accumulated_submission_time': 27353.098613739014, 'accumulated_eval_time': 1862.5940737724304, 'accumulated_logging_time': 1.89664626121521}
I0315 10:16:08.855306 139540685625088 logging_writer.py:48] [69815] accumulated_eval_time=1862.594074, accumulated_logging_time=1.896646, accumulated_submission_time=27353.098614, global_step=69815, preemption_count=0, score=27353.098614, test/accuracy=0.523400, test/loss=2.123891, test/num_examples=10000, total_duration=29220.060347, train/accuracy=0.714746, train/loss=1.149018, validation/accuracy=0.646940, validation/loss=1.461227, validation/num_examples=50000
I0315 10:17:21.559892 139540534654720 logging_writer.py:48] [70000] global_step=70000, grad_norm=1.9029971361160278, loss=2.135317325592041
I0315 10:20:37.180795 139540685625088 logging_writer.py:48] [70500] global_step=70500, grad_norm=1.707907795906067, loss=4.613826274871826
I0315 10:23:09.054985 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:23:22.069894 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:23:34.656909 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:23:37.352222 139734377899840 submission_runner.py:420] Time since start: 29668.58s, 	Step: 70890, 	{'train/accuracy': 0.7098242044448853, 'train/loss': 1.154585361480713, 'validation/accuracy': 0.6497799754142761, 'validation/loss': 1.4376181364059448, 'validation/num_examples': 50000, 'test/accuracy': 0.528700053691864, 'test/loss': 2.092740535736084, 'test/num_examples': 10000, 'score': 27773.24999809265, 'total_duration': 29668.57729792595, 'accumulated_submission_time': 27773.24999809265, 'accumulated_eval_time': 1890.8912887573242, 'accumulated_logging_time': 1.9263780117034912}
I0315 10:23:37.375720 139540534654720 logging_writer.py:48] [70890] accumulated_eval_time=1890.891289, accumulated_logging_time=1.926378, accumulated_submission_time=27773.249998, global_step=70890, preemption_count=0, score=27773.249998, test/accuracy=0.528700, test/loss=2.092741, test/num_examples=10000, total_duration=29668.577298, train/accuracy=0.709824, train/loss=1.154585, validation/accuracy=0.649780, validation/loss=1.437618, validation/num_examples=50000
I0315 10:24:20.751245 139540685625088 logging_writer.py:48] [71000] global_step=71000, grad_norm=1.7877590656280518, loss=3.1562070846557617
I0315 10:27:36.290273 139540534654720 logging_writer.py:48] [71500] global_step=71500, grad_norm=1.9505184888839722, loss=2.1861798763275146
I0315 10:30:37.492885 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:30:50.558398 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:31:02.912092 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:31:05.617432 139734377899840 submission_runner.py:420] Time since start: 30116.84s, 	Step: 71965, 	{'train/accuracy': 0.7422655820846558, 'train/loss': 1.0493677854537964, 'validation/accuracy': 0.6548199653625488, 'validation/loss': 1.4409143924713135, 'validation/num_examples': 50000, 'test/accuracy': 0.5309000015258789, 'test/loss': 2.10162353515625, 'test/num_examples': 10000, 'score': 28193.315749406815, 'total_duration': 30116.842511177063, 'accumulated_submission_time': 28193.315749406815, 'accumulated_eval_time': 1919.015851020813, 'accumulated_logging_time': 1.9618356227874756}
I0315 10:31:05.638120 139540685625088 logging_writer.py:48] [71965] accumulated_eval_time=1919.015851, accumulated_logging_time=1.961836, accumulated_submission_time=28193.315749, global_step=71965, preemption_count=0, score=28193.315749, test/accuracy=0.530900, test/loss=2.101624, test/num_examples=10000, total_duration=30116.842511, train/accuracy=0.742266, train/loss=1.049368, validation/accuracy=0.654820, validation/loss=1.440914, validation/num_examples=50000
I0315 10:31:19.741076 139540534654720 logging_writer.py:48] [72000] global_step=72000, grad_norm=2.046178102493286, loss=2.189553737640381
I0315 10:34:35.344942 139540685625088 logging_writer.py:48] [72500] global_step=72500, grad_norm=1.9981460571289062, loss=1.9765987396240234
I0315 10:37:50.931456 139540534654720 logging_writer.py:48] [73000] global_step=73000, grad_norm=2.072817325592041, loss=2.756194829940796
I0315 10:38:05.876881 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:38:18.899978 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:38:31.243758 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:38:33.936948 139734377899840 submission_runner.py:420] Time since start: 30565.16s, 	Step: 73040, 	{'train/accuracy': 0.7191991806030273, 'train/loss': 1.1370999813079834, 'validation/accuracy': 0.6542400121688843, 'validation/loss': 1.4398219585418701, 'validation/num_examples': 50000, 'test/accuracy': 0.5308000445365906, 'test/loss': 2.107109308242798, 'test/num_examples': 10000, 'score': 28613.507826805115, 'total_duration': 30565.16203045845, 'accumulated_submission_time': 28613.507826805115, 'accumulated_eval_time': 1947.0758850574493, 'accumulated_logging_time': 1.9914288520812988}
I0315 10:38:33.956998 139540685625088 logging_writer.py:48] [73040] accumulated_eval_time=1947.075885, accumulated_logging_time=1.991429, accumulated_submission_time=28613.507827, global_step=73040, preemption_count=0, score=28613.507827, test/accuracy=0.530800, test/loss=2.107109, test/num_examples=10000, total_duration=30565.162030, train/accuracy=0.719199, train/loss=1.137100, validation/accuracy=0.654240, validation/loss=1.439822, validation/num_examples=50000
I0315 10:41:34.267134 139540534654720 logging_writer.py:48] [73500] global_step=73500, grad_norm=2.0136983394622803, loss=2.089482069015503
I0315 10:44:49.883122 139540685625088 logging_writer.py:48] [74000] global_step=74000, grad_norm=1.8714371919631958, loss=2.4384710788726807
I0315 10:45:34.200912 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:45:47.259877 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:45:59.612625 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:46:02.316687 139734377899840 submission_runner.py:420] Time since start: 31013.54s, 	Step: 74115, 	{'train/accuracy': 0.7185937166213989, 'train/loss': 1.1530827283859253, 'validation/accuracy': 0.6581000089645386, 'validation/loss': 1.4239095449447632, 'validation/num_examples': 50000, 'test/accuracy': 0.5367000102996826, 'test/loss': 2.08459210395813, 'test/num_examples': 10000, 'score': 29033.705795288086, 'total_duration': 31013.541746854782, 'accumulated_submission_time': 29033.705795288086, 'accumulated_eval_time': 1975.1916115283966, 'accumulated_logging_time': 2.019712209701538}
I0315 10:46:02.338891 139540534654720 logging_writer.py:48] [74115] accumulated_eval_time=1975.191612, accumulated_logging_time=2.019712, accumulated_submission_time=29033.705795, global_step=74115, preemption_count=0, score=29033.705795, test/accuracy=0.536700, test/loss=2.084592, test/num_examples=10000, total_duration=31013.541747, train/accuracy=0.718594, train/loss=1.153083, validation/accuracy=0.658100, validation/loss=1.423910, validation/num_examples=50000
I0315 10:48:33.294254 139540685625088 logging_writer.py:48] [74500] global_step=74500, grad_norm=2.1182518005371094, loss=2.3182499408721924
I0315 10:51:48.943432 139540534654720 logging_writer.py:48] [75000] global_step=75000, grad_norm=1.9952260255813599, loss=1.9336379766464233
I0315 10:53:02.611645 139734377899840 spec.py:321] Evaluating on the training split.
I0315 10:53:15.681460 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 10:53:28.028776 139734377899840 spec.py:349] Evaluating on the test split.
I0315 10:53:30.726490 139734377899840 submission_runner.py:420] Time since start: 31461.95s, 	Step: 75190, 	{'train/accuracy': 0.73499995470047, 'train/loss': 1.0665316581726074, 'validation/accuracy': 0.6581599712371826, 'validation/loss': 1.401633381843567, 'validation/num_examples': 50000, 'test/accuracy': 0.5357000231742859, 'test/loss': 2.072315216064453, 'test/num_examples': 10000, 'score': 29453.931671142578, 'total_duration': 31461.95157265663, 'accumulated_submission_time': 29453.931671142578, 'accumulated_eval_time': 2003.3064270019531, 'accumulated_logging_time': 2.0511093139648438}
I0315 10:53:30.746807 139540685625088 logging_writer.py:48] [75190] accumulated_eval_time=2003.306427, accumulated_logging_time=2.051109, accumulated_submission_time=29453.931671, global_step=75190, preemption_count=0, score=29453.931671, test/accuracy=0.535700, test/loss=2.072315, test/num_examples=10000, total_duration=31461.951573, train/accuracy=0.735000, train/loss=1.066532, validation/accuracy=0.658160, validation/loss=1.401633, validation/num_examples=50000
I0315 10:55:32.441586 139540534654720 logging_writer.py:48] [75500] global_step=75500, grad_norm=1.970231533050537, loss=1.9952510595321655
I0315 10:58:48.061022 139540685625088 logging_writer.py:48] [76000] global_step=76000, grad_norm=1.7505638599395752, loss=4.470146179199219
I0315 11:00:31.013496 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:00:44.086286 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:00:56.426104 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:00:59.126361 139734377899840 submission_runner.py:420] Time since start: 31910.35s, 	Step: 76265, 	{'train/accuracy': 0.7275781035423279, 'train/loss': 1.0782517194747925, 'validation/accuracy': 0.6630600094795227, 'validation/loss': 1.3828036785125732, 'validation/num_examples': 50000, 'test/accuracy': 0.5392000079154968, 'test/loss': 2.038666009902954, 'test/num_examples': 10000, 'score': 29874.151214122772, 'total_duration': 31910.35142183304, 'accumulated_submission_time': 29874.151214122772, 'accumulated_eval_time': 2031.419240951538, 'accumulated_logging_time': 2.080518960952759}
I0315 11:00:59.149172 139540534654720 logging_writer.py:48] [76265] accumulated_eval_time=2031.419241, accumulated_logging_time=2.080519, accumulated_submission_time=29874.151214, global_step=76265, preemption_count=0, score=29874.151214, test/accuracy=0.539200, test/loss=2.038666, test/num_examples=10000, total_duration=31910.351422, train/accuracy=0.727578, train/loss=1.078252, validation/accuracy=0.663060, validation/loss=1.382804, validation/num_examples=50000
I0315 11:02:31.418456 139540685625088 logging_writer.py:48] [76500] global_step=76500, grad_norm=1.9645452499389648, loss=2.7976303100585938
I0315 11:05:47.019427 139540534654720 logging_writer.py:48] [77000] global_step=77000, grad_norm=1.8392361402511597, loss=4.446662425994873
I0315 11:07:59.349868 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:08:12.438809 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:08:24.758404 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:08:27.448910 139734377899840 submission_runner.py:420] Time since start: 32358.67s, 	Step: 77340, 	{'train/accuracy': 0.7515038847923279, 'train/loss': 1.0078914165496826, 'validation/accuracy': 0.6642400026321411, 'validation/loss': 1.3859093189239502, 'validation/num_examples': 50000, 'test/accuracy': 0.5437999963760376, 'test/loss': 2.0266125202178955, 'test/num_examples': 10000, 'score': 30294.305116415024, 'total_duration': 32358.673986196518, 'accumulated_submission_time': 30294.305116415024, 'accumulated_eval_time': 2059.518256664276, 'accumulated_logging_time': 2.112673282623291}
I0315 11:08:27.470227 139540685625088 logging_writer.py:48] [77340] accumulated_eval_time=2059.518257, accumulated_logging_time=2.112673, accumulated_submission_time=30294.305116, global_step=77340, preemption_count=0, score=30294.305116, test/accuracy=0.543800, test/loss=2.026613, test/num_examples=10000, total_duration=32358.673986, train/accuracy=0.751504, train/loss=1.007891, validation/accuracy=0.664240, validation/loss=1.385909, validation/num_examples=50000
I0315 11:09:30.464573 139540534654720 logging_writer.py:48] [77500] global_step=77500, grad_norm=1.9651068449020386, loss=2.2458243370056152
I0315 11:12:46.011191 139540685625088 logging_writer.py:48] [78000] global_step=78000, grad_norm=1.7088075876235962, loss=3.9728260040283203
I0315 11:15:27.614994 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:15:40.685959 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:15:53.051930 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:15:55.735324 139734377899840 submission_runner.py:420] Time since start: 32806.96s, 	Step: 78415, 	{'train/accuracy': 0.7408398389816284, 'train/loss': 1.038232445716858, 'validation/accuracy': 0.6656799912452698, 'validation/loss': 1.3740336894989014, 'validation/num_examples': 50000, 'test/accuracy': 0.5434000492095947, 'test/loss': 2.0228612422943115, 'test/num_examples': 10000, 'score': 30714.403047323227, 'total_duration': 32806.960404872894, 'accumulated_submission_time': 30714.403047323227, 'accumulated_eval_time': 2087.6385633945465, 'accumulated_logging_time': 2.1429443359375}
I0315 11:15:55.758871 139540534654720 logging_writer.py:48] [78415] accumulated_eval_time=2087.638563, accumulated_logging_time=2.142944, accumulated_submission_time=30714.403047, global_step=78415, preemption_count=0, score=30714.403047, test/accuracy=0.543400, test/loss=2.022861, test/num_examples=10000, total_duration=32806.960405, train/accuracy=0.740840, train/loss=1.038232, validation/accuracy=0.665680, validation/loss=1.374034, validation/num_examples=50000
I0315 11:16:29.390063 139540685625088 logging_writer.py:48] [78500] global_step=78500, grad_norm=1.8195699453353882, loss=4.043926239013672
I0315 11:19:44.948576 139540534654720 logging_writer.py:48] [79000] global_step=79000, grad_norm=2.0189881324768066, loss=2.1694984436035156
I0315 11:22:55.884772 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:23:08.936339 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:23:21.291932 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:23:23.984113 139734377899840 submission_runner.py:420] Time since start: 33255.21s, 	Step: 79490, 	{'train/accuracy': 0.7354687452316284, 'train/loss': 1.049497365951538, 'validation/accuracy': 0.670740008354187, 'validation/loss': 1.3522273302078247, 'validation/num_examples': 50000, 'test/accuracy': 0.5480000376701355, 'test/loss': 2.012040138244629, 'test/num_examples': 10000, 'score': 31134.480865716934, 'total_duration': 33255.20918631554, 'accumulated_submission_time': 31134.480865716934, 'accumulated_eval_time': 2115.737879514694, 'accumulated_logging_time': 2.1758697032928467}
I0315 11:23:24.007157 139540685625088 logging_writer.py:48] [79490] accumulated_eval_time=2115.737880, accumulated_logging_time=2.175870, accumulated_submission_time=31134.480866, global_step=79490, preemption_count=0, score=31134.480866, test/accuracy=0.548000, test/loss=2.012040, test/num_examples=10000, total_duration=33255.209186, train/accuracy=0.735469, train/loss=1.049497, validation/accuracy=0.670740, validation/loss=1.352227, validation/num_examples=50000
I0315 11:23:28.315978 139540534654720 logging_writer.py:48] [79500] global_step=79500, grad_norm=1.9928314685821533, loss=2.8059160709381104
I0315 11:26:43.823597 139540685625088 logging_writer.py:48] [80000] global_step=80000, grad_norm=2.3267910480499268, loss=2.2928273677825928
I0315 11:29:59.454723 139540534654720 logging_writer.py:48] [80500] global_step=80500, grad_norm=2.0077548027038574, loss=2.2346010208129883
I0315 11:30:24.205477 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:30:37.250298 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:30:49.579511 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:30:52.273410 139734377899840 submission_runner.py:420] Time since start: 33703.50s, 	Step: 80565, 	{'train/accuracy': 0.7537304759025574, 'train/loss': 0.968858003616333, 'validation/accuracy': 0.6736599802970886, 'validation/loss': 1.3394980430603027, 'validation/num_examples': 50000, 'test/accuracy': 0.5462000370025635, 'test/loss': 2.016737699508667, 'test/num_examples': 10000, 'score': 31554.630586624146, 'total_duration': 33703.49849128723, 'accumulated_submission_time': 31554.630586624146, 'accumulated_eval_time': 2143.805784225464, 'accumulated_logging_time': 2.209275960922241}
I0315 11:30:52.295350 139540685625088 logging_writer.py:48] [80565] accumulated_eval_time=2143.805784, accumulated_logging_time=2.209276, accumulated_submission_time=31554.630587, global_step=80565, preemption_count=0, score=31554.630587, test/accuracy=0.546200, test/loss=2.016738, test/num_examples=10000, total_duration=33703.498491, train/accuracy=0.753730, train/loss=0.968858, validation/accuracy=0.673660, validation/loss=1.339498, validation/num_examples=50000
I0315 11:33:42.867329 139540534654720 logging_writer.py:48] [81000] global_step=81000, grad_norm=2.162461042404175, loss=1.9947445392608643
I0315 11:36:58.444991 139540685625088 logging_writer.py:48] [81500] global_step=81500, grad_norm=2.1374101638793945, loss=2.0753581523895264
I0315 11:37:52.511208 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:38:05.654211 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:38:17.957998 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:38:20.646417 139734377899840 submission_runner.py:420] Time since start: 34151.87s, 	Step: 81640, 	{'train/accuracy': 0.7430273294448853, 'train/loss': 1.0334614515304565, 'validation/accuracy': 0.6747599840164185, 'validation/loss': 1.3455369472503662, 'validation/num_examples': 50000, 'test/accuracy': 0.5516000390052795, 'test/loss': 2.020983934402466, 'test/num_examples': 10000, 'score': 31974.79904460907, 'total_duration': 34151.871500492096, 'accumulated_submission_time': 31974.79904460907, 'accumulated_eval_time': 2171.9409697055817, 'accumulated_logging_time': 2.240649700164795}
I0315 11:38:20.669453 139540534654720 logging_writer.py:48] [81640] accumulated_eval_time=2171.940970, accumulated_logging_time=2.240650, accumulated_submission_time=31974.799045, global_step=81640, preemption_count=0, score=31974.799045, test/accuracy=0.551600, test/loss=2.020984, test/num_examples=10000, total_duration=34151.871500, train/accuracy=0.743027, train/loss=1.033461, validation/accuracy=0.674760, validation/loss=1.345537, validation/num_examples=50000
I0315 11:40:41.821389 139540685625088 logging_writer.py:48] [82000] global_step=82000, grad_norm=2.1841073036193848, loss=2.115363597869873
I0315 11:43:57.409660 139540534654720 logging_writer.py:48] [82500] global_step=82500, grad_norm=2.1414616107940674, loss=2.0831820964813232
I0315 11:45:20.798647 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:45:33.986392 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:45:46.322785 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:45:49.019120 139734377899840 submission_runner.py:420] Time since start: 34600.24s, 	Step: 82715, 	{'train/accuracy': 0.7436132431030273, 'train/loss': 1.012618899345398, 'validation/accuracy': 0.6788199543952942, 'validation/loss': 1.3165409564971924, 'validation/num_examples': 50000, 'test/accuracy': 0.5558000206947327, 'test/loss': 1.9720288515090942, 'test/num_examples': 10000, 'score': 32394.88243317604, 'total_duration': 34600.244175195694, 'accumulated_submission_time': 32394.88243317604, 'accumulated_eval_time': 2200.1613948345184, 'accumulated_logging_time': 2.2722578048706055}
I0315 11:45:49.041745 139540685625088 logging_writer.py:48] [82715] accumulated_eval_time=2200.161395, accumulated_logging_time=2.272258, accumulated_submission_time=32394.882433, global_step=82715, preemption_count=0, score=32394.882433, test/accuracy=0.555800, test/loss=1.972029, test/num_examples=10000, total_duration=34600.244175, train/accuracy=0.743613, train/loss=1.012619, validation/accuracy=0.678820, validation/loss=1.316541, validation/num_examples=50000
I0315 11:47:40.884818 139540534654720 logging_writer.py:48] [83000] global_step=83000, grad_norm=2.2904677391052246, loss=2.119671106338501
I0315 11:50:56.464111 139540685625088 logging_writer.py:48] [83500] global_step=83500, grad_norm=1.8490443229675293, loss=3.1190223693847656
I0315 11:52:49.181871 139734377899840 spec.py:321] Evaluating on the training split.
I0315 11:53:02.339506 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 11:53:14.701555 139734377899840 spec.py:349] Evaluating on the test split.
I0315 11:53:17.396188 139734377899840 submission_runner.py:420] Time since start: 35048.62s, 	Step: 83790, 	{'train/accuracy': 0.7532812356948853, 'train/loss': 0.9784535765647888, 'validation/accuracy': 0.6780200004577637, 'validation/loss': 1.3134093284606934, 'validation/num_examples': 50000, 'test/accuracy': 0.5522000193595886, 'test/loss': 1.9623016119003296, 'test/num_examples': 10000, 'score': 32814.973824739456, 'total_duration': 35048.62127113342, 'accumulated_submission_time': 32814.973824739456, 'accumulated_eval_time': 2228.3756980895996, 'accumulated_logging_time': 2.3050167560577393}
I0315 11:53:17.419357 139540534654720 logging_writer.py:48] [83790] accumulated_eval_time=2228.375698, accumulated_logging_time=2.305017, accumulated_submission_time=32814.973825, global_step=83790, preemption_count=0, score=32814.973825, test/accuracy=0.552200, test/loss=1.962302, test/num_examples=10000, total_duration=35048.621271, train/accuracy=0.753281, train/loss=0.978454, validation/accuracy=0.678020, validation/loss=1.313409, validation/num_examples=50000
I0315 11:54:39.891397 139540685625088 logging_writer.py:48] [84000] global_step=84000, grad_norm=2.033085346221924, loss=2.4655587673187256
I0315 11:57:55.499103 139540534654720 logging_writer.py:48] [84500] global_step=84500, grad_norm=1.8120583295822144, loss=3.095214366912842
I0315 12:00:17.547091 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:00:30.734407 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:00:43.091084 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:00:45.783853 139734377899840 submission_runner.py:420] Time since start: 35497.01s, 	Step: 84865, 	{'train/accuracy': 0.7472265362739563, 'train/loss': 0.986632764339447, 'validation/accuracy': 0.6819999814033508, 'validation/loss': 1.2906161546707153, 'validation/num_examples': 50000, 'test/accuracy': 0.5617000460624695, 'test/loss': 1.9442942142486572, 'test/num_examples': 10000, 'score': 33235.05148816109, 'total_duration': 35497.008912324905, 'accumulated_submission_time': 33235.05148816109, 'accumulated_eval_time': 2256.6124222278595, 'accumulated_logging_time': 2.3405017852783203}
I0315 12:00:45.807794 139540685625088 logging_writer.py:48] [84865] accumulated_eval_time=2256.612422, accumulated_logging_time=2.340502, accumulated_submission_time=33235.051488, global_step=84865, preemption_count=0, score=33235.051488, test/accuracy=0.561700, test/loss=1.944294, test/num_examples=10000, total_duration=35497.008912, train/accuracy=0.747227, train/loss=0.986633, validation/accuracy=0.682000, validation/loss=1.290616, validation/num_examples=50000
I0315 12:01:39.030200 139540534654720 logging_writer.py:48] [85000] global_step=85000, grad_norm=2.1123902797698975, loss=2.11015248298645
I0315 12:04:54.611906 139540685625088 logging_writer.py:48] [85500] global_step=85500, grad_norm=2.268723964691162, loss=1.9574966430664062
I0315 12:07:46.023353 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:07:59.184894 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:08:11.534789 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:08:14.227384 139734377899840 submission_runner.py:420] Time since start: 35945.45s, 	Step: 85940, 	{'train/accuracy': 0.768261730670929, 'train/loss': 0.9165685176849365, 'validation/accuracy': 0.6836599707603455, 'validation/loss': 1.292286992073059, 'validation/num_examples': 50000, 'test/accuracy': 0.5562000274658203, 'test/loss': 1.9705924987792969, 'test/num_examples': 10000, 'score': 33655.21841049194, 'total_duration': 35945.45246839523, 'accumulated_submission_time': 33655.21841049194, 'accumulated_eval_time': 2284.816447019577, 'accumulated_logging_time': 2.3753788471221924}
I0315 12:08:14.251601 139540534654720 logging_writer.py:48] [85940] accumulated_eval_time=2284.816447, accumulated_logging_time=2.375379, accumulated_submission_time=33655.218410, global_step=85940, preemption_count=0, score=33655.218410, test/accuracy=0.556200, test/loss=1.970592, test/num_examples=10000, total_duration=35945.452468, train/accuracy=0.768262, train/loss=0.916569, validation/accuracy=0.683660, validation/loss=1.292287, validation/num_examples=50000
I0315 12:08:38.096583 139540685625088 logging_writer.py:48] [86000] global_step=86000, grad_norm=1.878839135169983, loss=4.454165935516357
I0315 12:11:53.600987 139540534654720 logging_writer.py:48] [86500] global_step=86500, grad_norm=2.3431217670440674, loss=2.468571662902832
I0315 12:15:09.115748 139540685625088 logging_writer.py:48] [87000] global_step=87000, grad_norm=2.4182822704315186, loss=2.06598162651062
I0315 12:15:14.289875 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:15:27.434412 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:15:41.498023 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:15:44.193382 139734377899840 submission_runner.py:420] Time since start: 36395.42s, 	Step: 87015, 	{'train/accuracy': 0.7613476514816284, 'train/loss': 0.9502003788948059, 'validation/accuracy': 0.685759961605072, 'validation/loss': 1.2923638820648193, 'validation/num_examples': 50000, 'test/accuracy': 0.5633000135421753, 'test/loss': 1.9323105812072754, 'test/num_examples': 10000, 'score': 34075.2073597908, 'total_duration': 36395.41846227646, 'accumulated_submission_time': 34075.2073597908, 'accumulated_eval_time': 2314.7199215888977, 'accumulated_logging_time': 2.409738779067993}
I0315 12:15:44.216125 139540534654720 logging_writer.py:48] [87015] accumulated_eval_time=2314.719922, accumulated_logging_time=2.409739, accumulated_submission_time=34075.207360, global_step=87015, preemption_count=0, score=34075.207360, test/accuracy=0.563300, test/loss=1.932311, test/num_examples=10000, total_duration=36395.418462, train/accuracy=0.761348, train/loss=0.950200, validation/accuracy=0.685760, validation/loss=1.292364, validation/num_examples=50000
I0315 12:18:54.188778 139540685625088 logging_writer.py:48] [87500] global_step=87500, grad_norm=1.9268519878387451, loss=3.8058714866638184
I0315 12:22:09.804124 139540534654720 logging_writer.py:48] [88000] global_step=88000, grad_norm=2.342160224914551, loss=1.935347080230713
I0315 12:22:44.309604 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:22:57.435012 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:23:09.864274 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:23:12.563724 139734377899840 submission_runner.py:420] Time since start: 36843.79s, 	Step: 88090, 	{'train/accuracy': 0.7571093440055847, 'train/loss': 0.9640190601348877, 'validation/accuracy': 0.6872400045394897, 'validation/loss': 1.2790004014968872, 'validation/num_examples': 50000, 'test/accuracy': 0.5615000128746033, 'test/loss': 1.9326801300048828, 'test/num_examples': 10000, 'score': 34495.25335025787, 'total_duration': 36843.78880548477, 'accumulated_submission_time': 34495.25335025787, 'accumulated_eval_time': 2342.9740138053894, 'accumulated_logging_time': 2.4409990310668945}
I0315 12:23:12.584240 139540685625088 logging_writer.py:48] [88090] accumulated_eval_time=2342.974014, accumulated_logging_time=2.440999, accumulated_submission_time=34495.253350, global_step=88090, preemption_count=0, score=34495.253350, test/accuracy=0.561500, test/loss=1.932680, test/num_examples=10000, total_duration=36843.788805, train/accuracy=0.757109, train/loss=0.964019, validation/accuracy=0.687240, validation/loss=1.279000, validation/num_examples=50000
I0315 12:25:53.401557 139540534654720 logging_writer.py:48] [88500] global_step=88500, grad_norm=2.2756447792053223, loss=1.8109500408172607
I0315 12:29:09.008167 139540685625088 logging_writer.py:48] [89000] global_step=89000, grad_norm=2.2121455669403076, loss=1.7675939798355103
I0315 12:30:12.874030 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:30:25.958670 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:30:38.535416 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:30:41.218199 139734377899840 submission_runner.py:420] Time since start: 37292.44s, 	Step: 89165, 	{'train/accuracy': 0.7727734446525574, 'train/loss': 0.8953768610954285, 'validation/accuracy': 0.689079999923706, 'validation/loss': 1.2544082403182983, 'validation/num_examples': 50000, 'test/accuracy': 0.5685000419616699, 'test/loss': 1.909213900566101, 'test/num_examples': 10000, 'score': 34915.496957063675, 'total_duration': 37292.44328331947, 'accumulated_submission_time': 34915.496957063675, 'accumulated_eval_time': 2371.3181595802307, 'accumulated_logging_time': 2.4699888229370117}
I0315 12:30:41.239871 139540534654720 logging_writer.py:48] [89165] accumulated_eval_time=2371.318160, accumulated_logging_time=2.469989, accumulated_submission_time=34915.496957, global_step=89165, preemption_count=0, score=34915.496957, test/accuracy=0.568500, test/loss=1.909214, test/num_examples=10000, total_duration=37292.443283, train/accuracy=0.772773, train/loss=0.895377, validation/accuracy=0.689080, validation/loss=1.254408, validation/num_examples=50000
I0315 12:32:52.612675 139540685625088 logging_writer.py:48] [89500] global_step=89500, grad_norm=2.2986769676208496, loss=2.521228790283203
I0315 12:36:08.189936 139540534654720 logging_writer.py:48] [90000] global_step=90000, grad_norm=2.1605207920074463, loss=4.263850212097168
I0315 12:37:41.391041 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:37:54.461577 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:38:06.868428 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:38:09.567604 139734377899840 submission_runner.py:420] Time since start: 37740.79s, 	Step: 90240, 	{'train/accuracy': 0.7667773365974426, 'train/loss': 0.9181344509124756, 'validation/accuracy': 0.6922000050544739, 'validation/loss': 1.2458761930465698, 'validation/num_examples': 50000, 'test/accuracy': 0.5687000155448914, 'test/loss': 1.8983409404754639, 'test/num_examples': 10000, 'score': 35335.60144639015, 'total_duration': 37740.7926864624, 'accumulated_submission_time': 35335.60144639015, 'accumulated_eval_time': 2399.4947125911713, 'accumulated_logging_time': 2.500380516052246}
I0315 12:38:09.590948 139540685625088 logging_writer.py:48] [90240] accumulated_eval_time=2399.494713, accumulated_logging_time=2.500381, accumulated_submission_time=35335.601446, global_step=90240, preemption_count=0, score=35335.601446, test/accuracy=0.568700, test/loss=1.898341, test/num_examples=10000, total_duration=37740.792686, train/accuracy=0.766777, train/loss=0.918134, validation/accuracy=0.692200, validation/loss=1.245876, validation/num_examples=50000
I0315 12:39:51.690495 139540534654720 logging_writer.py:48] [90500] global_step=90500, grad_norm=2.0721065998077393, loss=2.1781389713287354
I0315 12:43:07.260440 139540685625088 logging_writer.py:48] [91000] global_step=91000, grad_norm=2.2647581100463867, loss=1.788375973701477
I0315 12:45:09.794485 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:45:22.871666 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:45:35.237119 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:45:37.927075 139734377899840 submission_runner.py:420] Time since start: 38189.15s, 	Step: 91315, 	{'train/accuracy': 0.788769543170929, 'train/loss': 0.8331679105758667, 'validation/accuracy': 0.6962999701499939, 'validation/loss': 1.23737370967865, 'validation/num_examples': 50000, 'test/accuracy': 0.5683000087738037, 'test/loss': 1.8899977207183838, 'test/num_examples': 10000, 'score': 35755.758419275284, 'total_duration': 38189.15215921402, 'accumulated_submission_time': 35755.758419275284, 'accumulated_eval_time': 2427.627291202545, 'accumulated_logging_time': 2.53277850151062}
I0315 12:45:37.951703 139540534654720 logging_writer.py:48] [91315] accumulated_eval_time=2427.627291, accumulated_logging_time=2.532779, accumulated_submission_time=35755.758419, global_step=91315, preemption_count=0, score=35755.758419, test/accuracy=0.568300, test/loss=1.889998, test/num_examples=10000, total_duration=38189.152159, train/accuracy=0.788770, train/loss=0.833168, validation/accuracy=0.696300, validation/loss=1.237374, validation/num_examples=50000
I0315 12:46:50.661931 139540685625088 logging_writer.py:48] [91500] global_step=91500, grad_norm=2.338467597961426, loss=1.735182285308838
I0315 12:50:06.225221 139540534654720 logging_writer.py:48] [92000] global_step=92000, grad_norm=2.3846747875213623, loss=2.585301399230957
I0315 12:52:38.069486 139734377899840 spec.py:321] Evaluating on the training split.
I0315 12:52:51.141803 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 12:53:03.521258 139734377899840 spec.py:349] Evaluating on the test split.
I0315 12:53:06.222351 139734377899840 submission_runner.py:420] Time since start: 38637.45s, 	Step: 92390, 	{'train/accuracy': 0.7783203125, 'train/loss': 0.8806977868080139, 'validation/accuracy': 0.6991999745368958, 'validation/loss': 1.2235431671142578, 'validation/num_examples': 50000, 'test/accuracy': 0.5734000205993652, 'test/loss': 1.8830280303955078, 'test/num_examples': 10000, 'score': 36175.828775405884, 'total_duration': 38637.4474298954, 'accumulated_submission_time': 36175.828775405884, 'accumulated_eval_time': 2455.7801399230957, 'accumulated_logging_time': 2.567004919052124}
I0315 12:53:06.243835 139540685625088 logging_writer.py:48] [92390] accumulated_eval_time=2455.780140, accumulated_logging_time=2.567005, accumulated_submission_time=36175.828775, global_step=92390, preemption_count=0, score=36175.828775, test/accuracy=0.573400, test/loss=1.883028, test/num_examples=10000, total_duration=38637.447430, train/accuracy=0.778320, train/loss=0.880698, validation/accuracy=0.699200, validation/loss=1.223543, validation/num_examples=50000
I0315 12:53:49.667892 139540534654720 logging_writer.py:48] [92500] global_step=92500, grad_norm=2.6753976345062256, loss=1.8823250532150269
I0315 12:57:05.267602 139540685625088 logging_writer.py:48] [93000] global_step=93000, grad_norm=2.2137763500213623, loss=3.4363534450531006
I0315 13:00:06.455387 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:00:19.541016 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:00:31.892484 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:00:34.583330 139734377899840 submission_runner.py:420] Time since start: 39085.81s, 	Step: 93465, 	{'train/accuracy': 0.7736523151397705, 'train/loss': 0.8952926397323608, 'validation/accuracy': 0.7000199556350708, 'validation/loss': 1.2245689630508423, 'validation/num_examples': 50000, 'test/accuracy': 0.5726000070571899, 'test/loss': 1.8683141469955444, 'test/num_examples': 10000, 'score': 36595.99108958244, 'total_duration': 39085.80840730667, 'accumulated_submission_time': 36595.99108958244, 'accumulated_eval_time': 2483.908063173294, 'accumulated_logging_time': 2.5983927249908447}
I0315 13:00:34.608245 139540534654720 logging_writer.py:48] [93465] accumulated_eval_time=2483.908063, accumulated_logging_time=2.598393, accumulated_submission_time=36595.991090, global_step=93465, preemption_count=0, score=36595.991090, test/accuracy=0.572600, test/loss=1.868314, test/num_examples=10000, total_duration=39085.808407, train/accuracy=0.773652, train/loss=0.895293, validation/accuracy=0.700020, validation/loss=1.224569, validation/num_examples=50000
I0315 13:00:48.688006 139540685625088 logging_writer.py:48] [93500] global_step=93500, grad_norm=2.437025308609009, loss=1.8077930212020874
I0315 13:04:04.172551 139540534654720 logging_writer.py:48] [94000] global_step=94000, grad_norm=2.005906820297241, loss=3.1678667068481445
I0315 13:07:19.721531 139540685625088 logging_writer.py:48] [94500] global_step=94500, grad_norm=2.2428297996520996, loss=1.7542895078659058
I0315 13:07:34.667874 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:07:47.746520 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:08:00.082627 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:08:02.774713 139734377899840 submission_runner.py:420] Time since start: 39534.00s, 	Step: 94540, 	{'train/accuracy': 0.7881054282188416, 'train/loss': 0.8393813371658325, 'validation/accuracy': 0.7005599737167358, 'validation/loss': 1.224228858947754, 'validation/num_examples': 50000, 'test/accuracy': 0.5746000409126282, 'test/loss': 1.872279405593872, 'test/num_examples': 10000, 'score': 37016.00253248215, 'total_duration': 39533.99979662895, 'accumulated_submission_time': 37016.00253248215, 'accumulated_eval_time': 2512.0148735046387, 'accumulated_logging_time': 2.6337575912475586}
I0315 13:08:02.795605 139540534654720 logging_writer.py:48] [94540] accumulated_eval_time=2512.014874, accumulated_logging_time=2.633758, accumulated_submission_time=37016.002532, global_step=94540, preemption_count=0, score=37016.002532, test/accuracy=0.574600, test/loss=1.872279, test/num_examples=10000, total_duration=39533.999797, train/accuracy=0.788105, train/loss=0.839381, validation/accuracy=0.700560, validation/loss=1.224229, validation/num_examples=50000
I0315 13:11:03.141260 139540685625088 logging_writer.py:48] [95000] global_step=95000, grad_norm=2.1865718364715576, loss=2.882833480834961
I0315 13:14:18.724000 139540534654720 logging_writer.py:48] [95500] global_step=95500, grad_norm=2.3646397590637207, loss=3.52093768119812
I0315 13:15:03.023432 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:15:16.087217 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:15:28.396419 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:15:31.085094 139734377899840 submission_runner.py:420] Time since start: 39982.31s, 	Step: 95615, 	{'train/accuracy': 0.779980480670929, 'train/loss': 0.8606881499290466, 'validation/accuracy': 0.7037400007247925, 'validation/loss': 1.2031241655349731, 'validation/num_examples': 50000, 'test/accuracy': 0.5786000490188599, 'test/loss': 1.8535703420639038, 'test/num_examples': 10000, 'score': 37436.18379282951, 'total_duration': 39982.31017231941, 'accumulated_submission_time': 37436.18379282951, 'accumulated_eval_time': 2540.0765228271484, 'accumulated_logging_time': 2.662832260131836}
I0315 13:15:31.108135 139540685625088 logging_writer.py:48] [95615] accumulated_eval_time=2540.076523, accumulated_logging_time=2.662832, accumulated_submission_time=37436.183793, global_step=95615, preemption_count=0, score=37436.183793, test/accuracy=0.578600, test/loss=1.853570, test/num_examples=10000, total_duration=39982.310172, train/accuracy=0.779980, train/loss=0.860688, validation/accuracy=0.703740, validation/loss=1.203124, validation/num_examples=50000
I0315 13:18:02.109431 139540534654720 logging_writer.py:48] [96000] global_step=96000, grad_norm=2.2485511302948, loss=3.3529717922210693
I0315 13:21:17.713847 139540685625088 logging_writer.py:48] [96500] global_step=96500, grad_norm=2.651890277862549, loss=2.149139881134033
I0315 13:22:31.334000 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:22:44.441258 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:22:56.788006 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:22:59.480104 139734377899840 submission_runner.py:420] Time since start: 40430.71s, 	Step: 96690, 	{'train/accuracy': 0.8011913895606995, 'train/loss': 0.7849521636962891, 'validation/accuracy': 0.7037599682807922, 'validation/loss': 1.210679054260254, 'validation/num_examples': 50000, 'test/accuracy': 0.5795000195503235, 'test/loss': 1.8425003290176392, 'test/num_examples': 10000, 'score': 37856.362481832504, 'total_duration': 40430.70518541336, 'accumulated_submission_time': 37856.362481832504, 'accumulated_eval_time': 2568.2226095199585, 'accumulated_logging_time': 2.6945512294769287}
I0315 13:22:59.502130 139540534654720 logging_writer.py:48] [96690] accumulated_eval_time=2568.222610, accumulated_logging_time=2.694551, accumulated_submission_time=37856.362482, global_step=96690, preemption_count=0, score=37856.362482, test/accuracy=0.579500, test/loss=1.842500, test/num_examples=10000, total_duration=40430.705185, train/accuracy=0.801191, train/loss=0.784952, validation/accuracy=0.703760, validation/loss=1.210679, validation/num_examples=50000
I0315 13:25:01.083165 139540685625088 logging_writer.py:48] [97000] global_step=97000, grad_norm=2.4074292182922363, loss=1.9484601020812988
I0315 13:28:16.665062 139540534654720 logging_writer.py:48] [97500] global_step=97500, grad_norm=2.681079387664795, loss=1.6764812469482422
I0315 13:29:59.651673 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:30:12.735521 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:30:25.303828 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:30:27.986276 139734377899840 submission_runner.py:420] Time since start: 40879.21s, 	Step: 97765, 	{'train/accuracy': 0.7937109470367432, 'train/loss': 0.8023425340652466, 'validation/accuracy': 0.7086799740791321, 'validation/loss': 1.1761871576309204, 'validation/num_examples': 50000, 'test/accuracy': 0.5842000246047974, 'test/loss': 1.8237043619155884, 'test/num_examples': 10000, 'score': 38276.46438193321, 'total_duration': 40879.211352586746, 'accumulated_submission_time': 38276.46438193321, 'accumulated_eval_time': 2596.557202100754, 'accumulated_logging_time': 2.726055145263672}
I0315 13:30:28.011492 139540685625088 logging_writer.py:48] [97765] accumulated_eval_time=2596.557202, accumulated_logging_time=2.726055, accumulated_submission_time=38276.464382, global_step=97765, preemption_count=0, score=38276.464382, test/accuracy=0.584200, test/loss=1.823704, test/num_examples=10000, total_duration=40879.211353, train/accuracy=0.793711, train/loss=0.802343, validation/accuracy=0.708680, validation/loss=1.176187, validation/num_examples=50000
I0315 13:32:00.250788 139540534654720 logging_writer.py:48] [98000] global_step=98000, grad_norm=2.415759801864624, loss=1.7645294666290283
I0315 13:35:15.799371 139540685625088 logging_writer.py:48] [98500] global_step=98500, grad_norm=2.7842586040496826, loss=1.7201510667800903
I0315 13:37:28.079548 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:37:41.162291 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:37:53.503720 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:37:56.197382 139734377899840 submission_runner.py:420] Time since start: 41327.42s, 	Step: 98840, 	{'train/accuracy': 0.79066401720047, 'train/loss': 0.8122550249099731, 'validation/accuracy': 0.7108799815177917, 'validation/loss': 1.1668226718902588, 'validation/num_examples': 50000, 'test/accuracy': 0.5883000493049622, 'test/loss': 1.8044285774230957, 'test/num_examples': 10000, 'score': 38696.48484325409, 'total_duration': 41327.42246246338, 'accumulated_submission_time': 38696.48484325409, 'accumulated_eval_time': 2624.675024986267, 'accumulated_logging_time': 2.7614381313323975}
I0315 13:37:56.220529 139540534654720 logging_writer.py:48] [98840] accumulated_eval_time=2624.675025, accumulated_logging_time=2.761438, accumulated_submission_time=38696.484843, global_step=98840, preemption_count=0, score=38696.484843, test/accuracy=0.588300, test/loss=1.804429, test/num_examples=10000, total_duration=41327.422462, train/accuracy=0.790664, train/loss=0.812255, validation/accuracy=0.710880, validation/loss=1.166823, validation/num_examples=50000
I0315 13:38:59.134726 139540685625088 logging_writer.py:48] [99000] global_step=99000, grad_norm=2.6855621337890625, loss=1.69788658618927
I0315 13:42:14.713523 139540534654720 logging_writer.py:48] [99500] global_step=99500, grad_norm=2.5955920219421387, loss=3.9405019283294678
I0315 13:44:56.206992 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:45:08.994327 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:45:21.338152 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:45:24.034769 139734377899840 submission_runner.py:420] Time since start: 41775.26s, 	Step: 99914, 	{'train/accuracy': 0.8043749928474426, 'train/loss': 0.7756077647209167, 'validation/accuracy': 0.7114999890327454, 'validation/loss': 1.1701703071594238, 'validation/num_examples': 50000, 'test/accuracy': 0.588200032711029, 'test/loss': 1.8171076774597168, 'test/num_examples': 10000, 'score': 39116.42384815216, 'total_duration': 41775.25985169411, 'accumulated_submission_time': 39116.42384815216, 'accumulated_eval_time': 2652.5027623176575, 'accumulated_logging_time': 2.7939517498016357}
I0315 13:45:24.058249 139540685625088 logging_writer.py:48] [99914] accumulated_eval_time=2652.502762, accumulated_logging_time=2.793952, accumulated_submission_time=39116.423848, global_step=99914, preemption_count=0, score=39116.423848, test/accuracy=0.588200, test/loss=1.817108, test/num_examples=10000, total_duration=41775.259852, train/accuracy=0.804375, train/loss=0.775608, validation/accuracy=0.711500, validation/loss=1.170170, validation/num_examples=50000
I0315 13:45:58.049921 139540534654720 logging_writer.py:48] [100000] global_step=100000, grad_norm=2.5761985778808594, loss=1.701474905014038
I0315 13:49:13.549315 139540685625088 logging_writer.py:48] [100500] global_step=100500, grad_norm=2.312760353088379, loss=4.083448886871338
I0315 13:52:24.106673 139734377899840 spec.py:321] Evaluating on the training split.
I0315 13:52:37.231904 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 13:52:49.813020 139734377899840 spec.py:349] Evaluating on the test split.
I0315 13:52:52.506744 139734377899840 submission_runner.py:420] Time since start: 42223.73s, 	Step: 100989, 	{'train/accuracy': 0.7991796731948853, 'train/loss': 0.7734871506690979, 'validation/accuracy': 0.7157599925994873, 'validation/loss': 1.1494746208190918, 'validation/num_examples': 50000, 'test/accuracy': 0.5963000059127808, 'test/loss': 1.785571575164795, 'test/num_examples': 10000, 'score': 39536.42637038231, 'total_duration': 42223.731813430786, 'accumulated_submission_time': 39536.42637038231, 'accumulated_eval_time': 2680.9027936458588, 'accumulated_logging_time': 2.8253557682037354}
I0315 13:52:52.530955 139540534654720 logging_writer.py:48] [100989] accumulated_eval_time=2680.902794, accumulated_logging_time=2.825356, accumulated_submission_time=39536.426370, global_step=100989, preemption_count=0, score=39536.426370, test/accuracy=0.596300, test/loss=1.785572, test/num_examples=10000, total_duration=42223.731813, train/accuracy=0.799180, train/loss=0.773487, validation/accuracy=0.715760, validation/loss=1.149475, validation/num_examples=50000
I0315 13:52:57.236017 139540685625088 logging_writer.py:48] [101000] global_step=101000, grad_norm=3.0033013820648193, loss=1.7194422483444214
I0315 13:56:12.773215 139540534654720 logging_writer.py:48] [101500] global_step=101500, grad_norm=2.4075286388397217, loss=1.7089927196502686
I0315 13:59:28.318088 139540685625088 logging_writer.py:48] [102000] global_step=102000, grad_norm=2.74574613571167, loss=1.7151944637298584
I0315 13:59:52.652287 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:00:05.808230 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:00:18.130465 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:00:20.821442 139734377899840 submission_runner.py:420] Time since start: 42672.05s, 	Step: 102064, 	{'train/accuracy': 0.8037499785423279, 'train/loss': 0.771857738494873, 'validation/accuracy': 0.7140600085258484, 'validation/loss': 1.1566945314407349, 'validation/num_examples': 50000, 'test/accuracy': 0.5914000272750854, 'test/loss': 1.7901370525360107, 'test/num_examples': 10000, 'score': 39956.501178979874, 'total_duration': 42672.04652261734, 'accumulated_submission_time': 39956.501178979874, 'accumulated_eval_time': 2709.0719146728516, 'accumulated_logging_time': 2.8588454723358154}
I0315 14:00:20.844117 139540534654720 logging_writer.py:48] [102064] accumulated_eval_time=2709.071915, accumulated_logging_time=2.858845, accumulated_submission_time=39956.501179, global_step=102064, preemption_count=0, score=39956.501179, test/accuracy=0.591400, test/loss=1.790137, test/num_examples=10000, total_duration=42672.046523, train/accuracy=0.803750, train/loss=0.771858, validation/accuracy=0.714060, validation/loss=1.156695, validation/num_examples=50000
I0315 14:03:11.669187 139540685625088 logging_writer.py:48] [102500] global_step=102500, grad_norm=2.6051323413848877, loss=1.7455406188964844
I0315 14:06:27.198287 139540534654720 logging_writer.py:48] [103000] global_step=103000, grad_norm=2.5129008293151855, loss=1.8220570087432861
I0315 14:07:20.846688 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:07:34.036523 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:07:46.385472 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:07:49.082118 139734377899840 submission_runner.py:420] Time since start: 43120.31s, 	Step: 103139, 	{'train/accuracy': 0.8059374690055847, 'train/loss': 0.7530930638313293, 'validation/accuracy': 0.7147600054740906, 'validation/loss': 1.1442608833312988, 'validation/num_examples': 50000, 'test/accuracy': 0.5913000106811523, 'test/loss': 1.789018988609314, 'test/num_examples': 10000, 'score': 40376.45714855194, 'total_duration': 43120.30718302727, 'accumulated_submission_time': 40376.45714855194, 'accumulated_eval_time': 2737.3073012828827, 'accumulated_logging_time': 2.890319347381592}
I0315 14:07:49.106647 139540685625088 logging_writer.py:48] [103139] accumulated_eval_time=2737.307301, accumulated_logging_time=2.890319, accumulated_submission_time=40376.457149, global_step=103139, preemption_count=0, score=40376.457149, test/accuracy=0.591300, test/loss=1.789019, test/num_examples=10000, total_duration=43120.307183, train/accuracy=0.805937, train/loss=0.753093, validation/accuracy=0.714760, validation/loss=1.144261, validation/num_examples=50000
I0315 14:10:10.703988 139540534654720 logging_writer.py:48] [103500] global_step=103500, grad_norm=2.63657546043396, loss=3.4154856204986572
I0315 14:13:26.262100 139540685625088 logging_writer.py:48] [104000] global_step=104000, grad_norm=2.6479363441467285, loss=1.658296823501587
I0315 14:14:49.245871 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:15:02.425169 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:15:14.793999 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:15:17.493154 139734377899840 submission_runner.py:420] Time since start: 43568.72s, 	Step: 104214, 	{'train/accuracy': 0.8067968487739563, 'train/loss': 0.747651219367981, 'validation/accuracy': 0.72079998254776, 'validation/loss': 1.1287459135055542, 'validation/num_examples': 50000, 'test/accuracy': 0.5952000021934509, 'test/loss': 1.7805838584899902, 'test/num_examples': 10000, 'score': 40796.54728913307, 'total_duration': 43568.718232393265, 'accumulated_submission_time': 40796.54728913307, 'accumulated_eval_time': 2765.554568052292, 'accumulated_logging_time': 2.9242961406707764}
I0315 14:15:17.515608 139540534654720 logging_writer.py:48] [104214] accumulated_eval_time=2765.554568, accumulated_logging_time=2.924296, accumulated_submission_time=40796.547289, global_step=104214, preemption_count=0, score=40796.547289, test/accuracy=0.595200, test/loss=1.780584, test/num_examples=10000, total_duration=43568.718232, train/accuracy=0.806797, train/loss=0.747651, validation/accuracy=0.720800, validation/loss=1.128746, validation/num_examples=50000
I0315 14:17:09.729485 139540685625088 logging_writer.py:48] [104500] global_step=104500, grad_norm=2.581188917160034, loss=3.343242645263672
I0315 14:20:25.304106 139540534654720 logging_writer.py:48] [105000] global_step=105000, grad_norm=2.7981631755828857, loss=4.0786895751953125
I0315 14:22:17.633600 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:22:30.777608 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:22:43.245209 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:22:45.938965 139734377899840 submission_runner.py:420] Time since start: 44017.16s, 	Step: 105289, 	{'train/accuracy': 0.820605456829071, 'train/loss': 0.6992701292037964, 'validation/accuracy': 0.7228999733924866, 'validation/loss': 1.1123130321502686, 'validation/num_examples': 50000, 'test/accuracy': 0.5967000126838684, 'test/loss': 1.759952187538147, 'test/num_examples': 10000, 'score': 41216.61836409569, 'total_duration': 44017.16404867172, 'accumulated_submission_time': 41216.61836409569, 'accumulated_eval_time': 2793.8599157333374, 'accumulated_logging_time': 2.956411838531494}
I0315 14:22:45.960875 139540685625088 logging_writer.py:48] [105289] accumulated_eval_time=2793.859916, accumulated_logging_time=2.956412, accumulated_submission_time=41216.618364, global_step=105289, preemption_count=0, score=41216.618364, test/accuracy=0.596700, test/loss=1.759952, test/num_examples=10000, total_duration=44017.164049, train/accuracy=0.820605, train/loss=0.699270, validation/accuracy=0.722900, validation/loss=1.112313, validation/num_examples=50000
I0315 14:24:08.842672 139540534654720 logging_writer.py:48] [105500] global_step=105500, grad_norm=2.722118854522705, loss=1.8640596866607666
I0315 14:27:24.430506 139540685625088 logging_writer.py:48] [106000] global_step=106000, grad_norm=2.570204019546509, loss=1.5023020505905151
I0315 14:29:46.181458 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:29:59.200742 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:30:11.762943 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:30:14.459124 139734377899840 submission_runner.py:420] Time since start: 44465.68s, 	Step: 106364, 	{'train/accuracy': 0.8125390410423279, 'train/loss': 0.7213648557662964, 'validation/accuracy': 0.7247399687767029, 'validation/loss': 1.1128995418548584, 'validation/num_examples': 50000, 'test/accuracy': 0.5978000164031982, 'test/loss': 1.7560226917266846, 'test/num_examples': 10000, 'score': 41636.791576862335, 'total_duration': 44465.6841981411, 'accumulated_submission_time': 41636.791576862335, 'accumulated_eval_time': 2822.1375629901886, 'accumulated_logging_time': 2.9876561164855957}
I0315 14:30:14.488906 139540534654720 logging_writer.py:48] [106364] accumulated_eval_time=2822.137563, accumulated_logging_time=2.987656, accumulated_submission_time=41636.791577, global_step=106364, preemption_count=0, score=41636.791577, test/accuracy=0.597800, test/loss=1.756023, test/num_examples=10000, total_duration=44465.684198, train/accuracy=0.812539, train/loss=0.721365, validation/accuracy=0.724740, validation/loss=1.112900, validation/num_examples=50000
I0315 14:31:08.013406 139540685625088 logging_writer.py:48] [106500] global_step=106500, grad_norm=3.153458833694458, loss=4.125571250915527
I0315 14:34:23.492550 139540534654720 logging_writer.py:48] [107000] global_step=107000, grad_norm=2.8878695964813232, loss=1.5076252222061157
I0315 14:37:14.506621 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:37:27.521658 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:37:41.318736 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:37:44.008051 139734377899840 submission_runner.py:420] Time since start: 44915.23s, 	Step: 107439, 	{'train/accuracy': 0.814453125, 'train/loss': 0.7248771786689758, 'validation/accuracy': 0.7274399995803833, 'validation/loss': 1.109386682510376, 'validation/num_examples': 50000, 'test/accuracy': 0.6027000546455383, 'test/loss': 1.7434618473052979, 'test/num_examples': 10000, 'score': 42056.76136255264, 'total_duration': 44915.23311281204, 'accumulated_submission_time': 42056.76136255264, 'accumulated_eval_time': 2851.6389589309692, 'accumulated_logging_time': 3.027472972869873}
I0315 14:37:44.039326 139540685625088 logging_writer.py:48] [107439] accumulated_eval_time=2851.638959, accumulated_logging_time=3.027473, accumulated_submission_time=42056.761363, global_step=107439, preemption_count=0, score=42056.761363, test/accuracy=0.602700, test/loss=1.743462, test/num_examples=10000, total_duration=44915.233113, train/accuracy=0.814453, train/loss=0.724877, validation/accuracy=0.727440, validation/loss=1.109387, validation/num_examples=50000
I0315 14:38:08.262768 139540534654720 logging_writer.py:48] [107500] global_step=107500, grad_norm=2.679011583328247, loss=3.1412973403930664
I0315 14:41:23.721714 139540685625088 logging_writer.py:48] [108000] global_step=108000, grad_norm=2.755859136581421, loss=2.09969162940979
I0315 14:44:39.311251 139540534654720 logging_writer.py:48] [108500] global_step=108500, grad_norm=2.68871808052063, loss=2.2344131469726562
I0315 14:44:44.096692 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:44:57.219519 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:45:09.664813 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:45:12.364876 139734377899840 submission_runner.py:420] Time since start: 45363.59s, 	Step: 108514, 	{'train/accuracy': 0.8226562142372131, 'train/loss': 0.6898142695426941, 'validation/accuracy': 0.7302199602127075, 'validation/loss': 1.1024210453033447, 'validation/num_examples': 50000, 'test/accuracy': 0.6082000136375427, 'test/loss': 1.7283380031585693, 'test/num_examples': 10000, 'score': 42476.77098417282, 'total_duration': 45363.58995103836, 'accumulated_submission_time': 42476.77098417282, 'accumulated_eval_time': 2879.9071016311646, 'accumulated_logging_time': 3.0687575340270996}
I0315 14:45:12.389705 139540685625088 logging_writer.py:48] [108514] accumulated_eval_time=2879.907102, accumulated_logging_time=3.068758, accumulated_submission_time=42476.770984, global_step=108514, preemption_count=0, score=42476.770984, test/accuracy=0.608200, test/loss=1.728338, test/num_examples=10000, total_duration=45363.589951, train/accuracy=0.822656, train/loss=0.689814, validation/accuracy=0.730220, validation/loss=1.102421, validation/num_examples=50000
I0315 14:48:22.845669 139540534654720 logging_writer.py:48] [109000] global_step=109000, grad_norm=3.0143775939941406, loss=1.5531326532363892
I0315 14:51:38.453705 139540685625088 logging_writer.py:48] [109500] global_step=109500, grad_norm=2.931513786315918, loss=3.915466070175171
I0315 14:52:12.581144 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:52:25.683775 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 14:52:38.107798 139734377899840 spec.py:349] Evaluating on the test split.
I0315 14:52:40.794266 139734377899840 submission_runner.py:420] Time since start: 45812.02s, 	Step: 109589, 	{'train/accuracy': 0.8191210627555847, 'train/loss': 0.6877502202987671, 'validation/accuracy': 0.7307199835777283, 'validation/loss': 1.0814051628112793, 'validation/num_examples': 50000, 'test/accuracy': 0.6058000326156616, 'test/loss': 1.7154690027236938, 'test/num_examples': 10000, 'score': 42896.91472172737, 'total_duration': 45812.01935052872, 'accumulated_submission_time': 42896.91472172737, 'accumulated_eval_time': 2908.1201968193054, 'accumulated_logging_time': 3.103774070739746}
I0315 14:52:40.820369 139540534654720 logging_writer.py:48] [109589] accumulated_eval_time=2908.120197, accumulated_logging_time=3.103774, accumulated_submission_time=42896.914722, global_step=109589, preemption_count=0, score=42896.914722, test/accuracy=0.605800, test/loss=1.715469, test/num_examples=10000, total_duration=45812.019351, train/accuracy=0.819121, train/loss=0.687750, validation/accuracy=0.730720, validation/loss=1.081405, validation/num_examples=50000
I0315 14:55:21.998264 139540685625088 logging_writer.py:48] [110000] global_step=110000, grad_norm=2.641538619995117, loss=1.8185617923736572
I0315 14:58:37.573457 139540534654720 logging_writer.py:48] [110500] global_step=110500, grad_norm=2.5920183658599854, loss=2.2953524589538574
I0315 14:59:41.032052 139734377899840 spec.py:321] Evaluating on the training split.
I0315 14:59:54.118529 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:00:06.452604 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:00:09.139099 139734377899840 submission_runner.py:420] Time since start: 46260.36s, 	Step: 110664, 	{'train/accuracy': 0.83216792345047, 'train/loss': 0.6448915004730225, 'validation/accuracy': 0.7317999601364136, 'validation/loss': 1.088350534439087, 'validation/num_examples': 50000, 'test/accuracy': 0.6075000166893005, 'test/loss': 1.7223092317581177, 'test/num_examples': 10000, 'score': 43317.07927131653, 'total_duration': 46260.36416435242, 'accumulated_submission_time': 43317.07927131653, 'accumulated_eval_time': 2936.227205991745, 'accumulated_logging_time': 3.13850736618042}
I0315 15:00:09.163710 139540685625088 logging_writer.py:48] [110664] accumulated_eval_time=2936.227206, accumulated_logging_time=3.138507, accumulated_submission_time=43317.079271, global_step=110664, preemption_count=0, score=43317.079271, test/accuracy=0.607500, test/loss=1.722309, test/num_examples=10000, total_duration=46260.364164, train/accuracy=0.832168, train/loss=0.644892, validation/accuracy=0.731800, validation/loss=1.088351, validation/num_examples=50000
I0315 15:02:20.903766 139540534654720 logging_writer.py:48] [111000] global_step=111000, grad_norm=2.8967819213867188, loss=3.2344586849212646
I0315 15:05:36.523781 139540685625088 logging_writer.py:48] [111500] global_step=111500, grad_norm=3.3209190368652344, loss=2.5967702865600586
I0315 15:07:09.321493 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:07:22.421309 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:07:34.752748 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:07:37.455630 139734377899840 submission_runner.py:420] Time since start: 46708.68s, 	Step: 111739, 	{'train/accuracy': 0.8270898461341858, 'train/loss': 0.6630663871765137, 'validation/accuracy': 0.733460009098053, 'validation/loss': 1.0728580951690674, 'validation/num_examples': 50000, 'test/accuracy': 0.6066000461578369, 'test/loss': 1.7066457271575928, 'test/num_examples': 10000, 'score': 43737.188535928726, 'total_duration': 46708.68071103096, 'accumulated_submission_time': 43737.188535928726, 'accumulated_eval_time': 2964.3613545894623, 'accumulated_logging_time': 3.172044277191162}
I0315 15:07:37.482589 139540534654720 logging_writer.py:48] [111739] accumulated_eval_time=2964.361355, accumulated_logging_time=3.172044, accumulated_submission_time=43737.188536, global_step=111739, preemption_count=0, score=43737.188536, test/accuracy=0.606600, test/loss=1.706646, test/num_examples=10000, total_duration=46708.680711, train/accuracy=0.827090, train/loss=0.663066, validation/accuracy=0.733460, validation/loss=1.072858, validation/num_examples=50000
I0315 15:09:19.931931 139540685625088 logging_writer.py:48] [112000] global_step=112000, grad_norm=3.5207056999206543, loss=4.109537124633789
I0315 15:12:35.531271 139540534654720 logging_writer.py:48] [112500] global_step=112500, grad_norm=3.2285244464874268, loss=3.9746525287628174
I0315 15:14:37.656765 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:14:50.744284 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:15:03.122632 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:15:05.821904 139734377899840 submission_runner.py:420] Time since start: 47157.05s, 	Step: 112814, 	{'train/accuracy': 0.8279492259025574, 'train/loss': 0.6634637117385864, 'validation/accuracy': 0.7366200089454651, 'validation/loss': 1.0635287761688232, 'validation/num_examples': 50000, 'test/accuracy': 0.6099000573158264, 'test/loss': 1.7054133415222168, 'test/num_examples': 10000, 'score': 44157.31499385834, 'total_duration': 47157.0469520092, 'accumulated_submission_time': 44157.31499385834, 'accumulated_eval_time': 2992.5264451503754, 'accumulated_logging_time': 3.2091495990753174}
I0315 15:15:05.847929 139540685625088 logging_writer.py:48] [112814] accumulated_eval_time=2992.526445, accumulated_logging_time=3.209150, accumulated_submission_time=44157.314994, global_step=112814, preemption_count=0, score=44157.314994, test/accuracy=0.609900, test/loss=1.705413, test/num_examples=10000, total_duration=47157.046952, train/accuracy=0.827949, train/loss=0.663464, validation/accuracy=0.736620, validation/loss=1.063529, validation/num_examples=50000
I0315 15:16:18.952320 139540534654720 logging_writer.py:48] [113000] global_step=113000, grad_norm=3.414029598236084, loss=1.6361454725265503
I0315 15:19:34.536921 139540685625088 logging_writer.py:48] [113500] global_step=113500, grad_norm=3.158198356628418, loss=1.4088139533996582
I0315 15:22:05.996580 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:22:19.058663 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:22:31.424255 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:22:34.111905 139734377899840 submission_runner.py:420] Time since start: 47605.34s, 	Step: 113889, 	{'train/accuracy': 0.8325390219688416, 'train/loss': 0.6506238579750061, 'validation/accuracy': 0.737019956111908, 'validation/loss': 1.0665639638900757, 'validation/num_examples': 50000, 'test/accuracy': 0.6160000562667847, 'test/loss': 1.7037070989608765, 'test/num_examples': 10000, 'score': 44577.41374921799, 'total_duration': 47605.33698582649, 'accumulated_submission_time': 44577.41374921799, 'accumulated_eval_time': 3020.641755104065, 'accumulated_logging_time': 3.245795488357544}
I0315 15:22:34.135747 139540534654720 logging_writer.py:48] [113889] accumulated_eval_time=3020.641755, accumulated_logging_time=3.245795, accumulated_submission_time=44577.413749, global_step=113889, preemption_count=0, score=44577.413749, test/accuracy=0.616000, test/loss=1.703707, test/num_examples=10000, total_duration=47605.336986, train/accuracy=0.832539, train/loss=0.650624, validation/accuracy=0.737020, validation/loss=1.066564, validation/num_examples=50000
I0315 15:23:17.963287 139540685625088 logging_writer.py:48] [114000] global_step=114000, grad_norm=3.0421154499053955, loss=2.2694807052612305
I0315 15:26:33.545807 139540534654720 logging_writer.py:48] [114500] global_step=114500, grad_norm=2.811197519302368, loss=1.9870898723602295
I0315 15:29:34.302407 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:29:47.362746 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:29:59.686323 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:30:02.369801 139734377899840 submission_runner.py:420] Time since start: 48053.59s, 	Step: 114964, 	{'train/accuracy': 0.8332617282867432, 'train/loss': 0.642020046710968, 'validation/accuracy': 0.73881995677948, 'validation/loss': 1.0511575937271118, 'validation/num_examples': 50000, 'test/accuracy': 0.6171000003814697, 'test/loss': 1.6760892868041992, 'test/num_examples': 10000, 'score': 44997.53186798096, 'total_duration': 48053.594883441925, 'accumulated_submission_time': 44997.53186798096, 'accumulated_eval_time': 3048.7091376781464, 'accumulated_logging_time': 3.2801101207733154}
I0315 15:30:02.396225 139540685625088 logging_writer.py:48] [114964] accumulated_eval_time=3048.709138, accumulated_logging_time=3.280110, accumulated_submission_time=44997.531868, global_step=114964, preemption_count=0, score=44997.531868, test/accuracy=0.617100, test/loss=1.676089, test/num_examples=10000, total_duration=48053.594883, train/accuracy=0.833262, train/loss=0.642020, validation/accuracy=0.738820, validation/loss=1.051158, validation/num_examples=50000
I0315 15:30:16.870315 139540534654720 logging_writer.py:48] [115000] global_step=115000, grad_norm=3.0187981128692627, loss=1.7698256969451904
I0315 15:33:32.382562 139540685625088 logging_writer.py:48] [115500] global_step=115500, grad_norm=3.1435186862945557, loss=1.433819055557251
I0315 15:36:47.991567 139540534654720 logging_writer.py:48] [116000] global_step=116000, grad_norm=3.110880136489868, loss=1.5564837455749512
I0315 15:37:02.560647 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:37:15.647942 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:37:27.971224 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:37:30.659200 139734377899840 submission_runner.py:420] Time since start: 48501.88s, 	Step: 116039, 	{'train/accuracy': 0.8462694883346558, 'train/loss': 0.5912107229232788, 'validation/accuracy': 0.7423399686813354, 'validation/loss': 1.0377609729766846, 'validation/num_examples': 50000, 'test/accuracy': 0.6160000562667847, 'test/loss': 1.6706985235214233, 'test/num_examples': 10000, 'score': 45417.64970135689, 'total_duration': 48501.88428449631, 'accumulated_submission_time': 45417.64970135689, 'accumulated_eval_time': 3076.8076598644257, 'accumulated_logging_time': 3.3152167797088623}
I0315 15:37:30.681787 139540685625088 logging_writer.py:48] [116039] accumulated_eval_time=3076.807660, accumulated_logging_time=3.315217, accumulated_submission_time=45417.649701, global_step=116039, preemption_count=0, score=45417.649701, test/accuracy=0.616000, test/loss=1.670699, test/num_examples=10000, total_duration=48501.884284, train/accuracy=0.846269, train/loss=0.591211, validation/accuracy=0.742340, validation/loss=1.037761, validation/num_examples=50000
I0315 15:40:31.370687 139540534654720 logging_writer.py:48] [116500] global_step=116500, grad_norm=3.4127674102783203, loss=3.4789633750915527
I0315 15:43:46.902294 139540685625088 logging_writer.py:48] [117000] global_step=117000, grad_norm=3.400578498840332, loss=3.940310001373291
I0315 15:44:30.794255 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:44:43.916265 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:44:56.239753 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:44:58.928977 139734377899840 submission_runner.py:420] Time since start: 48950.15s, 	Step: 117114, 	{'train/accuracy': 0.8408203125, 'train/loss': 0.6095035076141357, 'validation/accuracy': 0.7428999543190002, 'validation/loss': 1.034235954284668, 'validation/num_examples': 50000, 'test/accuracy': 0.6214000582695007, 'test/loss': 1.6589094400405884, 'test/num_examples': 10000, 'score': 45837.71575665474, 'total_duration': 48950.154040813446, 'accumulated_submission_time': 45837.71575665474, 'accumulated_eval_time': 3104.9423391819, 'accumulated_logging_time': 3.346100091934204}
I0315 15:44:58.952127 139540534654720 logging_writer.py:48] [117114] accumulated_eval_time=3104.942339, accumulated_logging_time=3.346100, accumulated_submission_time=45837.715757, global_step=117114, preemption_count=0, score=45837.715757, test/accuracy=0.621400, test/loss=1.658909, test/num_examples=10000, total_duration=48950.154041, train/accuracy=0.840820, train/loss=0.609504, validation/accuracy=0.742900, validation/loss=1.034236, validation/num_examples=50000
I0315 15:47:30.273532 139540685625088 logging_writer.py:48] [117500] global_step=117500, grad_norm=3.198651075363159, loss=1.293988823890686
I0315 15:50:45.787592 139540534654720 logging_writer.py:48] [118000] global_step=118000, grad_norm=3.1622889041900635, loss=1.8557310104370117
I0315 15:51:59.042948 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:52:12.197295 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:52:24.533653 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:52:27.225301 139734377899840 submission_runner.py:420] Time since start: 49398.45s, 	Step: 118189, 	{'train/accuracy': 0.8380078077316284, 'train/loss': 0.622999906539917, 'validation/accuracy': 0.7428799867630005, 'validation/loss': 1.0384109020233154, 'validation/num_examples': 50000, 'test/accuracy': 0.6210000514984131, 'test/loss': 1.6600441932678223, 'test/num_examples': 10000, 'score': 46257.759004831314, 'total_duration': 49398.45037841797, 'accumulated_submission_time': 46257.759004831314, 'accumulated_eval_time': 3133.124662399292, 'accumulated_logging_time': 3.378673553466797}
I0315 15:52:27.249349 139540685625088 logging_writer.py:48] [118189] accumulated_eval_time=3133.124662, accumulated_logging_time=3.378674, accumulated_submission_time=46257.759005, global_step=118189, preemption_count=0, score=46257.759005, test/accuracy=0.621000, test/loss=1.660044, test/num_examples=10000, total_duration=49398.450378, train/accuracy=0.838008, train/loss=0.623000, validation/accuracy=0.742880, validation/loss=1.038411, validation/num_examples=50000
I0315 15:54:29.216847 139540534654720 logging_writer.py:48] [118500] global_step=118500, grad_norm=3.156766414642334, loss=1.486743688583374
I0315 15:57:44.830464 139540685625088 logging_writer.py:48] [119000] global_step=119000, grad_norm=3.067288637161255, loss=1.710630178451538
I0315 15:59:27.388782 139734377899840 spec.py:321] Evaluating on the training split.
I0315 15:59:40.539478 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 15:59:52.888250 139734377899840 spec.py:349] Evaluating on the test split.
I0315 15:59:55.583182 139734377899840 submission_runner.py:420] Time since start: 49846.81s, 	Step: 119264, 	{'train/accuracy': 0.8441015481948853, 'train/loss': 0.5896441340446472, 'validation/accuracy': 0.74617999792099, 'validation/loss': 1.0193930864334106, 'validation/num_examples': 50000, 'test/accuracy': 0.6221000552177429, 'test/loss': 1.6508439779281616, 'test/num_examples': 10000, 'score': 46677.85278201103, 'total_duration': 49846.80826020241, 'accumulated_submission_time': 46677.85278201103, 'accumulated_eval_time': 3161.3190398216248, 'accumulated_logging_time': 3.4110894203186035}
I0315 15:59:55.611545 139540534654720 logging_writer.py:48] [119264] accumulated_eval_time=3161.319040, accumulated_logging_time=3.411089, accumulated_submission_time=46677.852782, global_step=119264, preemption_count=0, score=46677.852782, test/accuracy=0.622100, test/loss=1.650844, test/num_examples=10000, total_duration=49846.808260, train/accuracy=0.844102, train/loss=0.589644, validation/accuracy=0.746180, validation/loss=1.019393, validation/num_examples=50000
I0315 16:01:28.337100 139540685625088 logging_writer.py:48] [119500] global_step=119500, grad_norm=3.3130040168762207, loss=3.428809642791748
I0315 16:04:43.927468 139540534654720 logging_writer.py:48] [120000] global_step=120000, grad_norm=2.819653034210205, loss=2.357649803161621
I0315 16:06:55.757641 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:07:08.866153 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:07:21.245704 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:07:23.929074 139734377899840 submission_runner.py:420] Time since start: 50295.15s, 	Step: 120339, 	{'train/accuracy': 0.8456249833106995, 'train/loss': 0.5948187708854675, 'validation/accuracy': 0.7465400099754333, 'validation/loss': 1.023179292678833, 'validation/num_examples': 50000, 'test/accuracy': 0.6181000471115112, 'test/loss': 1.6532502174377441, 'test/num_examples': 10000, 'score': 47097.95237207413, 'total_duration': 50295.15413951874, 'accumulated_submission_time': 47097.95237207413, 'accumulated_eval_time': 3189.4904420375824, 'accumulated_logging_time': 3.4484405517578125}
I0315 16:07:23.955137 139540685625088 logging_writer.py:48] [120339] accumulated_eval_time=3189.490442, accumulated_logging_time=3.448441, accumulated_submission_time=47097.952372, global_step=120339, preemption_count=0, score=47097.952372, test/accuracy=0.618100, test/loss=1.653250, test/num_examples=10000, total_duration=50295.154140, train/accuracy=0.845625, train/loss=0.594819, validation/accuracy=0.746540, validation/loss=1.023179, validation/num_examples=50000
I0315 16:08:27.230363 139540534654720 logging_writer.py:48] [120500] global_step=120500, grad_norm=3.0289971828460693, loss=2.493739366531372
I0315 16:11:42.785746 139540685625088 logging_writer.py:48] [121000] global_step=121000, grad_norm=3.2613611221313477, loss=1.407941460609436
I0315 16:14:23.984132 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:14:37.109195 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:14:49.434478 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:14:52.130997 139734377899840 submission_runner.py:420] Time since start: 50743.36s, 	Step: 121414, 	{'train/accuracy': 0.8444335460662842, 'train/loss': 0.5856109261512756, 'validation/accuracy': 0.7487399578094482, 'validation/loss': 1.011536955833435, 'validation/num_examples': 50000, 'test/accuracy': 0.6230000257492065, 'test/loss': 1.6453951597213745, 'test/num_examples': 10000, 'score': 47517.9346408844, 'total_duration': 50743.356073856354, 'accumulated_submission_time': 47517.9346408844, 'accumulated_eval_time': 3217.637284517288, 'accumulated_logging_time': 3.483731746673584}
I0315 16:14:52.155350 139540534654720 logging_writer.py:48] [121414] accumulated_eval_time=3217.637285, accumulated_logging_time=3.483732, accumulated_submission_time=47517.934641, global_step=121414, preemption_count=0, score=47517.934641, test/accuracy=0.623000, test/loss=1.645395, test/num_examples=10000, total_duration=50743.356074, train/accuracy=0.844434, train/loss=0.585611, validation/accuracy=0.748740, validation/loss=1.011537, validation/num_examples=50000
I0315 16:15:26.162730 139540685625088 logging_writer.py:48] [121500] global_step=121500, grad_norm=4.0844221115112305, loss=1.3400273323059082
I0315 16:18:41.722521 139540534654720 logging_writer.py:48] [122000] global_step=122000, grad_norm=3.3047680854797363, loss=1.85427725315094
I0315 16:21:52.242552 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:22:05.397731 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:22:17.762854 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:22:20.461505 139734377899840 submission_runner.py:420] Time since start: 51191.69s, 	Step: 122489, 	{'train/accuracy': 0.8477343320846558, 'train/loss': 0.5809749364852905, 'validation/accuracy': 0.7500199675559998, 'validation/loss': 1.0088045597076416, 'validation/num_examples': 50000, 'test/accuracy': 0.6243000030517578, 'test/loss': 1.6385291814804077, 'test/num_examples': 10000, 'score': 47937.97454357147, 'total_duration': 51191.686584711075, 'accumulated_submission_time': 47937.97454357147, 'accumulated_eval_time': 3245.8562200069427, 'accumulated_logging_time': 3.517456293106079}
I0315 16:22:20.486746 139540685625088 logging_writer.py:48] [122489] accumulated_eval_time=3245.856220, accumulated_logging_time=3.517456, accumulated_submission_time=47937.974544, global_step=122489, preemption_count=0, score=47937.974544, test/accuracy=0.624300, test/loss=1.638529, test/num_examples=10000, total_duration=51191.686585, train/accuracy=0.847734, train/loss=0.580975, validation/accuracy=0.750020, validation/loss=1.008805, validation/num_examples=50000
I0315 16:22:25.188252 139540534654720 logging_writer.py:48] [122500] global_step=122500, grad_norm=3.300597667694092, loss=1.942115068435669
I0315 16:25:40.734923 139540685625088 logging_writer.py:48] [123000] global_step=123000, grad_norm=3.644181728363037, loss=1.580302119255066
I0315 16:28:56.273301 139540534654720 logging_writer.py:48] [123500] global_step=123500, grad_norm=3.7664406299591064, loss=4.018093109130859
I0315 16:29:20.607722 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:29:33.770061 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:29:46.114452 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:29:48.806891 139734377899840 submission_runner.py:420] Time since start: 51640.03s, 	Step: 123564, 	{'train/accuracy': 0.8473241925239563, 'train/loss': 0.5790875554084778, 'validation/accuracy': 0.7511199712753296, 'validation/loss': 1.0009024143218994, 'validation/num_examples': 50000, 'test/accuracy': 0.6279000043869019, 'test/loss': 1.6336430311203003, 'test/num_examples': 10000, 'score': 48358.04886507988, 'total_duration': 51640.03197526932, 'accumulated_submission_time': 48358.04886507988, 'accumulated_eval_time': 3274.0553612709045, 'accumulated_logging_time': 3.5517160892486572}
I0315 16:29:48.829938 139540685625088 logging_writer.py:48] [123564] accumulated_eval_time=3274.055361, accumulated_logging_time=3.551716, accumulated_submission_time=48358.048865, global_step=123564, preemption_count=0, score=48358.048865, test/accuracy=0.627900, test/loss=1.633643, test/num_examples=10000, total_duration=51640.031975, train/accuracy=0.847324, train/loss=0.579088, validation/accuracy=0.751120, validation/loss=1.000902, validation/num_examples=50000
I0315 16:32:39.674035 139540534654720 logging_writer.py:48] [124000] global_step=124000, grad_norm=3.531649589538574, loss=1.463757872581482
I0315 16:35:55.181696 139540685625088 logging_writer.py:48] [124500] global_step=124500, grad_norm=3.138650894165039, loss=2.611995220184326
I0315 16:36:48.834268 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:37:01.980667 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:37:14.336329 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:37:17.036295 139734377899840 submission_runner.py:420] Time since start: 52088.26s, 	Step: 124639, 	{'train/accuracy': 0.8570898175239563, 'train/loss': 0.5458067655563354, 'validation/accuracy': 0.7506200075149536, 'validation/loss': 1.0017110109329224, 'validation/num_examples': 50000, 'test/accuracy': 0.6260000467300415, 'test/loss': 1.6287956237792969, 'test/num_examples': 10000, 'score': 48778.007551431656, 'total_duration': 52088.26137685776, 'accumulated_submission_time': 48778.007551431656, 'accumulated_eval_time': 3302.2573626041412, 'accumulated_logging_time': 3.582996368408203}
I0315 16:37:17.059998 139540534654720 logging_writer.py:48] [124639] accumulated_eval_time=3302.257363, accumulated_logging_time=3.582996, accumulated_submission_time=48778.007551, global_step=124639, preemption_count=0, score=48778.007551, test/accuracy=0.626000, test/loss=1.628796, test/num_examples=10000, total_duration=52088.261377, train/accuracy=0.857090, train/loss=0.545807, validation/accuracy=0.750620, validation/loss=1.001711, validation/num_examples=50000
I0315 16:39:38.658986 139540685625088 logging_writer.py:48] [125000] global_step=125000, grad_norm=3.598647356033325, loss=1.3343852758407593
I0315 16:42:54.250151 139540534654720 logging_writer.py:48] [125500] global_step=125500, grad_norm=3.2716457843780518, loss=2.970411539077759
I0315 16:44:17.282369 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:44:30.392050 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:44:42.738760 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:44:45.436931 139734377899840 submission_runner.py:420] Time since start: 52536.66s, 	Step: 125714, 	{'train/accuracy': 0.850878894329071, 'train/loss': 0.5668322443962097, 'validation/accuracy': 0.7524999976158142, 'validation/loss': 0.9997560977935791, 'validation/num_examples': 50000, 'test/accuracy': 0.6292000412940979, 'test/loss': 1.6225883960723877, 'test/num_examples': 10000, 'score': 49198.183133363724, 'total_duration': 52536.66201090813, 'accumulated_submission_time': 49198.183133363724, 'accumulated_eval_time': 3330.411891222, 'accumulated_logging_time': 3.615069627761841}
I0315 16:44:45.461340 139540685625088 logging_writer.py:48] [125714] accumulated_eval_time=3330.411891, accumulated_logging_time=3.615070, accumulated_submission_time=49198.183133, global_step=125714, preemption_count=0, score=49198.183133, test/accuracy=0.629200, test/loss=1.622588, test/num_examples=10000, total_duration=52536.662011, train/accuracy=0.850879, train/loss=0.566832, validation/accuracy=0.752500, validation/loss=0.999756, validation/num_examples=50000
I0315 16:46:37.645668 139540534654720 logging_writer.py:48] [126000] global_step=126000, grad_norm=3.626741886138916, loss=1.384775161743164
I0315 16:49:53.170421 139540685625088 logging_writer.py:48] [126500] global_step=126500, grad_norm=3.266911745071411, loss=1.2569185495376587
I0315 16:51:45.500775 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:51:58.601521 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:52:10.944014 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:52:13.643441 139734377899840 submission_runner.py:420] Time since start: 52984.87s, 	Step: 126789, 	{'train/accuracy': 0.8553124666213989, 'train/loss': 0.5533652901649475, 'validation/accuracy': 0.7535399794578552, 'validation/loss': 0.9921098947525024, 'validation/num_examples': 50000, 'test/accuracy': 0.6314000487327576, 'test/loss': 1.6144118309020996, 'test/num_examples': 10000, 'score': 49618.17370700836, 'total_duration': 52984.86852097511, 'accumulated_submission_time': 49618.17370700836, 'accumulated_eval_time': 3358.554525375366, 'accumulated_logging_time': 3.65034556388855}
I0315 16:52:13.667470 139540534654720 logging_writer.py:48] [126789] accumulated_eval_time=3358.554525, accumulated_logging_time=3.650346, accumulated_submission_time=49618.173707, global_step=126789, preemption_count=0, score=49618.173707, test/accuracy=0.631400, test/loss=1.614412, test/num_examples=10000, total_duration=52984.868521, train/accuracy=0.855312, train/loss=0.553365, validation/accuracy=0.753540, validation/loss=0.992110, validation/num_examples=50000
I0315 16:53:36.557594 139540685625088 logging_writer.py:48] [127000] global_step=127000, grad_norm=3.316335439682007, loss=2.055173397064209
I0315 16:56:52.075009 139540534654720 logging_writer.py:48] [127500] global_step=127500, grad_norm=3.5979621410369873, loss=1.362081527709961
I0315 16:59:13.735446 139734377899840 spec.py:321] Evaluating on the training split.
I0315 16:59:26.829572 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 16:59:39.782314 139734377899840 spec.py:349] Evaluating on the test split.
I0315 16:59:42.456637 139734377899840 submission_runner.py:420] Time since start: 53433.68s, 	Step: 127864, 	{'train/accuracy': 0.8551757335662842, 'train/loss': 0.5507948994636536, 'validation/accuracy': 0.7538599967956543, 'validation/loss': 0.9891623258590698, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.614182472229004, 'test/num_examples': 10000, 'score': 50038.194083213806, 'total_duration': 53433.6817214489, 'accumulated_submission_time': 50038.194083213806, 'accumulated_eval_time': 3387.2756962776184, 'accumulated_logging_time': 3.683236837387085}
I0315 16:59:42.486037 139540685625088 logging_writer.py:48] [127864] accumulated_eval_time=3387.275696, accumulated_logging_time=3.683237, accumulated_submission_time=50038.194083, global_step=127864, preemption_count=0, score=50038.194083, test/accuracy=0.628800, test/loss=1.614182, test/num_examples=10000, total_duration=53433.681721, train/accuracy=0.855176, train/loss=0.550795, validation/accuracy=0.753860, validation/loss=0.989162, validation/num_examples=50000
I0315 17:00:35.980988 139540534654720 logging_writer.py:48] [128000] global_step=128000, grad_norm=3.54685378074646, loss=2.314005136489868
I0315 17:03:51.500700 139540685625088 logging_writer.py:48] [128500] global_step=128500, grad_norm=3.7092490196228027, loss=1.3363105058670044
I0315 17:06:42.506261 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:06:55.650351 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:07:08.468398 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:07:11.161479 139734377899840 submission_runner.py:420] Time since start: 53882.39s, 	Step: 128939, 	{'train/accuracy': 0.8582421541213989, 'train/loss': 0.544922947883606, 'validation/accuracy': 0.7541399598121643, 'validation/loss': 0.989403486251831, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.6124773025512695, 'test/num_examples': 10000, 'score': 50458.16389298439, 'total_duration': 53882.38656425476, 'accumulated_submission_time': 50458.16389298439, 'accumulated_eval_time': 3415.9308965206146, 'accumulated_logging_time': 3.723912477493286}
I0315 17:07:11.186322 139540534654720 logging_writer.py:48] [128939] accumulated_eval_time=3415.930897, accumulated_logging_time=3.723912, accumulated_submission_time=50458.163893, global_step=128939, preemption_count=0, score=50458.163893, test/accuracy=0.632500, test/loss=1.612477, test/num_examples=10000, total_duration=53882.386564, train/accuracy=0.858242, train/loss=0.544923, validation/accuracy=0.754140, validation/loss=0.989403, validation/num_examples=50000
I0315 17:07:35.420249 139540685625088 logging_writer.py:48] [129000] global_step=129000, grad_norm=4.135588645935059, loss=3.697256326675415
I0315 17:10:50.948298 139540534654720 logging_writer.py:48] [129500] global_step=129500, grad_norm=3.8796064853668213, loss=3.757580280303955
I0315 17:14:06.493031 139540685625088 logging_writer.py:48] [130000] global_step=130000, grad_norm=3.7145233154296875, loss=1.8331620693206787
I0315 17:14:11.271062 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:14:24.349836 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:14:36.810552 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:14:39.520589 139734377899840 submission_runner.py:420] Time since start: 54330.75s, 	Step: 130014, 	{'train/accuracy': 0.8580273389816284, 'train/loss': 0.5405624508857727, 'validation/accuracy': 0.7541199922561646, 'validation/loss': 0.9870275259017944, 'validation/num_examples': 50000, 'test/accuracy': 0.6303000450134277, 'test/loss': 1.6109708547592163, 'test/num_examples': 10000, 'score': 50878.201677560806, 'total_duration': 54330.74567198753, 'accumulated_submission_time': 50878.201677560806, 'accumulated_eval_time': 3444.18039226532, 'accumulated_logging_time': 3.758056402206421}
I0315 17:14:39.544622 139540534654720 logging_writer.py:48] [130014] accumulated_eval_time=3444.180392, accumulated_logging_time=3.758056, accumulated_submission_time=50878.201678, global_step=130014, preemption_count=0, score=50878.201678, test/accuracy=0.630300, test/loss=1.610971, test/num_examples=10000, total_duration=54330.745672, train/accuracy=0.858027, train/loss=0.540562, validation/accuracy=0.754120, validation/loss=0.987028, validation/num_examples=50000
I0315 17:17:50.008473 139540685625088 logging_writer.py:48] [130500] global_step=130500, grad_norm=3.353471040725708, loss=2.1656761169433594
I0315 17:21:05.525072 139540534654720 logging_writer.py:48] [131000] global_step=131000, grad_norm=3.574812650680542, loss=1.5167104005813599
I0315 17:21:39.668182 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:21:52.725809 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:22:05.140489 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:22:07.829428 139734377899840 submission_runner.py:420] Time since start: 54779.05s, 	Step: 131089, 	{'train/accuracy': 0.8587890267372131, 'train/loss': 0.536045491695404, 'validation/accuracy': 0.7555599808692932, 'validation/loss': 0.982154130935669, 'validation/num_examples': 50000, 'test/accuracy': 0.6327000260353088, 'test/loss': 1.6099995374679565, 'test/num_examples': 10000, 'score': 51298.278035879135, 'total_duration': 54779.05450677872, 'accumulated_submission_time': 51298.278035879135, 'accumulated_eval_time': 3472.341605901718, 'accumulated_logging_time': 3.790797472000122}
I0315 17:22:07.853607 139540685625088 logging_writer.py:48] [131089] accumulated_eval_time=3472.341606, accumulated_logging_time=3.790797, accumulated_submission_time=51298.278036, global_step=131089, preemption_count=0, score=51298.278036, test/accuracy=0.632700, test/loss=1.610000, test/num_examples=10000, total_duration=54779.054507, train/accuracy=0.858789, train/loss=0.536045, validation/accuracy=0.755560, validation/loss=0.982154, validation/num_examples=50000
I0315 17:24:49.020939 139540534654720 logging_writer.py:48] [131500] global_step=131500, grad_norm=3.452735185623169, loss=1.3118795156478882
I0315 17:28:04.589240 139540685625088 logging_writer.py:48] [132000] global_step=132000, grad_norm=3.3080625534057617, loss=2.339623212814331
I0315 17:29:08.032906 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:29:21.101230 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:29:33.548799 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:29:36.244034 139734377899840 submission_runner.py:420] Time since start: 55227.47s, 	Step: 132164, 	{'train/accuracy': 0.8575195074081421, 'train/loss': 0.5434736013412476, 'validation/accuracy': 0.7554599642753601, 'validation/loss': 0.9835134744644165, 'validation/num_examples': 50000, 'test/accuracy': 0.6321000456809998, 'test/loss': 1.6135687828063965, 'test/num_examples': 10000, 'score': 51718.40934872627, 'total_duration': 55227.46911454201, 'accumulated_submission_time': 51718.40934872627, 'accumulated_eval_time': 3500.552706718445, 'accumulated_logging_time': 3.8247225284576416}
I0315 17:29:36.270478 139540534654720 logging_writer.py:48] [132164] accumulated_eval_time=3500.552707, accumulated_logging_time=3.824723, accumulated_submission_time=51718.409349, global_step=132164, preemption_count=0, score=51718.409349, test/accuracy=0.632100, test/loss=1.613569, test/num_examples=10000, total_duration=55227.469115, train/accuracy=0.857520, train/loss=0.543474, validation/accuracy=0.755460, validation/loss=0.983513, validation/num_examples=50000
I0315 17:31:48.006076 139540685625088 logging_writer.py:48] [132500] global_step=132500, grad_norm=3.8261823654174805, loss=3.753838300704956
I0315 17:35:03.579765 139540534654720 logging_writer.py:48] [133000] global_step=133000, grad_norm=3.9835805892944336, loss=1.6938831806182861
I0315 17:36:36.396364 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:36:49.474465 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:37:01.825426 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:37:04.520024 139734377899840 submission_runner.py:420] Time since start: 55675.75s, 	Step: 133239, 	{'train/accuracy': 0.8625586032867432, 'train/loss': 0.520088791847229, 'validation/accuracy': 0.756339967250824, 'validation/loss': 0.9802817106246948, 'validation/num_examples': 50000, 'test/accuracy': 0.6328000426292419, 'test/loss': 1.6079225540161133, 'test/num_examples': 10000, 'score': 52138.48851490021, 'total_duration': 55675.74509596825, 'accumulated_submission_time': 52138.48851490021, 'accumulated_eval_time': 3528.676340341568, 'accumulated_logging_time': 3.8596837520599365}
I0315 17:37:04.547122 139540685625088 logging_writer.py:48] [133239] accumulated_eval_time=3528.676340, accumulated_logging_time=3.859684, accumulated_submission_time=52138.488515, global_step=133239, preemption_count=0, score=52138.488515, test/accuracy=0.632800, test/loss=1.607923, test/num_examples=10000, total_duration=55675.745096, train/accuracy=0.862559, train/loss=0.520089, validation/accuracy=0.756340, validation/loss=0.980282, validation/num_examples=50000
I0315 17:38:47.011771 139540534654720 logging_writer.py:48] [133500] global_step=133500, grad_norm=3.3675410747528076, loss=1.5463037490844727
I0315 17:42:02.605646 139540685625088 logging_writer.py:48] [134000] global_step=134000, grad_norm=5.0558881759643555, loss=3.5930309295654297
I0315 17:44:04.730547 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:44:17.809576 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:44:30.165349 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:44:32.866239 139734377899840 submission_runner.py:420] Time since start: 56124.09s, 	Step: 134314, 	{'train/accuracy': 0.8566992282867432, 'train/loss': 0.545985221862793, 'validation/accuracy': 0.7568999528884888, 'validation/loss': 0.9783429503440857, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.6068836450576782, 'test/num_examples': 10000, 'score': 52558.62541294098, 'total_duration': 56124.091317653656, 'accumulated_submission_time': 52558.62541294098, 'accumulated_eval_time': 3556.812022924423, 'accumulated_logging_time': 3.895678997039795}
I0315 17:44:32.892085 139540534654720 logging_writer.py:48] [134314] accumulated_eval_time=3556.812023, accumulated_logging_time=3.895679, accumulated_submission_time=52558.625413, global_step=134314, preemption_count=0, score=52558.625413, test/accuracy=0.632500, test/loss=1.606884, test/num_examples=10000, total_duration=56124.091318, train/accuracy=0.856699, train/loss=0.545985, validation/accuracy=0.756900, validation/loss=0.978343, validation/num_examples=50000
I0315 17:45:45.991104 139540685625088 logging_writer.py:48] [134500] global_step=134500, grad_norm=3.486844778060913, loss=3.48197865486145
I0315 17:49:01.528702 139540534654720 logging_writer.py:48] [135000] global_step=135000, grad_norm=3.8690173625946045, loss=1.7171969413757324
I0315 17:51:33.010422 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:51:46.132114 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:51:58.480133 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:52:01.177201 139734377899840 submission_runner.py:420] Time since start: 56572.40s, 	Step: 135389, 	{'train/accuracy': 0.8612695336341858, 'train/loss': 0.5244999527931213, 'validation/accuracy': 0.7570199966430664, 'validation/loss': 0.9779985547065735, 'validation/num_examples': 50000, 'test/accuracy': 0.6359000205993652, 'test/loss': 1.6035908460617065, 'test/num_examples': 10000, 'score': 52978.69073343277, 'total_duration': 56572.40228223801, 'accumulated_submission_time': 52978.69073343277, 'accumulated_eval_time': 3584.978801012039, 'accumulated_logging_time': 3.9358527660369873}
I0315 17:52:01.201689 139540685625088 logging_writer.py:48] [135389] accumulated_eval_time=3584.978801, accumulated_logging_time=3.935853, accumulated_submission_time=52978.690733, global_step=135389, preemption_count=0, score=52978.690733, test/accuracy=0.635900, test/loss=1.603591, test/num_examples=10000, total_duration=56572.402282, train/accuracy=0.861270, train/loss=0.524500, validation/accuracy=0.757020, validation/loss=0.977999, validation/num_examples=50000
I0315 17:52:45.022404 139540534654720 logging_writer.py:48] [135500] global_step=135500, grad_norm=4.180617332458496, loss=3.6104249954223633
I0315 17:56:00.571525 139540685625088 logging_writer.py:48] [136000] global_step=136000, grad_norm=3.5715692043304443, loss=1.4620604515075684
I0315 17:59:01.311409 139734377899840 spec.py:321] Evaluating on the training split.
I0315 17:59:14.458050 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 17:59:26.833091 139734377899840 spec.py:349] Evaluating on the test split.
I0315 17:59:29.539895 139734377899840 submission_runner.py:420] Time since start: 57020.76s, 	Step: 136464, 	{'train/accuracy': 0.86048823595047, 'train/loss': 0.5340384244918823, 'validation/accuracy': 0.7572599649429321, 'validation/loss': 0.9755660891532898, 'validation/num_examples': 50000, 'test/accuracy': 0.6351000070571899, 'test/loss': 1.6040593385696411, 'test/num_examples': 10000, 'score': 53398.75436234474, 'total_duration': 57020.7649538517, 'accumulated_submission_time': 53398.75436234474, 'accumulated_eval_time': 3613.207260131836, 'accumulated_logging_time': 3.968907117843628}
I0315 17:59:29.572975 139540534654720 logging_writer.py:48] [136464] accumulated_eval_time=3613.207260, accumulated_logging_time=3.968907, accumulated_submission_time=53398.754362, global_step=136464, preemption_count=0, score=53398.754362, test/accuracy=0.635100, test/loss=1.604059, test/num_examples=10000, total_duration=57020.764954, train/accuracy=0.860488, train/loss=0.534038, validation/accuracy=0.757260, validation/loss=0.975566, validation/num_examples=50000
I0315 17:59:44.041898 139540685625088 logging_writer.py:48] [136500] global_step=136500, grad_norm=4.018022060394287, loss=1.4463138580322266
I0315 18:02:59.550423 139540534654720 logging_writer.py:48] [137000] global_step=137000, grad_norm=3.7117910385131836, loss=1.4347083568572998
I0315 18:06:15.092510 139540685625088 logging_writer.py:48] [137500] global_step=137500, grad_norm=3.6999688148498535, loss=1.306673526763916
I0315 18:06:29.659325 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:06:42.818249 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:06:55.171034 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:06:57.863532 139734377899840 submission_runner.py:420] Time since start: 57469.09s, 	Step: 137539, 	{'train/accuracy': 0.8590039014816284, 'train/loss': 0.5354684591293335, 'validation/accuracy': 0.7573800086975098, 'validation/loss': 0.9761661291122437, 'validation/num_examples': 50000, 'test/accuracy': 0.6356000304222107, 'test/loss': 1.603734016418457, 'test/num_examples': 10000, 'score': 53818.79170393944, 'total_duration': 57469.088617801666, 'accumulated_submission_time': 53818.79170393944, 'accumulated_eval_time': 3641.411437511444, 'accumulated_logging_time': 4.013380765914917}
I0315 18:06:57.889410 139540534654720 logging_writer.py:48] [137539] accumulated_eval_time=3641.411438, accumulated_logging_time=4.013381, accumulated_submission_time=53818.791704, global_step=137539, preemption_count=0, score=53818.791704, test/accuracy=0.635600, test/loss=1.603734, test/num_examples=10000, total_duration=57469.088618, train/accuracy=0.859004, train/loss=0.535468, validation/accuracy=0.757380, validation/loss=0.976166, validation/num_examples=50000
I0315 18:09:58.559641 139540685625088 logging_writer.py:48] [138000] global_step=138000, grad_norm=3.8437659740448, loss=1.4612876176834106
I0315 18:13:14.120745 139540534654720 logging_writer.py:48] [138500] global_step=138500, grad_norm=3.9872689247131348, loss=1.3732950687408447
I0315 18:13:57.996169 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:14:11.152632 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:14:23.512213 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:14:26.202572 139734377899840 submission_runner.py:420] Time since start: 57917.43s, 	Step: 138614, 	{'train/accuracy': 0.8601366877555847, 'train/loss': 0.5311143398284912, 'validation/accuracy': 0.7568599581718445, 'validation/loss': 0.976474404335022, 'validation/num_examples': 50000, 'test/accuracy': 0.6350000500679016, 'test/loss': 1.6039568185806274, 'test/num_examples': 10000, 'score': 54238.85230445862, 'total_duration': 57917.42765760422, 'accumulated_submission_time': 54238.85230445862, 'accumulated_eval_time': 3669.6178154945374, 'accumulated_logging_time': 4.047449827194214}
I0315 18:14:26.226497 139540685625088 logging_writer.py:48] [138614] accumulated_eval_time=3669.617815, accumulated_logging_time=4.047450, accumulated_submission_time=54238.852304, global_step=138614, preemption_count=0, score=54238.852304, test/accuracy=0.635000, test/loss=1.603957, test/num_examples=10000, total_duration=57917.427658, train/accuracy=0.860137, train/loss=0.531114, validation/accuracy=0.756860, validation/loss=0.976474, validation/num_examples=50000
I0315 18:16:57.428013 139540534654720 logging_writer.py:48] [139000] global_step=139000, grad_norm=3.5700013637542725, loss=1.2088394165039062
I0315 18:20:12.928661 139540685625088 logging_writer.py:48] [139500] global_step=139500, grad_norm=3.3128061294555664, loss=1.4252487421035767
I0315 18:21:26.547377 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:21:39.715355 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:21:52.281150 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:21:54.980819 139734377899840 submission_runner.py:420] Time since start: 58366.21s, 	Step: 139690, 	{'train/accuracy': 0.8583593368530273, 'train/loss': 0.5393272042274475, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.976636528968811, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043870449066162, 'test/num_examples': 10000, 'score': 54659.12533760071, 'total_duration': 58366.20587968826, 'accumulated_submission_time': 54659.12533760071, 'accumulated_eval_time': 3698.051212787628, 'accumulated_logging_time': 4.081500768661499}
I0315 18:21:55.008888 139540534654720 logging_writer.py:48] [139690] accumulated_eval_time=3698.051213, accumulated_logging_time=4.081501, accumulated_submission_time=54659.125338, global_step=139690, preemption_count=0, score=54659.125338, test/accuracy=0.634600, test/loss=1.604387, test/num_examples=10000, total_duration=58366.205880, train/accuracy=0.858359, train/loss=0.539327, validation/accuracy=0.757000, validation/loss=0.976637, validation/num_examples=50000
I0315 18:23:56.611577 139540685625088 logging_writer.py:48] [140000] global_step=140000, grad_norm=3.649970293045044, loss=1.3751370906829834
I0315 18:27:12.181226 139540534654720 logging_writer.py:48] [140500] global_step=140500, grad_norm=3.4133431911468506, loss=1.3382937908172607
I0315 18:28:55.137124 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:29:08.301573 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:29:20.672779 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:29:23.367542 139734377899840 submission_runner.py:420] Time since start: 58814.59s, 	Step: 140765, 	{'train/accuracy': 0.861328125, 'train/loss': 0.5271535515785217, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55079.20550727844, 'total_duration': 58814.59260940552, 'accumulated_submission_time': 55079.20550727844, 'accumulated_eval_time': 3726.2815976142883, 'accumulated_logging_time': 4.118992328643799}
I0315 18:29:23.398070 139540685625088 logging_writer.py:48] [140765] accumulated_eval_time=3726.281598, accumulated_logging_time=4.118992, accumulated_submission_time=55079.205507, global_step=140765, preemption_count=0, score=55079.205507, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=58814.592609, train/accuracy=0.861328, train/loss=0.527154, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 18:30:55.648826 139540534654720 logging_writer.py:48] [141000] global_step=141000, grad_norm=3.6810522079467773, loss=1.3670852184295654
I0315 18:34:11.171194 139540685625088 logging_writer.py:48] [141500] global_step=141500, grad_norm=3.5978918075561523, loss=3.0901148319244385
I0315 18:36:23.451544 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:36:36.598458 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:36:48.930337 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:36:51.628621 139734377899840 submission_runner.py:420] Time since start: 59262.85s, 	Step: 141840, 	{'train/accuracy': 0.8594530820846558, 'train/loss': 0.5347545742988586, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55499.2118062973, 'total_duration': 59262.85370635986, 'accumulated_submission_time': 55499.2118062973, 'accumulated_eval_time': 3754.4586601257324, 'accumulated_logging_time': 4.159090280532837}
I0315 18:36:51.657443 139540534654720 logging_writer.py:48] [141840] accumulated_eval_time=3754.458660, accumulated_logging_time=4.159090, accumulated_submission_time=55499.211806, global_step=141840, preemption_count=0, score=55499.211806, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=59262.853706, train/accuracy=0.859453, train/loss=0.534755, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 18:37:54.585164 139540685625088 logging_writer.py:48] [142000] global_step=142000, grad_norm=3.735236406326294, loss=1.2990174293518066
I0315 18:41:10.126437 139540534654720 logging_writer.py:48] [142500] global_step=142500, grad_norm=3.8314778804779053, loss=1.2837339639663696
I0315 18:43:51.748340 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:44:04.971241 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:44:17.345245 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:44:20.043709 139734377899840 submission_runner.py:420] Time since start: 59711.27s, 	Step: 142915, 	{'train/accuracy': 0.8594140410423279, 'train/loss': 0.5365279912948608, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55919.25531768799, 'total_duration': 59711.26879477501, 'accumulated_submission_time': 55919.25531768799, 'accumulated_eval_time': 3782.754019498825, 'accumulated_logging_time': 4.197422981262207}
I0315 18:44:20.068300 139540685625088 logging_writer.py:48] [142915] accumulated_eval_time=3782.754019, accumulated_logging_time=4.197423, accumulated_submission_time=55919.255318, global_step=142915, preemption_count=0, score=55919.255318, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=59711.268795, train/accuracy=0.859414, train/loss=0.536528, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 18:44:53.689512 139540534654720 logging_writer.py:48] [143000] global_step=143000, grad_norm=3.5750269889831543, loss=1.2289035320281982
I0315 18:48:09.213720 139540685625088 logging_writer.py:48] [143500] global_step=143500, grad_norm=3.7924108505249023, loss=1.9226925373077393
I0315 18:51:20.075765 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:51:33.295947 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:51:45.656524 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:51:48.351989 139734377899840 submission_runner.py:420] Time since start: 60159.58s, 	Step: 143990, 	{'train/accuracy': 0.8576757907867432, 'train/loss': 0.5403394103050232, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 56339.21500205994, 'total_duration': 60159.57706785202, 'accumulated_submission_time': 56339.21500205994, 'accumulated_eval_time': 3811.030218601227, 'accumulated_logging_time': 4.232113361358643}
I0315 18:51:48.380254 139540534654720 logging_writer.py:48] [143990] accumulated_eval_time=3811.030219, accumulated_logging_time=4.232113, accumulated_submission_time=56339.215002, global_step=143990, preemption_count=0, score=56339.215002, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=60159.577068, train/accuracy=0.857676, train/loss=0.540339, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 18:51:52.882106 139540685625088 logging_writer.py:48] [144000] global_step=144000, grad_norm=3.7085742950439453, loss=1.8671127557754517
I0315 18:55:08.367620 139540534654720 logging_writer.py:48] [144500] global_step=144500, grad_norm=4.010756969451904, loss=3.8279733657836914
I0315 18:58:23.890502 139540685625088 logging_writer.py:48] [145000] global_step=145000, grad_norm=3.4131574630737305, loss=2.251707077026367
I0315 18:58:48.621716 139734377899840 spec.py:321] Evaluating on the training split.
I0315 18:59:01.831711 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 18:59:14.206145 139734377899840 spec.py:349] Evaluating on the test split.
I0315 18:59:16.909592 139734377899840 submission_runner.py:420] Time since start: 60608.13s, 	Step: 145065, 	{'train/accuracy': 0.8605859279632568, 'train/loss': 0.530600905418396, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 56759.219876766205, 'total_duration': 60608.134674072266, 'accumulated_submission_time': 56759.219876766205, 'accumulated_eval_time': 3839.318061351776, 'accumulated_logging_time': 4.458518743515015}
I0315 18:59:16.935213 139540534654720 logging_writer.py:48] [145065] accumulated_eval_time=3839.318061, accumulated_logging_time=4.458519, accumulated_submission_time=56759.219877, global_step=145065, preemption_count=0, score=56759.219877, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=60608.134674, train/accuracy=0.860586, train/loss=0.530601, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:02:07.364658 139540685625088 logging_writer.py:48] [145500] global_step=145500, grad_norm=4.049272060394287, loss=1.4862229824066162
I0315 19:05:22.916803 139540534654720 logging_writer.py:48] [146000] global_step=146000, grad_norm=3.302658796310425, loss=2.9692699909210205
I0315 19:06:16.958625 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:06:30.132217 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:06:42.495954 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:06:45.192835 139734377899840 submission_runner.py:420] Time since start: 61056.42s, 	Step: 146140, 	{'train/accuracy': 0.8607421517372131, 'train/loss': 0.5302925109863281, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 57179.19600915909, 'total_duration': 61056.417915821075, 'accumulated_submission_time': 57179.19600915909, 'accumulated_eval_time': 3867.55224609375, 'accumulated_logging_time': 4.492250204086304}
I0315 19:06:45.217478 139540685625088 logging_writer.py:48] [146140] accumulated_eval_time=3867.552246, accumulated_logging_time=4.492250, accumulated_submission_time=57179.196009, global_step=146140, preemption_count=0, score=57179.196009, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=61056.417916, train/accuracy=0.860742, train/loss=0.530293, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:09:06.365682 139540534654720 logging_writer.py:48] [146500] global_step=146500, grad_norm=4.189057350158691, loss=2.404827117919922
I0315 19:12:21.903706 139540685625088 logging_writer.py:48] [147000] global_step=147000, grad_norm=4.480495929718018, loss=3.669318199157715
I0315 19:13:45.289145 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:13:58.465439 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:14:10.872830 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:14:13.570704 139734377899840 submission_runner.py:420] Time since start: 61504.80s, 	Step: 147215, 	{'train/accuracy': 0.8565233945846558, 'train/loss': 0.545202910900116, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 57599.22167015076, 'total_duration': 61504.795778512955, 'accumulated_submission_time': 57599.22167015076, 'accumulated_eval_time': 3895.833779335022, 'accumulated_logging_time': 4.525409460067749}
I0315 19:14:13.599128 139540534654720 logging_writer.py:48] [147215] accumulated_eval_time=3895.833779, accumulated_logging_time=4.525409, accumulated_submission_time=57599.221670, global_step=147215, preemption_count=0, score=57599.221670, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=61504.795779, train/accuracy=0.856523, train/loss=0.545203, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:16:05.383188 139540685625088 logging_writer.py:48] [147500] global_step=147500, grad_norm=4.244166851043701, loss=3.828374147415161
I0315 19:19:20.924637 139540534654720 logging_writer.py:48] [148000] global_step=148000, grad_norm=3.3203837871551514, loss=1.3778250217437744
I0315 19:21:13.668232 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:21:26.819319 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:21:39.283303 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:21:41.965965 139734377899840 submission_runner.py:420] Time since start: 61953.19s, 	Step: 148290, 	{'train/accuracy': 0.862109363079071, 'train/loss': 0.5288084149360657, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58019.24427700043, 'total_duration': 61953.191044807434, 'accumulated_submission_time': 58019.24427700043, 'accumulated_eval_time': 3924.1314907073975, 'accumulated_logging_time': 4.562593698501587}
I0315 19:21:41.992304 139540685625088 logging_writer.py:48] [148290] accumulated_eval_time=3924.131491, accumulated_logging_time=4.562594, accumulated_submission_time=58019.244277, global_step=148290, preemption_count=0, score=58019.244277, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=61953.191045, train/accuracy=0.862109, train/loss=0.528808, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:23:04.497497 139540534654720 logging_writer.py:48] [148500] global_step=148500, grad_norm=3.7107346057891846, loss=1.322913646697998
I0315 19:26:20.074351 139540685625088 logging_writer.py:48] [149000] global_step=149000, grad_norm=3.4696743488311768, loss=1.2012426853179932
I0315 19:28:42.155957 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:28:55.322235 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:29:07.760071 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:29:10.457908 139734377899840 submission_runner.py:420] Time since start: 62401.68s, 	Step: 149365, 	{'train/accuracy': 0.8610156178474426, 'train/loss': 0.5339493155479431, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58439.35965394974, 'total_duration': 62401.6829867363, 'accumulated_submission_time': 58439.35965394974, 'accumulated_eval_time': 3952.4334218502045, 'accumulated_logging_time': 4.598416090011597}
I0315 19:29:10.485751 139540534654720 logging_writer.py:48] [149365] accumulated_eval_time=3952.433422, accumulated_logging_time=4.598416, accumulated_submission_time=58439.359654, global_step=149365, preemption_count=0, score=58439.359654, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=62401.682987, train/accuracy=0.861016, train/loss=0.533949, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:30:03.661320 139540685625088 logging_writer.py:48] [149500] global_step=149500, grad_norm=3.7624945640563965, loss=1.31850004196167
I0315 19:33:19.197990 139540534654720 logging_writer.py:48] [150000] global_step=150000, grad_norm=3.3646230697631836, loss=3.035353660583496
I0315 19:36:10.518625 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:36:23.656249 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:36:36.008282 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:36:38.713755 139734377899840 submission_runner.py:420] Time since start: 62849.94s, 	Step: 150440, 	{'train/accuracy': 0.8587109446525574, 'train/loss': 0.532126784324646, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58859.34544801712, 'total_duration': 62849.93879723549, 'accumulated_submission_time': 58859.34544801712, 'accumulated_eval_time': 3980.6284940242767, 'accumulated_logging_time': 4.635632276535034}
I0315 19:36:38.748328 139540685625088 logging_writer.py:48] [150440] accumulated_eval_time=3980.628494, accumulated_logging_time=4.635632, accumulated_submission_time=58859.345448, global_step=150440, preemption_count=0, score=58859.345448, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=62849.938797, train/accuracy=0.858711, train/loss=0.532127, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:37:02.602396 139540534654720 logging_writer.py:48] [150500] global_step=150500, grad_norm=3.97347092628479, loss=2.193092107772827
I0315 19:40:18.097923 139540685625088 logging_writer.py:48] [151000] global_step=151000, grad_norm=3.489408016204834, loss=1.2000864744186401
I0315 19:43:33.664786 139540534654720 logging_writer.py:48] [151500] global_step=151500, grad_norm=3.580718994140625, loss=2.0527427196502686
I0315 19:43:38.833266 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:43:51.978400 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:44:04.364222 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:44:07.058063 139734377899840 submission_runner.py:420] Time since start: 63298.28s, 	Step: 151515, 	{'train/accuracy': 0.8600780963897705, 'train/loss': 0.5306380987167358, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 59279.38299250603, 'total_duration': 63298.283148765564, 'accumulated_submission_time': 59279.38299250603, 'accumulated_eval_time': 4008.853268623352, 'accumulated_logging_time': 4.680060625076294}
I0315 19:44:07.083123 139540685625088 logging_writer.py:48] [151515] accumulated_eval_time=4008.853269, accumulated_logging_time=4.680061, accumulated_submission_time=59279.382993, global_step=151515, preemption_count=0, score=59279.382993, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=63298.283149, train/accuracy=0.860078, train/loss=0.530638, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:47:17.087126 139540534654720 logging_writer.py:48] [152000] global_step=152000, grad_norm=3.5054948329925537, loss=2.2826104164123535
I0315 19:50:32.595079 139540685625088 logging_writer.py:48] [152500] global_step=152500, grad_norm=3.7619972229003906, loss=3.5291357040405273
I0315 19:51:07.106375 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:51:20.240539 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:51:32.599835 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:51:35.298898 139734377899840 submission_runner.py:420] Time since start: 63746.52s, 	Step: 152590, 	{'train/accuracy': 0.8576562404632568, 'train/loss': 0.5374278426170349, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 59699.35824298859, 'total_duration': 63746.52398490906, 'accumulated_submission_time': 59699.35824298859, 'accumulated_eval_time': 4037.0457701683044, 'accumulated_logging_time': 4.714730501174927}
I0315 19:51:35.326968 139540534654720 logging_writer.py:48] [152590] accumulated_eval_time=4037.045770, accumulated_logging_time=4.714731, accumulated_submission_time=59699.358243, global_step=152590, preemption_count=0, score=59699.358243, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=63746.523985, train/accuracy=0.857656, train/loss=0.537428, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 19:54:15.977845 139540685625088 logging_writer.py:48] [153000] global_step=153000, grad_norm=4.107176780700684, loss=1.2203388214111328
I0315 19:57:31.541066 139540534654720 logging_writer.py:48] [153500] global_step=153500, grad_norm=3.5766661167144775, loss=2.3573741912841797
I0315 19:58:35.379459 139734377899840 spec.py:321] Evaluating on the training split.
I0315 19:58:48.540318 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 19:59:00.906182 139734377899840 spec.py:349] Evaluating on the test split.
I0315 19:59:03.603981 139734377899840 submission_runner.py:420] Time since start: 64194.83s, 	Step: 153665, 	{'train/accuracy': 0.8606249690055847, 'train/loss': 0.5324718952178955, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60119.36347913742, 'total_duration': 64194.829061985016, 'accumulated_submission_time': 60119.36347913742, 'accumulated_eval_time': 4065.270265340805, 'accumulated_logging_time': 4.751112937927246}
I0315 19:59:03.631480 139540685625088 logging_writer.py:48] [153665] accumulated_eval_time=4065.270265, accumulated_logging_time=4.751113, accumulated_submission_time=60119.363479, global_step=153665, preemption_count=0, score=60119.363479, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=64194.829062, train/accuracy=0.860625, train/loss=0.532472, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:01:15.034661 139540534654720 logging_writer.py:48] [154000] global_step=154000, grad_norm=3.7380590438842773, loss=3.5266404151916504
I0315 20:04:30.585879 139540685625088 logging_writer.py:48] [154500] global_step=154500, grad_norm=4.143516540527344, loss=1.3848943710327148
I0315 20:06:03.784785 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:06:16.949968 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:06:29.540604 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:06:32.240705 139734377899840 submission_runner.py:420] Time since start: 64643.47s, 	Step: 154740, 	{'train/accuracy': 0.8607226610183716, 'train/loss': 0.5319047570228577, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60539.47020316124, 'total_duration': 64643.465767383575, 'accumulated_submission_time': 60539.47020316124, 'accumulated_eval_time': 4093.7261395454407, 'accumulated_logging_time': 4.787616491317749}
I0315 20:06:32.270840 139540534654720 logging_writer.py:48] [154740] accumulated_eval_time=4093.726140, accumulated_logging_time=4.787616, accumulated_submission_time=60539.470203, global_step=154740, preemption_count=0, score=60539.470203, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=64643.465767, train/accuracy=0.860723, train/loss=0.531905, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:08:14.300895 139540685625088 logging_writer.py:48] [155000] global_step=155000, grad_norm=3.743043899536133, loss=1.6515860557556152
I0315 20:11:29.859907 139540534654720 logging_writer.py:48] [155500] global_step=155500, grad_norm=3.9337661266326904, loss=3.214556932449341
I0315 20:13:32.419726 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:13:45.591275 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:13:57.961666 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:14:00.653782 139734377899840 submission_runner.py:420] Time since start: 65091.88s, 	Step: 155815, 	{'train/accuracy': 0.8604296445846558, 'train/loss': 0.5312694907188416, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60959.57297253609, 'total_duration': 65091.87886476517, 'accumulated_submission_time': 60959.57297253609, 'accumulated_eval_time': 4121.9601809978485, 'accumulated_logging_time': 4.826525688171387}
I0315 20:14:00.679588 139540685625088 logging_writer.py:48] [155815] accumulated_eval_time=4121.960181, accumulated_logging_time=4.826526, accumulated_submission_time=60959.572973, global_step=155815, preemption_count=0, score=60959.572973, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=65091.878865, train/accuracy=0.860430, train/loss=0.531269, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:15:13.355770 139540534654720 logging_writer.py:48] [156000] global_step=156000, grad_norm=3.0824310779571533, loss=2.34952974319458
I0315 20:18:28.914141 139540685625088 logging_writer.py:48] [156500] global_step=156500, grad_norm=3.581939697265625, loss=1.325154423713684
I0315 20:21:00.756878 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:21:13.948354 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:21:26.288443 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:21:28.984359 139734377899840 submission_runner.py:420] Time since start: 65540.21s, 	Step: 156890, 	{'train/accuracy': 0.86195307970047, 'train/loss': 0.526210606098175, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 61379.602830171585, 'total_duration': 65540.20942354202, 'accumulated_submission_time': 61379.602830171585, 'accumulated_eval_time': 4150.187627077103, 'accumulated_logging_time': 4.86150860786438}
I0315 20:21:29.015112 139540534654720 logging_writer.py:48] [156890] accumulated_eval_time=4150.187627, accumulated_logging_time=4.861509, accumulated_submission_time=61379.602830, global_step=156890, preemption_count=0, score=61379.602830, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=65540.209424, train/accuracy=0.861953, train/loss=0.526211, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:22:12.464936 139540685625088 logging_writer.py:48] [157000] global_step=157000, grad_norm=3.300596237182617, loss=1.3606349229812622
I0315 20:25:27.990277 139540534654720 logging_writer.py:48] [157500] global_step=157500, grad_norm=3.8884992599487305, loss=1.4405968189239502
I0315 20:28:29.196634 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:28:42.385357 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:28:54.761789 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:28:57.467656 139734377899840 submission_runner.py:420] Time since start: 65988.69s, 	Step: 157965, 	{'train/accuracy': 0.8607031106948853, 'train/loss': 0.5282706022262573, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 61799.73689651489, 'total_duration': 65988.69274020195, 'accumulated_submission_time': 61799.73689651489, 'accumulated_eval_time': 4178.45863032341, 'accumulated_logging_time': 4.902294874191284}
I0315 20:28:57.496852 139540685625088 logging_writer.py:48] [157965] accumulated_eval_time=4178.458630, accumulated_logging_time=4.902295, accumulated_submission_time=61799.736897, global_step=157965, preemption_count=0, score=61799.736897, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=65988.692740, train/accuracy=0.860703, train/loss=0.528271, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:29:11.572022 139540534654720 logging_writer.py:48] [158000] global_step=158000, grad_norm=3.9332797527313232, loss=1.285191535949707
I0315 20:32:27.005222 139540685625088 logging_writer.py:48] [158500] global_step=158500, grad_norm=3.3484578132629395, loss=1.9621388912200928
I0315 20:35:42.575995 139540534654720 logging_writer.py:48] [159000] global_step=159000, grad_norm=3.7481069564819336, loss=1.7541868686676025
I0315 20:35:57.529162 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:36:10.709648 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:36:23.095563 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:36:25.787865 139734377899840 submission_runner.py:420] Time since start: 66437.01s, 	Step: 159040, 	{'train/accuracy': 0.8620898127555847, 'train/loss': 0.5255037546157837, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 62219.72119474411, 'total_duration': 66437.01294565201, 'accumulated_submission_time': 62219.72119474411, 'accumulated_eval_time': 4206.717297077179, 'accumulated_logging_time': 4.941739559173584}
I0315 20:36:25.816441 139540685625088 logging_writer.py:48] [159040] accumulated_eval_time=4206.717297, accumulated_logging_time=4.941740, accumulated_submission_time=62219.721195, global_step=159040, preemption_count=0, score=62219.721195, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=66437.012946, train/accuracy=0.862090, train/loss=0.525504, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:39:26.135109 139540534654720 logging_writer.py:48] [159500] global_step=159500, grad_norm=4.036590576171875, loss=3.506573438644409
I0315 20:42:41.759455 139540685625088 logging_writer.py:48] [160000] global_step=160000, grad_norm=3.1996805667877197, loss=2.444166898727417
I0315 20:43:26.036001 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:43:39.161567 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:43:51.502909 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:43:54.203634 139734377899840 submission_runner.py:420] Time since start: 66885.43s, 	Step: 160115, 	{'train/accuracy': 0.8607421517372131, 'train/loss': 0.5275111794471741, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 62639.89541435242, 'total_duration': 66885.42871928215, 'accumulated_submission_time': 62639.89541435242, 'accumulated_eval_time': 4234.88491153717, 'accumulated_logging_time': 4.978753328323364}
I0315 20:43:54.231514 139540534654720 logging_writer.py:48] [160115] accumulated_eval_time=4234.884912, accumulated_logging_time=4.978753, accumulated_submission_time=62639.895414, global_step=160115, preemption_count=0, score=62639.895414, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=66885.428719, train/accuracy=0.860742, train/loss=0.527511, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:46:25.111382 139540685625088 logging_writer.py:48] [160500] global_step=160500, grad_norm=3.3955395221710205, loss=1.3130513429641724
I0315 20:49:40.654947 139540534654720 logging_writer.py:48] [161000] global_step=161000, grad_norm=3.8826797008514404, loss=3.760000467300415
I0315 20:50:54.249094 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:51:07.432813 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:51:19.774541 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:51:22.472063 139734377899840 submission_runner.py:420] Time since start: 67333.70s, 	Step: 161190, 	{'train/accuracy': 0.8590429425239563, 'train/loss': 0.5375748872756958, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63059.86722278595, 'total_duration': 67333.69714355469, 'accumulated_submission_time': 63059.86722278595, 'accumulated_eval_time': 4263.107853651047, 'accumulated_logging_time': 5.014766693115234}
I0315 20:51:22.497978 139540685625088 logging_writer.py:48] [161190] accumulated_eval_time=4263.107854, accumulated_logging_time=5.014767, accumulated_submission_time=63059.867223, global_step=161190, preemption_count=0, score=63059.867223, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=67333.697144, train/accuracy=0.859043, train/loss=0.537575, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 20:53:24.083061 139540534654720 logging_writer.py:48] [161500] global_step=161500, grad_norm=3.3592917919158936, loss=1.9770827293395996
I0315 20:56:39.706192 139540685625088 logging_writer.py:48] [162000] global_step=162000, grad_norm=3.4148306846618652, loss=1.8987078666687012
I0315 20:58:22.646853 139734377899840 spec.py:321] Evaluating on the training split.
I0315 20:58:35.831309 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 20:58:48.203820 139734377899840 spec.py:349] Evaluating on the test split.
I0315 20:58:50.909955 139734377899840 submission_runner.py:420] Time since start: 67782.14s, 	Step: 162265, 	{'train/accuracy': 0.8607226610183716, 'train/loss': 0.5323317050933838, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63479.968104839325, 'total_duration': 67782.13503861427, 'accumulated_submission_time': 63479.968104839325, 'accumulated_eval_time': 4291.370937347412, 'accumulated_logging_time': 5.048900127410889}
I0315 20:58:50.936203 139540534654720 logging_writer.py:48] [162265] accumulated_eval_time=4291.370937, accumulated_logging_time=5.048900, accumulated_submission_time=63479.968105, global_step=162265, preemption_count=0, score=63479.968105, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=67782.135039, train/accuracy=0.860723, train/loss=0.532332, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:00:23.214943 139540685625088 logging_writer.py:48] [162500] global_step=162500, grad_norm=3.52017879486084, loss=1.8618581295013428
I0315 21:03:38.789137 139540534654720 logging_writer.py:48] [163000] global_step=163000, grad_norm=3.863295555114746, loss=1.4794923067092896
I0315 21:05:51.055886 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:06:04.245209 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:06:16.635260 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:06:19.339242 139734377899840 submission_runner.py:420] Time since start: 68230.56s, 	Step: 163340, 	{'train/accuracy': 0.8609374761581421, 'train/loss': 0.5290597677230835, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63900.0406870842, 'total_duration': 68230.56432247162, 'accumulated_submission_time': 63900.0406870842, 'accumulated_eval_time': 4319.654284477234, 'accumulated_logging_time': 5.083327293395996}
I0315 21:06:19.369107 139540685625088 logging_writer.py:48] [163340] accumulated_eval_time=4319.654284, accumulated_logging_time=5.083327, accumulated_submission_time=63900.040687, global_step=163340, preemption_count=0, score=63900.040687, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=68230.564322, train/accuracy=0.860937, train/loss=0.529060, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:07:22.291064 139540534654720 logging_writer.py:48] [163500] global_step=163500, grad_norm=4.057251930236816, loss=3.746805191040039
I0315 21:10:37.788254 139540685625088 logging_writer.py:48] [164000] global_step=164000, grad_norm=3.689934253692627, loss=1.7293440103530884
I0315 21:13:19.402689 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:13:32.566342 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:13:44.933770 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:13:47.623752 139734377899840 submission_runner.py:420] Time since start: 68678.85s, 	Step: 164415, 	{'train/accuracy': 0.8610156178474426, 'train/loss': 0.5297486186027527, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 64320.02638053894, 'total_duration': 68678.8488342762, 'accumulated_submission_time': 64320.02638053894, 'accumulated_eval_time': 4347.875331878662, 'accumulated_logging_time': 5.123032093048096}
I0315 21:13:47.650485 139540534654720 logging_writer.py:48] [164415] accumulated_eval_time=4347.875332, accumulated_logging_time=5.123032, accumulated_submission_time=64320.026381, global_step=164415, preemption_count=0, score=64320.026381, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=68678.848834, train/accuracy=0.861016, train/loss=0.529749, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:14:21.278177 139540685625088 logging_writer.py:48] [164500] global_step=164500, grad_norm=4.496897220611572, loss=1.8966810703277588
I0315 21:17:36.828550 139540534654720 logging_writer.py:48] [165000] global_step=165000, grad_norm=3.7542378902435303, loss=1.4336671829223633
I0315 21:20:47.795350 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:21:00.948621 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:21:13.555577 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:21:16.257039 139734377899840 submission_runner.py:420] Time since start: 69127.48s, 	Step: 165490, 	{'train/accuracy': 0.85755854845047, 'train/loss': 0.5375651717185974, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 64740.12442159653, 'total_duration': 69127.4820907116, 'accumulated_submission_time': 64740.12442159653, 'accumulated_eval_time': 4376.336975336075, 'accumulated_logging_time': 5.159077405929565}
I0315 21:21:16.290673 139540685625088 logging_writer.py:48] [165490] accumulated_eval_time=4376.336975, accumulated_logging_time=5.159077, accumulated_submission_time=64740.124422, global_step=165490, preemption_count=0, score=64740.124422, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=69127.482091, train/accuracy=0.857559, train/loss=0.537565, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:21:20.607860 139540534654720 logging_writer.py:48] [165500] global_step=165500, grad_norm=3.639808416366577, loss=2.3043744564056396
I0315 21:24:36.144824 139540685625088 logging_writer.py:48] [166000] global_step=166000, grad_norm=4.480521202087402, loss=2.0616657733917236
I0315 21:27:51.685195 139540534654720 logging_writer.py:48] [166500] global_step=166500, grad_norm=3.937917947769165, loss=3.685957670211792
I0315 21:28:16.415299 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:28:29.572327 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:28:46.254393 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:28:48.935539 139734377899840 submission_runner.py:420] Time since start: 69580.16s, 	Step: 166565, 	{'train/accuracy': 0.86048823595047, 'train/loss': 0.5354260206222534, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 65160.201233148575, 'total_duration': 69580.16062664986, 'accumulated_submission_time': 65160.201233148575, 'accumulated_eval_time': 4408.857195138931, 'accumulated_logging_time': 5.202617168426514}
I0315 21:28:48.961078 139540685625088 logging_writer.py:48] [166565] accumulated_eval_time=4408.857195, accumulated_logging_time=5.202617, accumulated_submission_time=65160.201233, global_step=166565, preemption_count=0, score=65160.201233, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=69580.160627, train/accuracy=0.860488, train/loss=0.535426, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:31:39.289182 139540534654720 logging_writer.py:48] [167000] global_step=167000, grad_norm=3.604375123977661, loss=2.320580005645752
I0315 21:34:54.873692 139540685625088 logging_writer.py:48] [167500] global_step=167500, grad_norm=3.5638844966888428, loss=1.2531883716583252
I0315 21:35:48.944907 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:36:02.092683 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:36:14.510266 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:36:17.229149 139734377899840 submission_runner.py:420] Time since start: 70028.45s, 	Step: 167640, 	{'train/accuracy': 0.8597851395606995, 'train/loss': 0.5338920950889587, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 65580.1396882534, 'total_duration': 70028.45423436165, 'accumulated_submission_time': 65580.1396882534, 'accumulated_eval_time': 4437.141412734985, 'accumulated_logging_time': 5.236555576324463}
I0315 21:36:17.255388 139540534654720 logging_writer.py:48] [167640] accumulated_eval_time=4437.141413, accumulated_logging_time=5.236556, accumulated_submission_time=65580.139688, global_step=167640, preemption_count=0, score=65580.139688, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=70028.454234, train/accuracy=0.859785, train/loss=0.533892, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:38:38.350253 139540685625088 logging_writer.py:48] [168000] global_step=168000, grad_norm=3.4419195652008057, loss=1.1374768018722534
I0315 21:41:53.932022 139540534654720 logging_writer.py:48] [168500] global_step=168500, grad_norm=3.321021556854248, loss=1.378032922744751
I0315 21:43:17.358313 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:43:30.470222 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:43:42.848970 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:43:45.540663 139734377899840 submission_runner.py:420] Time since start: 70476.77s, 	Step: 168715, 	{'train/accuracy': 0.8594530820846558, 'train/loss': 0.5353440642356873, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66000.19507908821, 'total_duration': 70476.7657456398, 'accumulated_submission_time': 66000.19507908821, 'accumulated_eval_time': 4465.323743104935, 'accumulated_logging_time': 5.2727274894714355}
I0315 21:43:45.567574 139540685625088 logging_writer.py:48] [168715] accumulated_eval_time=4465.323743, accumulated_logging_time=5.272727, accumulated_submission_time=66000.195079, global_step=168715, preemption_count=0, score=66000.195079, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=70476.765746, train/accuracy=0.859453, train/loss=0.535344, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:45:37.419481 139540534654720 logging_writer.py:48] [169000] global_step=169000, grad_norm=3.7968826293945312, loss=1.4616761207580566
I0315 21:48:52.972993 139540685625088 logging_writer.py:48] [169500] global_step=169500, grad_norm=4.092460632324219, loss=3.5183496475219727
I0315 21:50:45.674734 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:50:58.755503 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:51:11.126470 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:51:13.818323 139734377899840 submission_runner.py:420] Time since start: 70925.04s, 	Step: 169790, 	{'train/accuracy': 0.8575195074081421, 'train/loss': 0.5377094149589539, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66420.2550098896, 'total_duration': 70925.0434076786, 'accumulated_submission_time': 66420.2550098896, 'accumulated_eval_time': 4493.467316865921, 'accumulated_logging_time': 5.3090949058532715}
I0315 21:51:13.844574 139540534654720 logging_writer.py:48] [169790] accumulated_eval_time=4493.467317, accumulated_logging_time=5.309095, accumulated_submission_time=66420.255010, global_step=169790, preemption_count=0, score=66420.255010, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=70925.043408, train/accuracy=0.857520, train/loss=0.537709, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:52:36.283718 139540685625088 logging_writer.py:48] [170000] global_step=170000, grad_norm=3.7294678688049316, loss=3.383831024169922
I0315 21:55:51.856499 139540534654720 logging_writer.py:48] [170500] global_step=170500, grad_norm=3.293973445892334, loss=1.736367106437683
I0315 21:58:13.925674 139734377899840 spec.py:321] Evaluating on the training split.
I0315 21:58:26.979187 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 21:58:40.262960 139734377899840 spec.py:349] Evaluating on the test split.
I0315 21:58:42.947006 139734377899840 submission_runner.py:420] Time since start: 71374.17s, 	Step: 170865, 	{'train/accuracy': 0.8602538704872131, 'train/loss': 0.5354943871498108, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66840.29003763199, 'total_duration': 71374.17208337784, 'accumulated_submission_time': 66840.29003763199, 'accumulated_eval_time': 4522.488629102707, 'accumulated_logging_time': 5.343836307525635}
I0315 21:58:42.977706 139540685625088 logging_writer.py:48] [170865] accumulated_eval_time=4522.488629, accumulated_logging_time=5.343836, accumulated_submission_time=66840.290038, global_step=170865, preemption_count=0, score=66840.290038, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=71374.172083, train/accuracy=0.860254, train/loss=0.535494, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 21:59:36.086299 139540534654720 logging_writer.py:48] [171000] global_step=171000, grad_norm=3.618720769882202, loss=1.1050713062286377
I0315 22:02:51.616645 139540685625088 logging_writer.py:48] [171500] global_step=171500, grad_norm=3.9051055908203125, loss=1.4633771181106567
I0315 22:05:43.003638 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:05:56.058779 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:06:08.634445 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:06:11.333709 139734377899840 submission_runner.py:420] Time since start: 71822.56s, 	Step: 171940, 	{'train/accuracy': 0.85888671875, 'train/loss': 0.5339109897613525, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 67260.26974606514, 'total_duration': 71822.55878424644, 'accumulated_submission_time': 67260.26974606514, 'accumulated_eval_time': 4550.81867814064, 'accumulated_logging_time': 5.383878231048584}
I0315 22:06:11.361314 139540534654720 logging_writer.py:48] [171940] accumulated_eval_time=4550.818678, accumulated_logging_time=5.383878, accumulated_submission_time=67260.269746, global_step=171940, preemption_count=0, score=67260.269746, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=71822.558784, train/accuracy=0.858887, train/loss=0.533911, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:06:35.219007 139540685625088 logging_writer.py:48] [172000] global_step=172000, grad_norm=3.84104585647583, loss=3.4760067462921143
I0315 22:09:50.731158 139540534654720 logging_writer.py:48] [172500] global_step=172500, grad_norm=3.4000723361968994, loss=1.969620943069458
I0315 22:13:06.305643 139540685625088 logging_writer.py:48] [173000] global_step=173000, grad_norm=3.142512321472168, loss=2.433786392211914
I0315 22:13:11.482856 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:13:24.507505 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:13:36.966221 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:13:39.666423 139734377899840 submission_runner.py:420] Time since start: 72270.89s, 	Step: 173015, 	{'train/accuracy': 0.8616015315055847, 'train/loss': 0.5290973782539368, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 67680.34410786629, 'total_duration': 72270.89149141312, 'accumulated_submission_time': 67680.34410786629, 'accumulated_eval_time': 4579.00220656395, 'accumulated_logging_time': 5.420870304107666}
I0315 22:13:39.695435 139540534654720 logging_writer.py:48] [173015] accumulated_eval_time=4579.002207, accumulated_logging_time=5.420870, accumulated_submission_time=67680.344108, global_step=173015, preemption_count=0, score=67680.344108, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=72270.891491, train/accuracy=0.861602, train/loss=0.529097, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:16:49.731330 139540685625088 logging_writer.py:48] [173500] global_step=173500, grad_norm=3.5306637287139893, loss=3.2578344345092773
I0315 22:20:05.391410 139540534654720 logging_writer.py:48] [174000] global_step=174000, grad_norm=3.667341709136963, loss=1.3460861444473267
I0315 22:20:39.894001 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:20:52.867993 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:21:05.280504 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:21:07.975715 139734377899840 submission_runner.py:420] Time since start: 72719.20s, 	Step: 174090, 	{'train/accuracy': 0.8581640720367432, 'train/loss': 0.5384761095046997, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68100.49555897713, 'total_duration': 72719.20079088211, 'accumulated_submission_time': 68100.49555897713, 'accumulated_eval_time': 4607.083900690079, 'accumulated_logging_time': 5.459011554718018}
I0315 22:21:08.002213 139540685625088 logging_writer.py:48] [174090] accumulated_eval_time=4607.083901, accumulated_logging_time=5.459012, accumulated_submission_time=68100.495559, global_step=174090, preemption_count=0, score=68100.495559, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=72719.200791, train/accuracy=0.858164, train/loss=0.538476, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:23:48.694600 139540534654720 logging_writer.py:48] [174500] global_step=174500, grad_norm=3.417386054992676, loss=1.3631871938705444
I0315 22:27:04.243315 139540685625088 logging_writer.py:48] [175000] global_step=175000, grad_norm=4.286473274230957, loss=3.76248836517334
I0315 22:28:08.095941 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:28:21.120431 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:28:33.734829 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:28:36.424683 139734377899840 submission_runner.py:420] Time since start: 73167.65s, 	Step: 175165, 	{'train/accuracy': 0.8604101538658142, 'train/loss': 0.5355415940284729, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68520.54279351234, 'total_duration': 73167.64974188805, 'accumulated_submission_time': 68520.54279351234, 'accumulated_eval_time': 4635.41259765625, 'accumulated_logging_time': 5.493685960769653}
I0315 22:28:36.454870 139540534654720 logging_writer.py:48] [175165] accumulated_eval_time=4635.412598, accumulated_logging_time=5.493686, accumulated_submission_time=68520.542794, global_step=175165, preemption_count=0, score=68520.542794, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=73167.649742, train/accuracy=0.860410, train/loss=0.535542, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:30:47.767589 139540685625088 logging_writer.py:48] [175500] global_step=175500, grad_norm=3.37684965133667, loss=2.6448709964752197
I0315 22:34:03.342809 139540534654720 logging_writer.py:48] [176000] global_step=176000, grad_norm=3.7219207286834717, loss=2.6065592765808105
I0315 22:35:36.540409 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:35:49.568034 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:36:01.954519 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:36:04.655415 139734377899840 submission_runner.py:420] Time since start: 73615.88s, 	Step: 176240, 	{'train/accuracy': 0.8613476157188416, 'train/loss': 0.5301273465156555, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68940.58148026466, 'total_duration': 73615.88048815727, 'accumulated_submission_time': 68940.58148026466, 'accumulated_eval_time': 4663.5275757312775, 'accumulated_logging_time': 5.533310174942017}
I0315 22:36:04.683079 139540685625088 logging_writer.py:48] [176240] accumulated_eval_time=4663.527576, accumulated_logging_time=5.533310, accumulated_submission_time=68940.581480, global_step=176240, preemption_count=0, score=68940.581480, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=73615.880488, train/accuracy=0.861348, train/loss=0.530127, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:37:46.702419 139540534654720 logging_writer.py:48] [176500] global_step=176500, grad_norm=3.4359288215637207, loss=1.5412812232971191
I0315 22:41:02.270534 139540685625088 logging_writer.py:48] [177000] global_step=177000, grad_norm=3.8893232345581055, loss=1.3640071153640747
I0315 22:43:04.769122 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:43:17.811552 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:43:30.202249 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:43:32.898675 139734377899840 submission_runner.py:420] Time since start: 74064.12s, 	Step: 177315, 	{'train/accuracy': 0.8574804663658142, 'train/loss': 0.5385750532150269, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 69360.62168860435, 'total_duration': 74064.12375998497, 'accumulated_submission_time': 69360.62168860435, 'accumulated_eval_time': 4691.657100439072, 'accumulated_logging_time': 5.5693583488464355}
I0315 22:43:32.927583 139540534654720 logging_writer.py:48] [177315] accumulated_eval_time=4691.657100, accumulated_logging_time=5.569358, accumulated_submission_time=69360.621689, global_step=177315, preemption_count=0, score=69360.621689, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=74064.123760, train/accuracy=0.857480, train/loss=0.538575, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:44:45.699934 139540685625088 logging_writer.py:48] [177500] global_step=177500, grad_norm=4.3793253898620605, loss=1.3957797288894653
I0315 22:48:01.270975 139540534654720 logging_writer.py:48] [178000] global_step=178000, grad_norm=3.9431347846984863, loss=1.3643628358840942
I0315 22:50:33.109705 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:50:46.174901 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:50:58.549373 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:51:01.249162 139734377899840 submission_runner.py:420] Time since start: 74512.47s, 	Step: 178390, 	{'train/accuracy': 0.8599413633346558, 'train/loss': 0.5288510918617249, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 69780.7575404644, 'total_duration': 74512.47424793243, 'accumulated_submission_time': 69780.7575404644, 'accumulated_eval_time': 4719.79655790329, 'accumulated_logging_time': 5.6067774295806885}
I0315 22:51:01.278056 139540685625088 logging_writer.py:48] [178390] accumulated_eval_time=4719.796558, accumulated_logging_time=5.606777, accumulated_submission_time=69780.757540, global_step=178390, preemption_count=0, score=69780.757540, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=74512.474248, train/accuracy=0.859941, train/loss=0.528851, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:51:44.638782 139540534654720 logging_writer.py:48] [178500] global_step=178500, grad_norm=4.079058647155762, loss=1.3206120729446411
I0315 22:55:00.203156 139540685625088 logging_writer.py:48] [179000] global_step=179000, grad_norm=3.8867907524108887, loss=1.6538783311843872
I0315 22:58:01.322360 139734377899840 spec.py:321] Evaluating on the training split.
I0315 22:58:14.384345 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 22:58:26.777683 139734377899840 spec.py:349] Evaluating on the test split.
I0315 22:58:29.476348 139734377899840 submission_runner.py:420] Time since start: 74960.70s, 	Step: 179465, 	{'train/accuracy': 0.8600585460662842, 'train/loss': 0.534307599067688, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 70200.75301504135, 'total_duration': 74960.70142841339, 'accumulated_submission_time': 70200.75301504135, 'accumulated_eval_time': 4747.950520515442, 'accumulated_logging_time': 5.647037029266357}
I0315 22:58:29.505727 139540534654720 logging_writer.py:48] [179465] accumulated_eval_time=4747.950521, accumulated_logging_time=5.647037, accumulated_submission_time=70200.753015, global_step=179465, preemption_count=0, score=70200.753015, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=74960.701428, train/accuracy=0.860059, train/loss=0.534308, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 22:58:43.571012 139540685625088 logging_writer.py:48] [179500] global_step=179500, grad_norm=3.626983880996704, loss=2.758823871612549
I0315 23:01:59.086592 139540534654720 logging_writer.py:48] [180000] global_step=180000, grad_norm=3.4999001026153564, loss=1.4734959602355957
I0315 23:05:14.673370 139540685625088 logging_writer.py:48] [180500] global_step=180500, grad_norm=3.3213651180267334, loss=2.059743881225586
I0315 23:05:29.623245 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:05:42.696284 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:05:55.052849 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:05:57.752367 139734377899840 submission_runner.py:420] Time since start: 75408.98s, 	Step: 180540, 	{'train/accuracy': 0.8602148294448853, 'train/loss': 0.5280645489692688, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 70620.82184553146, 'total_duration': 75408.97744894028, 'accumulated_submission_time': 70620.82184553146, 'accumulated_eval_time': 4776.079607009888, 'accumulated_logging_time': 5.686467885971069}
I0315 23:05:57.780190 139540534654720 logging_writer.py:48] [180540] accumulated_eval_time=4776.079607, accumulated_logging_time=5.686468, accumulated_submission_time=70620.821846, global_step=180540, preemption_count=0, score=70620.821846, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=75408.977449, train/accuracy=0.860215, train/loss=0.528065, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:08:58.035171 139540685625088 logging_writer.py:48] [181000] global_step=181000, grad_norm=3.4258484840393066, loss=1.3515909910202026
I0315 23:12:13.637000 139540534654720 logging_writer.py:48] [181500] global_step=181500, grad_norm=3.7091047763824463, loss=1.677378535270691
I0315 23:12:57.919698 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:13:11.046267 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:13:23.387274 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:13:26.088048 139734377899840 submission_runner.py:420] Time since start: 75857.31s, 	Step: 181615, 	{'train/accuracy': 0.8608593344688416, 'train/loss': 0.5353047251701355, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71040.9156525135, 'total_duration': 75857.31313347816, 'accumulated_submission_time': 71040.9156525135, 'accumulated_eval_time': 4804.247930526733, 'accumulated_logging_time': 5.72279953956604}
I0315 23:13:26.114659 139540685625088 logging_writer.py:48] [181615] accumulated_eval_time=4804.247931, accumulated_logging_time=5.722800, accumulated_submission_time=71040.915653, global_step=181615, preemption_count=0, score=71040.915653, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=75857.313133, train/accuracy=0.860859, train/loss=0.535305, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:15:57.015591 139540534654720 logging_writer.py:48] [182000] global_step=182000, grad_norm=3.382680654525757, loss=1.3626384735107422
I0315 23:19:12.572093 139540685625088 logging_writer.py:48] [182500] global_step=182500, grad_norm=3.7224249839782715, loss=1.2944247722625732
I0315 23:20:26.192383 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:20:39.347455 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:20:51.699289 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:20:54.396733 139734377899840 submission_runner.py:420] Time since start: 76305.62s, 	Step: 182690, 	{'train/accuracy': 0.8613085746765137, 'train/loss': 0.5287285447120667, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71460.94657707214, 'total_duration': 76305.62181925774, 'accumulated_submission_time': 71460.94657707214, 'accumulated_eval_time': 4832.452265024185, 'accumulated_logging_time': 5.7577900886535645}
I0315 23:20:54.424383 139540534654720 logging_writer.py:48] [182690] accumulated_eval_time=4832.452265, accumulated_logging_time=5.757790, accumulated_submission_time=71460.946577, global_step=182690, preemption_count=0, score=71460.946577, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=76305.621819, train/accuracy=0.861309, train/loss=0.528729, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:22:56.012489 139540685625088 logging_writer.py:48] [183000] global_step=183000, grad_norm=4.043346881866455, loss=1.441807508468628
I0315 23:26:11.545889 139540534654720 logging_writer.py:48] [183500] global_step=183500, grad_norm=3.946277618408203, loss=1.5029094219207764
I0315 23:27:54.467525 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:28:07.625055 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:28:19.996356 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:28:22.688624 139734377899840 submission_runner.py:420] Time since start: 76753.91s, 	Step: 183765, 	{'train/accuracy': 0.8620507717132568, 'train/loss': 0.5245758891105652, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71880.94136238098, 'total_duration': 76753.91370868683, 'accumulated_submission_time': 71880.94136238098, 'accumulated_eval_time': 4860.673353433609, 'accumulated_logging_time': 5.795462369918823}
I0315 23:28:22.716755 139540685625088 logging_writer.py:48] [183765] accumulated_eval_time=4860.673353, accumulated_logging_time=5.795462, accumulated_submission_time=71880.941362, global_step=183765, preemption_count=0, score=71880.941362, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=76753.913709, train/accuracy=0.862051, train/loss=0.524576, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:29:54.948664 139540534654720 logging_writer.py:48] [184000] global_step=184000, grad_norm=3.432886838912964, loss=1.2742586135864258
I0315 23:33:10.460656 139540685625088 logging_writer.py:48] [184500] global_step=184500, grad_norm=3.849849224090576, loss=3.64591121673584
I0315 23:35:22.722886 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:35:35.912675 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:35:48.248085 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:35:50.930538 139734377899840 submission_runner.py:420] Time since start: 77202.16s, 	Step: 184840, 	{'train/accuracy': 0.85888671875, 'train/loss': 0.5343407392501831, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 72300.90002083778, 'total_duration': 77202.1556148529, 'accumulated_submission_time': 72300.90002083778, 'accumulated_eval_time': 4888.880987167358, 'accumulated_logging_time': 5.833362817764282}
I0315 23:35:50.960866 139540534654720 logging_writer.py:48] [184840] accumulated_eval_time=4888.880987, accumulated_logging_time=5.833363, accumulated_submission_time=72300.900021, global_step=184840, preemption_count=0, score=72300.900021, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=77202.155615, train/accuracy=0.858887, train/loss=0.534341, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:36:53.917438 139540685625088 logging_writer.py:48] [185000] global_step=185000, grad_norm=3.718714475631714, loss=3.196991443634033
I0315 23:40:09.482072 139540534654720 logging_writer.py:48] [185500] global_step=185500, grad_norm=3.968569278717041, loss=1.2023329734802246
I0315 23:42:51.066146 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:43:04.277407 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:43:16.644378 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:43:19.342418 139734377899840 submission_runner.py:420] Time since start: 77650.57s, 	Step: 185915, 	{'train/accuracy': 0.8598241806030273, 'train/loss': 0.5328004956245422, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 72720.95833444595, 'total_duration': 77650.56750535965, 'accumulated_submission_time': 72720.95833444595, 'accumulated_eval_time': 4917.157248735428, 'accumulated_logging_time': 5.871784448623657}
I0315 23:43:19.375231 139540685625088 logging_writer.py:48] [185915] accumulated_eval_time=4917.157249, accumulated_logging_time=5.871784, accumulated_submission_time=72720.958334, global_step=185915, preemption_count=0, score=72720.958334, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=77650.567505, train/accuracy=0.859824, train/loss=0.532800, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:43:52.970196 139540534654720 logging_writer.py:48] [186000] global_step=186000, grad_norm=3.6424193382263184, loss=1.4617987871170044
I0315 23:47:08.412840 139540685625088 logging_writer.py:48] [186500] global_step=186500, grad_norm=3.6107733249664307, loss=3.251169443130493
I0315 23:48:12.686568 139734377899840 spec.py:321] Evaluating on the training split.
I0315 23:48:25.877366 139734377899840 spec.py:333] Evaluating on the validation split.
I0315 23:48:38.262961 139734377899840 spec.py:349] Evaluating on the test split.
I0315 23:48:40.963312 139734377899840 submission_runner.py:420] Time since start: 77972.19s, 	Step: 186666, 	{'train/accuracy': 0.8631835579872131, 'train/loss': 0.5244746208190918, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 73014.23394227028, 'total_duration': 77972.18837976456, 'accumulated_submission_time': 73014.23394227028, 'accumulated_eval_time': 4945.43395447731, 'accumulated_logging_time': 5.913134336471558}
I0315 23:48:40.996431 139540534654720 logging_writer.py:48] [186666] accumulated_eval_time=4945.433954, accumulated_logging_time=5.913134, accumulated_submission_time=73014.233942, global_step=186666, preemption_count=0, score=73014.233942, test/accuracy=0.634600, test/loss=1.604389, test/num_examples=10000, total_duration=77972.188380, train/accuracy=0.863184, train/loss=0.524475, validation/accuracy=0.757000, validation/loss=0.976636, validation/num_examples=50000
I0315 23:48:41.020278 139540685625088 logging_writer.py:48] [186666] global_step=186666, preemption_count=0, score=73014.233942
I0315 23:48:41.661073 139734377899840 checkpoints.py:490] Saving checkpoint at step: 186666
I0315 23:48:43.849287 139734377899840 checkpoints.py:422] Saved checkpoint at /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1/checkpoint_186666
I0315 23:48:43.901135 139734377899840 checkpoint_utils.py:240] Saved checkpoint to /experiment_runs/variants_target_setting/study_0/imagenet_vit_glu_jax/trial_1/checkpoint_186666.
I0315 23:48:44.122744 139734377899840 submission_runner.py:593] Tuning trial 1/1
I0315 23:48:44.123012 139734377899840 submission_runner.py:594] Hyperparameters: Hyperparameters(learning_rate=0.0008445074561975979, beta1=0.8895758153482813, beta2=0.9978504782314613, warmup_steps=6999, weight_decay=0.08135402759553023)
I0315 23:48:44.134253 139734377899840 submission_runner.py:595] Metrics: {'eval_results': [(1, {'train/accuracy': 0.0007617187220603228, 'train/loss': 6.907756328582764, 'validation/accuracy': 0.0009999999310821295, 'validation/loss': 6.9077558517456055, 'validation/num_examples': 50000, 'test/accuracy': 0.0010000000474974513, 'test/loss': 6.907756805419922, 'test/num_examples': 10000, 'score': 41.72967982292175, 'total_duration': 88.55736303329468, 'accumulated_submission_time': 41.72967982292175, 'accumulated_eval_time': 46.82756495475769, 'accumulated_logging_time': 0, 'global_step': 1, 'preemption_count': 0}), (1013, {'train/accuracy': 0.016718748956918716, 'train/loss': 6.275478363037109, 'validation/accuracy': 0.016419999301433563, 'validation/loss': 6.287055492401123, 'validation/num_examples': 50000, 'test/accuracy': 0.012900000438094139, 'test/loss': 6.35337495803833, 'test/num_examples': 10000, 'score': 462.00606775283813, 'total_duration': 535.7927763462067, 'accumulated_submission_time': 462.00606775283813, 'accumulated_eval_time': 73.72658395767212, 'accumulated_logging_time': 0.026311874389648438, 'global_step': 1013, 'preemption_count': 0}), (2091, {'train/accuracy': 0.04833984375, 'train/loss': 5.618739604949951, 'validation/accuracy': 0.04793999716639519, 'validation/loss': 5.6484575271606445, 'validation/num_examples': 50000, 'test/accuracy': 0.03760000318288803, 'test/loss': 5.799871921539307, 'test/num_examples': 10000, 'score': 881.9834010601044, 'total_duration': 983.0003850460052, 'accumulated_submission_time': 881.9834010601044, 'accumulated_eval_time': 100.89297294616699, 'accumulated_logging_time': 0.052314043045043945, 'global_step': 2091, 'preemption_count': 0}), (3168, {'train/accuracy': 0.08355468511581421, 'train/loss': 5.139497756958008, 'validation/accuracy': 0.07763999700546265, 'validation/loss': 5.19743013381958, 'validation/num_examples': 50000, 'test/accuracy': 0.06160000339150429, 'test/loss': 5.409333229064941, 'test/num_examples': 10000, 'score': 1302.0117499828339, 'total_duration': 1430.0064475536346, 'accumulated_submission_time': 1302.0117499828339, 'accumulated_eval_time': 127.80873513221741, 'accumulated_logging_time': 0.07586097717285156, 'global_step': 3168, 'preemption_count': 0}), (4244, {'train/accuracy': 0.1238085925579071, 'train/loss': 4.724140644073486, 'validation/accuracy': 0.11699999868869781, 'validation/loss': 4.780978202819824, 'validation/num_examples': 50000, 'test/accuracy': 0.08860000222921371, 'test/loss': 5.077528953552246, 'test/num_examples': 10000, 'score': 1722.0173926353455, 'total_duration': 1877.2899487018585, 'accumulated_submission_time': 1722.0173926353455, 'accumulated_eval_time': 155.0246467590332, 'accumulated_logging_time': 0.09940552711486816, 'global_step': 4244, 'preemption_count': 0}), (5319, {'train/accuracy': 0.16015625, 'train/loss': 4.408839702606201, 'validation/accuracy': 0.1536400020122528, 'validation/loss': 4.4599199295043945, 'validation/num_examples': 50000, 'test/accuracy': 0.1153000071644783, 'test/loss': 4.801263332366943, 'test/num_examples': 10000, 'score': 2141.9897899627686, 'total_duration': 2324.321508169174, 'accumulated_submission_time': 2141.9897899627686, 'accumulated_eval_time': 182.01797032356262, 'accumulated_logging_time': 0.12645864486694336, 'global_step': 5319, 'preemption_count': 0}), (6394, {'train/accuracy': 0.20556640625, 'train/loss': 4.094365119934082, 'validation/accuracy': 0.18813998997211456, 'validation/loss': 4.188604831695557, 'validation/num_examples': 50000, 'test/accuracy': 0.14259999990463257, 'test/loss': 4.584964752197266, 'test/num_examples': 10000, 'score': 2562.018432378769, 'total_duration': 2771.4054958820343, 'accumulated_submission_time': 2562.018432378769, 'accumulated_eval_time': 209.00794339179993, 'accumulated_logging_time': 0.15285372734069824, 'global_step': 6394, 'preemption_count': 0}), (7469, {'train/accuracy': 0.23644530773162842, 'train/loss': 3.8184990882873535, 'validation/accuracy': 0.2181599885225296, 'validation/loss': 3.9290621280670166, 'validation/num_examples': 50000, 'test/accuracy': 0.16510000824928284, 'test/loss': 4.373502731323242, 'test/num_examples': 10000, 'score': 2982.2403173446655, 'total_duration': 3218.7005162239075, 'accumulated_submission_time': 2982.2403173446655, 'accumulated_eval_time': 236.0189769268036, 'accumulated_logging_time': 0.1773977279663086, 'global_step': 7469, 'preemption_count': 0}), (8543, {'train/accuracy': 0.27927732467651367, 'train/loss': 3.5570497512817383, 'validation/accuracy': 0.24913999438285828, 'validation/loss': 3.730613946914673, 'validation/num_examples': 50000, 'test/accuracy': 0.1925000101327896, 'test/loss': 4.175887107849121, 'test/num_examples': 10000, 'score': 3402.2068305015564, 'total_duration': 3665.7541551589966, 'accumulated_submission_time': 3402.2068305015564, 'accumulated_eval_time': 263.0356225967407, 'accumulated_logging_time': 0.20886874198913574, 'global_step': 8543, 'preemption_count': 0}), (9618, {'train/accuracy': 0.30341795086860657, 'train/loss': 3.334085702896118, 'validation/accuracy': 0.2781600058078766, 'validation/loss': 3.4821395874023438, 'validation/num_examples': 50000, 'test/accuracy': 0.21800000965595245, 'test/loss': 3.977511405944824, 'test/num_examples': 10000, 'score': 3822.4579470157623, 'total_duration': 4113.754719257355, 'accumulated_submission_time': 3822.4579470157623, 'accumulated_eval_time': 290.722473859787, 'accumulated_logging_time': 0.23267745971679688, 'global_step': 9618, 'preemption_count': 0}), (10693, {'train/accuracy': 0.3306835889816284, 'train/loss': 3.1823666095733643, 'validation/accuracy': 0.30776000022888184, 'validation/loss': 3.304899215698242, 'validation/num_examples': 50000, 'test/accuracy': 0.23990000784397125, 'test/loss': 3.8208560943603516, 'test/num_examples': 10000, 'score': 4242.626497507095, 'total_duration': 4561.009375572205, 'accumulated_submission_time': 4242.626497507095, 'accumulated_eval_time': 317.747389793396, 'accumulated_logging_time': 0.25598788261413574, 'global_step': 10693, 'preemption_count': 0}), (11768, {'train/accuracy': 0.3617578148841858, 'train/loss': 3.022171974182129, 'validation/accuracy': 0.33142000436782837, 'validation/loss': 3.1789186000823975, 'validation/num_examples': 50000, 'test/accuracy': 0.25460001826286316, 'test/loss': 3.7280092239379883, 'test/num_examples': 10000, 'score': 4662.86850976944, 'total_duration': 5008.3557913303375, 'accumulated_submission_time': 4662.86850976944, 'accumulated_eval_time': 344.7848219871521, 'accumulated_logging_time': 0.2850813865661621, 'global_step': 11768, 'preemption_count': 0}), (12843, {'train/accuracy': 0.3828710913658142, 'train/loss': 2.8559679985046387, 'validation/accuracy': 0.3553999960422516, 'validation/loss': 3.0134873390197754, 'validation/num_examples': 50000, 'test/accuracy': 0.2738000154495239, 'test/loss': 3.567352533340454, 'test/num_examples': 10000, 'score': 5082.946170091629, 'total_duration': 5455.77977514267, 'accumulated_submission_time': 5082.946170091629, 'accumulated_eval_time': 372.06721353530884, 'accumulated_logging_time': 0.31165504455566406, 'global_step': 12843, 'preemption_count': 0}), (13918, {'train/accuracy': 0.4347265660762787, 'train/loss': 2.5692591667175293, 'validation/accuracy': 0.37498000264167786, 'validation/loss': 2.8813555240631104, 'validation/num_examples': 50000, 'test/accuracy': 0.2930000126361847, 'test/loss': 3.458757162094116, 'test/num_examples': 10000, 'score': 5503.202824115753, 'total_duration': 5903.109926223755, 'accumulated_submission_time': 5503.202824115753, 'accumulated_eval_time': 399.0784823894501, 'accumulated_logging_time': 0.33634138107299805, 'global_step': 13918, 'preemption_count': 0}), (14993, {'train/accuracy': 0.4290429651737213, 'train/loss': 2.589291572570801, 'validation/accuracy': 0.39593997597694397, 'validation/loss': 2.756913661956787, 'validation/num_examples': 50000, 'test/accuracy': 0.31070002913475037, 'test/loss': 3.3564560413360596, 'test/num_examples': 10000, 'score': 5923.3575963974, 'total_duration': 6350.450917482376, 'accumulated_submission_time': 5923.3575963974, 'accumulated_eval_time': 426.20317244529724, 'accumulated_logging_time': 0.3604750633239746, 'global_step': 14993, 'preemption_count': 0}), (16068, {'train/accuracy': 0.4355859160423279, 'train/loss': 2.5344467163085938, 'validation/accuracy': 0.4030799865722656, 'validation/loss': 2.7032179832458496, 'validation/num_examples': 50000, 'test/accuracy': 0.3110000193119049, 'test/loss': 3.3090555667877197, 'test/num_examples': 10000, 'score': 6343.56699514389, 'total_duration': 6797.920631885529, 'accumulated_submission_time': 6343.56699514389, 'accumulated_eval_time': 453.39901423454285, 'accumulated_logging_time': 0.38715529441833496, 'global_step': 16068, 'preemption_count': 0}), (17143, {'train/accuracy': 0.4674023389816284, 'train/loss': 2.382639169692993, 'validation/accuracy': 0.42239999771118164, 'validation/loss': 2.6041572093963623, 'validation/num_examples': 50000, 'test/accuracy': 0.32500001788139343, 'test/loss': 3.2311201095581055, 'test/num_examples': 10000, 'score': 6763.80282998085, 'total_duration': 7245.421663284302, 'accumulated_submission_time': 6763.80282998085, 'accumulated_eval_time': 480.5976753234863, 'accumulated_logging_time': 0.4140584468841553, 'global_step': 17143, 'preemption_count': 0}), (18218, {'train/accuracy': 0.45326170325279236, 'train/loss': 2.457263946533203, 'validation/accuracy': 0.42010000348091125, 'validation/loss': 2.6309633255004883, 'validation/num_examples': 50000, 'test/accuracy': 0.3278000056743622, 'test/loss': 3.2264232635498047, 'test/num_examples': 10000, 'score': 7183.971779346466, 'total_duration': 7693.234092712402, 'accumulated_submission_time': 7183.971779346466, 'accumulated_eval_time': 508.1776280403137, 'accumulated_logging_time': 0.43997907638549805, 'global_step': 18218, 'preemption_count': 0}), (19293, {'train/accuracy': 0.4686523377895355, 'train/loss': 2.34665846824646, 'validation/accuracy': 0.43441998958587646, 'validation/loss': 2.5446348190307617, 'validation/num_examples': 50000, 'test/accuracy': 0.33560001850128174, 'test/loss': 3.165062665939331, 'test/num_examples': 10000, 'score': 7604.140007734299, 'total_duration': 8140.908233880997, 'accumulated_submission_time': 7604.140007734299, 'accumulated_eval_time': 535.6079642772675, 'accumulated_logging_time': 0.477703332901001, 'global_step': 19293, 'preemption_count': 0}), (20368, {'train/accuracy': 0.48093748092651367, 'train/loss': 2.3270905017852783, 'validation/accuracy': 0.44312000274658203, 'validation/loss': 2.5323879718780518, 'validation/num_examples': 50000, 'test/accuracy': 0.34130001068115234, 'test/loss': 3.1465437412261963, 'test/num_examples': 10000, 'score': 8024.4110107421875, 'total_duration': 8588.818693876266, 'accumulated_submission_time': 8024.4110107421875, 'accumulated_eval_time': 563.1773550510406, 'accumulated_logging_time': 0.5101757049560547, 'global_step': 20368, 'preemption_count': 0}), (21443, {'train/accuracy': 0.4955078065395355, 'train/loss': 2.2387301921844482, 'validation/accuracy': 0.4577399790287018, 'validation/loss': 2.429197311401367, 'validation/num_examples': 50000, 'test/accuracy': 0.35510000586509705, 'test/loss': 3.056088447570801, 'test/num_examples': 10000, 'score': 8444.608211994171, 'total_duration': 9036.673830986023, 'accumulated_submission_time': 8444.608211994171, 'accumulated_eval_time': 590.7654292583466, 'accumulated_logging_time': 0.5419635772705078, 'global_step': 21443, 'preemption_count': 0}), (22518, {'train/accuracy': 0.5196679830551147, 'train/loss': 2.116511821746826, 'validation/accuracy': 0.46661999821662903, 'validation/loss': 2.3763182163238525, 'validation/num_examples': 50000, 'test/accuracy': 0.36330002546310425, 'test/loss': 3.0050151348114014, 'test/num_examples': 10000, 'score': 8864.854481458664, 'total_duration': 9484.614896535873, 'accumulated_submission_time': 8864.854481458664, 'accumulated_eval_time': 618.3871674537659, 'accumulated_logging_time': 0.5770328044891357, 'global_step': 22518, 'preemption_count': 0}), (23593, {'train/accuracy': 0.5162890553474426, 'train/loss': 2.1125574111938477, 'validation/accuracy': 0.4773399829864502, 'validation/loss': 2.3147103786468506, 'validation/num_examples': 50000, 'test/accuracy': 0.3775000274181366, 'test/loss': 2.9368526935577393, 'test/num_examples': 10000, 'score': 9285.034385204315, 'total_duration': 9933.46540260315, 'accumulated_submission_time': 9285.034385204315, 'accumulated_eval_time': 646.9943106174469, 'accumulated_logging_time': 0.6027960777282715, 'global_step': 23593, 'preemption_count': 0}), (24668, {'train/accuracy': 0.5253124833106995, 'train/loss': 2.0703892707824707, 'validation/accuracy': 0.483379989862442, 'validation/loss': 2.2770378589630127, 'validation/num_examples': 50000, 'test/accuracy': 0.3769000172615051, 'test/loss': 2.9155163764953613, 'test/num_examples': 10000, 'score': 9705.235731124878, 'total_duration': 10381.610446214676, 'accumulated_submission_time': 9705.235731124878, 'accumulated_eval_time': 674.871443271637, 'accumulated_logging_time': 0.6316502094268799, 'global_step': 24668, 'preemption_count': 0}), (25743, {'train/accuracy': 0.5356835722923279, 'train/loss': 2.03143572807312, 'validation/accuracy': 0.48881998658180237, 'validation/loss': 2.2614190578460693, 'validation/num_examples': 50000, 'test/accuracy': 0.3850000202655792, 'test/loss': 2.894301176071167, 'test/num_examples': 10000, 'score': 10125.427013635635, 'total_duration': 10829.696096420288, 'accumulated_submission_time': 10125.427013635635, 'accumulated_eval_time': 702.6989147663116, 'accumulated_logging_time': 0.6608777046203613, 'global_step': 25743, 'preemption_count': 0}), (26818, {'train/accuracy': 0.5406249761581421, 'train/loss': 1.9762295484542847, 'validation/accuracy': 0.5010200142860413, 'validation/loss': 2.181331157684326, 'validation/num_examples': 50000, 'test/accuracy': 0.3930000066757202, 'test/loss': 2.834824562072754, 'test/num_examples': 10000, 'score': 10545.649332761765, 'total_duration': 11277.784814834595, 'accumulated_submission_time': 10545.649332761765, 'accumulated_eval_time': 730.4974730014801, 'accumulated_logging_time': 0.691148042678833, 'global_step': 26818, 'preemption_count': 0}), (27893, {'train/accuracy': 0.570507824420929, 'train/loss': 1.8765980005264282, 'validation/accuracy': 0.5060799717903137, 'validation/loss': 2.1884729862213135, 'validation/num_examples': 50000, 'test/accuracy': 0.39590001106262207, 'test/loss': 2.8308162689208984, 'test/num_examples': 10000, 'score': 10965.946343421936, 'total_duration': 11725.935274362564, 'accumulated_submission_time': 10965.946343421936, 'accumulated_eval_time': 758.2779412269592, 'accumulated_logging_time': 0.7246453762054443, 'global_step': 27893, 'preemption_count': 0}), (28968, {'train/accuracy': 0.5558984279632568, 'train/loss': 1.9142109155654907, 'validation/accuracy': 0.5089600086212158, 'validation/loss': 2.141429901123047, 'validation/num_examples': 50000, 'test/accuracy': 0.4043000340461731, 'test/loss': 2.7905051708221436, 'test/num_examples': 10000, 'score': 11386.19047832489, 'total_duration': 12174.090614080429, 'accumulated_submission_time': 11386.19047832489, 'accumulated_eval_time': 786.1237938404083, 'accumulated_logging_time': 0.7524659633636475, 'global_step': 28968, 'preemption_count': 0}), (30043, {'train/accuracy': 0.5616406202316284, 'train/loss': 1.890612006187439, 'validation/accuracy': 0.5192800164222717, 'validation/loss': 2.092430353164673, 'validation/num_examples': 50000, 'test/accuracy': 0.40220001339912415, 'test/loss': 2.742039680480957, 'test/num_examples': 10000, 'score': 11806.372581005096, 'total_duration': 12622.341912984848, 'accumulated_submission_time': 11806.372581005096, 'accumulated_eval_time': 814.1186220645905, 'accumulated_logging_time': 0.788611888885498, 'global_step': 30043, 'preemption_count': 0}), (31118, {'train/accuracy': 0.5644921660423279, 'train/loss': 1.891753911972046, 'validation/accuracy': 0.5156599879264832, 'validation/loss': 2.124831438064575, 'validation/num_examples': 50000, 'test/accuracy': 0.40310001373291016, 'test/loss': 2.7682459354400635, 'test/num_examples': 10000, 'score': 12226.592665433884, 'total_duration': 13070.643585920334, 'accumulated_submission_time': 12226.592665433884, 'accumulated_eval_time': 842.1354243755341, 'accumulated_logging_time': 0.8152530193328857, 'global_step': 31118, 'preemption_count': 0}), (32193, {'train/accuracy': 0.5709765553474426, 'train/loss': 1.8355311155319214, 'validation/accuracy': 0.5263000130653381, 'validation/loss': 2.0540130138397217, 'validation/num_examples': 50000, 'test/accuracy': 0.41510000824928284, 'test/loss': 2.7045395374298096, 'test/num_examples': 10000, 'score': 12646.741933107376, 'total_duration': 13518.917974710464, 'accumulated_submission_time': 12646.741933107376, 'accumulated_eval_time': 870.1968598365784, 'accumulated_logging_time': 0.8407182693481445, 'global_step': 32193, 'preemption_count': 0}), (33268, {'train/accuracy': 0.6173632740974426, 'train/loss': 1.6312971115112305, 'validation/accuracy': 0.5347200036048889, 'validation/loss': 2.0119359493255615, 'validation/num_examples': 50000, 'test/accuracy': 0.4172000288963318, 'test/loss': 2.6746208667755127, 'test/num_examples': 10000, 'score': 13066.884756326675, 'total_duration': 13967.424229860306, 'accumulated_submission_time': 13066.884756326675, 'accumulated_eval_time': 898.4931993484497, 'accumulated_logging_time': 0.8703837394714355, 'global_step': 33268, 'preemption_count': 0}), (34343, {'train/accuracy': 0.5891015529632568, 'train/loss': 1.746524453163147, 'validation/accuracy': 0.5367000102996826, 'validation/loss': 1.9880625009536743, 'validation/num_examples': 50000, 'test/accuracy': 0.42170003056526184, 'test/loss': 2.6583588123321533, 'test/num_examples': 10000, 'score': 13487.050795793533, 'total_duration': 14415.766685247421, 'accumulated_submission_time': 13487.050795793533, 'accumulated_eval_time': 926.6028730869293, 'accumulated_logging_time': 0.8991312980651855, 'global_step': 34343, 'preemption_count': 0}), (35418, {'train/accuracy': 0.5856054425239563, 'train/loss': 1.7603331804275513, 'validation/accuracy': 0.542199969291687, 'validation/loss': 1.9779938459396362, 'validation/num_examples': 50000, 'test/accuracy': 0.41940000653266907, 'test/loss': 2.6502013206481934, 'test/num_examples': 10000, 'score': 13907.255617380142, 'total_duration': 14864.1759724617, 'accumulated_submission_time': 13907.255617380142, 'accumulated_eval_time': 954.7406280040741, 'accumulated_logging_time': 0.9276912212371826, 'global_step': 35418, 'preemption_count': 0}), (36493, {'train/accuracy': 0.5997265577316284, 'train/loss': 1.7268105745315552, 'validation/accuracy': 0.5432999730110168, 'validation/loss': 1.9965629577636719, 'validation/num_examples': 50000, 'test/accuracy': 0.4263000190258026, 'test/loss': 2.640662908554077, 'test/num_examples': 10000, 'score': 14327.414219141006, 'total_duration': 15312.552569150925, 'accumulated_submission_time': 14327.414219141006, 'accumulated_eval_time': 982.8827528953552, 'accumulated_logging_time': 0.9647958278656006, 'global_step': 36493, 'preemption_count': 0}), (37568, {'train/accuracy': 0.6006640195846558, 'train/loss': 1.7108898162841797, 'validation/accuracy': 0.5539000034332275, 'validation/loss': 1.9328171014785767, 'validation/num_examples': 50000, 'test/accuracy': 0.43290001153945923, 'test/loss': 2.5919063091278076, 'test/num_examples': 10000, 'score': 14747.632803916931, 'total_duration': 15761.075187206268, 'accumulated_submission_time': 14747.632803916931, 'accumulated_eval_time': 1011.1202862262726, 'accumulated_logging_time': 0.9931976795196533, 'global_step': 37568, 'preemption_count': 0}), (38643, {'train/accuracy': 0.6182226538658142, 'train/loss': 1.598379135131836, 'validation/accuracy': 0.5583999752998352, 'validation/loss': 1.8778663873672485, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.5246849060058594, 'test/num_examples': 10000, 'score': 15167.889869451523, 'total_duration': 16209.667258501053, 'accumulated_submission_time': 15167.889869451523, 'accumulated_eval_time': 1039.3915419578552, 'accumulated_logging_time': 1.0191874504089355, 'global_step': 38643, 'preemption_count': 0}), (39718, {'train/accuracy': 0.6103320121765137, 'train/loss': 1.6485371589660645, 'validation/accuracy': 0.562559962272644, 'validation/loss': 1.8861223459243774, 'validation/num_examples': 50000, 'test/accuracy': 0.4458000063896179, 'test/loss': 2.535008430480957, 'test/num_examples': 10000, 'score': 15588.118755817413, 'total_duration': 16658.228201389313, 'accumulated_submission_time': 15588.118755817413, 'accumulated_eval_time': 1067.6589496135712, 'accumulated_logging_time': 1.0449261665344238, 'global_step': 39718, 'preemption_count': 0}), (40793, {'train/accuracy': 0.6161327958106995, 'train/loss': 1.6052472591400146, 'validation/accuracy': 0.5676400065422058, 'validation/loss': 1.839556097984314, 'validation/num_examples': 50000, 'test/accuracy': 0.44950002431869507, 'test/loss': 2.5017149448394775, 'test/num_examples': 10000, 'score': 16008.369101762772, 'total_duration': 17106.836500883102, 'accumulated_submission_time': 16008.369101762772, 'accumulated_eval_time': 1095.9517030715942, 'accumulated_logging_time': 1.072103500366211, 'global_step': 40793, 'preemption_count': 0}), (41868, {'train/accuracy': 0.6323046684265137, 'train/loss': 1.5458195209503174, 'validation/accuracy': 0.5681799650192261, 'validation/loss': 1.8447296619415283, 'validation/num_examples': 50000, 'test/accuracy': 0.4515000283718109, 'test/loss': 2.504584312438965, 'test/num_examples': 10000, 'score': 16428.54066300392, 'total_duration': 17555.354459047318, 'accumulated_submission_time': 16428.54066300392, 'accumulated_eval_time': 1124.2281475067139, 'accumulated_logging_time': 1.1044514179229736, 'global_step': 41868, 'preemption_count': 0}), (42943, {'train/accuracy': 0.62109375, 'train/loss': 1.5963397026062012, 'validation/accuracy': 0.569379985332489, 'validation/loss': 1.8445096015930176, 'validation/num_examples': 50000, 'test/accuracy': 0.45570001006126404, 'test/loss': 2.490640640258789, 'test/num_examples': 10000, 'score': 16848.79888153076, 'total_duration': 18003.914548397064, 'accumulated_submission_time': 16848.79888153076, 'accumulated_eval_time': 1152.4645340442657, 'accumulated_logging_time': 1.1316595077514648, 'global_step': 42943, 'preemption_count': 0}), (44017, {'train/accuracy': 0.6287695169448853, 'train/loss': 1.566895604133606, 'validation/accuracy': 0.576200008392334, 'validation/loss': 1.8047599792480469, 'validation/num_examples': 50000, 'test/accuracy': 0.45830002427101135, 'test/loss': 2.45627498626709, 'test/num_examples': 10000, 'score': 17268.929253578186, 'total_duration': 18452.478810548782, 'accumulated_submission_time': 17268.929253578186, 'accumulated_eval_time': 1180.829502105713, 'accumulated_logging_time': 1.1626203060150146, 'global_step': 44017, 'preemption_count': 0}), (45092, {'train/accuracy': 0.634960949420929, 'train/loss': 1.5245351791381836, 'validation/accuracy': 0.5781999826431274, 'validation/loss': 1.7938686609268188, 'validation/num_examples': 50000, 'test/accuracy': 0.45810002088546753, 'test/loss': 2.4540762901306152, 'test/num_examples': 10000, 'score': 17689.10785293579, 'total_duration': 18901.07377076149, 'accumulated_submission_time': 17689.10785293579, 'accumulated_eval_time': 1209.1742882728577, 'accumulated_logging_time': 1.1968097686767578, 'global_step': 45092, 'preemption_count': 0}), (46167, {'train/accuracy': 0.6251757740974426, 'train/loss': 1.5695594549179077, 'validation/accuracy': 0.5769000053405762, 'validation/loss': 1.8058549165725708, 'validation/num_examples': 50000, 'test/accuracy': 0.460500031709671, 'test/loss': 2.470344305038452, 'test/num_examples': 10000, 'score': 18109.35847568512, 'total_duration': 19349.652705192566, 'accumulated_submission_time': 18109.35847568512, 'accumulated_eval_time': 1237.4322583675385, 'accumulated_logging_time': 1.2294011116027832, 'global_step': 46167, 'preemption_count': 0}), (47242, {'train/accuracy': 0.6563280820846558, 'train/loss': 1.4442133903503418, 'validation/accuracy': 0.5828199982643127, 'validation/loss': 1.7790160179138184, 'validation/num_examples': 50000, 'test/accuracy': 0.46790000796318054, 'test/loss': 2.432217597961426, 'test/num_examples': 10000, 'score': 18529.57877254486, 'total_duration': 19798.17009449005, 'accumulated_submission_time': 18529.57877254486, 'accumulated_eval_time': 1265.6619102954865, 'accumulated_logging_time': 1.2582430839538574, 'global_step': 47242, 'preemption_count': 0}), (48317, {'train/accuracy': 0.6399804353713989, 'train/loss': 1.4858754873275757, 'validation/accuracy': 0.5850799679756165, 'validation/loss': 1.7439395189285278, 'validation/num_examples': 50000, 'test/accuracy': 0.467600017786026, 'test/loss': 2.4006543159484863, 'test/num_examples': 10000, 'score': 18949.731778621674, 'total_duration': 20246.544842243195, 'accumulated_submission_time': 18949.731778621674, 'accumulated_eval_time': 1293.817842245102, 'accumulated_logging_time': 1.2849884033203125, 'global_step': 48317, 'preemption_count': 0}), (49392, {'train/accuracy': 0.6422656178474426, 'train/loss': 1.4632335901260376, 'validation/accuracy': 0.5943599939346313, 'validation/loss': 1.6997281312942505, 'validation/num_examples': 50000, 'test/accuracy': 0.48190003633499146, 'test/loss': 2.353092670440674, 'test/num_examples': 10000, 'score': 19369.939849853516, 'total_duration': 20695.021906375885, 'accumulated_submission_time': 19369.939849853516, 'accumulated_eval_time': 1322.0201544761658, 'accumulated_logging_time': 1.3136389255523682, 'global_step': 49392, 'preemption_count': 0}), (50467, {'train/accuracy': 0.655566394329071, 'train/loss': 1.4283013343811035, 'validation/accuracy': 0.5932799577713013, 'validation/loss': 1.7206931114196777, 'validation/num_examples': 50000, 'test/accuracy': 0.4756000339984894, 'test/loss': 2.3874094486236572, 'test/num_examples': 10000, 'score': 19790.172041893005, 'total_duration': 21143.512743234634, 'accumulated_submission_time': 19790.172041893005, 'accumulated_eval_time': 1350.2092118263245, 'accumulated_logging_time': 1.3454182147979736, 'global_step': 50467, 'preemption_count': 0}), (51542, {'train/accuracy': 0.6568750143051147, 'train/loss': 1.4333698749542236, 'validation/accuracy': 0.6020399928092957, 'validation/loss': 1.684518814086914, 'validation/num_examples': 50000, 'test/accuracy': 0.4845000207424164, 'test/loss': 2.354658365249634, 'test/num_examples': 10000, 'score': 20210.40957069397, 'total_duration': 21592.355147123337, 'accumulated_submission_time': 20210.40957069397, 'accumulated_eval_time': 1378.7460765838623, 'accumulated_logging_time': 1.3763620853424072, 'global_step': 51542, 'preemption_count': 0}), (52617, {'train/accuracy': 0.6830663681030273, 'train/loss': 1.2850286960601807, 'validation/accuracy': 0.5993599891662598, 'validation/loss': 1.6752032041549683, 'validation/num_examples': 50000, 'test/accuracy': 0.4782000184059143, 'test/loss': 2.3473029136657715, 'test/num_examples': 10000, 'score': 20630.652017354965, 'total_duration': 22040.806235551834, 'accumulated_submission_time': 20630.652017354965, 'accumulated_eval_time': 1406.8904960155487, 'accumulated_logging_time': 1.4034199714660645, 'global_step': 52617, 'preemption_count': 0}), (53692, {'train/accuracy': 0.6595507860183716, 'train/loss': 1.4042620658874512, 'validation/accuracy': 0.6054999828338623, 'validation/loss': 1.669420838356018, 'validation/num_examples': 50000, 'test/accuracy': 0.48570001125335693, 'test/loss': 2.336071252822876, 'test/num_examples': 10000, 'score': 21050.792801380157, 'total_duration': 22489.067804336548, 'accumulated_submission_time': 21050.792801380157, 'accumulated_eval_time': 1434.9433960914612, 'accumulated_logging_time': 1.4332911968231201, 'global_step': 53692, 'preemption_count': 0}), (54766, {'train/accuracy': 0.6583788990974426, 'train/loss': 1.3919808864593506, 'validation/accuracy': 0.6048600077629089, 'validation/loss': 1.6459424495697021, 'validation/num_examples': 50000, 'test/accuracy': 0.48820000886917114, 'test/loss': 2.3061442375183105, 'test/num_examples': 10000, 'score': 21470.724470615387, 'total_duration': 22937.150980710983, 'accumulated_submission_time': 21470.724470615387, 'accumulated_eval_time': 1463.02574801445, 'accumulated_logging_time': 1.4640347957611084, 'global_step': 54766, 'preemption_count': 0}), (55840, {'train/accuracy': 0.67626953125, 'train/loss': 1.3267338275909424, 'validation/accuracy': 0.6133399605751038, 'validation/loss': 1.6220921277999878, 'validation/num_examples': 50000, 'test/accuracy': 0.492900013923645, 'test/loss': 2.2858996391296387, 'test/num_examples': 10000, 'score': 21890.660034418106, 'total_duration': 23385.426328659058, 'accumulated_submission_time': 21890.660034418106, 'accumulated_eval_time': 1491.2993965148926, 'accumulated_logging_time': 1.4927337169647217, 'global_step': 55840, 'preemption_count': 0}), (56915, {'train/accuracy': 0.6681054830551147, 'train/loss': 1.3655517101287842, 'validation/accuracy': 0.6129400134086609, 'validation/loss': 1.6313343048095703, 'validation/num_examples': 50000, 'test/accuracy': 0.48280003666877747, 'test/loss': 2.329977035522461, 'test/num_examples': 10000, 'score': 22310.907233953476, 'total_duration': 23833.952456712723, 'accumulated_submission_time': 22310.907233953476, 'accumulated_eval_time': 1519.506608247757, 'accumulated_logging_time': 1.5257229804992676, 'global_step': 56915, 'preemption_count': 0}), (57990, {'train/accuracy': 0.6885156035423279, 'train/loss': 1.3053981065750122, 'validation/accuracy': 0.6219599843025208, 'validation/loss': 1.5993369817733765, 'validation/num_examples': 50000, 'test/accuracy': 0.5071000456809998, 'test/loss': 2.248518943786621, 'test/num_examples': 10000, 'score': 22731.152432203293, 'total_duration': 24282.509819746017, 'accumulated_submission_time': 22731.152432203293, 'accumulated_eval_time': 1547.7474370002747, 'accumulated_logging_time': 1.5581462383270264, 'global_step': 57990, 'preemption_count': 0}), (59065, {'train/accuracy': 0.6809374690055847, 'train/loss': 1.3111419677734375, 'validation/accuracy': 0.623199999332428, 'validation/loss': 1.5841891765594482, 'validation/num_examples': 50000, 'test/accuracy': 0.499500036239624, 'test/loss': 2.2402901649475098, 'test/num_examples': 10000, 'score': 23151.4269323349, 'total_duration': 24731.14370560646, 'accumulated_submission_time': 23151.4269323349, 'accumulated_eval_time': 1576.0334043502808, 'accumulated_logging_time': 1.5937366485595703, 'global_step': 59065, 'preemption_count': 0}), (60140, {'train/accuracy': 0.6778124570846558, 'train/loss': 1.3237377405166626, 'validation/accuracy': 0.6237999796867371, 'validation/loss': 1.5753084421157837, 'validation/num_examples': 50000, 'test/accuracy': 0.5049999952316284, 'test/loss': 2.238182544708252, 'test/num_examples': 10000, 'score': 23571.66185235977, 'total_duration': 25179.726477622986, 'accumulated_submission_time': 23571.66185235977, 'accumulated_eval_time': 1604.3155086040497, 'accumulated_logging_time': 1.621769666671753, 'global_step': 60140, 'preemption_count': 0}), (61215, {'train/accuracy': 0.6948632597923279, 'train/loss': 1.2332534790039062, 'validation/accuracy': 0.6238799691200256, 'validation/loss': 1.5658894777297974, 'validation/num_examples': 50000, 'test/accuracy': 0.5010000467300415, 'test/loss': 2.2323102951049805, 'test/num_examples': 10000, 'score': 23991.91918349266, 'total_duration': 25628.58084011078, 'accumulated_submission_time': 23991.91918349266, 'accumulated_eval_time': 1632.8445754051208, 'accumulated_logging_time': 1.650775671005249, 'global_step': 61215, 'preemption_count': 0}), (62290, {'train/accuracy': 0.6827734112739563, 'train/loss': 1.2909884452819824, 'validation/accuracy': 0.6261199712753296, 'validation/loss': 1.559798240661621, 'validation/num_examples': 50000, 'test/accuracy': 0.5069000124931335, 'test/loss': 2.2323246002197266, 'test/num_examples': 10000, 'score': 24412.13849759102, 'total_duration': 26077.064366340637, 'accumulated_submission_time': 24412.13849759102, 'accumulated_eval_time': 1661.038922548294, 'accumulated_logging_time': 1.6826434135437012, 'global_step': 62290, 'preemption_count': 0}), (63365, {'train/accuracy': 0.6887109279632568, 'train/loss': 1.2545818090438843, 'validation/accuracy': 0.6304599642753601, 'validation/loss': 1.5248576402664185, 'validation/num_examples': 50000, 'test/accuracy': 0.5080000162124634, 'test/loss': 2.1767449378967285, 'test/num_examples': 10000, 'score': 24832.284222841263, 'total_duration': 26525.4783039093, 'accumulated_submission_time': 24832.284222841263, 'accumulated_eval_time': 1689.239952802658, 'accumulated_logging_time': 1.7124104499816895, 'global_step': 63365, 'preemption_count': 0}), (64440, {'train/accuracy': 0.6983984112739563, 'train/loss': 1.2290480136871338, 'validation/accuracy': 0.6302599906921387, 'validation/loss': 1.5308572053909302, 'validation/num_examples': 50000, 'test/accuracy': 0.5085000395774841, 'test/loss': 2.1962881088256836, 'test/num_examples': 10000, 'score': 25252.524570703506, 'total_duration': 26976.5887298584, 'accumulated_submission_time': 25252.524570703506, 'accumulated_eval_time': 1720.037649154663, 'accumulated_logging_time': 1.746248722076416, 'global_step': 64440, 'preemption_count': 0}), (65515, {'train/accuracy': 0.6917968392372131, 'train/loss': 1.2603040933609009, 'validation/accuracy': 0.6354599595069885, 'validation/loss': 1.5285406112670898, 'validation/num_examples': 50000, 'test/accuracy': 0.5040000081062317, 'test/loss': 2.2069759368896484, 'test/num_examples': 10000, 'score': 25672.51306271553, 'total_duration': 27424.912562847137, 'accumulated_submission_time': 25672.51306271553, 'accumulated_eval_time': 1748.3002469539642, 'accumulated_logging_time': 1.780982255935669, 'global_step': 65515, 'preemption_count': 0}), (66590, {'train/accuracy': 0.7171093821525574, 'train/loss': 1.1421173810958862, 'validation/accuracy': 0.64028000831604, 'validation/loss': 1.4945441484451294, 'validation/num_examples': 50000, 'test/accuracy': 0.5195000171661377, 'test/loss': 2.15171217918396, 'test/num_examples': 10000, 'score': 26092.61092352867, 'total_duration': 27874.869310617447, 'accumulated_submission_time': 26092.61092352867, 'accumulated_eval_time': 1778.0911870002747, 'accumulated_logging_time': 1.8104863166809082, 'global_step': 66590, 'preemption_count': 0}), (67665, {'train/accuracy': 0.7054101228713989, 'train/loss': 1.2118762731552124, 'validation/accuracy': 0.6391800045967102, 'validation/loss': 1.5081987380981445, 'validation/num_examples': 50000, 'test/accuracy': 0.5146999955177307, 'test/loss': 2.1746602058410645, 'test/num_examples': 10000, 'score': 26512.69844007492, 'total_duration': 28323.292452812195, 'accumulated_submission_time': 26512.69844007492, 'accumulated_eval_time': 1806.360939025879, 'accumulated_logging_time': 1.8380200862884521, 'global_step': 67665, 'preemption_count': 0}), (68740, {'train/accuracy': 0.7085546851158142, 'train/loss': 1.1703555583953857, 'validation/accuracy': 0.6516799926757812, 'validation/loss': 1.4402635097503662, 'validation/num_examples': 50000, 'test/accuracy': 0.5311000347137451, 'test/loss': 2.0866637229919434, 'test/num_examples': 10000, 'score': 26932.97707104683, 'total_duration': 28771.82215476036, 'accumulated_submission_time': 26932.97707104683, 'accumulated_eval_time': 1834.5438992977142, 'accumulated_logging_time': 1.8677911758422852, 'global_step': 68740, 'preemption_count': 0}), (69815, {'train/accuracy': 0.7147460579872131, 'train/loss': 1.1490181684494019, 'validation/accuracy': 0.6469399929046631, 'validation/loss': 1.4612271785736084, 'validation/num_examples': 50000, 'test/accuracy': 0.5234000086784363, 'test/loss': 2.1238906383514404, 'test/num_examples': 10000, 'score': 27353.098613739014, 'total_duration': 29220.060346603394, 'accumulated_submission_time': 27353.098613739014, 'accumulated_eval_time': 1862.5940737724304, 'accumulated_logging_time': 1.89664626121521, 'global_step': 69815, 'preemption_count': 0}), (70890, {'train/accuracy': 0.7098242044448853, 'train/loss': 1.154585361480713, 'validation/accuracy': 0.6497799754142761, 'validation/loss': 1.4376181364059448, 'validation/num_examples': 50000, 'test/accuracy': 0.528700053691864, 'test/loss': 2.092740535736084, 'test/num_examples': 10000, 'score': 27773.24999809265, 'total_duration': 29668.57729792595, 'accumulated_submission_time': 27773.24999809265, 'accumulated_eval_time': 1890.8912887573242, 'accumulated_logging_time': 1.9263780117034912, 'global_step': 70890, 'preemption_count': 0}), (71965, {'train/accuracy': 0.7422655820846558, 'train/loss': 1.0493677854537964, 'validation/accuracy': 0.6548199653625488, 'validation/loss': 1.4409143924713135, 'validation/num_examples': 50000, 'test/accuracy': 0.5309000015258789, 'test/loss': 2.10162353515625, 'test/num_examples': 10000, 'score': 28193.315749406815, 'total_duration': 30116.842511177063, 'accumulated_submission_time': 28193.315749406815, 'accumulated_eval_time': 1919.015851020813, 'accumulated_logging_time': 1.9618356227874756, 'global_step': 71965, 'preemption_count': 0}), (73040, {'train/accuracy': 0.7191991806030273, 'train/loss': 1.1370999813079834, 'validation/accuracy': 0.6542400121688843, 'validation/loss': 1.4398219585418701, 'validation/num_examples': 50000, 'test/accuracy': 0.5308000445365906, 'test/loss': 2.107109308242798, 'test/num_examples': 10000, 'score': 28613.507826805115, 'total_duration': 30565.16203045845, 'accumulated_submission_time': 28613.507826805115, 'accumulated_eval_time': 1947.0758850574493, 'accumulated_logging_time': 1.9914288520812988, 'global_step': 73040, 'preemption_count': 0}), (74115, {'train/accuracy': 0.7185937166213989, 'train/loss': 1.1530827283859253, 'validation/accuracy': 0.6581000089645386, 'validation/loss': 1.4239095449447632, 'validation/num_examples': 50000, 'test/accuracy': 0.5367000102996826, 'test/loss': 2.08459210395813, 'test/num_examples': 10000, 'score': 29033.705795288086, 'total_duration': 31013.541746854782, 'accumulated_submission_time': 29033.705795288086, 'accumulated_eval_time': 1975.1916115283966, 'accumulated_logging_time': 2.019712209701538, 'global_step': 74115, 'preemption_count': 0}), (75190, {'train/accuracy': 0.73499995470047, 'train/loss': 1.0665316581726074, 'validation/accuracy': 0.6581599712371826, 'validation/loss': 1.401633381843567, 'validation/num_examples': 50000, 'test/accuracy': 0.5357000231742859, 'test/loss': 2.072315216064453, 'test/num_examples': 10000, 'score': 29453.931671142578, 'total_duration': 31461.95157265663, 'accumulated_submission_time': 29453.931671142578, 'accumulated_eval_time': 2003.3064270019531, 'accumulated_logging_time': 2.0511093139648438, 'global_step': 75190, 'preemption_count': 0}), (76265, {'train/accuracy': 0.7275781035423279, 'train/loss': 1.0782517194747925, 'validation/accuracy': 0.6630600094795227, 'validation/loss': 1.3828036785125732, 'validation/num_examples': 50000, 'test/accuracy': 0.5392000079154968, 'test/loss': 2.038666009902954, 'test/num_examples': 10000, 'score': 29874.151214122772, 'total_duration': 31910.35142183304, 'accumulated_submission_time': 29874.151214122772, 'accumulated_eval_time': 2031.419240951538, 'accumulated_logging_time': 2.080518960952759, 'global_step': 76265, 'preemption_count': 0}), (77340, {'train/accuracy': 0.7515038847923279, 'train/loss': 1.0078914165496826, 'validation/accuracy': 0.6642400026321411, 'validation/loss': 1.3859093189239502, 'validation/num_examples': 50000, 'test/accuracy': 0.5437999963760376, 'test/loss': 2.0266125202178955, 'test/num_examples': 10000, 'score': 30294.305116415024, 'total_duration': 32358.673986196518, 'accumulated_submission_time': 30294.305116415024, 'accumulated_eval_time': 2059.518256664276, 'accumulated_logging_time': 2.112673282623291, 'global_step': 77340, 'preemption_count': 0}), (78415, {'train/accuracy': 0.7408398389816284, 'train/loss': 1.038232445716858, 'validation/accuracy': 0.6656799912452698, 'validation/loss': 1.3740336894989014, 'validation/num_examples': 50000, 'test/accuracy': 0.5434000492095947, 'test/loss': 2.0228612422943115, 'test/num_examples': 10000, 'score': 30714.403047323227, 'total_duration': 32806.960404872894, 'accumulated_submission_time': 30714.403047323227, 'accumulated_eval_time': 2087.6385633945465, 'accumulated_logging_time': 2.1429443359375, 'global_step': 78415, 'preemption_count': 0}), (79490, {'train/accuracy': 0.7354687452316284, 'train/loss': 1.049497365951538, 'validation/accuracy': 0.670740008354187, 'validation/loss': 1.3522273302078247, 'validation/num_examples': 50000, 'test/accuracy': 0.5480000376701355, 'test/loss': 2.012040138244629, 'test/num_examples': 10000, 'score': 31134.480865716934, 'total_duration': 33255.20918631554, 'accumulated_submission_time': 31134.480865716934, 'accumulated_eval_time': 2115.737879514694, 'accumulated_logging_time': 2.1758697032928467, 'global_step': 79490, 'preemption_count': 0}), (80565, {'train/accuracy': 0.7537304759025574, 'train/loss': 0.968858003616333, 'validation/accuracy': 0.6736599802970886, 'validation/loss': 1.3394980430603027, 'validation/num_examples': 50000, 'test/accuracy': 0.5462000370025635, 'test/loss': 2.016737699508667, 'test/num_examples': 10000, 'score': 31554.630586624146, 'total_duration': 33703.49849128723, 'accumulated_submission_time': 31554.630586624146, 'accumulated_eval_time': 2143.805784225464, 'accumulated_logging_time': 2.209275960922241, 'global_step': 80565, 'preemption_count': 0}), (81640, {'train/accuracy': 0.7430273294448853, 'train/loss': 1.0334614515304565, 'validation/accuracy': 0.6747599840164185, 'validation/loss': 1.3455369472503662, 'validation/num_examples': 50000, 'test/accuracy': 0.5516000390052795, 'test/loss': 2.020983934402466, 'test/num_examples': 10000, 'score': 31974.79904460907, 'total_duration': 34151.871500492096, 'accumulated_submission_time': 31974.79904460907, 'accumulated_eval_time': 2171.9409697055817, 'accumulated_logging_time': 2.240649700164795, 'global_step': 81640, 'preemption_count': 0}), (82715, {'train/accuracy': 0.7436132431030273, 'train/loss': 1.012618899345398, 'validation/accuracy': 0.6788199543952942, 'validation/loss': 1.3165409564971924, 'validation/num_examples': 50000, 'test/accuracy': 0.5558000206947327, 'test/loss': 1.9720288515090942, 'test/num_examples': 10000, 'score': 32394.88243317604, 'total_duration': 34600.244175195694, 'accumulated_submission_time': 32394.88243317604, 'accumulated_eval_time': 2200.1613948345184, 'accumulated_logging_time': 2.2722578048706055, 'global_step': 82715, 'preemption_count': 0}), (83790, {'train/accuracy': 0.7532812356948853, 'train/loss': 0.9784535765647888, 'validation/accuracy': 0.6780200004577637, 'validation/loss': 1.3134093284606934, 'validation/num_examples': 50000, 'test/accuracy': 0.5522000193595886, 'test/loss': 1.9623016119003296, 'test/num_examples': 10000, 'score': 32814.973824739456, 'total_duration': 35048.62127113342, 'accumulated_submission_time': 32814.973824739456, 'accumulated_eval_time': 2228.3756980895996, 'accumulated_logging_time': 2.3050167560577393, 'global_step': 83790, 'preemption_count': 0}), (84865, {'train/accuracy': 0.7472265362739563, 'train/loss': 0.986632764339447, 'validation/accuracy': 0.6819999814033508, 'validation/loss': 1.2906161546707153, 'validation/num_examples': 50000, 'test/accuracy': 0.5617000460624695, 'test/loss': 1.9442942142486572, 'test/num_examples': 10000, 'score': 33235.05148816109, 'total_duration': 35497.008912324905, 'accumulated_submission_time': 33235.05148816109, 'accumulated_eval_time': 2256.6124222278595, 'accumulated_logging_time': 2.3405017852783203, 'global_step': 84865, 'preemption_count': 0}), (85940, {'train/accuracy': 0.768261730670929, 'train/loss': 0.9165685176849365, 'validation/accuracy': 0.6836599707603455, 'validation/loss': 1.292286992073059, 'validation/num_examples': 50000, 'test/accuracy': 0.5562000274658203, 'test/loss': 1.9705924987792969, 'test/num_examples': 10000, 'score': 33655.21841049194, 'total_duration': 35945.45246839523, 'accumulated_submission_time': 33655.21841049194, 'accumulated_eval_time': 2284.816447019577, 'accumulated_logging_time': 2.3753788471221924, 'global_step': 85940, 'preemption_count': 0}), (87015, {'train/accuracy': 0.7613476514816284, 'train/loss': 0.9502003788948059, 'validation/accuracy': 0.685759961605072, 'validation/loss': 1.2923638820648193, 'validation/num_examples': 50000, 'test/accuracy': 0.5633000135421753, 'test/loss': 1.9323105812072754, 'test/num_examples': 10000, 'score': 34075.2073597908, 'total_duration': 36395.41846227646, 'accumulated_submission_time': 34075.2073597908, 'accumulated_eval_time': 2314.7199215888977, 'accumulated_logging_time': 2.409738779067993, 'global_step': 87015, 'preemption_count': 0}), (88090, {'train/accuracy': 0.7571093440055847, 'train/loss': 0.9640190601348877, 'validation/accuracy': 0.6872400045394897, 'validation/loss': 1.2790004014968872, 'validation/num_examples': 50000, 'test/accuracy': 0.5615000128746033, 'test/loss': 1.9326801300048828, 'test/num_examples': 10000, 'score': 34495.25335025787, 'total_duration': 36843.78880548477, 'accumulated_submission_time': 34495.25335025787, 'accumulated_eval_time': 2342.9740138053894, 'accumulated_logging_time': 2.4409990310668945, 'global_step': 88090, 'preemption_count': 0}), (89165, {'train/accuracy': 0.7727734446525574, 'train/loss': 0.8953768610954285, 'validation/accuracy': 0.689079999923706, 'validation/loss': 1.2544082403182983, 'validation/num_examples': 50000, 'test/accuracy': 0.5685000419616699, 'test/loss': 1.909213900566101, 'test/num_examples': 10000, 'score': 34915.496957063675, 'total_duration': 37292.44328331947, 'accumulated_submission_time': 34915.496957063675, 'accumulated_eval_time': 2371.3181595802307, 'accumulated_logging_time': 2.4699888229370117, 'global_step': 89165, 'preemption_count': 0}), (90240, {'train/accuracy': 0.7667773365974426, 'train/loss': 0.9181344509124756, 'validation/accuracy': 0.6922000050544739, 'validation/loss': 1.2458761930465698, 'validation/num_examples': 50000, 'test/accuracy': 0.5687000155448914, 'test/loss': 1.8983409404754639, 'test/num_examples': 10000, 'score': 35335.60144639015, 'total_duration': 37740.7926864624, 'accumulated_submission_time': 35335.60144639015, 'accumulated_eval_time': 2399.4947125911713, 'accumulated_logging_time': 2.500380516052246, 'global_step': 90240, 'preemption_count': 0}), (91315, {'train/accuracy': 0.788769543170929, 'train/loss': 0.8331679105758667, 'validation/accuracy': 0.6962999701499939, 'validation/loss': 1.23737370967865, 'validation/num_examples': 50000, 'test/accuracy': 0.5683000087738037, 'test/loss': 1.8899977207183838, 'test/num_examples': 10000, 'score': 35755.758419275284, 'total_duration': 38189.15215921402, 'accumulated_submission_time': 35755.758419275284, 'accumulated_eval_time': 2427.627291202545, 'accumulated_logging_time': 2.53277850151062, 'global_step': 91315, 'preemption_count': 0}), (92390, {'train/accuracy': 0.7783203125, 'train/loss': 0.8806977868080139, 'validation/accuracy': 0.6991999745368958, 'validation/loss': 1.2235431671142578, 'validation/num_examples': 50000, 'test/accuracy': 0.5734000205993652, 'test/loss': 1.8830280303955078, 'test/num_examples': 10000, 'score': 36175.828775405884, 'total_duration': 38637.4474298954, 'accumulated_submission_time': 36175.828775405884, 'accumulated_eval_time': 2455.7801399230957, 'accumulated_logging_time': 2.567004919052124, 'global_step': 92390, 'preemption_count': 0}), (93465, {'train/accuracy': 0.7736523151397705, 'train/loss': 0.8952926397323608, 'validation/accuracy': 0.7000199556350708, 'validation/loss': 1.2245689630508423, 'validation/num_examples': 50000, 'test/accuracy': 0.5726000070571899, 'test/loss': 1.8683141469955444, 'test/num_examples': 10000, 'score': 36595.99108958244, 'total_duration': 39085.80840730667, 'accumulated_submission_time': 36595.99108958244, 'accumulated_eval_time': 2483.908063173294, 'accumulated_logging_time': 2.5983927249908447, 'global_step': 93465, 'preemption_count': 0}), (94540, {'train/accuracy': 0.7881054282188416, 'train/loss': 0.8393813371658325, 'validation/accuracy': 0.7005599737167358, 'validation/loss': 1.224228858947754, 'validation/num_examples': 50000, 'test/accuracy': 0.5746000409126282, 'test/loss': 1.872279405593872, 'test/num_examples': 10000, 'score': 37016.00253248215, 'total_duration': 39533.99979662895, 'accumulated_submission_time': 37016.00253248215, 'accumulated_eval_time': 2512.0148735046387, 'accumulated_logging_time': 2.6337575912475586, 'global_step': 94540, 'preemption_count': 0}), (95615, {'train/accuracy': 0.779980480670929, 'train/loss': 0.8606881499290466, 'validation/accuracy': 0.7037400007247925, 'validation/loss': 1.2031241655349731, 'validation/num_examples': 50000, 'test/accuracy': 0.5786000490188599, 'test/loss': 1.8535703420639038, 'test/num_examples': 10000, 'score': 37436.18379282951, 'total_duration': 39982.31017231941, 'accumulated_submission_time': 37436.18379282951, 'accumulated_eval_time': 2540.0765228271484, 'accumulated_logging_time': 2.662832260131836, 'global_step': 95615, 'preemption_count': 0}), (96690, {'train/accuracy': 0.8011913895606995, 'train/loss': 0.7849521636962891, 'validation/accuracy': 0.7037599682807922, 'validation/loss': 1.210679054260254, 'validation/num_examples': 50000, 'test/accuracy': 0.5795000195503235, 'test/loss': 1.8425003290176392, 'test/num_examples': 10000, 'score': 37856.362481832504, 'total_duration': 40430.70518541336, 'accumulated_submission_time': 37856.362481832504, 'accumulated_eval_time': 2568.2226095199585, 'accumulated_logging_time': 2.6945512294769287, 'global_step': 96690, 'preemption_count': 0}), (97765, {'train/accuracy': 0.7937109470367432, 'train/loss': 0.8023425340652466, 'validation/accuracy': 0.7086799740791321, 'validation/loss': 1.1761871576309204, 'validation/num_examples': 50000, 'test/accuracy': 0.5842000246047974, 'test/loss': 1.8237043619155884, 'test/num_examples': 10000, 'score': 38276.46438193321, 'total_duration': 40879.211352586746, 'accumulated_submission_time': 38276.46438193321, 'accumulated_eval_time': 2596.557202100754, 'accumulated_logging_time': 2.726055145263672, 'global_step': 97765, 'preemption_count': 0}), (98840, {'train/accuracy': 0.79066401720047, 'train/loss': 0.8122550249099731, 'validation/accuracy': 0.7108799815177917, 'validation/loss': 1.1668226718902588, 'validation/num_examples': 50000, 'test/accuracy': 0.5883000493049622, 'test/loss': 1.8044285774230957, 'test/num_examples': 10000, 'score': 38696.48484325409, 'total_duration': 41327.42246246338, 'accumulated_submission_time': 38696.48484325409, 'accumulated_eval_time': 2624.675024986267, 'accumulated_logging_time': 2.7614381313323975, 'global_step': 98840, 'preemption_count': 0}), (99914, {'train/accuracy': 0.8043749928474426, 'train/loss': 0.7756077647209167, 'validation/accuracy': 0.7114999890327454, 'validation/loss': 1.1701703071594238, 'validation/num_examples': 50000, 'test/accuracy': 0.588200032711029, 'test/loss': 1.8171076774597168, 'test/num_examples': 10000, 'score': 39116.42384815216, 'total_duration': 41775.25985169411, 'accumulated_submission_time': 39116.42384815216, 'accumulated_eval_time': 2652.5027623176575, 'accumulated_logging_time': 2.7939517498016357, 'global_step': 99914, 'preemption_count': 0}), (100989, {'train/accuracy': 0.7991796731948853, 'train/loss': 0.7734871506690979, 'validation/accuracy': 0.7157599925994873, 'validation/loss': 1.1494746208190918, 'validation/num_examples': 50000, 'test/accuracy': 0.5963000059127808, 'test/loss': 1.785571575164795, 'test/num_examples': 10000, 'score': 39536.42637038231, 'total_duration': 42223.731813430786, 'accumulated_submission_time': 39536.42637038231, 'accumulated_eval_time': 2680.9027936458588, 'accumulated_logging_time': 2.8253557682037354, 'global_step': 100989, 'preemption_count': 0}), (102064, {'train/accuracy': 0.8037499785423279, 'train/loss': 0.771857738494873, 'validation/accuracy': 0.7140600085258484, 'validation/loss': 1.1566945314407349, 'validation/num_examples': 50000, 'test/accuracy': 0.5914000272750854, 'test/loss': 1.7901370525360107, 'test/num_examples': 10000, 'score': 39956.501178979874, 'total_duration': 42672.04652261734, 'accumulated_submission_time': 39956.501178979874, 'accumulated_eval_time': 2709.0719146728516, 'accumulated_logging_time': 2.8588454723358154, 'global_step': 102064, 'preemption_count': 0}), (103139, {'train/accuracy': 0.8059374690055847, 'train/loss': 0.7530930638313293, 'validation/accuracy': 0.7147600054740906, 'validation/loss': 1.1442608833312988, 'validation/num_examples': 50000, 'test/accuracy': 0.5913000106811523, 'test/loss': 1.789018988609314, 'test/num_examples': 10000, 'score': 40376.45714855194, 'total_duration': 43120.30718302727, 'accumulated_submission_time': 40376.45714855194, 'accumulated_eval_time': 2737.3073012828827, 'accumulated_logging_time': 2.890319347381592, 'global_step': 103139, 'preemption_count': 0}), (104214, {'train/accuracy': 0.8067968487739563, 'train/loss': 0.747651219367981, 'validation/accuracy': 0.72079998254776, 'validation/loss': 1.1287459135055542, 'validation/num_examples': 50000, 'test/accuracy': 0.5952000021934509, 'test/loss': 1.7805838584899902, 'test/num_examples': 10000, 'score': 40796.54728913307, 'total_duration': 43568.718232393265, 'accumulated_submission_time': 40796.54728913307, 'accumulated_eval_time': 2765.554568052292, 'accumulated_logging_time': 2.9242961406707764, 'global_step': 104214, 'preemption_count': 0}), (105289, {'train/accuracy': 0.820605456829071, 'train/loss': 0.6992701292037964, 'validation/accuracy': 0.7228999733924866, 'validation/loss': 1.1123130321502686, 'validation/num_examples': 50000, 'test/accuracy': 0.5967000126838684, 'test/loss': 1.759952187538147, 'test/num_examples': 10000, 'score': 41216.61836409569, 'total_duration': 44017.16404867172, 'accumulated_submission_time': 41216.61836409569, 'accumulated_eval_time': 2793.8599157333374, 'accumulated_logging_time': 2.956411838531494, 'global_step': 105289, 'preemption_count': 0}), (106364, {'train/accuracy': 0.8125390410423279, 'train/loss': 0.7213648557662964, 'validation/accuracy': 0.7247399687767029, 'validation/loss': 1.1128995418548584, 'validation/num_examples': 50000, 'test/accuracy': 0.5978000164031982, 'test/loss': 1.7560226917266846, 'test/num_examples': 10000, 'score': 41636.791576862335, 'total_duration': 44465.6841981411, 'accumulated_submission_time': 41636.791576862335, 'accumulated_eval_time': 2822.1375629901886, 'accumulated_logging_time': 2.9876561164855957, 'global_step': 106364, 'preemption_count': 0}), (107439, {'train/accuracy': 0.814453125, 'train/loss': 0.7248771786689758, 'validation/accuracy': 0.7274399995803833, 'validation/loss': 1.109386682510376, 'validation/num_examples': 50000, 'test/accuracy': 0.6027000546455383, 'test/loss': 1.7434618473052979, 'test/num_examples': 10000, 'score': 42056.76136255264, 'total_duration': 44915.23311281204, 'accumulated_submission_time': 42056.76136255264, 'accumulated_eval_time': 2851.6389589309692, 'accumulated_logging_time': 3.027472972869873, 'global_step': 107439, 'preemption_count': 0}), (108514, {'train/accuracy': 0.8226562142372131, 'train/loss': 0.6898142695426941, 'validation/accuracy': 0.7302199602127075, 'validation/loss': 1.1024210453033447, 'validation/num_examples': 50000, 'test/accuracy': 0.6082000136375427, 'test/loss': 1.7283380031585693, 'test/num_examples': 10000, 'score': 42476.77098417282, 'total_duration': 45363.58995103836, 'accumulated_submission_time': 42476.77098417282, 'accumulated_eval_time': 2879.9071016311646, 'accumulated_logging_time': 3.0687575340270996, 'global_step': 108514, 'preemption_count': 0}), (109589, {'train/accuracy': 0.8191210627555847, 'train/loss': 0.6877502202987671, 'validation/accuracy': 0.7307199835777283, 'validation/loss': 1.0814051628112793, 'validation/num_examples': 50000, 'test/accuracy': 0.6058000326156616, 'test/loss': 1.7154690027236938, 'test/num_examples': 10000, 'score': 42896.91472172737, 'total_duration': 45812.01935052872, 'accumulated_submission_time': 42896.91472172737, 'accumulated_eval_time': 2908.1201968193054, 'accumulated_logging_time': 3.103774070739746, 'global_step': 109589, 'preemption_count': 0}), (110664, {'train/accuracy': 0.83216792345047, 'train/loss': 0.6448915004730225, 'validation/accuracy': 0.7317999601364136, 'validation/loss': 1.088350534439087, 'validation/num_examples': 50000, 'test/accuracy': 0.6075000166893005, 'test/loss': 1.7223092317581177, 'test/num_examples': 10000, 'score': 43317.07927131653, 'total_duration': 46260.36416435242, 'accumulated_submission_time': 43317.07927131653, 'accumulated_eval_time': 2936.227205991745, 'accumulated_logging_time': 3.13850736618042, 'global_step': 110664, 'preemption_count': 0}), (111739, {'train/accuracy': 0.8270898461341858, 'train/loss': 0.6630663871765137, 'validation/accuracy': 0.733460009098053, 'validation/loss': 1.0728580951690674, 'validation/num_examples': 50000, 'test/accuracy': 0.6066000461578369, 'test/loss': 1.7066457271575928, 'test/num_examples': 10000, 'score': 43737.188535928726, 'total_duration': 46708.68071103096, 'accumulated_submission_time': 43737.188535928726, 'accumulated_eval_time': 2964.3613545894623, 'accumulated_logging_time': 3.172044277191162, 'global_step': 111739, 'preemption_count': 0}), (112814, {'train/accuracy': 0.8279492259025574, 'train/loss': 0.6634637117385864, 'validation/accuracy': 0.7366200089454651, 'validation/loss': 1.0635287761688232, 'validation/num_examples': 50000, 'test/accuracy': 0.6099000573158264, 'test/loss': 1.7054133415222168, 'test/num_examples': 10000, 'score': 44157.31499385834, 'total_duration': 47157.0469520092, 'accumulated_submission_time': 44157.31499385834, 'accumulated_eval_time': 2992.5264451503754, 'accumulated_logging_time': 3.2091495990753174, 'global_step': 112814, 'preemption_count': 0}), (113889, {'train/accuracy': 0.8325390219688416, 'train/loss': 0.6506238579750061, 'validation/accuracy': 0.737019956111908, 'validation/loss': 1.0665639638900757, 'validation/num_examples': 50000, 'test/accuracy': 0.6160000562667847, 'test/loss': 1.7037070989608765, 'test/num_examples': 10000, 'score': 44577.41374921799, 'total_duration': 47605.33698582649, 'accumulated_submission_time': 44577.41374921799, 'accumulated_eval_time': 3020.641755104065, 'accumulated_logging_time': 3.245795488357544, 'global_step': 113889, 'preemption_count': 0}), (114964, {'train/accuracy': 0.8332617282867432, 'train/loss': 0.642020046710968, 'validation/accuracy': 0.73881995677948, 'validation/loss': 1.0511575937271118, 'validation/num_examples': 50000, 'test/accuracy': 0.6171000003814697, 'test/loss': 1.6760892868041992, 'test/num_examples': 10000, 'score': 44997.53186798096, 'total_duration': 48053.594883441925, 'accumulated_submission_time': 44997.53186798096, 'accumulated_eval_time': 3048.7091376781464, 'accumulated_logging_time': 3.2801101207733154, 'global_step': 114964, 'preemption_count': 0}), (116039, {'train/accuracy': 0.8462694883346558, 'train/loss': 0.5912107229232788, 'validation/accuracy': 0.7423399686813354, 'validation/loss': 1.0377609729766846, 'validation/num_examples': 50000, 'test/accuracy': 0.6160000562667847, 'test/loss': 1.6706985235214233, 'test/num_examples': 10000, 'score': 45417.64970135689, 'total_duration': 48501.88428449631, 'accumulated_submission_time': 45417.64970135689, 'accumulated_eval_time': 3076.8076598644257, 'accumulated_logging_time': 3.3152167797088623, 'global_step': 116039, 'preemption_count': 0}), (117114, {'train/accuracy': 0.8408203125, 'train/loss': 0.6095035076141357, 'validation/accuracy': 0.7428999543190002, 'validation/loss': 1.034235954284668, 'validation/num_examples': 50000, 'test/accuracy': 0.6214000582695007, 'test/loss': 1.6589094400405884, 'test/num_examples': 10000, 'score': 45837.71575665474, 'total_duration': 48950.154040813446, 'accumulated_submission_time': 45837.71575665474, 'accumulated_eval_time': 3104.9423391819, 'accumulated_logging_time': 3.346100091934204, 'global_step': 117114, 'preemption_count': 0}), (118189, {'train/accuracy': 0.8380078077316284, 'train/loss': 0.622999906539917, 'validation/accuracy': 0.7428799867630005, 'validation/loss': 1.0384109020233154, 'validation/num_examples': 50000, 'test/accuracy': 0.6210000514984131, 'test/loss': 1.6600441932678223, 'test/num_examples': 10000, 'score': 46257.759004831314, 'total_duration': 49398.45037841797, 'accumulated_submission_time': 46257.759004831314, 'accumulated_eval_time': 3133.124662399292, 'accumulated_logging_time': 3.378673553466797, 'global_step': 118189, 'preemption_count': 0}), (119264, {'train/accuracy': 0.8441015481948853, 'train/loss': 0.5896441340446472, 'validation/accuracy': 0.74617999792099, 'validation/loss': 1.0193930864334106, 'validation/num_examples': 50000, 'test/accuracy': 0.6221000552177429, 'test/loss': 1.6508439779281616, 'test/num_examples': 10000, 'score': 46677.85278201103, 'total_duration': 49846.80826020241, 'accumulated_submission_time': 46677.85278201103, 'accumulated_eval_time': 3161.3190398216248, 'accumulated_logging_time': 3.4110894203186035, 'global_step': 119264, 'preemption_count': 0}), (120339, {'train/accuracy': 0.8456249833106995, 'train/loss': 0.5948187708854675, 'validation/accuracy': 0.7465400099754333, 'validation/loss': 1.023179292678833, 'validation/num_examples': 50000, 'test/accuracy': 0.6181000471115112, 'test/loss': 1.6532502174377441, 'test/num_examples': 10000, 'score': 47097.95237207413, 'total_duration': 50295.15413951874, 'accumulated_submission_time': 47097.95237207413, 'accumulated_eval_time': 3189.4904420375824, 'accumulated_logging_time': 3.4484405517578125, 'global_step': 120339, 'preemption_count': 0}), (121414, {'train/accuracy': 0.8444335460662842, 'train/loss': 0.5856109261512756, 'validation/accuracy': 0.7487399578094482, 'validation/loss': 1.011536955833435, 'validation/num_examples': 50000, 'test/accuracy': 0.6230000257492065, 'test/loss': 1.6453951597213745, 'test/num_examples': 10000, 'score': 47517.9346408844, 'total_duration': 50743.356073856354, 'accumulated_submission_time': 47517.9346408844, 'accumulated_eval_time': 3217.637284517288, 'accumulated_logging_time': 3.483731746673584, 'global_step': 121414, 'preemption_count': 0}), (122489, {'train/accuracy': 0.8477343320846558, 'train/loss': 0.5809749364852905, 'validation/accuracy': 0.7500199675559998, 'validation/loss': 1.0088045597076416, 'validation/num_examples': 50000, 'test/accuracy': 0.6243000030517578, 'test/loss': 1.6385291814804077, 'test/num_examples': 10000, 'score': 47937.97454357147, 'total_duration': 51191.686584711075, 'accumulated_submission_time': 47937.97454357147, 'accumulated_eval_time': 3245.8562200069427, 'accumulated_logging_time': 3.517456293106079, 'global_step': 122489, 'preemption_count': 0}), (123564, {'train/accuracy': 0.8473241925239563, 'train/loss': 0.5790875554084778, 'validation/accuracy': 0.7511199712753296, 'validation/loss': 1.0009024143218994, 'validation/num_examples': 50000, 'test/accuracy': 0.6279000043869019, 'test/loss': 1.6336430311203003, 'test/num_examples': 10000, 'score': 48358.04886507988, 'total_duration': 51640.03197526932, 'accumulated_submission_time': 48358.04886507988, 'accumulated_eval_time': 3274.0553612709045, 'accumulated_logging_time': 3.5517160892486572, 'global_step': 123564, 'preemption_count': 0}), (124639, {'train/accuracy': 0.8570898175239563, 'train/loss': 0.5458067655563354, 'validation/accuracy': 0.7506200075149536, 'validation/loss': 1.0017110109329224, 'validation/num_examples': 50000, 'test/accuracy': 0.6260000467300415, 'test/loss': 1.6287956237792969, 'test/num_examples': 10000, 'score': 48778.007551431656, 'total_duration': 52088.26137685776, 'accumulated_submission_time': 48778.007551431656, 'accumulated_eval_time': 3302.2573626041412, 'accumulated_logging_time': 3.582996368408203, 'global_step': 124639, 'preemption_count': 0}), (125714, {'train/accuracy': 0.850878894329071, 'train/loss': 0.5668322443962097, 'validation/accuracy': 0.7524999976158142, 'validation/loss': 0.9997560977935791, 'validation/num_examples': 50000, 'test/accuracy': 0.6292000412940979, 'test/loss': 1.6225883960723877, 'test/num_examples': 10000, 'score': 49198.183133363724, 'total_duration': 52536.66201090813, 'accumulated_submission_time': 49198.183133363724, 'accumulated_eval_time': 3330.411891222, 'accumulated_logging_time': 3.615069627761841, 'global_step': 125714, 'preemption_count': 0}), (126789, {'train/accuracy': 0.8553124666213989, 'train/loss': 0.5533652901649475, 'validation/accuracy': 0.7535399794578552, 'validation/loss': 0.9921098947525024, 'validation/num_examples': 50000, 'test/accuracy': 0.6314000487327576, 'test/loss': 1.6144118309020996, 'test/num_examples': 10000, 'score': 49618.17370700836, 'total_duration': 52984.86852097511, 'accumulated_submission_time': 49618.17370700836, 'accumulated_eval_time': 3358.554525375366, 'accumulated_logging_time': 3.65034556388855, 'global_step': 126789, 'preemption_count': 0}), (127864, {'train/accuracy': 0.8551757335662842, 'train/loss': 0.5507948994636536, 'validation/accuracy': 0.7538599967956543, 'validation/loss': 0.9891623258590698, 'validation/num_examples': 50000, 'test/accuracy': 0.6288000345230103, 'test/loss': 1.614182472229004, 'test/num_examples': 10000, 'score': 50038.194083213806, 'total_duration': 53433.6817214489, 'accumulated_submission_time': 50038.194083213806, 'accumulated_eval_time': 3387.2756962776184, 'accumulated_logging_time': 3.683236837387085, 'global_step': 127864, 'preemption_count': 0}), (128939, {'train/accuracy': 0.8582421541213989, 'train/loss': 0.544922947883606, 'validation/accuracy': 0.7541399598121643, 'validation/loss': 0.989403486251831, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.6124773025512695, 'test/num_examples': 10000, 'score': 50458.16389298439, 'total_duration': 53882.38656425476, 'accumulated_submission_time': 50458.16389298439, 'accumulated_eval_time': 3415.9308965206146, 'accumulated_logging_time': 3.723912477493286, 'global_step': 128939, 'preemption_count': 0}), (130014, {'train/accuracy': 0.8580273389816284, 'train/loss': 0.5405624508857727, 'validation/accuracy': 0.7541199922561646, 'validation/loss': 0.9870275259017944, 'validation/num_examples': 50000, 'test/accuracy': 0.6303000450134277, 'test/loss': 1.6109708547592163, 'test/num_examples': 10000, 'score': 50878.201677560806, 'total_duration': 54330.74567198753, 'accumulated_submission_time': 50878.201677560806, 'accumulated_eval_time': 3444.18039226532, 'accumulated_logging_time': 3.758056402206421, 'global_step': 130014, 'preemption_count': 0}), (131089, {'train/accuracy': 0.8587890267372131, 'train/loss': 0.536045491695404, 'validation/accuracy': 0.7555599808692932, 'validation/loss': 0.982154130935669, 'validation/num_examples': 50000, 'test/accuracy': 0.6327000260353088, 'test/loss': 1.6099995374679565, 'test/num_examples': 10000, 'score': 51298.278035879135, 'total_duration': 54779.05450677872, 'accumulated_submission_time': 51298.278035879135, 'accumulated_eval_time': 3472.341605901718, 'accumulated_logging_time': 3.790797472000122, 'global_step': 131089, 'preemption_count': 0}), (132164, {'train/accuracy': 0.8575195074081421, 'train/loss': 0.5434736013412476, 'validation/accuracy': 0.7554599642753601, 'validation/loss': 0.9835134744644165, 'validation/num_examples': 50000, 'test/accuracy': 0.6321000456809998, 'test/loss': 1.6135687828063965, 'test/num_examples': 10000, 'score': 51718.40934872627, 'total_duration': 55227.46911454201, 'accumulated_submission_time': 51718.40934872627, 'accumulated_eval_time': 3500.552706718445, 'accumulated_logging_time': 3.8247225284576416, 'global_step': 132164, 'preemption_count': 0}), (133239, {'train/accuracy': 0.8625586032867432, 'train/loss': 0.520088791847229, 'validation/accuracy': 0.756339967250824, 'validation/loss': 0.9802817106246948, 'validation/num_examples': 50000, 'test/accuracy': 0.6328000426292419, 'test/loss': 1.6079225540161133, 'test/num_examples': 10000, 'score': 52138.48851490021, 'total_duration': 55675.74509596825, 'accumulated_submission_time': 52138.48851490021, 'accumulated_eval_time': 3528.676340341568, 'accumulated_logging_time': 3.8596837520599365, 'global_step': 133239, 'preemption_count': 0}), (134314, {'train/accuracy': 0.8566992282867432, 'train/loss': 0.545985221862793, 'validation/accuracy': 0.7568999528884888, 'validation/loss': 0.9783429503440857, 'validation/num_examples': 50000, 'test/accuracy': 0.6325000524520874, 'test/loss': 1.6068836450576782, 'test/num_examples': 10000, 'score': 52558.62541294098, 'total_duration': 56124.091317653656, 'accumulated_submission_time': 52558.62541294098, 'accumulated_eval_time': 3556.812022924423, 'accumulated_logging_time': 3.895678997039795, 'global_step': 134314, 'preemption_count': 0}), (135389, {'train/accuracy': 0.8612695336341858, 'train/loss': 0.5244999527931213, 'validation/accuracy': 0.7570199966430664, 'validation/loss': 0.9779985547065735, 'validation/num_examples': 50000, 'test/accuracy': 0.6359000205993652, 'test/loss': 1.6035908460617065, 'test/num_examples': 10000, 'score': 52978.69073343277, 'total_duration': 56572.40228223801, 'accumulated_submission_time': 52978.69073343277, 'accumulated_eval_time': 3584.978801012039, 'accumulated_logging_time': 3.9358527660369873, 'global_step': 135389, 'preemption_count': 0}), (136464, {'train/accuracy': 0.86048823595047, 'train/loss': 0.5340384244918823, 'validation/accuracy': 0.7572599649429321, 'validation/loss': 0.9755660891532898, 'validation/num_examples': 50000, 'test/accuracy': 0.6351000070571899, 'test/loss': 1.6040593385696411, 'test/num_examples': 10000, 'score': 53398.75436234474, 'total_duration': 57020.7649538517, 'accumulated_submission_time': 53398.75436234474, 'accumulated_eval_time': 3613.207260131836, 'accumulated_logging_time': 3.968907117843628, 'global_step': 136464, 'preemption_count': 0}), (137539, {'train/accuracy': 0.8590039014816284, 'train/loss': 0.5354684591293335, 'validation/accuracy': 0.7573800086975098, 'validation/loss': 0.9761661291122437, 'validation/num_examples': 50000, 'test/accuracy': 0.6356000304222107, 'test/loss': 1.603734016418457, 'test/num_examples': 10000, 'score': 53818.79170393944, 'total_duration': 57469.088617801666, 'accumulated_submission_time': 53818.79170393944, 'accumulated_eval_time': 3641.411437511444, 'accumulated_logging_time': 4.013380765914917, 'global_step': 137539, 'preemption_count': 0}), (138614, {'train/accuracy': 0.8601366877555847, 'train/loss': 0.5311143398284912, 'validation/accuracy': 0.7568599581718445, 'validation/loss': 0.976474404335022, 'validation/num_examples': 50000, 'test/accuracy': 0.6350000500679016, 'test/loss': 1.6039568185806274, 'test/num_examples': 10000, 'score': 54238.85230445862, 'total_duration': 57917.42765760422, 'accumulated_submission_time': 54238.85230445862, 'accumulated_eval_time': 3669.6178154945374, 'accumulated_logging_time': 4.047449827194214, 'global_step': 138614, 'preemption_count': 0}), (139690, {'train/accuracy': 0.8583593368530273, 'train/loss': 0.5393272042274475, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.976636528968811, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043870449066162, 'test/num_examples': 10000, 'score': 54659.12533760071, 'total_duration': 58366.20587968826, 'accumulated_submission_time': 54659.12533760071, 'accumulated_eval_time': 3698.051212787628, 'accumulated_logging_time': 4.081500768661499, 'global_step': 139690, 'preemption_count': 0}), (140765, {'train/accuracy': 0.861328125, 'train/loss': 0.5271535515785217, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55079.20550727844, 'total_duration': 58814.59260940552, 'accumulated_submission_time': 55079.20550727844, 'accumulated_eval_time': 3726.2815976142883, 'accumulated_logging_time': 4.118992328643799, 'global_step': 140765, 'preemption_count': 0}), (141840, {'train/accuracy': 0.8594530820846558, 'train/loss': 0.5347545742988586, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55499.2118062973, 'total_duration': 59262.85370635986, 'accumulated_submission_time': 55499.2118062973, 'accumulated_eval_time': 3754.4586601257324, 'accumulated_logging_time': 4.159090280532837, 'global_step': 141840, 'preemption_count': 0}), (142915, {'train/accuracy': 0.8594140410423279, 'train/loss': 0.5365279912948608, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 55919.25531768799, 'total_duration': 59711.26879477501, 'accumulated_submission_time': 55919.25531768799, 'accumulated_eval_time': 3782.754019498825, 'accumulated_logging_time': 4.197422981262207, 'global_step': 142915, 'preemption_count': 0}), (143990, {'train/accuracy': 0.8576757907867432, 'train/loss': 0.5403394103050232, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 56339.21500205994, 'total_duration': 60159.57706785202, 'accumulated_submission_time': 56339.21500205994, 'accumulated_eval_time': 3811.030218601227, 'accumulated_logging_time': 4.232113361358643, 'global_step': 143990, 'preemption_count': 0}), (145065, {'train/accuracy': 0.8605859279632568, 'train/loss': 0.530600905418396, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 56759.219876766205, 'total_duration': 60608.134674072266, 'accumulated_submission_time': 56759.219876766205, 'accumulated_eval_time': 3839.318061351776, 'accumulated_logging_time': 4.458518743515015, 'global_step': 145065, 'preemption_count': 0}), (146140, {'train/accuracy': 0.8607421517372131, 'train/loss': 0.5302925109863281, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 57179.19600915909, 'total_duration': 61056.417915821075, 'accumulated_submission_time': 57179.19600915909, 'accumulated_eval_time': 3867.55224609375, 'accumulated_logging_time': 4.492250204086304, 'global_step': 146140, 'preemption_count': 0}), (147215, {'train/accuracy': 0.8565233945846558, 'train/loss': 0.545202910900116, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 57599.22167015076, 'total_duration': 61504.795778512955, 'accumulated_submission_time': 57599.22167015076, 'accumulated_eval_time': 3895.833779335022, 'accumulated_logging_time': 4.525409460067749, 'global_step': 147215, 'preemption_count': 0}), (148290, {'train/accuracy': 0.862109363079071, 'train/loss': 0.5288084149360657, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58019.24427700043, 'total_duration': 61953.191044807434, 'accumulated_submission_time': 58019.24427700043, 'accumulated_eval_time': 3924.1314907073975, 'accumulated_logging_time': 4.562593698501587, 'global_step': 148290, 'preemption_count': 0}), (149365, {'train/accuracy': 0.8610156178474426, 'train/loss': 0.5339493155479431, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58439.35965394974, 'total_duration': 62401.6829867363, 'accumulated_submission_time': 58439.35965394974, 'accumulated_eval_time': 3952.4334218502045, 'accumulated_logging_time': 4.598416090011597, 'global_step': 149365, 'preemption_count': 0}), (150440, {'train/accuracy': 0.8587109446525574, 'train/loss': 0.532126784324646, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 58859.34544801712, 'total_duration': 62849.93879723549, 'accumulated_submission_time': 58859.34544801712, 'accumulated_eval_time': 3980.6284940242767, 'accumulated_logging_time': 4.635632276535034, 'global_step': 150440, 'preemption_count': 0}), (151515, {'train/accuracy': 0.8600780963897705, 'train/loss': 0.5306380987167358, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 59279.38299250603, 'total_duration': 63298.283148765564, 'accumulated_submission_time': 59279.38299250603, 'accumulated_eval_time': 4008.853268623352, 'accumulated_logging_time': 4.680060625076294, 'global_step': 151515, 'preemption_count': 0}), (152590, {'train/accuracy': 0.8576562404632568, 'train/loss': 0.5374278426170349, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 59699.35824298859, 'total_duration': 63746.52398490906, 'accumulated_submission_time': 59699.35824298859, 'accumulated_eval_time': 4037.0457701683044, 'accumulated_logging_time': 4.714730501174927, 'global_step': 152590, 'preemption_count': 0}), (153665, {'train/accuracy': 0.8606249690055847, 'train/loss': 0.5324718952178955, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60119.36347913742, 'total_duration': 64194.829061985016, 'accumulated_submission_time': 60119.36347913742, 'accumulated_eval_time': 4065.270265340805, 'accumulated_logging_time': 4.751112937927246, 'global_step': 153665, 'preemption_count': 0}), (154740, {'train/accuracy': 0.8607226610183716, 'train/loss': 0.5319047570228577, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60539.47020316124, 'total_duration': 64643.465767383575, 'accumulated_submission_time': 60539.47020316124, 'accumulated_eval_time': 4093.7261395454407, 'accumulated_logging_time': 4.787616491317749, 'global_step': 154740, 'preemption_count': 0}), (155815, {'train/accuracy': 0.8604296445846558, 'train/loss': 0.5312694907188416, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 60959.57297253609, 'total_duration': 65091.87886476517, 'accumulated_submission_time': 60959.57297253609, 'accumulated_eval_time': 4121.9601809978485, 'accumulated_logging_time': 4.826525688171387, 'global_step': 155815, 'preemption_count': 0}), (156890, {'train/accuracy': 0.86195307970047, 'train/loss': 0.526210606098175, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 61379.602830171585, 'total_duration': 65540.20942354202, 'accumulated_submission_time': 61379.602830171585, 'accumulated_eval_time': 4150.187627077103, 'accumulated_logging_time': 4.86150860786438, 'global_step': 156890, 'preemption_count': 0}), (157965, {'train/accuracy': 0.8607031106948853, 'train/loss': 0.5282706022262573, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 61799.73689651489, 'total_duration': 65988.69274020195, 'accumulated_submission_time': 61799.73689651489, 'accumulated_eval_time': 4178.45863032341, 'accumulated_logging_time': 4.902294874191284, 'global_step': 157965, 'preemption_count': 0}), (159040, {'train/accuracy': 0.8620898127555847, 'train/loss': 0.5255037546157837, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 62219.72119474411, 'total_duration': 66437.01294565201, 'accumulated_submission_time': 62219.72119474411, 'accumulated_eval_time': 4206.717297077179, 'accumulated_logging_time': 4.941739559173584, 'global_step': 159040, 'preemption_count': 0}), (160115, {'train/accuracy': 0.8607421517372131, 'train/loss': 0.5275111794471741, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 62639.89541435242, 'total_duration': 66885.42871928215, 'accumulated_submission_time': 62639.89541435242, 'accumulated_eval_time': 4234.88491153717, 'accumulated_logging_time': 4.978753328323364, 'global_step': 160115, 'preemption_count': 0}), (161190, {'train/accuracy': 0.8590429425239563, 'train/loss': 0.5375748872756958, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63059.86722278595, 'total_duration': 67333.69714355469, 'accumulated_submission_time': 63059.86722278595, 'accumulated_eval_time': 4263.107853651047, 'accumulated_logging_time': 5.014766693115234, 'global_step': 161190, 'preemption_count': 0}), (162265, {'train/accuracy': 0.8607226610183716, 'train/loss': 0.5323317050933838, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63479.968104839325, 'total_duration': 67782.13503861427, 'accumulated_submission_time': 63479.968104839325, 'accumulated_eval_time': 4291.370937347412, 'accumulated_logging_time': 5.048900127410889, 'global_step': 162265, 'preemption_count': 0}), (163340, {'train/accuracy': 0.8609374761581421, 'train/loss': 0.5290597677230835, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 63900.0406870842, 'total_duration': 68230.56432247162, 'accumulated_submission_time': 63900.0406870842, 'accumulated_eval_time': 4319.654284477234, 'accumulated_logging_time': 5.083327293395996, 'global_step': 163340, 'preemption_count': 0}), (164415, {'train/accuracy': 0.8610156178474426, 'train/loss': 0.5297486186027527, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 64320.02638053894, 'total_duration': 68678.8488342762, 'accumulated_submission_time': 64320.02638053894, 'accumulated_eval_time': 4347.875331878662, 'accumulated_logging_time': 5.123032093048096, 'global_step': 164415, 'preemption_count': 0}), (165490, {'train/accuracy': 0.85755854845047, 'train/loss': 0.5375651717185974, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 64740.12442159653, 'total_duration': 69127.4820907116, 'accumulated_submission_time': 64740.12442159653, 'accumulated_eval_time': 4376.336975336075, 'accumulated_logging_time': 5.159077405929565, 'global_step': 165490, 'preemption_count': 0}), (166565, {'train/accuracy': 0.86048823595047, 'train/loss': 0.5354260206222534, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 65160.201233148575, 'total_duration': 69580.16062664986, 'accumulated_submission_time': 65160.201233148575, 'accumulated_eval_time': 4408.857195138931, 'accumulated_logging_time': 5.202617168426514, 'global_step': 166565, 'preemption_count': 0}), (167640, {'train/accuracy': 0.8597851395606995, 'train/loss': 0.5338920950889587, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 65580.1396882534, 'total_duration': 70028.45423436165, 'accumulated_submission_time': 65580.1396882534, 'accumulated_eval_time': 4437.141412734985, 'accumulated_logging_time': 5.236555576324463, 'global_step': 167640, 'preemption_count': 0}), (168715, {'train/accuracy': 0.8594530820846558, 'train/loss': 0.5353440642356873, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66000.19507908821, 'total_duration': 70476.7657456398, 'accumulated_submission_time': 66000.19507908821, 'accumulated_eval_time': 4465.323743104935, 'accumulated_logging_time': 5.2727274894714355, 'global_step': 168715, 'preemption_count': 0}), (169790, {'train/accuracy': 0.8575195074081421, 'train/loss': 0.5377094149589539, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66420.2550098896, 'total_duration': 70925.0434076786, 'accumulated_submission_time': 66420.2550098896, 'accumulated_eval_time': 4493.467316865921, 'accumulated_logging_time': 5.3090949058532715, 'global_step': 169790, 'preemption_count': 0}), (170865, {'train/accuracy': 0.8602538704872131, 'train/loss': 0.5354943871498108, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 66840.29003763199, 'total_duration': 71374.17208337784, 'accumulated_submission_time': 66840.29003763199, 'accumulated_eval_time': 4522.488629102707, 'accumulated_logging_time': 5.343836307525635, 'global_step': 170865, 'preemption_count': 0}), (171940, {'train/accuracy': 0.85888671875, 'train/loss': 0.5339109897613525, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 67260.26974606514, 'total_duration': 71822.55878424644, 'accumulated_submission_time': 67260.26974606514, 'accumulated_eval_time': 4550.81867814064, 'accumulated_logging_time': 5.383878231048584, 'global_step': 171940, 'preemption_count': 0}), (173015, {'train/accuracy': 0.8616015315055847, 'train/loss': 0.5290973782539368, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 67680.34410786629, 'total_duration': 72270.89149141312, 'accumulated_submission_time': 67680.34410786629, 'accumulated_eval_time': 4579.00220656395, 'accumulated_logging_time': 5.420870304107666, 'global_step': 173015, 'preemption_count': 0}), (174090, {'train/accuracy': 0.8581640720367432, 'train/loss': 0.5384761095046997, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68100.49555897713, 'total_duration': 72719.20079088211, 'accumulated_submission_time': 68100.49555897713, 'accumulated_eval_time': 4607.083900690079, 'accumulated_logging_time': 5.459011554718018, 'global_step': 174090, 'preemption_count': 0}), (175165, {'train/accuracy': 0.8604101538658142, 'train/loss': 0.5355415940284729, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68520.54279351234, 'total_duration': 73167.64974188805, 'accumulated_submission_time': 68520.54279351234, 'accumulated_eval_time': 4635.41259765625, 'accumulated_logging_time': 5.493685960769653, 'global_step': 175165, 'preemption_count': 0}), (176240, {'train/accuracy': 0.8613476157188416, 'train/loss': 0.5301273465156555, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 68940.58148026466, 'total_duration': 73615.88048815727, 'accumulated_submission_time': 68940.58148026466, 'accumulated_eval_time': 4663.5275757312775, 'accumulated_logging_time': 5.533310174942017, 'global_step': 176240, 'preemption_count': 0}), (177315, {'train/accuracy': 0.8574804663658142, 'train/loss': 0.5385750532150269, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 69360.62168860435, 'total_duration': 74064.12375998497, 'accumulated_submission_time': 69360.62168860435, 'accumulated_eval_time': 4691.657100439072, 'accumulated_logging_time': 5.5693583488464355, 'global_step': 177315, 'preemption_count': 0}), (178390, {'train/accuracy': 0.8599413633346558, 'train/loss': 0.5288510918617249, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 69780.7575404644, 'total_duration': 74512.47424793243, 'accumulated_submission_time': 69780.7575404644, 'accumulated_eval_time': 4719.79655790329, 'accumulated_logging_time': 5.6067774295806885, 'global_step': 178390, 'preemption_count': 0}), (179465, {'train/accuracy': 0.8600585460662842, 'train/loss': 0.534307599067688, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 70200.75301504135, 'total_duration': 74960.70142841339, 'accumulated_submission_time': 70200.75301504135, 'accumulated_eval_time': 4747.950520515442, 'accumulated_logging_time': 5.647037029266357, 'global_step': 179465, 'preemption_count': 0}), (180540, {'train/accuracy': 0.8602148294448853, 'train/loss': 0.5280645489692688, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 70620.82184553146, 'total_duration': 75408.97744894028, 'accumulated_submission_time': 70620.82184553146, 'accumulated_eval_time': 4776.079607009888, 'accumulated_logging_time': 5.686467885971069, 'global_step': 180540, 'preemption_count': 0}), (181615, {'train/accuracy': 0.8608593344688416, 'train/loss': 0.5353047251701355, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71040.9156525135, 'total_duration': 75857.31313347816, 'accumulated_submission_time': 71040.9156525135, 'accumulated_eval_time': 4804.247930526733, 'accumulated_logging_time': 5.72279953956604, 'global_step': 181615, 'preemption_count': 0}), (182690, {'train/accuracy': 0.8613085746765137, 'train/loss': 0.5287285447120667, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71460.94657707214, 'total_duration': 76305.62181925774, 'accumulated_submission_time': 71460.94657707214, 'accumulated_eval_time': 4832.452265024185, 'accumulated_logging_time': 5.7577900886535645, 'global_step': 182690, 'preemption_count': 0}), (183765, {'train/accuracy': 0.8620507717132568, 'train/loss': 0.5245758891105652, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 71880.94136238098, 'total_duration': 76753.91370868683, 'accumulated_submission_time': 71880.94136238098, 'accumulated_eval_time': 4860.673353433609, 'accumulated_logging_time': 5.795462369918823, 'global_step': 183765, 'preemption_count': 0}), (184840, {'train/accuracy': 0.85888671875, 'train/loss': 0.5343407392501831, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 72300.90002083778, 'total_duration': 77202.1556148529, 'accumulated_submission_time': 72300.90002083778, 'accumulated_eval_time': 4888.880987167358, 'accumulated_logging_time': 5.833362817764282, 'global_step': 184840, 'preemption_count': 0}), (185915, {'train/accuracy': 0.8598241806030273, 'train/loss': 0.5328004956245422, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 72720.95833444595, 'total_duration': 77650.56750535965, 'accumulated_submission_time': 72720.95833444595, 'accumulated_eval_time': 4917.157248735428, 'accumulated_logging_time': 5.871784448623657, 'global_step': 185915, 'preemption_count': 0}), (186666, {'train/accuracy': 0.8631835579872131, 'train/loss': 0.5244746208190918, 'validation/accuracy': 0.7569999694824219, 'validation/loss': 0.9766362309455872, 'validation/num_examples': 50000, 'test/accuracy': 0.634600043296814, 'test/loss': 1.6043891906738281, 'test/num_examples': 10000, 'score': 73014.23394227028, 'total_duration': 77972.18837976456, 'accumulated_submission_time': 73014.23394227028, 'accumulated_eval_time': 4945.43395447731, 'accumulated_logging_time': 5.913134336471558, 'global_step': 186666, 'preemption_count': 0})], 'global_step': 186666}
I0315 23:48:44.135318 139734377899840 submission_runner.py:596] Timing: 73014.23394227028
I0315 23:48:44.135422 139734377899840 submission_runner.py:598] Total number of evals: 175
I0315 23:48:44.135471 139734377899840 submission_runner.py:599] ====================
I0315 23:48:44.135825 139734377899840 submission_runner.py:683] Final imagenet_vit_glu score: 0
